url,content,token_count,char_count,techStackName
https://kestra.io/docs/getting-started,"""""""DocsGetting Started
Getting Started
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Follow the Quickstart Guide to install Kestra and start building your first workflows.
Quickstart
Start Kestra in a Docker container and create your first flow.
Installation Guide
Install Kestra in your preferred environment.
Tutorial
Follow the tutorial to schedule and orchestrate your first workflows.
Workflow Components
Get to know the main orchestration components of a Kestra workflow.
Concepts
Learn the concepts and best practices to get the most out of Kestra.
Enterprise Edition
Explore unique features of the Enterprise Edition and Kestra Cloud.
Architecture
Dive into Kestra's architecture and learn how it differs between various editions.
Version Control & CI/CD
Develop Workflows and integrate them with Git and CI/CD.
Plugins
Browse Kestra's integrations and learn how to create your own plugins.
Administrator Guide
Deploy, configure, secure, and manage Kestra in production.
Configuration
Almost everything is configurable in Kestra. Here you'll find the different configuration options available to Administrators.
API Reference
Check the API reference for the Open-Source and Cloud & Enterprise Edition.
Migration Guide
Migrate to the latest version of Kestra.
Terraform Provider
Manage resources and their underlying infrastructure with our official Terraform provider.
User Interface
Navigate Kestra's UI.
Contributing
Contribute to our open-source community.
How-to Guides
Tutorials covering various use cases step by step.
Community Guidelines
The Kestra community is a friendly and welcoming place for everyone.
Was this page helpful?
Yes
No
Docs
Docs
Getting Started
Quickstart""""""",358,1715,kestra
https://kestra.io/docs/getting-started/quickstart,"""""""DocsGetting StartedQuickstart
Quickstart
Table of Contents
Start Kestra
Create Your First Flow
Next Steps
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Start Kestra in a Docker container and create your first flow.
Start Kestra
Prerequisites: Make sure that Docker is installed in your environment. We recommend Docker Desktop.
Make sure that Docker is running. Then, you can start Kestra in a single command using Docker (if you run it on Windows, make sure to use WSL):
bash
docker run --pull=always --rm -it -p 8080:8080 --user=root -v /var/run/docker.sock:/var/run/docker.sock -v /tmp:/tmp kestra/kestra:latest server local
Open http://localhost:8080 in your browser to launch the UI and start building your first flows.
The above command starts Kestra with an embedded H2 database that will not persist data. If you want to use a persistent database backend with Postgres and more configurability, follow the Docker Compose installation.
Create Your First Flow
Navigate to Flows in the left menu, then click the ""Create"" button and paste the following configuration to create your first flow:
yaml
id: getting_started
namespace: company.team
tasks:
  - id: hello_world
    type: io.kestra.plugin.core.log.Log
    message: Hello World!
Click on Save and then on the Execute button to start your first execution.
For a more detailed introduction to Kestra, check our Tutorial
Next Steps
Congrats! You've just installed Kestra and executed your first flow! üëè
Next, you can follow the documentation in this order:
Check out the tutorial
Get to know the building blocks of a flow
Learn the core concepts
Check out the available Plugins to integrate with external systems and start orchestrating your applications, microservices and processes
Deploy Kestra to remote development and production environments
Almost everything is configurable in Kestra. You can find the different configuration options available to Administrators in the Configuration Guide
Was this page helpful?
Yes
No
Docs
Getting Started
Getting Started
Installation Guide""""""",463,2069,kestra
https://kestra.io/docs/getting-started/installation,"""""""DocsGetting StartedInstallation Guide
Installation Guide
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Install Kestra in your preferred environment.
Docker
Start Kestra in a single Docker container.
Docker Compose
Start Kestra with a PostgreSQL database backend using a Docker Compose file.
Kubernetes
Install Kestra in a Kubernetes cluster using a Helm chart.
Kubernetes on AWS EKS with Amazon RDS and S3
Deploy Kestra to AWS EKS with PostgreSQL RDS database and S3 internal storage backend.
Kubernetes on GCP GKE with CloudSQL and Cloud Storage
Deploy Kestra to GCP GKE with CloudSQL as a database backend and Google Cloud Storage as internal storage backend.
Kubernetes on Azure AKS with Azure Database and Blob Storage
Deploy Kestra to Azure AKS with Azure Database for PostgreSQL servers as a database backend and Blob Storage as internal storage backend.
AWS EC2 with Amazon RDS and S3
Install Kestra on AWS EC2 with PostgreSQL RDS database and S3 internal storage backend.
GCP VM with Cloud SQL and GCS
Install Kestra on a GCP VM with Cloud SQL PostgreSQL database backend and Cloud Storage as internal storage backend.
Azure VM with Azure Database
Install Kestra on Azure VM with Azure Database as a database backend and Blob Storage as internal storage backend.
DigitalOcean Droplet with Managed Database
Install Kestra on DigitalOcean Droplet with DigitalOcean Database as a database backend.
Standalone Server
Install Kestra on a standalone server with a simple executable file.
Podman Compose
Start Kestra with a PostgreSQL database backend using Podman Compose.
Kestra Cloud (Alpha)
Sign up for a free Kestra Cloud account to get started.
Was this page helpful?
Yes
No
Getting Started
Quickstart
Getting Started
Tutorial""""""",396,1762,kestra
https://kestra.io/docs/getting-started/tutorial,"""""""DocsGetting StartedTutorial
Tutorial
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Follow the tutorial to schedule and orchestrate your first workflows.
Kestra is an open-source orchestrator designed to bring Infrastructure as Code (IaC) best practices to all workflows ‚Äî from those orchestrating mission-critical applications, IT operations, business processes, and data pipelines, to simple Zapier-style automations.
You can use Kestra to:
run workflows on-demand, event-driven or based on a regular schedule
programmatically interact with any system or programming language
orchestrate microservices, batch jobs, ad-hoc scripts (written in Python, R, Julia, Node.js, and more), SQL queries, data ingestion syncs, dbt or Spark jobs, or any other applications or processes
This tutorial will guide you through key concepts in Kestra. We'll build upon the ""Hello world"" flow from the Quickstart, and we'll gradually introduce new concepts including namespaces, tasks, parametrization with inputs and scheduling using triggers.
We'll then dive into parallel task execution, error handling, as well as custom scripts and microservices running in isolated containers. Let's get started!
Fundamentals
Start by building a ""Hello world"" example.
Inputs
Inputs allow you to make your flows more dynamic and reusable.
Outputs
Outputs allow you to pass data between tasks and flows.
Triggers
Triggers automatically start your flow based on events.
Flowable Tasks
Run tasks or subflows in parallel, create loops and conditional branching.
Errors and Retries
Handle errors with automatic retries and notifications.
Docker
Run custom Python, R, Julia, Node.js and Shell scripts in isolated containers.
Was this page helpful?
Yes
No
Getting Started
Installation Guide
Getting Started
Workflow Components""""""",378,1819,kestra
https://kestra.io/docs/getting-started/workflow-components,"""""""DocsGetting StartedWorkflow Components
Workflow Components
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Get to know the main orchestration components of a Kestra workflow.
Flow
Flow is a container for tasks and their orchestration logic.
Tasks
Tasks are the steps within a flow.
Namespace
Namespace is a logical grouping of flows.
Execution
Execute your flows and view the outcome.
Variables
Variables are key-value pairs that help reuse some values across tasks.
Inputs
Inputs is a list of dynamic values passed to the flow at runtime.
Outputs
Outputs allow you to pass data between tasks and flows.
Triggers
Trigger is a mechanism that automates the execution of a flow.
Labels
Labels are key-value pairs used to organize flows and executions.
Plugin Defaults
Plugin defaults are a list of default values applied to each task of a certain type within your flow(s).
Subflows
Subflows allow you to build modular and reusable workflow components.
Errors
Allow your flow to continue to operate despite errors.
Retries
Retries handle transient failures in your workflows.
Timeout
Timeout allows you to set a maximum duration for a task run.
Concurrency limits
Control concurrent executions of a given flow.
Descriptions
You can document your flows, inputs, outputs, tasks and triggers by adding a description property.
Disabled flag
The disabled flag is a boolean property that allows you to skip a flow, task or trigger.
States
States control the status of your workflow execution.
Was this page helpful?
Yes
No
Getting Started
Tutorial
Getting Started
Concepts""""""",324,1589,kestra
https://kestra.io/docs/getting-started/concepts,"""""""DocsGetting StartedConcepts
Concepts
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Learn the concepts and best practices to get the most out of Kestra.
Namespace Files
Manage Namespace Files and how to use them in your flows.
Revision
Manage versions of flows.
Secret
Store sensitive information securely.
Key Value (KV) Store
Build stateful workflows with the KV Store.
Pebble Templating Engine
Dynamically render variables, inputs and outputs.
Blueprints
Ready-to-use examples designed to kickstart your workflow.
Backfill
Backfills are replays of missed schedule intervals between a defined start and end date.
Replay
Replay allows you to re-run a workflow execution from any chosen task run.
Data storage and processing
Manage data processed by tasks.
Caching
Manage file caching inside of Kestra.
System Flows
Automate maintenance workflows with System Flows.
Was this page helpful?
Yes
No
Getting Started
Workflow Components
Getting Started
Enterprise Edition""""""",216,994,kestra
https://kestra.io/docs/getting-started/enterprise,"""""""DocsGetting StartedEnterprise Edition
Enterprise Edition
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Explore unique features of the Enterprise Edition and Kestra Cloud.
Enterprise Edition (EE)
Learn about the Enterprise Edition and how it can help you run Kestra securely and reliably at scale.
Setup
How to setup Kestra Enterprise Edition.
Tenants
How to enable multi-tenancy in your Kestra instance.
Authentication
How to configure the authentication for your Kestra instance.
Single Sign-On (SSO)
How to enable and setup SSO in your Kestra Enterprise instance.
Audit Logs
How to use Audit Logs to govern activities in your Kestra instance.
Namespace Management
How to govern secrets, variables and plugin defaults on a namespace level.
Centralized Task Configuration
How to centrally govern your task configuration in a modular way.
Allowed namespaces
How to manage cross-namespace permissions in the Enterprise Edition.
Kestra EE API
How to interact with Kestra Enterprise Edition using the API.
API Tokens
How to manage API tokens in Kestra.
Kestra EE CLI
How to interact with Kestra Enterprise Edition using the CLI.
Custom Blueprints
How to create and manage Custom Blueprints.
Enterprise Edition FAQ
Frequently asked questions about the Enterprise Edition of Kestra.
Kestra Identity
Common questions about the identity.
Role-Based Access Control (RBAC)
How to manage access and permissions to your instance.
Releases
Release cadence and support policy for Kestra Enterprise Edition (EE).
SCIM Directory Sync
Sync users and groups from your Identity Provider to Kestra using SCIM.
Secrets
How to create and manage Secrets in the Enterprise Edition.
Secrets Manager
How to configure the secrets manager.
Service Accounts
How to create and manage Service Accounts.
Task Runners
Task Runner capabilities and supported plugins.
Worker Group
How to configure Worker Groups in Kestra Enterprise Edition.
Worker Isolation
How to configure worker isolation in Kestra.
Was this page helpful?
Yes
No
Getting Started
Concepts
Getting Started
Architecture""""""",443,2081,kestra
https://kestra.io/docs/getting-started/architecture,"""""""DocsGetting StartedArchitecture
Architecture
Table of Contents
Choosing the right architecture for your needs
Architecture with JDBC backend
Scalability with JDBC
Architecture with Kafka and Elasticsearch backend
Scalability with Kafka and Elasticsearch
Comparison between JDBC and Kafka architectures
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Dive into Kestra's architecture and learn how it differs between various editions.
Choosing the right architecture for your needs
Kestra's architecture is designed to be scalable, flexible and fault-tolerant. Depending on your needs, you can choose between two different architectures: JDBC and Kafka.
Architecture with JDBC backend
The following diagram shows the main components of Kestra using the JDBC backend.
Here are the components and their interactions:
JDBC Backend: this is the data storage layer used for orchestration metadata.
Server: this is the central part of the system, composed of:
Webserver: this components is serving both an API and a User Interface.
Scheduler: an essential part of the system that schedules workflows and handles all triggers except for the flow triggers (see below).
Executor: another critical component responsible for the orchestration logic including flow triggers.
Worker: this might be one or multiple processes that carry out the heavy computation of runnable tasks and polling triggers. For privacy reasons, workers are the only components that interact with the user's infrastructure, including the internal storage and external services.
User: interacts with the system via UI and API.
User‚Äôs Infrastructure: private infrastructure components that are part of the user‚Äôs environment, which Kestra interacts with:
Internal Storage: can be any cloud storage system within the user's infrastructure (e.g. AWS S3, Google Cloud Storage, or Azure Blob Storage).
External Services: third-party APIs or services outside of Kestra which Workers might interact with to process data within a given task.
The arrows indicate the direction of communication. The JDBC Backend connects to the Server, which in turn interacts with the User's Infrastructure. The User interacts with the system through the API and UI.
Scalability with JDBC
The scalable design of the architecture allows you to run multiple instances of the Webserver, Executor, Worker and Scheduler to handle increased load. As your workload increases, more instances of the required components can be added to the system to distribute the load and maintain performance.
The JDBC Backend can be scaled too, either through clustering or sharding, to handle larger volumes of data and a higher number of requests from the Server components. Most cloud providers offer managed database services that can be scaled up and down as needed.
Architecture with Kafka and Elasticsearch backend
The following diagram shows the main components of Kestra using the Kafka and Elasticsearch backend.
Note that this architecture is only available in the Enterprise Edition of Kestra.
This architecture is designed to provide enhanced scalability, high availability, and fault tolerance, required to meet the needs of large-scale enterprise deployments.
Kafka: this component serves as the messaging backend, which communicates between different components of the system and allows for robust scalability and fault tolerance.
Microservices: This layer includes several services:
Webserver: serves the API and User Interface for interaction with the system.
Scheduler: schedules workflows and processes all triggers except for the flow triggers.
Executor: handles the orchestration logic, including flow triggers.
Indexer: indexes data from Kafka to Elasticsearch for quick retrieval and search.
Worker: runs tasks and interacts with the user's infrastructure.
User: engages with the system through the Webserver's API and UI.
Elasticsearch: acts as a search and UI backend, storing logs, execution history, and enabling fast data retrieval.
User‚Äôs Infrastructure: private infrastructure components that are part of the user‚Äôs environment, which Kestra interacts with:
Internal Storage: Cloud storage services where user's data is stored (e.g. AWS S3, Google Cloud Storage, or Azure Blob Storage).
External Services: APIs or services that Workers might interact with during task processing.
Scalability with Kafka and Elasticsearch
Kafka's messaging backend allows handling large volumes of data with the ability to scale out as needed. You can run multiple (horizontally scaled) instances of services such as Workers, Schedulers, Webservers and Executors to distribute load and maintain system performance as demand increases. Elasticsearch contributes to scalability by providing a robust, horizontally scalable UI backend that can efficiently search across large amounts of data.
Comparison between JDBC and Kafka architectures
When comparing both diagrams, the main difference between the architecture of the JDBC and an Kafka architectures is the data layer (JDBC Database vs. Kafka and Elasticsearch).
Note that it's possible to use the Enterprise Edition with a JDBC database backend for smaller deployments. In fact, it's often easier to start with a JDBC backend and migrate to Kafka and Elasticsearch when your deployment grows.
The Worker is the only component communicating with your private data sources to extract and transform data. The Worker also interacts with Internal Storage to persist intermediary results and store the final task run outputs.
All components of the application layer (including the Worker, Executor, and Scheduler) are decoupled and stateless, communicating with each other through the Queue (Kafka/JDBC). You can deploy and scale them independently. When using Kafka and Elasticsearch, you can scale the replica count for the Scheduler as well, making the component highly available.
The Webserver communicates with the (Elasticsearch/JDBC) Repository to serve data for Kestra UI and API.
The data layer is decoupled from the application layer and provides a separation between:
storing your private data processing artifacts ‚Äî Internal Storage is used to store outputs of your executions; you can think of Internal Storage as your own private S3 bucket
storing execution metadata ‚Äî (Kafka/JDBC) Queue is used as the orchestration backend
storing logs and user-facing data ‚Äî the (Elasticsearch/JDBC) Repository is used to store data needed to serve Kestra UI and API.
The Indexer, available only in the Enterprise Edition, indexes content from Kafka topics (such as the flows and executions topics) to the Elasticsearch repositories. Thanks to the separation between Queue and Repository in the Kafka Architecture, even if your Elasticsearch instance experiences downtime, your executions will continue to work by relying on the Kafka backend.
Main components
Technical description of Kestra's main components, including the internal storage, queue, repository, and plugins.
Server components
Detailed breakdown of the server components behind Kestra.
Deployment Architecture
Examples of deployment architectures, depending on your needs.
Executor
The Executor processes all executions and Flowable tasks.
Worker
The Worker is a server component that processes all runnable tasks and polling triggers.
Scheduler
The Scheduler is a server component responsible for processing all triggers except for the Flow Triggers (managed by the executor).
Indexer
Indexer is an optional component only needed when using Kafka and Elasticsearch.
Webserver
The Webserver serves the APIs and the User Interface (UI).
Internal Storage
Internal Storage is a dedicated storage area to store arbitrary-sized files used during executions.
Multi-tenancy
Multi-tenancy allows you to manage multiple environments (e.g., dev, staging, prod) in a single Kestra instance.
Was this page helpful?
Yes
No
Getting Started
Enterprise Edition
Getting Started
Version Control & CI/CD""""""",1487,7950,kestra
https://kestra.io/docs/getting-started/version-control-cicd,"""""""DocsGetting StartedVersion Control & CI/CD
Version Control & CI/CD
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Develop Workflows and integrate them with Git and CI/CD.
Version Control with Git
Setup Version Control with Git to store your flows and namespace files.
CI/CD Pipeline
Kestra provides several ways to create a CI/CD pipeline for your flows.
Was this page helpful?
Yes
No
Getting Started
Architecture
Getting Started
Plugins""""""",108,465,kestra
https://kestra.io/docs/getting-started/plugins,"""""""DocsGetting StartedPlugins
Plugins
Table of Contents
The purpose of plugins
Custom Plugins
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Browse Kestra's integrations and learn how to create your own plugins.
The purpose of plugins
Plugins are the building blocks of Kestra's tasks and triggers. They encompass components interacting with external systems and performing the actual work in your flows.
Kestra comes prepackaged with hundreds of plugins, and you can also develop your own custom plugins.
Custom Plugins
To integrate with your internal systems and processes, you can build custom plugins. If you think it could be useful to others, consider contributing your plugin to our open-source community. Check out more on in Plugins Developer Guide.
Was this page helpful?
Yes
No
Getting Started
Version Control & CI/CD
Getting Started
Administrator Guide""""""",183,889,kestra
https://kestra.io/docs/getting-started/administrator-guide,"""""""DocsGetting StartedAdministrator Guide
Administrator Guide
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Deploy, configure, secure, and manage Kestra in production.
Here, you will find the necessary information for deploying and configuring your Kestra cluster.
Software and Hardware Requirements
This page describes the software and hardware requirements for Kestra.
Alerting & Monitoring
Here are some best practices for alerting and monitoring your Kestra instance.
Troubleshooting
Something doesn't work as expected? Check out our advice to help you troubleshoot.
Backup & Restore
Backup Kestra.
High Availability
Kestra is designed to be highly available and fault-tolerant. This section describes how to configure Kestra for high availability.
Purge
Purge old executions and logs to save disk space.
Managing Upgrades
Kestra is a fast-evolving project. This section will guide you through the process of upgrading your Kestra installation.
Usage
Here are the configuration options for the usage report.
Webserver URL
How to configure the URL of your Kestra webserver.
Was this page helpful?
Yes
No
Getting Started
Plugins
Getting Started
Configuration""""""",252,1186,kestra
https://kestra.io/docs/getting-started/configuration-guide,"""""""DocsGetting StartedConfiguration
Configuration
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Almost everything is configurable in Kestra. Here you'll find the different configuration options available to Administrators.
Was this page helpful?
Yes
No
Getting Started
Administrator Guide
Getting Started
API Reference""""""",69,344,kestra
https://kestra.io/docs/getting-started/api-reference,"""""""DocsGetting StartedAPI Reference
API Reference
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Check the API reference for the Open-Source and Cloud & Enterprise Edition.
Cloud & Enterprise Edition API
API Reference of Kestra Cloud & Enterprise.
Open Source API
API Reference of the Open-Source edition of Kestra.
Was this page helpful?
Yes
No
Getting Started
Configuration
Getting Started
Migration Guide""""""",96,432,kestra
https://kestra.io/docs/getting-started/migration-guide,"""""""DocsGetting StartedMigration Guide
Migration Guide
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Migrate to the latest version of Kestra.
0.11.0
Deprecated features and migration guides for 0.11.0 and onwards.
0.12.0
Deprecated features and migration guides for 0.12.0 and onwards.
0.13.0
Deprecated features and migration guides for 0.13.0 and onwards.
0.14.0
Deprecated features and migration guides for 0.14.0 and onwards.
0.15.0
Deprecated features and migration guides for 0.15.0 and onwards.
0.17.0
Deprecated features and migration guides for 0.17.0 and onwards.
0.18.0
Deprecated features and migration guides for 0.18.0 and onwards.
0.19.0
Deprecated features and migration guides for 0.19.0 and onwards.
Was this page helpful?
Yes
No
Getting Started
API Reference
Getting Started
Terraform Provider""""""",230,837,kestra
https://kestra.io/docs/getting-started/terraform,"""""""DocsGetting StartedTerraform Provider
Terraform Provider
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage resources and their underlying infrastructure with our official Terraform provider.
Data Sources
Guides
Resources
Was this page helpful?
Yes
No
Getting Started
Migration Guide
Getting Started
User Interface""""""",74,345,kestra
https://kestra.io/docs/getting-started/ui,"""""""DocsGetting StartedUser Interface
User Interface
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Navigate Kestra's UI.
Dashboard
Get insights into your workflows with the Dashboard.
Flows
Manage your flows in one place.
Executions
Manage Executions of your Flows in one place.
Logs
Manage Logs generated by tasks.
Namespaces
Manage resources associated with a namespace in one place.
Blueprints
Ready-to-use examples designed to kickstart your workflow.
Settings
Configure Settings for Kestra.
Administration
Manage your Kestra Instance.
Task Runs
Manage Task Runs in one place.
Was this page helpful?
Yes
No
Getting Started
Terraform Provider
Getting Started
Contributing""""""",156,699,kestra
https://kestra.io/docs/getting-started/contributing,"""""""DocsGetting StartedContributing
Contributing
Table of Contents
Build a plugin
Contribute to the documentation
Documentation structure
Build the documentation locally
Write a blog post
Other ways to show support
Build Kestra locally
Requirements
Backend development
Frontend development
Setup the configuration to connect to the backend
Setup to work without building the backend from the source code
Plugin development
Code of Conduct
Legal Notice
Submit issues
Reporting bugs
Reporting security issues
Requesting new features
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Contribute to our open-source community.
You can contribute to Kestra in many ways depending on your skills and interests. The issues with the label good first issue are a great place to start and get familiar with the codebase. Follow this link to see good first issues.
Build a plugin
Check out our Plugin Developer Guide for instructions on how to build a new plugin.
Contribute to the documentation
We love documentation contributions. To contribute to the documentation, make sure to fork the docs repository and create a pull request with your changes.
Documentation structure
If your changes relate to a specific Kestra edition or are valid only since a specific release, you can add the following fields to the front matter of your markdown file:
markdown
---
title: My new page for a +0.18.0 feature
editions: [""OSS"", ""EE""]
version: "">= 0.18.0""
---
Build the documentation locally
The following dependencies are required to build Kestra docs locally:
Node 14+ and npm
an IDE
To start contributing:
Fork the repository
Clone the fork on your workstation:
shell
$ git clone git@github.com:{YOUR_USERNAME}/docs.git
$ cd docs
Use the following commands to serve the docs locally:
shell
# install dependencies
$ npm install
# serve with hot reload at localhost:3001
$ npm run dev
# to generate static pages
$ npm run generate
# making a production build
$ npm run build
Write a blog post
You can contribute an article about how you use Kestra to our blog. Email hello@kestra.io to start the collaboration. And if you wrote a post mentioning Kestra on your personal blog, we'd be happy to feature it in our community section.
Other ways to show support
Star Kestra on GitHub.
Follow us on X and LinkedIn.
Join the Slack community.
Build Kestra locally
Requirements
The following dependencies are required to build Kestra locally:
Java 21+
Node 14+ and npm
Docker & Docker Compose
an IDE (Intellij IDEA, Eclipse or VS Code)
To start contributing:
Fork the repository
Clone the fork on your workstation:
shell
$ git clone git@github.com:{YOUR_USERNAME}/kestra.git
$ cd kestra
Backend development
The backend is built using Micronaut.
Open the cloned repository in your favorite IDE. In many IDEs, Gradle build will be detected and all dependencies will be downloaded.
You can also build it from a terminal using ./gradlew build, the Gradle wrapper will download the right Gradle version to use.
You may need to enable Java annotation processors since we are using it a lot.
The main class is io.kestra.cli.App from module kestra.cli.main
Pass as program arguments the server you want to develop, for example server standalone will start a standalone Kestra server.
The Intellij Idea configuration can be found in screenshot below:
MICRONAUT_ENVIRONMENTS: can be set any string and will load a custom configuration file in cli/src/main/resources/application-{env}.yml.
KESTRA_PLUGINS_PATH: is the path where you will save plugins as Jar and will be loaded during the startup process.
If you encounter JavaScript memory heap out error during startup, configure NODE_OPTIONS environment variable with some large value.
Example NODE_OPTIONS: --max-old-space-size=4096 or NODE_OPTIONS: --max-old-space-size=8192
You can also use the gradle task ./gradlew runStandalone that will run a standalone server with MICRONAUT_ENVIRONMENTS=override and plugins path local/plugins
The server start by default on port 8080 and is reachable on http://localhost:8080.
If you want to launch all tests, you need Python and some packages installed on your machine. On Ubuntu, you can install them with the following command:
shell
$ sudo apt install python3 pip python3-venv
$ python3 -m pip install virtualenv
Frontend development
Our front-end uses Vue.js with the version 18.18.0. The code is located in the /ui folder.
shell
$ npm install
Setup the configuration to connect to the backend
Create a file ui/.env.development.local with the content VITE_APP_API_URL=http://localhost:8080 (or your actual server URL).
Install the dependencies with npm install.
You can serve the UI with hot reload at http://localhost:5173 using the command: npm run dev. For a production build, use: npm run build.
To avoid CORS restrictions when using the local development npm server, you need to configure the backend to allow the http://localhost:5173 origin in cli/src/main/resources/application-override.yml using the following addition to your Kestra configuration YAML definition:
yaml
micronaut:
  server:
    cors:
      enabled: true
      configurations:
        all:
          allowedOrigins:
            - http://localhost:5173
Setup to work without building the backend from the source code
If you want to work on the frontend without having to install Java and everything to run the Kestra Application, you may only start a Kestra Docker container and connect the frontend to it.
To do so, you can first use the following docker compose file.
Save it as docker-compose.yml and run the following command:
shell
$ docker-compose up
This will start Kestra running with H2 as the database. In the above docker compose, we redirected the port 8080 to 8085 and 8081 to 8086. You can change it to any port you want.
Then, enter in the /ui folder, create a file ui/.env.development.local with the content VITE_APP_API_URL=http://localhost:8085 (if you did not use 8085 as the port for Kestra, remember to also change it here).
Finally, you can install the dependencies with npm install and serve the UI with hot reload at http://localhost:5173 using the command: npm run dev.
Plugin development
A documentation for developing a plugin can be found in the Plugin Documentation.
Code of Conduct
This project and everyone participating in it is governed by the
Kestra Code of Conduct.
By participating, you are expected to uphold this code. Please report unacceptable behavior to hello@kestra.io.
Legal Notice
When contributing to this project, you must agree that you have authored 100% of the content, that you have the necessary rights to the content and that the content you contribute may be provided under the project license.
Submit issues
To submit feature requests or report bugs, please open an issue on GitHub.
Reporting bugs
Bug reports help us make Kestra better for everyone. We provide a preconfigured template for bugs to make it very clear what information we need.
Please search within our already reported bugs before raising a new one to make sure you're not raising a duplicate.
Reporting security issues
Please do not create a public GitHub issue. If you've found a security issue, please email us directly at hello@kestra.io instead of raising an issue.
Requesting new features
Use our issue templates when opening new issues. It contains a few essential questions that help us understand the problem you are looking to solve.
To see what has already been proposed by the community, you can look here.
Was this page helpful?
Yes
No
Getting Started
User Interface
Getting Started
How-to Guides""""""",1667,7586,kestra
https://kestra.io/docs/getting-started/how-to-guides,"""""""DocsGetting StartedHow-to Guides
How-to Guides
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Tutorials covering various use cases step by step.
Access Local Files in Kestra
Access locally stored files on your machine.
Configure Alerts inside of Kestra
Configure alerts when workflow failures occurs.
Extend Kestra with the API
Extend Kestra by using the API.
Use Azure Managed Workload on Kestra
How to use Azure Workload identity to provide access to resources such as Azure Key Vault in Kestra
Conditional Branching
How to use the Switch task to branch the flow based on a value.
Build a Custom Plugin for Kestra
Build your own Custom Plugin for Kestra.
Using Dataform in Kestra
Run transformations on BigQuery using Dataform in Kestra
Manage dbt projects with Kestra's Code Editor
Edit dbt code from Kestra's Code Editor
Debezium Tasks and Triggers
How to enable databases to leverage Debezium tasks and triggers.
ETL Pipelines in Kestra
Build ETL pipelines in Kestra using DuckDB, Python and Task Runners.
Validate and Deploy your Flows with GitHub Actions
How to use GitHub Actions to automatically validate and deploy your flows to Kestra.
Run Go inside of your Flows
Run Go code directly inside of your Flows and generate outputs.
Configure Google Service Account
Setup a Google Service Account inside of Kestra.
Connect Google Sheets to Kestra
Learn step-by-step how to read data from a Google Sheet inside of a Kestra flow.
Make HTTP Requests inside of your flows
Make HTTP Requests to fetch data and generate outputs.
Pass Inputs via an API call
Passing Inputs via an API Call
Validate Inputs with Enum Data Type
Input validation with the Enum data type
Run JavaScript inside of your Flows
Run Node.js code directly inside of your Flows and generate outputs.
Connect JavaScript Apps to Kestra
Integrate Kestra into your JavaScript App using Webhooks.
Run Julia inside of your Flows
Run Julia code directly inside of your Flows and generate outputs.
Configure KeyCloak SSO in Kestra
Setup KeyCloak SSO to manage authentication for users.
Set Up Secrets from a Helm Chart
How to add Kestra Secrets to your Helm Chart deployment.
Long running and intensive processes on Kubernetes
Schedule long running and intensive processes with Kestra on Kubernetes.
Loop Over a List of Values
How to iterate over a list of values in your flow.
Configure Monitoring with Grafana & Prometheus
Set up Prometheus and Grafana for monitoring Kestra.
Multiple Condition Listener
How to set up a Flow to only trigger when multiple conditions are met.
Handling null and undefined values
How to use the null coalescing operator to handle null and undefined values.
Parallel vs. Sequential Tasks
When to use parallel tasks and when to use sequential tasks in Kestra.
Pause and Resume Flows in Kestra
How to Pause and Resume your flows.
Run Perl inside of your Flows
Run Perl code directly inside of your Flows and generate outputs.
Run Powershell inside of your Flows
Run PowerShell code inside of your flow.
Push Flows to a Git Repository
Push your Flows to a Git Repository with the PushFlows Task.
Push Namespace Files to a Git Repository
Push files in your namespace to a Git Repository with the PushNamespaceFiles Task.
Run Python inside of your Flows
Run Python code directly inside of your Flows and generate outputs.
Manage Python Dependencies
Manage your Python dependencies inside of Kestra.
Run R inside of your Flows
Run R code directly inside of your Flows and generate outputs.
Realtime Triggers
How to React to events as they happen with millisecond latency.
Revision History & Rollback
Use revision history to rollback to an older version of a flow.
Run Ruby inside of your Flow
Run Ruby code directly inside of your Flows and generate outputs.
Run Rust inside of your Flows
Run Rust code directly inside of your Flows and generate outputs.
Configure Secrets
How you can use secrets in various Kestra use cases.
Run Shell scripts inside of your Flows
Run Shell scripts directly inside of your Flows and generate outputs.
Migrate from Shipyard
Migrate from Shipyard to Kestra.
Slack Events API
Trigger Kestra flows based on Slack events.
Using SQLMesh to run dbt Projects
Using SQLMesh to run dbt project with Kestra.
Configure SSL for Kestra
Configure secure access via https to the Kestra UI.
Sync Flows from a Git Repository
Sync flows from a Git Repository to Kestra with the SyncFlows Task.
Synchronous Executions API
Manage the Executions API Synchronously.
Sync Namespace Files from a Git Repository
Sync files from a Git Repository to Kestra with SyncNamespaceFiles Task.
Modularize your triggers and schedules with Terraform
Scale your codebase using Terraform to template and make scheduling a breeze
Leverage Terraform for flow modularity
Scale your codebase using Terraform to template and define flows
Access Values Between Flows
How to access values across different flows.
Setup Webhooks to trigger Flows
Execute flows using the Webhooks Trigger.
Was this page helpful?
Yes
No
Getting Started
Contributing
Getting Started
Community Guidelines""""""",1133,5085,kestra
https://kestra.io/docs/getting-started/community-guidelines,"""""""DocsGetting StartedCommunity Guidelines
Community Guidelines
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
The Kestra community is a friendly and welcoming place for everyone.
Be respectful to the Kestra community
Be respectful towards other members of this Slack Community. Do not harass others.
Assume positive intent.
Make it easy to help you
Please share relevant flows(YAML), logs and stack traces formatted in code blocks (no screenshots, please).
Please share how you have deployed Kestra:
Deployment choice (Standalone, Docker, Kubernetes etc).
The version of Kestra.
Your OS and its version.
Use relevant channels
Refrain from asking questions multiple times across different channels.
Don‚Äôt spam ‚Äî While we‚Äôll do our best to help you, there is no guaranteed timeline to answer your question. If you need support with SLA guarantees, reach out to us.
If you have any questions, don't hesitate to ask us on Slack
Was this page helpful?
Yes
No
Getting Started
How-to Guides
Docs
Tutorial""""""",222,1023,kestra
https://kestra.io/docs/tutorial,"""""""DocsTutorial
Tutorial
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Kestra is an open-source orchestrator designed to bring Infrastructure as Code (IaC) best practices to all workflows ‚Äî from those orchestrating mission-critical applications, IT operations, business processes, and data pipelines, to simple Zapier-style automations.
You can use Kestra to:
run workflows on-demand, event-driven or based on a regular schedule
programmatically interact with any system or programming language
orchestrate microservices, batch jobs, ad-hoc scripts (written in Python, R, Julia, Node.js, and more), SQL queries, data ingestion syncs, dbt or Spark jobs, or any other applications or processes
This tutorial will guide you through key concepts in Kestra. We'll start with the same ""Hello world"" flow from the Quickstart Guide, and we'll gradually introduce new concepts including namespaces, tasks, parametrization with inputs and scheduling using triggers.
We'll then dive into parallel task execution, error handling, as well as custom scripts and microservices running in isolated containers. Let's get started!
Fundamentals: build a ""Hello World"" flow
Fundamentals
Start by building a ""Hello world"" example.
Inputs
Inputs allow you to make your flows more dynamic and reusable.
Outputs
Outputs allow you to pass data between tasks and flows.
Triggers
Triggers automatically start your flow based on events.
Flowable Tasks
Run tasks or subflows in parallel, create loops and conditional branching.
Errors and Retries
Handle errors with automatic retries and notifications.
Docker
Run custom Python, R, Julia, Node.js and Shell scripts in isolated containers.
Was this page helpful?
Yes
No
Getting Started
Community Guidelines
Tutorial
Fundamentals""""""",376,1774,kestra
https://kestra.io/docs/tutorial/fundamentals,"""""""DocsTutorialFundamentals
Fundamentals
Table of Contents
Flows
Namespaces
Labels
Description(s)
Tasks
The order of task execution
Autocompletion
Supported task types
Core
Scripts
Internal Storage
KV Store
‚ö°Ô∏è Plugins
Create and run your first flow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Start by building a ""Hello world"" example.
To install Kestra, follow the Quickstart Guide or check the detailed Installation Guide.
Flows
Flows are defined in a declarative YAML syntax to keep the orchestration code portable and language-agnostic.
Each flow consists of three required components: id, namespace and tasks:
id represents the name of the flow
namespace can be used to separate development and production environments
tasks is a list of tasks that will be executed in the order they are defined
Here are those three components in a YAML file:
yaml
id: getting_started
namespace: company.team
tasks:
  - id: hello_world
    type: io.kestra.plugin.core.log.Log
    message: Hello World!
The id of a flow must be unique within a namespace. For example:
‚úÖ you can have a flow named getting_started in the company.team1 namespace and another flow named getting_started in the company.team2 namespace.
‚ùå you cannot have two flows named getting_started in the company.team namespace at the same time.
The combination of id and namespace serves as a unique identifier for a flow.
Namespaces
Namespaces are used to group flows and provide structure. Keep in mind that the allocation of a flow to a namespace is immutable. Once a flow is created, you cannot change its namespace. If you need to change the namespace of a flow, create a new flow with the desired namespace and delete the old flow.
Labels
To add another layer of organization, you can use labels, allowing you to group flows using key-value pairs.
Description(s)
You can optionally add a description property to keep your flows documented. The description is a string that supports markdown syntax. That markdown description will be rendered and displayed in the UI.
Not only flows can have a description. You can also add a description property to tasks and triggers to keep all the components of your workflow documented.
Here is the same flow as before, but this time with labels and descriptions:
yaml
id: getting_started
namespace: company.team
description: |
  # Getting Started
  Let's `write` some **markdown** - [first flow](https://t.ly/Vemr0) üöÄ
labels:
  owner: rick.astley
  project: never-gonna-give-you-up
tasks:
  - id: hello_world
    type: io.kestra.plugin.core.log.Log
    message: Hello World!
    description: |
      ## About this task
      This task will print ""Hello World!"" to the logs.
Learn more about flows in the Flows section.
Tasks
Tasks are atomic actions in your flows. You can design your tasks to be small and granular, e.g. fetching data from a REST API or running a self-contained Python script. However, tasks can also represent large and complex processes, e.g. triggering containerized processes or long-running batch jobs (e.g. using dbt, Spark, AWS Batch, Azure Batch, etc.) and waiting for their completion.
The order of task execution
Tasks are defined in the form of a list. By default, all tasks in the list will be executed sequentially ‚Äî the second task will start as soon as the first one finishes successfully.
Kestra provides additional customization allowing to run tasks in parallel, iterating (sequentially or in parallel) over a list of items, or to allow failure of specific tasks. Those are called Flowable tasks because they define the flow logic.
A task in Kestra must have an id and a type. Other properties depend on the task type. You can think of a task as a step in a flow that should execute a specific action, such as running a Python or Node.js script in a Docker container, or loading data from a database.
yaml
tasks:
  - id: python
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:slim
    script: |
      print(""Hello World!"")
Autocompletion
Kestra supports hundreds of tasks integrating with various external systems. Use the shortcut CTRL + SPACE on Windows/Linux or fn + control + SPACE on Mac to trigger autocompletion listing available tasks or properties of a given task.
If you want to comment out some part of your code, use the CTRL or ‚åò + K + C shortcut, and to uncomment it, use CTRL or ‚åò + K + U. To remember it, C stands for comment and U stands for uncomment. All available keyboard shortcuts are listed upon right-clicking anywhere in the code editor.
Supported task types
Let's look at supported task types.
Core
Core tasks from the io.kestra.plugin.core.flow category are commonly used to control the flow logic. You can use them to declare which processes should run in parallel or sequentially. You can specify conditional branching, iterating over a list of items, pausing or allowing certain tasks to fail without failing the execution.
Scripts
Script tasks are used to run scripts in Docker containers or local processes. You can use them to run Python, Node.js, R, Julia, or any other script. You can also use them to execute a series of commands in Shell or PowerShell. Check the Script tasks page for more details.
Internal Storage
Tasks from the io.kestra.plugin.core.storage category, along with Outputs, are used to interact with the internal storage. Kestra uses internal storage to pass data between tasks. You can think of internal storage as an S3 bucket. In fact, you can use your private S3 bucket as internal storage. This storage layer helps avoid proliferation of connectors. For example, you can use the Postgres plugin to extract data from a Postgres database and load it to the internal storage. Other task(s) can read that data from internal storage and load it to other systems such as Snowflake, BigQuery, or Redshift, or process it using any other plugin, without requiring point to point connections between each of them.
KV Store
Internal storage is mainly used to pass data within a single flow execution. If you need to pass data between different flow executions, you can use the KV Store. The tasks Set, Get and Delete from the io.kestra.plugin.core.kv category allow you to persist data between executions (even across namespaces). For example, if you are using dbt, you can leverage the KV Store to persist the manifest.json file between executions and implement the slim CI pattern.
‚ö°Ô∏è Plugins
Apart from core tasks, the plugins library provides a wide range of integrations. Kestra has built-in plugins for data ingestion, data transformation, interacting with databases, object stores, or message queues, and the list keeps growing with every new release. On top of that, you can also create your own plugins to integrate with any system or programming language.
Create and run your first flow
Now, let's create and run your first flow. On the left side of the screen, click on the Flows menu. Then, click on the Create button.
Paste the following code to the Flow editor:
yaml
id: getting_started
namespace: company.team
tasks:
  - id: api
    type: io.kestra.plugin.core.http.Request
    uri: https://dummyjson.com/products
Then, hit the Save button.
This flow has a single task that will fetch data from the dummyjson API. Let's run it!
Next, let's parametrize this flow using inputs
Was this page helpful?
Yes
No
Docs
Tutorial
Tutorial
Inputs""""""",1617,7388,kestra
https://kestra.io/docs/tutorial/inputs,"""""""DocsTutorialInputs
Inputs
Table of Contents
How to retrieve inputs
Defining inputs
Parametrize your flow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Inputs allow you to make your flows more dynamic and reusable.
Instead of hardcoding values in your flow, you can use inputs to make your workflows more adaptable to change.
How to retrieve inputs
Inputs can be accessed in any task using the following expression {{ inputs.input_name }}.
Defining inputs
Similar to tasks, inputs is a list of key-value pairs. Each input must have a name and a type. You can also set defaults for each input. Setting default values for an input is always recommended, especially if you want to run your flow on a schedule.
To reference an input value in your flow, use the {{ inputs.input_name }} syntax.
yaml
id: inputs_demo
namespace: company.team
inputs:
  - id: user
    type: STRING
    defaults: Rick Astley
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: Hey there, {{ inputs.user }}
Try running the above flow with different values for the user input. You can do this by clicking on the Execute button in the UI, and then typing the desired value in the menu.
The plural form of defaults rather than default has two reasons. First, default is a reserved keyword in Java, so it couldn't be used. Second, this property allows you to set default value for a JSON object which can simultaneously be an array defining multiple default values.
Here are the most common input types:
Type Description
STRING It can be any string value. Strings are not parsed, they are passed as-is to any task that uses them.
INT It can be any valid integer number (without decimals).
BOOLEAN It must be either true or false.
Check the inputs documentation for a full list of supported input types.
Parametrize your flow
In our example, we will provide the URL of the API as an input. This way, we can easily change the URL when calling the flow without having to modify the flow itself.
yaml
id: getting_started
namespace: company.team
inputs:
  - id: api_url
    type: STRING
    defaults: https://dummyjson.com/products
tasks:
  - id: api
    type: io.kestra.plugin.core.http.Request
    uri: ""{{ inputs.api_url }}""
To learn more about inputs, check out the full inputs documentation.
Next, let's look at outputs
Was this page helpful?
Yes
No
Tutorial
Fundamentals
Tutorial
Outputs""""""",541,2406,kestra
https://kestra.io/docs/tutorial/outputs,"""""""DocsTutorialOutputs
Outputs
Table of Contents
How to retrieve outputs
Use outputs in your flow
Debug Outputs
Passing data between tasks
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Outputs allow you to pass data between tasks and flows.
Tasks and flows can generate outputs, which can be passed to downstream processes. These outputs can be variables or files stored in the internal storage.
How to retrieve outputs
Use the syntax {{ outputs.task_id.output_property }} to retrieve a specific output of a task.
If your task id contains one or more hyphens (i.e. the - sign), wrap the task id in square brackets, e.g. {{ outputs['task-id'].output_property }}.
To see which outputs have been generated during a flow execution, go to the Outputs tab on the Execution page:
The outputs are useful for troubleshooting and auditing. Additionally, you can use outputs to:
share downloadable artifacts with business stakeholders, e.g. a table generated by a SQL query, or a CSV file generated by a Python script
pass data between decoupled processes (e.g. pass subflow's outputs or a file detected by S3 trigger to downstream tasks)
Use outputs in your flow
When fetching data from a REST API, Kestra stores that fetched data in the internal storage, and makes it available to downstream tasks using the body output argument.
Use the {{ outputs.task_id.body }} syntax to process that fetched data in a downstream task, as shown in the Python script task below.
yaml
id: getting_started_output
namespace: company.team
inputs:
  - id: api_url
    type: STRING
    defaults: https://dummyjson.com/products
tasks:
  - id: api
    type: io.kestra.plugin.core.http.Request
    uri: ""{{ inputs.api_url }}""
  - id: python
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:slim
    beforeCommands:
      - pip install polars
    warningOnStdErr: false
    outputFiles:
      - ""products.csv""
    script: |
      import polars as pl
      data = {{outputs.api.body | jq('.products') | first}}
      df = pl.from_dicts(data)
      df.glimpse()
      df.select([""brand"", ""price""]).write_csv(""products.csv"")
This flow processes data using Polars and stores the result as a CSV file.
To avoid package dependency conflicts, the Python task is running in an independent Docker container. You can optionally provide a custom Docker image from a private container registry, or use a public Python image from DockerHub, and install any custom package dependencies using the beforeCommands argument. The beforeCommands argument allows you to install any custom package dependencies ‚Äî here, we install Polars. Use as many commands as needed to prepare containerized environment for the script execution.
Debug Outputs
When referencing the output from the previous task, this flow uses jq language to extract the products array from the API response ‚Äî jq is available in all Kestra tasks without having to install it.
You can test {{ outputs.task_id.body | jq('.products') | first }} and any other output parsing expression using the built-in expressions evaluator on the Outputs page:
Passing data between tasks
Let's add another task to the flow to process the CSV file generated by the Python script task. We will use the io.kestra.plugin.jdbc.duckdb.Query task to run a SQL query on the CSV file and store the result as a downloadable artifact in the internal storage.
yaml
id: getting_started
namespace: company.team
tasks:
  - id: api
    type: io.kestra.plugin.core.http.Request
    uri: https://dummyjson.com/products
  - id: python
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:slim
    beforeCommands:
      - pip install polars
    warningOnStdErr: false
    outputFiles:
      - ""products.csv""
    script: |
      import polars as pl
      data = {{ outputs.api.body | jq('.products') | first }}
      df = pl.from_dicts(data)
      df.glimpse()
      df.select([""brand"", ""price""]).write_csv(""products.csv"")
  - id: sqlQuery
    type: io.kestra.plugin.jdbc.duckdb.Query
    inputFiles:
      in.csv: ""{{ outputs.python.outputFiles['products.csv'] }}""
    sql: |
      SELECT brand, round(avg(price), 2) as avg_price
      FROM read_csv_auto('{{ workingDir }}/in.csv', header=True)
      GROUP BY brand
      ORDER BY avg_price DESC;
    store: true
This example flow passes data between tasks using outputs. The inputFiles argument of the io.kestra.plugin.jdbc.duckdb.Query task allows you to pass files from internal storage to the task. The store: true ensures that the result of the SQL query is stored in the internal storage and can be previewed and downloaded from the Outputs tab.
To sum up, our flow extracts data from an API, uses that data in a Python script, executes a SQL query and generates a downloadable artifact.
If you encounter any issues while executing the above flow, this might be a Docker related issue (e.g. Docker-in-Docker setup, which might be difficult to configure on Windows). Set the runner property to PROCESS to run the Python script task in the same process as the flow rather than in a Docker container, as shown in the example below. This will avoid any Docker related issues.
yaml
id: getting_started
namespace: company.team
inputs:
  - id: api_url
    type: STRING
    defaults: https://dummyjson.com/products
tasks:
  - id: api
    type: io.kestra.plugin.core.http.Request
    uri: ""{{ inputs.api_url }}""
  - id: python
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    beforeCommands:
      - pip install polars
    warningOnStdErr: false
    outputFiles:
      - ""products.csv""
    script: |
      import polars as pl
      data = {{ outputs.api.body | jq('.products') | first }}
      df = pl.from_dicts(data)
      df.glimpse()
      df.select([""brand"", ""price""]).write_csv(""products.csv"")
  - id: sqlQuery
    type: io.kestra.plugin.jdbc.duckdb.Query
    inputFiles:
      in.csv: ""{{ outputs.python.outputFiles['products.csv'] }}""
    sql: |
      SELECT brand, round(avg(price), 2) as avg_price
      FROM read_csv_auto('{{ workingDir }}/in.csv', header=True)
      GROUP BY brand
      ORDER BY avg_price DESC;
    store: true
To learn more about outputs, check out the full outputs documentation.
Next, let's cover triggers to schedule the flow
Was this page helpful?
Yes
No
Tutorial
Inputs
Tutorial
Triggers""""""",1462,6392,kestra
https://kestra.io/docs/tutorial/triggers,"""""""DocsTutorialTriggers
Triggers
Table of Contents
Defining triggers
Add a trigger to your flow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Triggers automatically start your flow based on events.
A trigger can be a scheduled date, a new file arrival, a new message in a queue, or the end of another flow's execution.
Defining triggers
Use the triggers keyword in the flow and define a list of triggers. You can have several triggers attached to a flow.
The trigger definition looks similar to the task definition ‚Äî it contains an id, a type, and additional properties related to the specific trigger type.
The workflow below will be automatically triggered every day at 10 AM, as well as anytime when the first_flow finishes its execution. Both triggers are independent of each other.
yaml
id: getting_started
namespace: company.team
tasks:
  - id: hello_world
    type: io.kestra.plugin.core.log.Log
    message: Hello World!
triggers:
  - id: schedule_trigger
    type: io.kestra.plugin.core.trigger.Schedule
    cron: 0 10 * * *
  - id: flow_trigger
    type: io.kestra.plugin.core.trigger.Flow
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionFlowCondition
        namespace: company.team
        flowId: first_flow
Add a trigger to your flow
Let's look at another trigger example. This trigger will start our flow every Monday at 10 AM.
yaml
triggers:
  - id: every_monday_at_10_am
    type: io.kestra.plugin.core.trigger.Schedule
    cron: 0 10 * * 1
Click here to see the full workflow example with this Schedule trigger
To learn more about triggers, check out the full triggers documentation.
Next, let's orchestrate more complex workflows
Was this page helpful?
Yes
No
Tutorial
Outputs
Tutorial
Flowable Tasks""""""",411,1768,kestra
https://kestra.io/docs/tutorial/flowable,"""""""DocsTutorialFlowable Tasks
Flowable Tasks
Table of Contents
Add parallelism using Flowable tasks
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Run tasks or subflows in parallel, create loops and conditional branching.
Add parallelism using Flowable tasks
One of the most common orchestration requirements is to execute independent processes in parallel. For example, you can process data for each partition in parallel. This can significantly speed up the processing time.
The flow below uses the EachParallel flowable task to execute a list of tasks in parallel.
The value property defines the list of items to iterate over.
The tasks property defines the list of tasks to execute for each item in the list. You can access the iteration value using the {{ taskrun.value }} variable.
yaml
id: python_partitions
namespace: company.team
description: Process partitions in parallel
tasks:
  - id: getPartitions
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: ghcr.io/kestra-io/pydata:latest
    script: |
      from kestra import Kestra
      partitions = [f""file_{nr}.parquet"" for nr in range(1, 10)]
      Kestra.outputs({'partitions': partitions})
  - id: processPartitions
    type: io.kestra.plugin.core.flow.EachParallel
    value: '{{ outputs.getPartitions.vars.partitions }}'
    tasks:
      - id: partition
        type: io.kestra.plugin.scripts.python.Script
        taskRunner:
          type: io.kestra.plugin.scripts.runner.docker.Docker
        containerImage: ghcr.io/kestra-io/pydata:latest
        script: |
          import random
          import time
          from kestra import Kestra
          filename = '{{ taskrun.value }}'
          print(f""Reading and processing partition {filename}"")
          nr_rows = random.randint(1, 1000)
          processing_time = random.randint(1, 20)
          time.sleep(processing_time)
          Kestra.counter('nr_rows', nr_rows, {'partition': filename})
          Kestra.timer('processing_time', processing_time, {'partition': filename})
To learn more about flowable tasks, check out the full documentation.
Next, let's configure failure notifications and retries
Was this page helpful?
Yes
No
Tutorial
Triggers
Tutorial
Errors and Retries""""""",527,2323,kestra
https://kestra.io/docs/tutorial/errors,"""""""DocsTutorialErrors and Retries
Errors and Retries
Table of Contents
Error handling
Flow-level error handling using errors
Namespace-level error handling using a Flow trigger
Retries
Configuring retries
Adding a retry configuration to our tutorial workflow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Handle errors with automatic retries and notifications.
Failure is inevitable. Kestra provides automatic retries and error handling to help you build resilient workflows.
Error handling
By default, a failure of any task will stop the execution and will mark it as failed. For more control over error handling, you can add errors tasks, AllowFailure tasks, or automatic retries.
The errors property allows you to execute one or more actions before terminating the flow, e.g. sending an email or a Slack message to your team. The property is named errors because they are triggered upon errors within your flow.
You can implement error handling at the flow-level or on a namespace-level.
Flow-level: Useful to implement custom alerting for a specific flow or task. This can be accomplished by adding errors tasks.
Namespace-level: Useful to send a notification for any failed Execution within a given namespace. This approach allows you to implement centralized error handling for all flows within a given namespace.
Flow-level error handling using errors
The errors is a property of a flow that accepts a list of tasks that will be executed when an error occurs. You can add as many tasks as you want, and they will be executed sequentially.
The example below sends a flow-level failure alert via Slack using the SlackIncomingWebhook task defined using the errors property.
yaml
id: unreliable_flow
namespace: company.team
tasks:
  - id: fail
    type: io.kestra.plugin.core.execution.Fail
errors:
  - id: alert_on_failure
    type: io.kestra.plugin.notifications.slack.SlackIncomingWebhook
    url: ""{{ secret('SLACK_WEBHOOK') }}"" # https://hooks.slack.com/services/xyz/xyz/xyz
    payload: |
      {
        ""channel"": ""#alerts"",
        ""text"": ""Failure alert for flow {{ flow.namespace }}.{{ flow.id }} with ID {{ execution.id }}""
      }
Check the error handling page for more details.
Namespace-level error handling using a Flow trigger
To get notified on a workflow failure, you can leverage Kestra's built-in notification tasks, including among others (the list keeps growing with new releases):
Slack
Microsoft Teams
Email
For a centralized namespace-level alerting, we recommend adding a dedicated monitoring workflow with one of the above mentioned notification tasks and a Flow trigger. Below is an example workflow that automatically sends a Slack alert as soon as any flow in the namespace company.analytics fails or finishes with warnings.
yaml
id: failure_alert
namespace: company.monitoring
tasks:
  - id: send
    type: io.kestra.plugin.notifications.slack.SlackExecution
    url: ""{{ secret('SLACK_WEBHOOK') }}""
    channel: ""#general""
    executionId: ""{{trigger.executionId}}""
triggers:
  - id: listen
    type: io.kestra.plugin.core.trigger.Flow
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - FAILED
          - WARNING
      - type: io.kestra.plugin.core.condition.ExecutionNamespaceCondition
        namespace: company.analytics
        prefix: true
Adding this single flow will ensure that you receive a Slack alert on any flow failure in the prod namespace. Here is an example alert notification:
Retries
When working with external systems, transient errors are common. For example, a file may not be available yet, an API might be temporarily unreachable, or a database can be under maintenance. In such cases, retries can automatically fix the issue without human intervention.
Configuring retries
Each task can be retried a certain number of times and in a specific way. Use the retry property with the desired type of retry.
The following types of retries are currently supported:
Constant: The task will be retried every X seconds/minutes/hours/days.
Exponential: The task will also be retried every X seconds/minutes/hours/days, but with an exponential backoff, i.e. an exponential time interval in between each retry attempt.
Random: The task will be retried every X seconds/minutes/hours/days with a random delay i.e. a random time interval in between each retry attempt.
In this example, we will retry the task 5 times up to 1 minute of a total task run duration, with a constant interval of 2 seconds between each retry attempt.
yaml
id: retries
namespace: company.team
tasks:
  - id: fail_four_times
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - 'if [ ""{{ taskrun.attemptsCount }}"" -eq 4 ]; then exit 0; else exit 1; fi'
    retry:
      type: constant
      interval: PT2S
      maxAttempt: 5
      maxDuration: PT1M
      warningOnRetry: false
errors:
  - id: will_never_run
    type: io.kestra.plugin.core.debug.Return
    format: This will never be executed as retries will fix the issue
Adding a retry configuration to our tutorial workflow
Let's get back to our example from the Fundamentals section. We will add a retry configuration to the api task. API calls are prone to transient errors, so we will retry that task up to 10 times, for at most 1 hour of total duration, every 10 seconds (i.e. with a constant interval of 10 seconds in between retry attempts).
yaml
id: getting_started
namespace: company.team
tasks:
  - id: api
    type: io.kestra.plugin.core.http.Request
    uri: https://dummyjson.com/products
    retry:
      type: constant # type: string
      interval: PT20S # type: Duration
      maxDuration: PT1H # type: Duration
      maxAttempt: 10 # type: int
      warningOnRetry: true # type: boolean, default is false
Next, let's run tasks in separate containers
Was this page helpful?
Yes
No
Tutorial
Flowable Tasks
Tutorial
Docker""""""",1326,5980,kestra
https://kestra.io/docs/tutorial/docker,"""""""DocsTutorialDocker
Docker
Table of Contents
Tasks running in Docker containers
Defining a Docker task runner
Next steps
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Run custom Python, R, Julia, Node.js and Shell scripts in isolated containers.
Tasks running in Docker containers
Many tasks in Kestra will run in dedicated Docker containers, including among others:
Script tasks running Python, Node.js, R, Julia, Bash, and more
Singer tasks running data ingestion syncs
dbt tasks running dbt jobs
Kestra uses Docker for those tasks to ensure that they run in a consistent environment and to avoid dependency conflicts.
Those tasks require a Docker daemon running on the host. Refer to the Troubleshooting guide if you encounter any issues configuring Docker.
Defining a Docker task runner
To run a task in a Docker container, set the taskRunner property with the type io.kestra.plugin.scripts.runner.docker.Docker:
yaml
taskRunner:
  type: io.kestra.plugin.scripts.runner.docker.Docker
Many tasks, including Python, use the io.kestra.plugin.scripts.runner.docker.Docker task runner by default.
Using the containerImage property, you can define the Docker image for the task. You can use any image from a public or private container registry, as well as a custom local image built from a Dockerfile. You may even build a Docker image using the Docker plugin in one task, and reference the built image by the tag in a downstream task.
yaml
containerImage: ghcr.io/kestra-io/pydata:latest
The taskRunner property also allows you to configure credentials with nested username and password properties to authenticate a private container registry.
yaml
id: private_docker_image
namespace: company.team
tasks:
  - id: custom_image
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      credentials:
        username: your_username
        password: ""{{ secret('GITHUB_ACCESS_TOKEN') }}""
    containerImage: ghcr.io/your_org/your_package:tag
    script: |
        print(""this runs using a private container image"")
The task documentation of each script task provides more details about available taskRunner properties.
For more examples of running scripts in Docker containers, check the Script tasks page.
Next steps
Congrats! üéâ You've completed the tutorial.
Next, you can dive into:
Architecture
Key concepts
Plugins to integrate with external systems
Deployments to deploy Kestra to production.
Was this page helpful?
Yes
No
Tutorial
Errors and Retries
Docs
Architecture""""""",558,2570,kestra
https://kestra.io/docs/architecture,"""""""DocsArchitecture
Architecture
Table of Contents
Architecture with JDBC backend
Scalability with JDBC
Architecture with Kafka and Elasticsearch backend
Scalability with Kafka and Elasticsearch
Comparison between JDBC and Kafka architectures
Components in detail
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Kestra's architecture is designed to be scalable, flexible and fault-tolerant. Depending on your needs, you can choose between two different architectures: JDBC and Kafka.
Architecture with JDBC backend
The following diagram shows the main components of Kestra using the JDBC backend.
While it's not captured in the diagram above, the JDBC backend in the Enterprise Edition also supports SQL Server starting from Kestra 0.18.0.
Here are the components and their interactions:
JDBC Backend: this is the data storage layer used for orchestration metadata.
Server: this is the central part of the system, composed of:
Webserver: serves both an API and a User Interface.
Scheduler: an essential part of the system that schedules workflows and handles all triggers except for the flow triggers (see below).
Executor: another critical component responsible for the orchestration logic including flow triggers.
Worker: this might be one or multiple processes that carry out the heavy computation of runnable tasks and polling triggers. For privacy reasons, workers are the only components that interact with the user's infrastructure, including the internal storage and external services.
User: interacts with the system via UI and API.
User‚Äôs Infrastructure: private infrastructure components that are part of the user‚Äôs environment, which Kestra interacts with:
Internal Storage: can be any cloud storage system within the user's infrastructure (e.g. AWS S3, Google Cloud Storage, or Azure Blob Storage).
External Services: third-party APIs or services outside of Kestra which Workers might interact with to process data within a given task.
The arrows indicate the direction of communication. The JDBC Backend connects to the Server, which in turn interacts with the User's Infrastructure. The User interacts with the system through the API and UI.
Scalability with JDBC
The scalable design of the architecture allows you to run multiple instances of the Webserver, Executor, Worker and Scheduler to handle increased load. As your workload increases, more instances of the required components can be added to the system to distribute the load and maintain performance.
The JDBC Backend can be scaled too, either through clustering or sharding, to handle larger volumes of data and a higher number of requests from the Server components. Most cloud providers offer managed database services that can be scaled up and down as needed.
Architecture with Kafka and Elasticsearch backend
The following diagram shows the main components of Kestra using the Kafka and Elasticsearch backend.
Note that this architecture is only available in the Enterprise Edition of Kestra.
This architecture is designed to provide enhanced scalability, high availability, and fault tolerance, required to meet the needs of large-scale enterprise deployments.
Kafka: this component serves as the messaging backend, which communicates between different components of the system and allows for robust scalability and fault tolerance.
Microservices: This layer includes several services:
Webserver: serves the API and User Interface for interaction with the system.
Scheduler: schedules workflows and processes all triggers except for the flow triggers.
Executor: handles the orchestration logic, including flow triggers.
Indexer: indexes data from Kafka to Elasticsearch for quick retrieval and search.
Worker: runs tasks and interacts with the user's infrastructure.
User: engages with the system through the Webserver's API and UI.
Elasticsearch: acts as a search and UI backend, storing logs, execution history, and enabling fast data retrieval.
User‚Äôs Infrastructure: private infrastructure components that are part of the user‚Äôs environment, which Kestra interacts with:
Internal Storage: Cloud storage services where user's data is stored (e.g. AWS S3, Google Cloud Storage, or Azure Blob Storage).
External Services: APIs or services that Workers might interact with during task processing.
Scalability with Kafka and Elasticsearch
Kafka's messaging backend allows handling large volumes of data with the ability to scale out as needed. You can run multiple (horizontally scaled) instances of services such as Workers, Schedulers, Webservers and Executors to ensure fault tolerance, distribute the load and maintain system performance as demand increases. Elasticsearch contributes to scalability by providing a robust, horizontally scalable UI backend that can efficiently search across large amounts of data.
Comparison between JDBC and Kafka architectures
When comparing both diagrams, the main difference between the architecture of the JDBC and an Kafka architectures is the data layer (JDBC Database vs. Kafka and Elasticsearch).
Note that it's possible to use the Enterprise Edition with a JDBC database backend for smaller deployments. In fact, it's often easier to start with a JDBC backend and migrate to Kafka and Elasticsearch when your deployment grows.
The Worker is the only component communicating with your private data sources to extract and transform data. The Worker also interacts with Internal Storage to persist intermediary results and store the final task run outputs.
All components of the application layer (including the Worker, Executor, and Scheduler) are decoupled and stateless, communcating with each other through the Queue (Kafka/JDBC). You can deploy and scale them independently.
The Webserver communicates with the (Elasticsearch/JDBC) Repository to serve data for Kestra UI and API.
The data layer is decoupled from the application layer and provides a separation between:
storing your private data processing artifacts ‚Äî Internal Storage is used to store outputs of your executions; you can think of Internal Storage as your own private S3 bucket
storing execution metadata ‚Äî (Kafka/JDBC) Queue is used as the orchestration backend
storing logs and user-facing data ‚Äî the (Elasticsearch/JDBC) Repository is used to store data needed to serve Kestra UI and API.
The Indexer, available only in the Enterprise Edition, indexes content from Kafka topics (such as the flows and executions topics) to the Elasticsearch repositories. Thanks to the separation between Queue and Repository in the Kafka Architecture, even if your Elasticsearch instance experiences downtime, your executions will continue to work by relying on the Kafka backend.
Components in detail
The following sections provide more details about the components of the architecture.
Main components
Technical description of Kestra's main components, including the internal storage, queue, repository, and plugins.
Server components
Detailed breakdown of the server components behind Kestra.
Deployment Architecture
Examples of deployment architectures, depending on your needs.
Executor
The Executor processes all executions and Flowable tasks.
Worker
The Worker is a server component that processes all runnable tasks and polling triggers.
Scheduler
The Scheduler is a server component responsible for processing all triggers except for the Flow Triggers (managed by the executor).
Indexer
Indexer is an optional component only needed when using Kafka and Elasticsearch.
Webserver
The Webserver serves the APIs and the User Interface (UI).
Internal Storage
Internal Storage is a dedicated storage area to store arbitrary-sized files used during executions.
Multi-tenancy
Multi-tenancy allows you to manage multiple environments (e.g., dev, staging, prod) in a single Kestra instance.
Was this page helpful?
Yes
No
Tutorial
Docker
Architecture
Main components""""""",1480,7872,kestra
https://kestra.io/docs/architecture/main-components,"""""""DocsArchitectureMain components
Main components
Table of Contents
Internal Storage
Queue
Repository
Plugins
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Technical description of Kestra's main components, including the internal storage, queue, repository, and plugins.
Kestra has three internal components:
The Internal Storage stores flow data like task outputs and flow inputs.
The Queue is used for internal communication between Kestra server components.
The Repository is used to store flows, templates, executions, logs, etc. The repository stores every internal object.
The Plugins extend the core of Kestra with new task and trigger types, storage implementations, etc.
These internal components are provided on multiple implementations depending on your needs and deployment architecture. You may need to install additional plugins to use some implementations.
Internal Storage
Kestra uses the concept of Internal Storage for storing input and output data. Multiple storage options are available, including local storage (default), S3 and Minio, Google Cloud Storage, and Azure Blobs Storage.
Check the Internal Storage documentation for more information.
Queue
The Queue, or more precisely, queues, are used internally for communication between the different Kestra server components. Kestra provides multiple queue types that must be used with their repository counterparts.
There are three types of queues:
In-Memory that must be used with the In-Memory Repository.
Database that must be used with the Database Repository.
Kafka that must be used with the Elasticsearch Repository. Only available in the Enterprise Edition.
Repository
The Repository, or more precisely, repositories, are the internal way to store data. Kestra provides multiple repository types that must be used with their queue counterparts.
There exist three types of repositories:
In-Memory that must be used with the In-Memory Queue.
Database that must be used with the Database Queue.
Elasticsearch that must be used with the Kafka Queue. Only available in the Enterprise Edition.
Plugins
Kestra's core is not able to handle a lot of task types on its own. We have therefore, included a Plugins' ecosystem that allows developing as many task types as you need. A wide range of plugins are already available, and many more will be delivered by the Kestra team!
Plugins are also used to provide different implementations for Kestra's internal components like its Internal Storage.
Was this page helpful?
Yes
No
Docs
Architecture
Architecture
Server components""""""",501,2571,kestra
https://kestra.io/docs/architecture/server-components,"""""""DocsArchitectureServer components
Server components
Table of Contents
Executor
Worker
Worker Group (EE)
Scheduler
Indexer
Webserver
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Detailed breakdown of the server components behind Kestra.
Kestra consists of multiple server components that can be scaled independently.
Each server component interacts with internal components (internal storage, queues, and repositories).
Executor
The Executor oversees all executions and certain types of tasks, such as Flowable tasks or Flow Triggers. It requires minimal resources as it doesn't perform heavy computations.
Generally speaking, the Executor never touches your data. It orchestrates workflows based on the information it receives from the Scheduler and the Queue, and it defers the execution of tasks to Workers.
If you have a large number of Executions, you can scale the Executor horizontally. However, this is rarely necessary as the Executor is very lightweight ‚Äî all heavy computations are performed by Workers.
Worker
Workers execute tasks (from the Executor) and polling triggers (from the Scheduler).
Workers are highly configurable and scalable, accommodating a wide range of tasks from simple API calls to complex computations. Workers are the only server components that need access to external services in order to connect to databases, APIs, or other services that your tasks interact with.
Worker Group (EE)
In the Enterprise Edition, Worker Groups allow tasks and polling triggers to be executed on specific worker sets. They can be beneficial in various scenarios, such as using compute instances with GPUs, executing tasks on a specific OS, restricting backend access, and region-specific execution. A default worker group is recommended per tenant or namespace.
To specify a worker group for a task, use the workerGroup.key property in the task definition to point the task to a specific worker group key. If no worker group is specified, the task will be executed on the default worker group.
Scheduler
The Scheduler manages all triggers except for Flow triggers handled by the Executor. It determines when to start a flow based on trigger conditions.
Indexer
The Indexer indexes content from Kafka topics (such as the flows and executions topics) to Elasticsearch repositories.
Webserver
The Webserver is the entry point for all external communications with Kestra. It handles all REST API calls made to Kestra and serves the Kestra UI.
Was this page helpful?
Yes
No
Architecture
Main components
Architecture
Deployment Architecture""""""",494,2579,kestra
https://kestra.io/docs/architecture/deployment-architecture,"""""""DocsArchitectureDeployment Architecture
Deployment Architecture
Table of Contents
Small-sized deployment
Medium-sized deployment
High-availability deployment
Kafka
Elasticsearch
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Examples of deployment architectures, depending on your needs.
Kestra is a Java application that is provided as an executable. You have many deployments options:
Docker
Kubernetes
Manual deployment
At its heart, Kestra has a plugin system allowing you to choose the dependency type that fits your needs.
You can find three example deployment architectures below.
Small-sized deployment
For small-sized deployments, you can use the Kestra standalone server, an all-in-one server component that allows running all Kestra server components in a single process. This deployment architecture has no scaling capability.
In this case, a database is the only dependency. This allows running Kestra with a minimal stack to maintain. For now, we have three databases available:
PostgreSQL
MySQL
H2
Medium-sized deployment
For medium-sized deployments, where high availability is not a strict requirement, you can use a database (Postgres or MySQL) as the only dependency. This allows running Kestra with a minimal stack to maintain. For now, we have two databases available for this kind of architecture, as H2 is not a good fit when running distributed components:
PostgreSQL
MySQL
All server components will communicate through the database.
In this deployment mode, unless all components run on the same host, you must use a distributed storage implementation like Google Cloud Storage, AWS S3, or Azure Blob Storage.
High-availability deployment
To support higher throughput, and full horizontal and vertical scaling of the Kestra cluster, we can replace the database with Kafka and Elasticsearch. In this case, all the server components can be scaled without any single point of failure.
Kafka and Elasticsearch are available only in the Enterprise Edition.
In this deployment mode, unless all components run on the same host, you must use a distributed storage implementation like Google Cloud Storage, AWS S3, or Azure Blob Storage
Kafka
Kafka is Kestra's primary dependency in high availability mode. Each of the most important server components in the deployment must have a Kafka instance up and running. Kafka allows Kestra to be a highly scalable solution.
Kafka Executor
With Kafka, the Executor is a heavy Kafka Stream application. The Executor processes all events from Kafka in the right order, keeps an internal state of the execution, and merges task run results from the Worker. It also detects dead Workers and resubmits the tasks run by a dead Worker.
As the Executor is a Kafka Stream, it can be scaled as needed (within the limits of partitions count on Kafka). Still, as no heavy computations are done in the Executor, this server component only requires a few resources (unless you have a very high rate of executions).
Kafka Worker
With Kafka, the Worker is a Kafka Consumer that will process any Task Run submitted to it. Workers will receive all tasks and dispatch them internally in their Thread Pool.
It can be scaled as needed (within the limits of partitions count on Kafka) and have many instances on multiple servers, each with its own Thread Pool.
With Kafka, if a Worker is dead, the Executor will detect it and resubmit their current task run to another Worker.
Elasticsearch
Elasticsearch is Kestra's User Interface database in high availability mode, allowing the display, search, and aggregation of all Kestra's data (Flows, Executions, etc.). Elasticsearch is only used by the Webserver (API and UI).
Was this page helpful?
Yes
No
Architecture
Server components
Architecture
Executor""""""",765,3767,kestra
https://kestra.io/docs/architecture/executor,"""""""DocsArchitectureExecutor
Executor
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
The Executor processes all executions and Flowable tasks.
The primary goal of the Executor is to receive created executions and look for the next tasks to run. This server component doesn't perform any heavy computation.
The Executor also handles special execution cases:
Flow Triggers
Templates (deprecated)
Listeners (deprecated)
You can scale Executors as necessary. Given that no heavy computations are performed by this component, it requires very few resources (except for deployments with a large number of executions).
Was this page helpful?
Yes
No
Architecture
Deployment Architecture
Architecture
Worker""""""",137,722,kestra
https://kestra.io/docs/architecture/worker,"""""""DocsArchitectureWorker
Worker
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
The Worker is a server component that processes all runnable tasks and polling triggers.
A Worker receives and processes tasks from the Executor and polling triggers from the Scheduler. Given that tasks and polling triggers can be virtually anything (heavy computations, simple API calls, etc.), the Worker is essentially a Thread Pool where you can configure the number of threads you need.
You can scale Workers as necessary and have many instances on multiple servers, each with its own Thread Pool.
As the worker executes the tasks and the polling triggers, it will need access to any external services they use (database, REST services, message broker, etc.). Workers are the only server components that need access to external services.
Was this page helpful?
Yes
No
Architecture
Executor
Architecture
Scheduler""""""",177,922,kestra
https://kestra.io/docs/architecture/scheduler,"""""""DocsArchitectureScheduler
Scheduler
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
The Scheduler is a server component responsible for processing all triggers except for the Flow Triggers (managed by the executor).
It continuously watches all the triggers and, if all conditions are met, will start an execution of the flow (submit the flow to the Executor).
In the case of polling triggers, the Scheduler will decide (based on the configured evaluation interval) whether to execute the flow. If the polling trigger conditions are met, the Scheduler will send the execution, along with the trigger metadata, to the Worker for execution.
Note that polling triggers cannot be evaluated concurrently. They also can't be reevaluated i.e. if the execution of a flow, which started as a result of the same trigger, is already in a Running state, the next execution will not be started until the previous one finishes.
Internally, the Scheduler will keep checking every second whether some trigger must be evaluated.
By default, Kestra will handle all dates based on your system timezone. You can change the timezone with JVM options.
Was this page helpful?
Yes
No
Architecture
Worker
Architecture
Indexer""""""",246,1226,kestra
https://kestra.io/docs/architecture/indexer,"""""""DocsArchitectureIndexer
Indexer
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Indexer is an optional component only needed when using Kafka and Elasticsearch.
The Indexer watches for Kafka topics (including flows and executions) and indexes their content to Elasticsearch.
Was this page helpful?
Yes
No
Architecture
Scheduler
Architecture
Webserver""""""",85,410,kestra
https://kestra.io/docs/architecture/webserver,"""""""DocsArchitectureWebserver
Webserver
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
The Webserver serves the APIs and the User Interface (UI).
The Webserver offers two main modules in the same component:
API: All the APIs that allow triggering executions for any system, and interacting with Kestra.
UI: The User Interface (UI) is also served by the Webserver.
The Webserver interacts mostly with the Repository to deliver a rich API/UI. It also interacts with the Queue to trigger new executions, follow executions in real-time, etc.
Each server component (other than the Scheduler) can continue to work as long as the Queue is up and running. The Repository is only used to help provide our rich Webserver UI, and even if the Repository is down, workloads can continue to process on Kestra.
Was this page helpful?
Yes
No
Architecture
Indexer
Architecture
Internal Storage""""""",197,900,kestra
https://kestra.io/docs/architecture/internal-storage,"""""""DocsArchitectureInternal Storage
Internal Storage
Table of Contents
The purpose of Internal Storage
Internal Storage Types
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Internal Storage is a dedicated storage area to store arbitrary-sized files used during executions.
The purpose of Internal Storage
Kestra uses an Internal Storage to handle incoming and outgoing files in a scalable way. It stores files generated during a flow execution and used to pass data between tasks.
Data stored in the internal storage can be retrieved from execution context with {{ outputs.task_id.output_attribute }} (usually it's a uri property). Kestra will automatically fetch the file.
Inputs of type FILE will be automatically stored inside the internal storage. On the Outputs tab of an execution, if an output attribute is from the internal storage, there will be a link to download it.
Other execution metadatas (so the actual paths to internal storage) are stored into the Repository.
Internal Storage Types
By default, only the local storage is available. It uses a directory inside the host filesystem, so it is not scalable and not designed for production usage.
More implementations are available as plugins.
You can replace the local storage with one of the following storage implementations:
Storage Minio for Minio, which is compatible with AWS S3 and all other object storage solutions.
Storage GCS for Google Cloud Storage.
Storage Azure for Azure Blob Storage.
Was this page helpful?
Yes
No
Architecture
Webserver
Architecture
Multi-tenancy""""""",307,1568,kestra
https://kestra.io/docs/architecture/multi-tenancy,"""""""DocsArchitectureMulti-tenancy
Multi-tenancy
Table of Contents
What is multi-tenancy
How does multi-tenancy work in Kestra
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.13.0
Multi-tenancy allows you to manage multiple environments (e.g., dev, staging, prod) in a single Kestra instance.
What is multi-tenancy
Multi-tenancy is a software architecture in which a single instance of software serves multiple tenants. You can think of it as running multiple virtual instances in a single physical instance. You can use multi-tenancy to separate resources between business units, teams, or customers.
This feature requires a commercial license.
How does multi-tenancy work in Kestra
By default, multi-tenancy is disabled. When multi-tenancy is enabled, all resources (such as flows, triggers, executions, RBAC, and more) are isolated by the tenant. This means that you can have a flow with the same identifier and the same namespace in multiple tenants at the same time.
Data stored inside the internal storage is also isolated by tenants.
Multi-tenancy functionality is not visible to end-users from the UI except for the tenant selection dropdown menu. That dropdown menu lists all tenants a user has access to, allowing users to switch between tenants easily. Each UI page will also include the tenant ID in the URL e.g. https://demo.kestra.io/ui/yourTenantId/executions/namespace/flow/executionId.
The API URLs will also change to include the tenant identifier.
For example, the URL of the API operation to list flows of the products namespace is /api/v1/flows/products when multi-tenancy is not enabled, and becomes /api/v1/production/flows/products for the production tenant when multi-tenancy is enabled. You can check the Enterprise Edition API Guide for more information.
Tenants must be created upfront, and a user needs to be granted access to use a specific tenant.
Was this page helpful?
Yes
No
Architecture
Internal Storage
Docs
Installation Guide""""""",451,2022,kestra
https://kestra.io/docs/installation,"""""""DocsInstallation Guide
Installation Guide
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
You can install Kestra using different methods. Select one that matches your preferred environment.
You can deploy Kestra (almost) anywhere, from your laptop or an on-prem server to a distributed cluster running in a public cloud. Note that some Kestra plugins such as the Script plugin require Docker-in-Docker (DinD). This is not supported in certain environments such as e.g. on AWS Fargate. For production deployments, we recommend using Kubernetes or a virtual machine.
The easiest way to install Kestra locally is to use Docker.
Docker
Start Kestra in a single Docker container.
Docker Compose
Start Kestra with a PostgreSQL database backend using a Docker Compose file.
Kubernetes
Install Kestra in a Kubernetes cluster using a Helm chart.
Kubernetes on AWS EKS with Amazon RDS and S3
Deploy Kestra to AWS EKS with PostgreSQL RDS database and S3 internal storage backend.
Kubernetes on GCP GKE with CloudSQL and Cloud Storage
Deploy Kestra to GCP GKE with CloudSQL as a database backend and Google Cloud Storage as internal storage backend.
Kubernetes on Azure AKS with Azure Database and Blob Storage
Deploy Kestra to Azure AKS with Azure Database for PostgreSQL servers as a database backend and Blob Storage as internal storage backend.
AWS EC2 with Amazon RDS and S3
Install Kestra on AWS EC2 with PostgreSQL RDS database and S3 internal storage backend.
GCP VM with Cloud SQL and GCS
Install Kestra on a GCP VM with Cloud SQL PostgreSQL database backend and Cloud Storage as internal storage backend.
Azure VM with Azure Database
Install Kestra on Azure VM with Azure Database as a database backend and Blob Storage as internal storage backend.
DigitalOcean Droplet with Managed Database
Install Kestra on DigitalOcean Droplet with DigitalOcean Database as a database backend.
Standalone Server
Install Kestra on a standalone server with a simple executable file.
Podman Compose
Start Kestra with a PostgreSQL database backend using Podman Compose.
Kestra Cloud (Alpha)
Sign up for a free Kestra Cloud account to get started.
Was this page helpful?
Yes
No
Architecture
Multi-tenancy
Installation
Docker""""""",501,2231,kestra
https://kestra.io/docs/installation/docker,"""""""DocsInstallation GuideDocker
Docker
Table of Contents
Configuration
Using a configuration file
Using the KESTRA_CONFIGURATION environment variable
Official Docker images
Docker image tags
Recommended images for production
Recommended images for development
Build a custom Docker image
Add custom binaries
Add plugins to a Docker image
Add custom plugins to a Docker image
Add custom plugins from a Git repository
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Start Kestra in a single Docker container.
Make sure that Docker is running. Then, you can start Kestra in a single command using Docker (if you run it on Windows, make sure to use WSL):
bash
docker run --pull=always --rm -it -p 8080:8080 --user=root -v /var/run/docker.sock:/var/run/docker.sock -v /tmp:/tmp kestra/kestra:latest server local
Open http://localhost:8080 in your browser to launch the UI and start building your first flow.
The above command starts Kestra with an embedded H2 database. If you want to use a persistent database backend with PostgreSQL and more configurability, follow the Docker Compose installation.
Configuration
Using a configuration file
You can adjust Kestra's configuration using a file passed to the Docker container as a bind volume.
First, create a configuration file, for example, in a file named application.yaml:
yaml
datasources:
  postgres:
    url: jdbc:postgresql://postgres:5432/kestra
    driverClassName: org.postgresql.Driver
    username: kestra
    password: k3str4
kestra:
  server:
    basicAuth:
      enabled: false
      username: ""admin@kestra.io"" # it must be a valid email address
      password: kestra
  repository:
    type: postgres
  storage:
    type: local
    local:
      basePath: ""/app/storage""
  queue:
    type: postgres
  tasks:
    tmpDir:
      path: ""/tmp/kestra-wd/tmp""
  url: ""http://localhost:8080/""
Note: this configuration is taken from our official docker-compose.yaml file and uses a PostgreSQL database, you may want to retrieve it there to be sure it is accurate.
Then, change the command to mount the file to the container and start Kestra with the configuration file; we also adjust the Kestra command to start a standalone version as we now have a PostgreSQL database as a backend.
bash
docker run --pull=always --rm -it -p 8080:8080 --user=root \
 -v $PWD/application.yaml:/etc/config/application.yaml \
 -v /var/run/docker.sock:/var/run/docker.sock \
 -v /tmp:/tmp kestra/kestra:latest server standalone --config /etc/config/application.yaml
Using the KESTRA_CONFIGURATION environment variable
You can adjust the Kestra configuration with a KESTRA_CONFIGURATION passed to the Docker container via the -e options. This environment variable must be a valid YAML string.
Managing a large configuration via a single YAML string can be tedious. To make that easier, you can leverage a configuration file.
First, define an environment variable:
bash
export KESTRA_CONFIGURATION=""datasources:
          postgres:
            url: jdbc:postgresql://postgres:5432/kestra
            driverClassName: org.postgresql.Driver
            username: kestra
            password: k3str4
        kestra:
          server:
            basicAuth:
              enabled: false
              username: ""admin@kestra.io"" # it must be a valid email address
              password: kestra
          repository:
            type: postgres
          storage:
            type: local
            local:
              basePath: ""/app/storage""
          queue:
            type: postgres
          tasks:
            tmpDir:
              path: /tmp/kestra-wd/tmp
          url: http://localhost:8080/
Note: this configuration is taken from our official docker-compose.yaml file and uses a PostgreSQL database, you may want to retrieve it there to be sure it is accurate.
Then pass this environment variable in the Docker command and adjust the Kestra command to run the standalone server:
bash
docker run --pull=always --rm -it -p 8080:8080 --user=root \
 -e KESTRA_CONFIGURATION=$KESTRA_CONFIGURATION
 -v /var/run/docker.sock:/var/run/docker.sock \
 -v /tmp:/tmp kestra/kestra:latest server standalone
Official Docker images
The official Kestra Docker images are available on DockerHub for both linux/amd64 and linux/arm64 platforms.
We provide two image variants:
kestra/kestra:*
kestra/kestra:*-no-plugins
Both variants are based on the eclipse-temurin:21-jre Docker image.
The kestra/kestra:* images contain all Kestra plugins in their latest version. The kestra/kestra:*-no-plugins images do not contain any plugins. We recommend using the kestra/kestra:* version.
Docker image tags
We provide the following tags for each Docker image:
latest: the default image with the latest stable release, including all plugins.
latest-no-plugins: the default image with the latest stable release, excluding all plugins.
v<release-version>: image for a specific Kestra release, including all plugins.
v<release-version>-no-plugins: image for a specific Kestra release, excluding all plugins.
develop: an image based on the develop branch that changes daily and contains unstable features we are working on, including all plugins.
develop-no-plugins: an image based on the develop branch that changes daily and contains unstable features we are working on, excluding all plugins.
The default Kestra image kestra/kestra:latest already includes all plugins. To use a lightweight version of Kestra without plugins, add a suffix *-no-plugins.
Recommended images for production
We recommend using the latest image for production deployments. This image includes the latest stable release and optionally also all plugins:
kestra/kestra:latest ‚Äî contains the latest stable version of Kestra and all plugins
kestra/kestra:latest-no-plugins ‚Äî contains the latest stable version of Kestra without any plugins.
If your deployment strategy is to pin the version, make sure to change the image as follows (here, based on the v0.18.0 release):
kestra/kestra:v0.18.0 if you want to have all plugins included in the image
kestra/kestra:v0.18.0-no-plugins if you prefer to use only your custom plugins.
Recommended images for development
The most recently developed (but not yet released) features and bug fixes are included in the develop image. This image is updated daily and contains the latest changes from the develop branch:
kestra/kestra:develop if you want to have all plugins included in the image
kestra/kestra:develop-no-plugins if you prefer to use only your custom plugins.
Build a custom Docker image
If the base or full image doesn't contain package dependencies you need, you can build a custom image by using the Kestra base image and adding the required binaries and dependencies.
Add custom binaries
The following Dockerfile creates an image from the Kestra base image and adds the golang binary and Python packages:
dockerfile
ARG IMAGE_TAG=latest
FROM kestra/kestra:$IMAGE_TAG
RUN mkdir -p /app/plugins && \
  apt-get update -y && \
  apt-get install -y --no-install-recommends golang && \
  apt-get install -y pip && \
  pip install pandas==2.0.3 requests==2.31.0 && \
  apt-get clean && rm -rf /var/lib/apt/lists/* /var/tmp/*
Add plugins to a Docker image
By default, the base Docker image kestra/kestra:latest contains all plugins (unless you use the kestra/kestra:latest-no-plugins version). You can add specific plugins to the base image and build a custom image.
The following example Dockerfile creates an image from the base image and adds the plugin-notifications, storage-gcs and plugin-gcp binaries using the command kestra plugins install:
dockerfile
ARG IMAGE_TAG=latest-no-plugins
FROM kestra/kestra:$IMAGE_TAG
RUN /app/kestra plugins install \
  io.kestra.plugin:plugin-notifications:LATEST \
  io.kestra.storage:storage-gcs:LATEST \
  io.kestra.plugin:plugin-gcp:LATEST
Add custom plugins to a Docker image
The above example Dockerfile installs plugins that have already been published to Maven Central. If you are developing a custom plugin, make sure to build it. Once the shadowJar is built, add it to the plugins directory:
dockerfile
ARG IMAGE_TAG=latest
FROM kestra/kestra:$IMAGE_TAG
RUN mkdir -p /app/plugins
COPY /build/libs/*.jar /app/plugins
Add custom plugins from a Git repository
If you would like to build custom plugins from a specific Git repository, you can use the following approach:
dockerfile
FROM openjdk:17-slim as stage-build
WORKDIR /
USER root
RUN apt-get update -y
RUN apt-get install git -y && \
    git clone https://github.com/kestra-io/plugin-aws.git
RUN cd plugin-aws && ./gradlew :shadowJar
FROM kestra/kestra:latest
# https://github.com/WASdev/ci.docker/issues/194#issuecomment-433519379
USER root
RUN mkdir -p /app/plugins && \
  apt-get update -y && \
  apt-get install -y --no-install-recommends golang && \
  apt-get install -y pip && \
  pip install pandas==2.0.3 requests==2.31.0 && \
  apt-get clean && rm -rf /var/lib/apt/lists/* /var/tmp/*
RUN rm -rf /app/plugins/plugin-aws-*.jar
COPY --from=stage-build /plugin-aws/build/libs/plugin-aws-*.jar /app/plugins
This multi-stage Docker build allows you to overwrite a plugin that has already been installed. In this example, the AWS plugin is by default already included in the kestra/kestra:latest image. However, it's overwritten by a plugin built in the first Docker build stage.
Was this page helpful?
Yes
No
Docs
Installation Guide
Installation
Docker Compose""""""",2208,9418,kestra
https://kestra.io/docs/installation/docker-compose,"""""""DocsInstallation GuideDocker Compose
Docker Compose
Table of Contents
Before you begin
Download the Docker Compose file
Launch Kestra
Adjusting the Configuration
Use a configuration file
Networking in Docker Compose
Postgres 16 Not Compatible with 17 Error
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Start Kestra with a PostgreSQL database backend using a Docker Compose file.
The quickest way to a production-ready lightweight Kestra installation is to leverage Docker and Docker Compose. This guide will help you get started with Kestra using Docker.
In order to run Kestra using docker-compose.yml file in production in rootless mode, please look at the Launch Kestra in Rootless Mode section on the Podman Compose page.
Before you begin
Make sure you have already installed:
Docker
Docker Compose
Download the Docker Compose file
Download the Docker Compose file using the following command on Linux and macOS:
bash
curl -o docker-compose.yml \
https://raw.githubusercontent.com/kestra-io/kestra/develop/docker-compose.yml
If you're on Windows, use the following command:
powershell
Invoke-WebRequest -Uri ""https://raw.githubusercontent.com/kestra-io/kestra/develop/docker-compose.yml"" -OutFile ""docker-compose.yml""
You can also download the Docker Compose file manually and save it as docker-compose.yml.
Launch Kestra
Use the following command to start the Kestra server:
bash
docker-compose up -d
Open the URL http://localhost:8080 in your browser to launch the UI.
Adjusting the Configuration
The command above starts a standalone server (all architecture components in one JVM).
The configuration will be done inside the KESTRA_CONFIGURATION environment variable of the Kestra container. You can update the environment variable inside the Docker compose file, or pass it via the Docker command line argument.
If you want to extend your Docker Compose file, modify container networking, or if you have any other issues using this Docker Compose file, check the Troubleshooting Guide.
Use a configuration file
If you want to use a configuration file instead of the KESTRA_CONFIGURATION environment variable to configure Kestra you can update the default docker-compose.yml.
First, create a configuration file containing the KESTRA_CONFIGURATION environment variable defined in the docker-compose.yml file. You can name it application.yaml.
Then, update kestra service in the docker-compose.yml file to mount this file into the container and make Kestra using it via the --config option:
yaml
# [...]
  kestra:
    image: kestra/kestra:latest
    pull_policy: always
    # Note that this is meant for development only. Refer to the documentation for production deployments of Kestra which runs without a root user.
    user: ""root""
    command: server standalone --worker-thread=128 --config /etc/config/application.yaml
    volumes:
      - kestra-data:/app/storage
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/kestra-wd:/tmp/kestra-wd
      - $PWD/application.yaml:/etc/config/application.yaml
    ports:
      - ""8080:8080""
      - ""8081:8081""
    depends_on:
      postgres:
        condition: service_started
Networking in Docker Compose
The default docker-compose file doesn't configure networking for the Kestra containers. This means that you won't be able to access any services exposed via localhost on your local machine (e.g., another Docker container with a mapped port). Your machine and Docker container use a different network. To use a locally exposed service from Kestra container, you can use the host.docker.internal hostname or 172.17.0.1. The host.docker.internal address allows you to reach your host machine's services from Kestra's container.
Alternatively, you can leverage Docker network. By default, your Kestra container will be placed in a default network. You can add your custom services to the docker-compose.yml file provided by Kestra and use the services' alias (keys from services) to reach them. Even better would be if you create a new network e.g. network kestra_net and add your services to it. Then you can add this network to the networks section of the kestra service. With this, you will have access via localhost to all your exposed ports.
The example below shows how you can add iceberg-rest, minio and mc (i.e. Minio client) to your Kestra Docker Compose file.
Example
Finally, you can also use the host network mode for the kestra service. This will make your container use your host network and you will be able to reach all your exposed ports. This means you have to change the services.kestra.environment.KESTRA_CONFIGURATION.datasources.postgres.url to jdbc:postgresql://localhost:5432/kestra. This is the easiest way but it can be a security risk.
See the example below using network_mode: host.
Example
Postgres 16 Not Compatible with 17 Error
By default, the Docker Compose template uses the latest image for postgres. However, if you initated your Kestra database on an older version of Postgres to the latest image, you might encounter the following error:
The data directory was initialized by PostgreSQL version 16, which is not compatible with this version 17.0 (Debian 17.0-1.pgdg120+1).
To resolve this, you need to specify a specific tag for the postgres image in your Docker Compose file. In the example below, we specify 16 as the error above was originally initialized by version 16:
yaml
services:
  postgres:
    image: postgres:16
Was this page helpful?
Yes
No
Installation
Docker
Installation
Kubernetes""""""",1232,5530,kestra
https://kestra.io/docs/installation/kubernetes,"""""""DocsInstallation GuideKubernetes
Kubernetes
Table of Contents
Helm Chart repository
Install the chart
Configuration
Docker in Docker (DinD) Worker side car
Troubleshooting
Docker in Docker (DinD)
Docker in Docker using Helm charts
Disable Docker in Docker and use Kubernetes task runner
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Install Kestra in a Kubernetes cluster using a Helm chart.
Helm Chart repository
We recommend Kubernetes deployment for production workloads, as it allows you to scale specific Kestra services as needed.
We provide an official Helm Chart to make the deployment easier.
The chart repository is available under helm.kestra.io.
The source code of the charts can be found in the kestra-io/helm-charts repository on GitHub.
All image tags provided by default can be found in the Docker installation guide.
Install the chart
bash
helm repo add kestra https://helm.kestra.io/
helm install kestra kestra/kestra
By default, the chart will only deploy one standalone Kestra service with one replica. This means that all Kestra server components will be deployed within a single pod. You can change that default behavior and deploy each service independently using the following Helm chart values:
yaml
deployments:
  webserver:
    enabled: true
  executor:
    enabled: true
  indexer:
    enabled: true
  scheduler:
    enabled: true
  worker:
    enabled: true
  standalone:
    enabled: false
The chart can also deploy the following related services:
A Kafka cluster and Zookeeper using kafka.enabled: true
An Elasticsearch cluster using elasticsearch.enabled: true
A MinIO standalone using minio.enabled: true
A PostgreSQL using postgresql.enabled: true
The MinIO (as the internal storage backend) and PostgreSQL (as the database backend) services are enabled by default to provide a fully working setup out of the box.
All external services (Kafka, Elasticsearch, Zookeeper, MinIO, PostgreSQL) are deployed using unsecured configurations (no authentication, no TLS, etc.). When installing for a production environment, make sure to adjust their configurations to secure your deployment.
Configuration
Here is how you can adjust the Kestra configuration:
Using a Kubernetes ConfigMap via the configuration Helm value.
Using a Kubernetes Secret via the secrets Helm value.
Both must be valid YAML that will be merged as the Kestra configuration file.
Here is an example showing how to enable Kafka as the queue implementation and configure its bootstrap.servers property using a secret:
yaml
configuration:
  kestra:
    queue:
      type: kafka
secrets:
  kestra:
    kafka:
      client:
        properties:
          bootstrap.servers: ""localhost:9092""
Docker in Docker (DinD) Worker side car
By default, Docker in Docker (DinD) is installed on the worker in the rootless version. This can be restricted on some environment due to security limitations.
Some solutions you may try:
On Google Kubernetes Engine (GKE), use a node pool based on UBUNTU_CONTAINERD that works well with Docker DinD, even rootless
Some Kubernetes clusters support only a root version of DinD; to make your Kestra deployment work, disable the rootless version using the following Helm chart values:
yaml
dind:
  image:
    image: docker
    tag: dind
  args:
    - --log-level=fatal
Troubleshooting
Docker in Docker (DinD)
If you face some issues using Docker in Docker e.g. with Script tasks using DOCKER runner, start troubleshooting by attaching the terminal: docker run -it --privileged docker:dind sh. Then, use docker logs container_ID to get the container logs. Also, try docker inspect container_ID to get more information about your Docker container. The output from this command displays details about the container, its environments, network settings, etc. This information can help you identify what might be wrong.
Docker in Docker using Helm charts
On some Kubernetes deployments, using DinD with our default Helm charts can lead to:
bash
Device ""ip_tables"" does not exist.
ip_tables              24576  4 iptable_raw,iptable_mangle,iptable_nat,iptable_filter
modprobe: can't change directory to '/lib/modules': No such file or directory
error: attempting to run rootless dockerd but need 'kernel.unprivileged_userns_clone' (/proc/sys/kernel/unprivileged_userns_clone) set to 1
To fix this, use root to launch the DinD container by setting the following values:
yaml
dind:
  image:
    tag: dind
  args:
    - --log-level=fatal
  securityContext:
    runAsUser: 0
    runAsGroup: 0
securityContext:
  runAsUser: 0
  runAsGroup: 0
Disable Docker in Docker and use Kubernetes task runner
To avoid using root to spin up containers via DinD, disable DinD by setting the following Helm chart values:
yaml
dind:
  enabled: false
Then, set Kubernetes task runner as the default way to run script tasks:
yaml
pluginDefaults:
  - type: io.kestra.plugin.scripts
    forced: true
    values:
      taskRunner:
        type: io.kestra.plugin.ee.kubernetes.runner.Kubernetes
        # ... your Kubernetes runner configuration
Was this page helpful?
Yes
No
Installation
Docker Compose
Installation
Kubernetes on AWS EKS with Amazon RDS and S3""""""",1170,5176,kestra
https://kestra.io/docs/installation/kubernetes-aws-eks,"""""""DocsInstallation GuideKubernetes on AWS EKS with Amazon RDS and S3
Kubernetes on AWS EKS with Amazon RDS and S3
Table of Contents
Overview
Launch an EKS Cluster
Launch AWS RDS for PostgreSQL
Prepare an AWS S3 Bucket
Install Kestra on AWS EKS
Access Kestra UI
Next steps
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Deploy Kestra to AWS EKS with PostgreSQL RDS database and S3 internal storage backend.
Overview
This guide provides detailed instructions for deploying Kestra to AWS Elastic Kubernetes Service (EKS) with a PostgreSQL RDS database backend, and AWS S3 for internal storage.
Prerequisites:
Basic command line interface skills.
Familiarity with AWS EKS, RDS, S3, and Kubernetes.
Launch an EKS Cluster
First, install eksctl and kubectl. After installing them, you can create the EKS cluster. There are plenty of configuration options available with eksctl, but the default settings are sufficient for this guide. Run the following command to create a cluster named my-kestra-cluster:
shell
eksctl create cluster --name my-kestra-cluster --region us-east-1
Wait for the cluster to be created. Then, confirm that the cluster is up, and that your kubecontext points to the cluster:
shell
kubectl get svc
Launch AWS RDS for PostgreSQL
Navigate to the RDS console to create a PostgreSQL database. Configure the settings, ensuring the database is accessible from your EKS cluster. Note the database endpoint and port after creation.
Prepare an AWS S3 Bucket
Create a private S3 bucket (private meaning that public access is blocked). Keep a record of the bucket name as this is needed for the Kestra configuration.
Install Kestra on AWS EKS
Add the Kestra Helm chart repository and install Kestra:
shell
helm repo add kestra https://helm.kestra.io/
helm install my-kestra kestra/kestra
In the deployment configuration, integrate RDS and S3. Set the database connection under datasources and S3 details under storage in your Helm values.
Here is how you can configure RDS in the Helm chart's values:
yaml
configuration:
  kestra:
    queue:
      type: postgres
    repository:
      type: postgres
  datasources:
    postgres:
      url: jdbc:postgresql://<your-rds-url-endpoint>:5432/kestra
      driverClassName: org.postgresql.Driver
      username: your_username
      password: your_password
Also, disable the PostgreSQL pod by changing the enabled value in the postgresql section from true to false in the same file.
yaml
postgresql:
  enabled: false
And here is how you can add the S3 configuration in the Helm chart's values:
yaml
configuration:
  kestra:
    storage:
      type: s3
      s3:
        accessKey: ""<your-aws-access-key-id>""
        secretKey: ""<your-aws-secret-access-key>""
        region: ""<your-aws-region>""
        bucket: ""<your-s3-bucket-name>""
Also, disable the Minio pod by changing the enabled value in the minio section from true to false in the same file.
yaml
minio:
  enabled: false
Apply these configurations using the following command:
bash
helm upgrade kestra kestra/kestra -f values.yaml
Access Kestra UI
Implement an ingress controller for access. You can install the AWS Load Balancer (ALB) Controller via Helm:
shell
helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
-n kube-system \
--set clusterName=my-kestra-cluster \
--set serviceAccount.create=false \
--set serviceAccount.name=aws-load-balancer-controller
Once the ALB is set, you can access the Kestra UI through the ALB URL.
Next steps
This guide walked you through installing Kestra to AWS EKS with PostgreSQL RDS database and S3 storage backend.
Reach out via Slack if you encounter any issues or if you have any questions regarding deploying Kestra to production.
Was this page helpful?
Yes
No
Installation
Kubernetes
Installation
Kubernetes on GCP GKE with CloudSQL and Cloud Storage""""""",899,3851,kestra
https://kestra.io/docs/installation/kubernetes-gcp-gke,"""""""DocsInstallation GuideKubernetes on GCP GKE with CloudSQL and Cloud Storage
Kubernetes on GCP GKE with CloudSQL and Cloud Storage
Table of Contents
Overview
Launch an GKE Cluster
Install Kestra on GCP GKE
Workload Identity Setup
Launch CloudSQL
Prepare a GCS bucket
Commented-out Examples in values.yaml
Next steps
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Deploy Kestra to GCP GKE with CloudSQL as a database backend and Google Cloud Storage as internal storage backend.
Overview
This guide provides detailed instructions for deploying Kestra to Google Kubernetes Engine (GKE) with CloudSQL as database backend, and Google Cloud Storage(GCS) for internal storage.
Prerequisites:
Basic command line interface skills.
Familiarity with GCP GKE, PostgreSQL, GCS, and Kubernetes.
Launch an GKE Cluster
First, login to GCP using gcloud init.
Run the following command to create an GKE cluster named my-kestra-cluster:
shell
gcloud container clusters create my-kestra-cluster --region=europe-west3
Confirm using the GCP console that the cluster is up.
Before proceeding, check whether the gke-gcloud-auth-plugin plugin is already installed:
shell
gke-gcloud-auth-plugin --version
If the output displays version information, skip this section.
You can install the authentication plugin using:
shell
gcloud components install gke-gcloud-auth-plugin
Run the following command to have your kubecontext point to the newly created cluster:
shell
gcloud container clusters get-credentials my-kestra-cluster --region=europe-west3
You can now confirm that your kubecontext points to the GKE cluster using:
shell
kubectl get svc
Install Kestra on GCP GKE
Add the Kestra Helm chart repository and install Kestra:
shell
helm repo add kestra https://helm.kestra.io/
helm install my-kestra kestra/kestra
Workload Identity Setup
If you are using Google Cloud Workload Identity, you can annotate your Kubernetes service account in the Helm chart configuration. This will allow Kestra to automatically use the associated GCP service account for authentication.
To configure this, you can add the following to your ""values.yaml"" file:
yaml
serviceAccount:
  create: true
  name: <your-service-account-name>
  annotations:
    iam.gke.io/gcp-service-account: ""<gcp-service-account>@<gcp-project-id>.iam.gserviceaccount.com""
Alternatively, you can apply the annotation directly when you install Kestra using Helm:
shell
helm install my-kestra kestra/kestra \
  --set serviceAccount.annotations.iam.gke.io/gcp-service-account=<gcp-service-account>@<gcp-project-id>.iam.gserviceaccount.com
This configuration links your Kubernetes service account to the GCP service account, enabling Workload Identity for secure access to Google Cloud resources.
Launch CloudSQL
Go to the Cloud SQL console.
Click on Choose PostgreSQL (Kestra also supports MySQL, but PostgreSQL is recommended).
Put an appropriate Instance ID and password for the admin user postgres.
Select the latest PostgreSQL version from the dropdown.
Choose Enterprise Plus or Enterprise edition based on your requirements.
Choose an appropriate preset among Production, Development or Sandbox as per your requirement.
Choose the appropriate region and zonal availability.
Hit create and wait for completion.
Enable VM connection to database
Go to the database overview page and click on Connections from the left-side navigation menu.
Go to the Networking tab, and click on Add a Network.
In the New Network section, add an appropriate name like Kestra VM, and put your GKE pods IP address range in the Network.
Click on Done in the section.
Click on Save on the page.
Create database user
Go to the database overview page and click on Users from the left-side navigation menu.
Click on Add User Account.
Put an appropriate username and password, and click on Add.
Create Kestra database
Go to the database overview page, and click on Databases from the left side navigation menu.
Click on Create Database.
Put an appropriate database name, and click on Create.
Update Kestra configuration
Here is how you can configure CloudSQL Database in the Helm chart's values:
yaml
configuration:
  kestra:
    queue:
      type: postgres
    repository:
      type: postgres
  datasources:
    postgres:
      url: jdbc:postgresql://<your-db-external-endpoint>:5432/<db_name>
      driverClassName: org.postgresql.Driver
      username: <your-username>
      password: <your-password>
Also, disable the postgres pod by changing enabled value in the postgresql section from true to false in the same file.
yaml
postgresql:
  enabled: false
In order for the changes to take effect, run the helm upgrade command as:
shell
helm upgrade my-kestra kestra/kestra -f values.yaml
Prepare a GCS bucket
By default, minio pod is being used as storage backend. This section will guide you on how to change the storage backend to Google Cloud Storage.
By default, internal storage is implemented using the local file system. This section will guide you on how to change the storage backend to Cloud Storage to ensure more reliable, durable, and scalable storage.
Go to the Cloud Storage console and create a bucket.
Go to IAM and select Service Accounts from the left-side navigation menu.
On the Service Accounts page, click on Create Service Account at the top of the page.
Put the appropriate Service account name and Service account description, and grant the service account Storage Admin access. Click Done.
On the Service Accounts page, click on the newly created service account.
On the newly created service account page, go to the Keys tab at the top of the page and click on Add Key. From the dropdown, select Create New Key.
Select the Key type as JSON and click on Create. The JSON key file for the service account will get downloaded.
We will be using the stringified JSON for our configuration. You can use the bash command % cat <path_to_json_file> | jq '@json' to generate stringified JSON.
Edit Kestra storage configuration in the Helm chart's values.
Note: If you want to use a Kubernetes service account configured as a workload identify, you don't need to provide anything for serviceAccount as it will be autodetected for the pod configuration if it's well configured.
yaml
configuration:
  kestra:
    storage:
      type: gcs
      gcs:
        bucket: ""<your-cloud-storage-bucket-name>""
        projectId: ""<your-gcp-project-name>""
        serviceAccount: |
          ""<stringified-json-file-contents>""
Also, disable the minio pod by changing enabled value in the minio section from true to false in the same file.
yaml
minio:
  enabled: false
In order for the changes to take effect, run the helm upgrade command as:
shell
helm upgrade my-kestra kestra/kestra -f values.yaml
You can validate the storage change from minio to Google Cloud Storage by executing the flow example below with a file and then checking it is uploaded to Google Cloud Storage.
yaml
id: inputs
namespace: company.team
inputs:
  - id: file
    type: FILE
tasks:
  - id: validator
    type: io.kestra.plugin.core.log.Log
    message: User {{ inputs.file }}
Commented-out Examples in values.yaml
To provide users with clear guidance on configuring the values.yaml file, we have included some commented-out examples in the configuration. These examples can be used to set up various aspects of Kestra, such as secrets, database configurations, and other key parameters. You can uncomment and modify them as needed.
Here‚Äôs an example of how you can define secrets and other configurations in the values.yaml file:
yaml
# Example configuration for secrets:
configuration:
  kestra:
    # Configure this section to set secrets for your Kestra instance.
    # secret:
    #   - name: ""MY_SECRET_KEY""
    #     value: ""my-secret-value""
    #   - name: ""ANOTHER_SECRET""
    #     valueFrom:
    #       secretKeyRef:
    #         name: ""my-k8s-secret""
    #         key: ""my-secret-key""
    # Configure this section to use PostgreSQL as the queue and repository backend.
    # queue:
    #   type: postgres
    # repository:
    #   type: postgres
    # Example of connecting to a PostgreSQL database:
    # datasources:
    #   postgres:
    #     url: jdbc:postgresql://<your-db-endpoint>:5432/<db-name>
    #     driverClassName: org.postgresql.Driver
    #     username: <your-username>
    #     password: <your-password>
# Example to disable default services like MinIO and PostgreSQL if you're using external services:
minio:
  # enabled: false
postgresql:
  # enabled: false
In this example:
-Secrets: You can configure sensitive values as secrets, either hardcoding them or referencing existing Kubernetes secrets.
-Queue and Repository: By default, these can use PostgreSQL or any other supported type. Uncomment the relevant lines to use them.
-PostgreSQL Configuration: Set the datasources section to provide details for connecting to a PostgreSQL database.
-Disabling Services: If you're using external services like CloudSQL or Google Cloud Storage, you can disable the built-in services (MinIO and PostgreSQL).
Feel free to uncomment and modify these examples based on your setup needs. This provides flexibility while keeping your values.yaml well-structured.
Next steps
This guide walked you through installing Kestra to Google GKE with CloudSQL as database and Google Cloud Storage as storage backend.
Reach out via Slack if you encounter any issues or if you have any questions regarding deploying Kestra to production.
Was this page helpful?
Yes
No
Installation
Kubernetes on AWS EKS with Amazon RDS and S3
Installation
Kubernetes on Azure AKS with Azure Database and Blob Storage""""""",2108,9631,kestra
https://kestra.io/docs/installation/kubernetes-azure-aks,"""""""DocsInstallation GuideKubernetes on Azure AKS with Azure Database and Blob Storage
Kubernetes on Azure AKS with Azure Database and Blob Storage
Table of Contents
Overview
Launch an AKS Cluster
Install Kestra on Azure AKS
Launch Azure Database for PostgreSQL servers
Prepare an Azure Blob Storage container
Access Kestra UI
Next steps
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Deploy Kestra to Azure AKS with Azure Database for PostgreSQL servers as a database backend and Blob Storage as internal storage backend.
Overview
This guide provides detailed instructions for deploying Kestra to Azure Kubernetes Service (AKS) with Azure Database for PostgreSQL servers as database backend, and Blob Storage for internal storage.
Prerequisites:
Basic command line interface skills.
Familiarity with Azure AKS, PostgreSQL, Blob Storage, and Kubernetes.
Launch an AKS Cluster
First, login to Azure using az login.
Run the following command to create an AKS cluster named my-kestra-cluster:
shell
az aks create \
  --resource-group <resource-group> \
  --name my-kestra-cluster \
  --enable-managed-identity \
  --node-count 1 \
  --generate-ssh-keys
Confirm that the cluster is up.
Run the following command to have your kubecontext point to the newly created cluster:
shell
az aks get-credentials --resource-group <resource-group> --name my-kestra-cluster
You can now confirm that your kubecontext points to the AKS cluster using:
shell
kubectl get svc
Install Kestra on Azure AKS
Add the Kestra Helm chart repository and install Kestra:
shell
helm repo add kestra https://helm.kestra.io/
helm install my-kestra kestra/kestra
Launch Azure Database for PostgreSQL servers
This first installation relies on a PostgreSQL database running alongside the Kestra server - on a separate pod.
However, for a production-grade installation, we recommend a managed database service such as Azure Database for PostgreSQL servers.
Launch a database using Azure Database for PostgreSQL servers
Go to the Azure Database for PostgreSQL servers.
Click on Create Azure Database for PostgreSQL server (Kestra also supports MySQL, but PostgreSQL is recommended).
Choose an appropriate Subscription and Resource Group.
Put an appropriate Server name, and select the preferred Region.
Choose the latest PostgreSQL version. We recommend version 15.
Select the Workload type as per your requirement.
Choose Authentication method as PostgreSQL authentication only.
Provide an appropriate Admin username and Password.
Click on Next: Networking.
Select the box for Allow public access from any Azure service within Azure to this server.
Click on Review + Create. Review the configurations and click on Create.
Wait for the database to be provisioned.
Create a Kestra database
Go to the database overview page, and click on Databases from the left side navigation menu.
Click on Add.
Put an appropriate database name, and click on Save at the top.
Update Kestra configuration
Here is how you can configure Azure Database in the Helm chart's values:
yaml
configuration:
  kestra:
    queue:
      type: postgres
    repository:
      type: postgres
  datasources:
    postgres:
      url: jdbc:postgresql://<your-db-external-endpoint>:5432/<db_name>
      driverClassName: org.postgresql.Driver
      username: <your-username>
      password: <your-password>
Also, disable the PostgreSQL pod by changing enabled value in the postgresql section from true to false in the same file.
yaml
postgresql:
  enabled: false
In order for the changes to take effect, run the helm upgrade command as:
shell
helm upgrade my-kestra kestra/kestra -f values.yaml
Prepare an Azure Blob Storage container
By default, Minio pod is being used as storage backend. This section will guide you on how to change the storage backend to Blob Storage.
Go to the Storage Accounts.
Click on Create.
Choose an appropriate Subscription and Resource Group.
Put an appropriate Storage account name, and select the preferred Region.
Select Performance and Redundancy as per your requirement.
Click on Review, and post reviewing the configurations, click on Create.
Click on the newly created storage account.
On the storage account overview page, click on the Containers from the left side navigation menu.
Click on Create button at the top to create a new container.
Put an appropriate name for the container, and click on Create. A new container will be created.
Now, click on Access keys from the left side navigation menu.
For one of the keys, either key1 or key2, click on Show for the Connection string, and click on Copy to clipboard button.
Note down the connection string with you. We will require this for configuring the storage backend.
Here is how you can add Blob Storage configuration in the Helm chart's values:
yaml
configuration:
  kestra:
    storage:
      type: azure
      azure:
        container: ""<your-container>""
        endpoint: ""https://<your-storage-account>.blob.core.windows.net/""
        connectionString: ""<your-connection-string>""
Also, disable the Minio pod by changing the enabled value in the minio section from true to false in the same file.
yaml
minio:
  enabled: false
In order for the changes to take effect, run the helm upgrade command as:
shell
helm upgrade my-kestra kestra/kestra -f values.yaml
Access Kestra UI
Note that you will have to create an Application Gateway in Azure for creating an ingress controller.
Implement an ingress controller for access. You can install AKS Load Balancer Controller via Helm:
shell
helm install aks-load-balancer-controller application-gateway-kubernetes-ingress/ingress-azure \
     --set appgw.name=kestra-application-gateway \
     --set appgw.resourceGroup=<resource-group> \
     --set appgw.subscriptionId=<subscription-uuid> \
     --set appgw.shared=false \
     --set armAuth.type=servicePrincipal \
     --set armAuth.secretJSON=$(az ad sp create-for-rbac --role Contributor --scopes /subscriptions/<subscription-uuid>/resourceGroups/<resource-group> --sdk-auth | base64 -w0) \
     --set rbac.enabled=true \
     --set verbosityLevel=3 \
     --set kubernetes.watchNamespace=default \
     --set aksClusterConfiguration.apiServerAddress=<aks-server-address>
Once the load balancer is set, you can access the Kestra UI through the ALB URL.
Next steps
This guide walked you through installing Kestra to Azure AKS with Azure Database for PostgreSQL as database and Blob Storage as storage backend.
Reach out via Slack if you encounter any issues or if you have any questions regarding deploying Kestra to production.
Was this page helpful?
Yes
No
Installation
Kubernetes on GCP GKE with CloudSQL and Cloud Storage
Installation
AWS EC2 with Amazon RDS and S3""""""",1445,6712,kestra
https://kestra.io/docs/installation/aws-ec2,"""""""DocsInstallation GuideAWS EC2 with Amazon RDS and S3
AWS EC2 with Amazon RDS and S3
Table of Contents
Step 1: Create an EC2 instance & install Docker
Step 2: Download and Run Kestra
Step 3: Allow external traffic
Step 4: Use AWS RDS PostgreSQL as a database backend
Step 5: Use AWS S3 for storage
Next steps
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Install Kestra on AWS EC2 with PostgreSQL RDS database and S3 internal storage backend.
This guide provides instructions for deploying Kestra on Amazon Web Services (AWS). We‚Äôll use an EC2 with Docker to host Kestra server, a PostgreSQL RDS database and AWS S3 as storage backend.
Prerequisites:
basic knowledge about using a command line interface
basic knowledge about EC2, S3 and PostgreSQL.
You can find the corresponding full Terraform configuration in this repository.
Step 1: Create an EC2 instance & install Docker
First, create an EC2 instance. To do so, go to the AWS console and choose EC2.
Give a name to your instance.
Choose Ubuntu as your OS.
Instance type: Kestra needs at least 4GiB Memory and 2vCPU to run correctly. Choosing t3-medium is a good starting point.
Create a key-pair to securely connect to your instance. This key is needed to connect through SSH in the following steps.
Create a security group that allows SSH traffic from your IP. Also allow HTTPS traffic.
You can now click on ‚ÄúLaunch instance‚Äù and wait a few seconds for the instance to be up and running.
Then you can open a terminal on your laptop and connect to your instance through SSH: ssh -i <your-key-pair.pem> ubuntu@<your-EC2-public-IP>
Kestra can be run directly from the .jar binary or using Docker. We‚Äôll use Docker here for quicker setup:
Install Docker on the EC2 instance. You can find the last updated instruction on the Docker website.
Install docker-compose.
To check your installation, run docker version and docker-compose version. You're now ready to download and launch the Kestra server.
Step 2: Download and Run Kestra
Download the official Docker-Compose file:
bash
curl -o docker-compose.yml \
https://raw.githubusercontent.com/kestra-io/kestra/develop/docker-compose.yml
Use an editor such as Vim to modify the docker-compose.yml and set basic authentication to true, and configure your basic authentication credentials to secure your Kestra instance. Make sure to add a valid email address too.
yaml
kestra:
  server:
    basicAuth:
      enabled: true
      username: admin@kestra.io # it must be a valid email address
      password: kestra
Then use the following command to start the Kestra server: docker-compose up -d
Step 3: Allow external traffic
Kestra is now running and the Kestra server is exposing traffic on the 8080 port. To connect through your web browser, update the inbound traffic rules in the EC2 security group.
Go to the EC2 console, and select Security Group. Choose the security group attached to your EC2 instance and add a new inbound rule to open access to the 8080 port. If you did not select an existing security group when creating the instance the security group will be prefixed with ""launch-wizard-"".
If you want to only allow traffic coming from your IP address, set the source to your own IP. If you want to make it open to the entire Internet, leave it at 0.0.0.0.
Note that if you haven't set up basic authentication in the previous step, your Kestra instance will be publicly available to anyone without any access restriction.
You can now access your Kestra instance and create, edit and run Flows.
Step 4: Use AWS RDS PostgreSQL as a database backend
This first installation relies on a PostgreSQL database running alongside the Kestra server on the EC2 instance (see the PostgreSQL service running thanks to the docker-compose).
For a simple proof of concept (PoC), you can keep the PostgreSQL database running in Docker.
However, for a production-grade installation, we recommend a managed database service such as AWS RDS.
Create a AWS RDS database
Go to the RDS console.
Create a database and choose PostgreSQL (Kestra also supports MySQL, but PostgreSQL is recommended)
Set a username and password.
On the connectivity configuration choose ‚ÄúConnect to an EC2 compute resource‚Äù and choose your EC2 instance.
Also select the existing DB subnet group and existing VPC security group and choose the one attached to your EC2 instance.
Fine-tune instance class, and storage type to avoid import AWS costs. For a first step, a small PostgreSQL instance is enough
Hit create and wait for completion
Create Kestra database
Before attaching your Kestra server to our new database backend, initialize the database with a base schema as follows:
Connect to your EC2 instance with ssh
Install a PostgreSQL client: sudo apt-get install postgresql-client
Create the Kestra database: createdb -h <your-rds-url-endpoint> -U <your-username> -p 5432 kestra
Update Kestra configuration
In the docker-compose configuration, edit the datasources property of the Kestra service in the following way:
yaml
datasources:
  postgres:
    url: jdbc:postgresql://<your-rds-url-endpoint>:5432/kestra
    driverClassName: org.postgresql.Driver
    username: <your-username>
    password: <your-password>
Because you now use RDS service, you don't need the PostgreSQL service anymore. Remove it from the docker-compose.yml file.
In order for the changes to take effect, restart the docker services with docker compose restart or docker compose up -d.
Step 5: Use AWS S3 for storage
By default, internal storage is implemented using the local file system. This section will guide you on how to change the storage backend to S3 to ensure a more reliable, durable and scalable storage.
Go to the S3 console and create a bucket.
Go to IAM and create a new User Group with AWS S3 full access.
Create a new user and attach it to the user group.
For the new user, go to Security Credentials and create an access key. Choose ‚ÄúApplication running on an AWS compute service‚Äù and retrieve the access and secret keys.
Edit the Kestra storage configuration.
yaml
kestra:
  storage:
      type: s3
      s3:
        accessKey: ""<your-aws-access-key-id>""
        secretKey: ""<your-aws-secret-access-key>""
        region: ""<your-aws-region>""
        bucket: ""<your-s3-bucket-name>""
Restart docker services.
For more information on S3 storage configuration, check out the guide here.
Next steps
This guide walked you through installing Kestra on an AWS EC2 instance with RDS database and S3 storage backend.
This setup provides the easiest starting point for running Kestra in production on a single machine. For a deployment to a distributed cluster, check the Kubernetes deployment guide.
Reach out via Slack if you encounter any issues or if you have any questions regarding deploying Kestra to production.
Make sure to also check the CI/CD guide to automate your workflow deployments based on changes in Git.
Was this page helpful?
Yes
No
Installation
Kubernetes on Azure AKS with Azure Database and Blob Storage
Installation
GCP VM with Cloud SQL and GCS""""""",1595,7052,kestra
https://kestra.io/docs/installation/gcp-vm,"""""""DocsInstallation GuideGCP VM with Cloud SQL and GCS
GCP VM with Cloud SQL and GCS
Table of Contents
Overview
Create a VM instance
Install Docker
Install Kestra
Launch Cloud SQL
Configure GCS
Next steps
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Install Kestra on a GCP VM with Cloud SQL PostgreSQL database backend and Cloud Storage as internal storage backend.
Overview
This guide provides instructions for deploying Kestra on Google Cloud Platform (GCP). We‚Äôll use Compute Engine with Docker to host Kestra server, a PostgreSQL Cloud SQL database and Cloud Storage as storage backend.
Prerequisites:
basic knowledge about using a command line interface
basic knowledge about Compute Engine, Cloud Storage and PostgreSQL.
Create a VM instance
First, create a VM instance using the Compute Engine. To do so, go to the GCP console and choose Compute Engine.
Click on the Create Instance button at the top.
Give a name to your instance.
Choose an appropriate Region and Zone.
Choose the General Purpose machine of the E2 series.
Machine type: Kestra needs at least 4GiB Memory and 2vCPU to run correctly. Choosing the Preset machine type e2-standard-2 is a good starting point.
Click on Change in the ""Boot Disk"" section, as we would like to change the image.
Under the ""Public Images"" tab, choose Ubuntu as the operating system and the Ubuntu 22.04 LTS version.
Continue with the ""Allow default access"" access scope, and select ""Allow HTTPS traffic"" in the Firewall section.
You can now click on ""Create"" and wait a few seconds for the VM instance to be up and running.
Install Docker
Click on the SSH button on the right side of the VM instance details to SSH into the VM instance terminal. Click on the Authorize button in the pop-up to authorize the SSH connection into the VM instance.
Kestra can be started directly from a .jar binary or using Docker. We‚Äôll use Docker here for a quicker setup. Install Docker on the GCP VM instance. You can find the last updated instruction on the Docker website.
To check your installation, run sudo docker version and sudo docker compose version. You're now ready to download and launch the Kestra server.
Install Kestra
Download the official Docker-Compose file:
bash
curl -o docker-compose.yml \
https://raw.githubusercontent.com/kestra-io/kestra/develop/docker-compose.yml
Use an editor such as Vim to modify the docker-compose.yml, set basic authentication to true, and configure your basic authentication credentials to secure your Kestra instance.
yaml
kestra:
  server:
    basicAuth:
      enabled: true
      username: admin@kestra.io # it must be a valid email address
      password: kestra
Note that if you haven't set up basic authentication in the previous step, your Kestra instance will be publicly available to anyone without any access restriction.
You can now access your Kestra instance and start developing flows.
Launch Cloud SQL
This first installation relies on a PostgreSQL database running alongside the Kestra server - on the VM instance (see the PostgreSQL service running thanks to the docker-compose).
For a simple proof of concept (PoC), you can keep the PostgreSQL database running in Docker.
However, for a production-grade installation, we recommend a managed database service such as Cloud SQL.
Create a Cloud SQL database
Go to the Cloud SQL console.
Click on Choose PostgreSQL (Kestra also supports MySQL, but PostgreSQL is recommended).
Put an appropriate Instance ID and password for the admin user postgres.
Select the latest PostgreSQL version from the dropdown.
Choose Enterprise Plus or Enterprise edition based on your requirements.
Choose an appropriate preset among Production, Development or Sandbox as per your requirement.
Choose the appropriate region and zonal availability.
Expand Show Show Configuration Options at the bottom of the page.
Enable VM connection to database
Expand the Connections section from the dropdown.
Uncheck Public IP and check Private IP. If this is your first time using a Private IP connection, you will be prompted to Setup Connection.
You will then need to choose Enable API on the right hand side pop out.
Choose Use an automatically allocated IP range and click Continue.
Click on Create Connection.
Enable Deletion
If you are just testing or would like to be able to delete your instance and all of it's data:
Expand out the Data Protection on the left hand side and make sure Enable deletion protection is UNCHECKED
Create database user
Go to the database overview page and click on Users from the left-side navigation menu.
Click on Add User Account.
Put an appropriate username and password, and click on Add.
Create Kestra database
Go to the database overview page, and click on Databases from the left side navigation menu.
Click on Create Database.
Put an appropriate database name, and click on Create.
Update Kestra configuration
In the docker-compose configuration, edit the datasources property of the Kestra service in the following way:
yaml
datasources:
  postgres:
    url: jdbc:postgresql://<your-db-external-endpoint>:5432/<db_name>
    driverClassName: org.postgresql.Driver
    username: <your-username>
    password: <your-password>
And delete the depends_on section at the end of the YAML file:
yaml
depends_on:
  postgres:
    condition: service_started
Because you now use the Cloud SQL service, you don't need the PostgreSQL Docker service anymore. Remove it from the docker-compose.yml file.
In order for the changes to take effect, restart the docker services with sudo docker compose restart or sudo docker compose up -d.
Configure GCS
By default, internal storage is implemented using the local file system. This section will guide you on how to change the storage backend to Cloud Storage to ensure more reliable, durable, and scalable storage.
Go to the Cloud Storage console and create a bucket.
Go to IAM and select Service Accounts from the left-side navigation menu.
On the Service Accounts page, click on Create Service Account at the top of the page.
Put the appropriate Service account name and Service account description, and grant the service account Storage Admin access. Click Done.
On the Service Accounts page, click on the newly created service account.
On the newly created service account page, go to the Keys tab at the top of the page and click on Add Key. From the dropdown, select Create New Key.
Select the Key type as JSON and click on Create. The JSON key file for the service account will get downloaded.
We will be using the stringified JSON for our configuration. You can use the bash command % cat <path_to_json_file> | jq '@json' to generate stringified JSON.
Edit the Kestra storage configuration.
yaml
kestra:
  storage:
    type: gcs
    gcs:
      bucket: ""<your-cloud-storage-bucket-name>""
      projectId: ""<your-gcp-project-name>""
      serviceAccount: ""<stringified-json-file-contents>""
In order for the changes to take effect, restart the docker services with sudo docker compose restart or sudo docker compose up -d.
Next steps
This guide walked you through installing Kestra on a GCP VM instance with Cloud SQL database and Cloud Storage as storage backend.
This setup provides the easiest starting point for running Kestra in production on a single machine. For a deployment to a distributed cluster on GCP, check the GKE Kubernetes deployment guide.
Reach out via Slack if you encounter any issues or if you have any questions regarding deploying Kestra to production.
Make sure to also check the CI/CD guide to automate your workflow deployments based on changes in Git.
Was this page helpful?
Yes
No
Installation
AWS EC2 with Amazon RDS and S3
Installation
Azure VM with Azure Database""""""",1620,7714,kestra
https://kestra.io/docs/installation/azure-vm,"""""""DocsInstallation GuideAzure VM with Azure Database
Azure VM with Azure Database
Table of Contents
Create an Azure VM
Install Docker
Install Kestra
Allow external traffic
Launch Azure Database
Configure Azure Blob Storage
Next steps
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Install Kestra on Azure VM with Azure Database as a database backend and Blob Storage as internal storage backend.
This guide provides instructions for deploying Kestra on Azure VM with Azure Database as a database backend and Blob Storage as internal storage backend.
Prerequisites:
basic knowledge about using a command line interface
basic knowledge about Azure and PostgreSQL.
Create an Azure VM
First, create a virtual machine using Azure Virtual Machines. To do so, go to the Azure portal and choose Virtual Machines.
Click on Create and select Azure Virtual Machine.
Choose an appropriate Subscription and Resource Group.
Give a name for your VM, and choose a Region where it should be launched.
For Availability options, choose Availabilty zone, and keep the default availability zone.
For Image, choose Ubuntu Server 22.04 LTS - x64 Gen2, and x64 as the VM architecture.
Kestra needs at least 4GiB Memory and 2vCPU to run correctly. Choosing the Size as Standard_D2s_v3 is a good starting point.
Select SSH public key as the Authentication type.
You can keep the default azureuser as the Username.
For SSH public key source, you can select Generate new key pair, and provide an appropriate name for the key pair.
For Public inbound ports, choose Allow selected ports, and from the Select inbound ports dropdown, select HTTPS and SSH.
Click on Review + Create.
You can now review the configurations and click on ""Create"". On the Generate new key pair popup, click on Download private key and create resource.
Wait until the virtual machine is up and running.
Install Docker
In your terminal, run the following commands to SSH into the virtual machine:
shell
chmod 400 <your-key-pair.pem>
ssh -i <your-key-pair.pem> azureuser@<your-VM-public-IP>
Kestra can be started directly from a .jar binary or using Docker. We‚Äôll use Docker here for a quick setup:
Install Docker on the Azure VM instance. You can find the last updated instruction on the Docker website.
Install docker-compose.
To check your installation, run sudo docker version and sudo docker compose version. You're now ready to download and launch the Kestra server.
Install Kestra
Download the official Docker-Compose file:
bash
curl -o docker-compose.yml \
https://raw.githubusercontent.com/kestra-io/kestra/develop/docker-compose.yml
Use an editor such as Vim to modify the docker-compose.yml, set basic authentication to true, and configure your basic authentication credentials to secure your Kestra instance.
yaml
kestra:
  server:
    basicAuth:
      enabled: true
      username: admin@kestra.io # it must be a valid email address
      password: kestra
Then, use the following command to start the Kestra server:
bash
sudo docker compose up -d
Allow external traffic
Kestra is now running and the Kestra server exposes traffic on the 8080 port. To connect through your web browser, update the inbound traffic rules in the Azure security group.
Go to the Virtual Machines console, and select the recently created virtual machine.
On the left navigation menu, click on Networking.
Under Inbound port rules tab, click on the Add inbound port rule button.
In the Add inbound security rule page, put Destination port ranges as 8080. You can keep the default values for the remaining properties. Finally, click on Add at the bottom of the page.
If you want to only allow traffic coming from your local machine, set the Source to your own IP address. To open the instance to the entire Internet, leave it at Any.
Note that if you haven't set up basic authentication in the previous step, your Kestra instance will be publicly available to anyone without any access restriction.
You can now access your Kestra instance and start developing flows.
Launch Azure Database
This first installation relies on a PostgreSQL database running alongside the Kestra server - on the VM instance (see the PostgreSQL service running thanks to the docker-compose).
For a simple proof of concept (PoC), you can keep the PostgreSQL database running in Docker.
However, for a production-grade installation, we recommend a managed database service such as Azure Database for PostgreSQL servers.
Launch a database using Azure Database for PostgreSQL servers
Go to the Azure Database for PostgreSQL servers.
Click on Create Azure Database for PostgreSQL server (Kestra also supports MySQL, but PostgreSQL is recommended).
Choose an appropriate Subscription and Resource Group.
Put an appropriate Server name, and select the preferred Region.
Choose the latest PostgreSQL version. We recommend version 15.
Select the Workload type as per your requirement.
Choose Authentication method as PostgreSQL authentication only.
Provide an appropriate Admin username and Password, and re-write the password in Confirm password.
Click on Next: Networking.
Click on the select box for Allow public access from any Azure service within Azure to this server.
Click on Review + Create. Review the configurations and click on Create.
Wait for the database to be provisioned.
Create a Kestra database
Go to the database overview page, and click on Databases from the left side navigation menu.
Click on Add.
Put an appropriate database name, and click on Save at the top.
Update Kestra configuration
In the docker-compose configuration, edit the datasources property of the Kestra service to point Kestra to your Azure database:
yaml
datasources:
  postgres:
    url: jdbc:postgresql://<your-db-external-endpoint>:5432/<db_name>
    driverClassName: org.postgresql.Driver
    username: <your-username>
    password: <your-password>
Because you now use the ""Azure Database for PostgreSQL servers"" service, you don't need the PostgreSQL Docker service anymore. Remove it from the docker-compose.yml file.
In order for the changes to take effect, restart the docker services with sudo docker compose restart or sudo docker compose up -d.
Configure Azure Blob Storage
By default, internal storage is implemented using the local file system. This section will guide you on how to change the storage backend to Blob Storage to ensure more reliable, durable, and scalable storage.
Go to the Storage Accounts.
Click on Create.
Choose an appropriate Subscription and Resource Group.
Put an appropriate Storage account name, and select the preferred Region.
Select Performance and Redundancy as per your requirement.
Click on Review, and post reviewing the configurations, click on Create.
Click on the newly created storage account.
On the storage account overview page, click on the Containers from the left side navigation menu.
Click on Create button at the top to create a new container.
Put an appropriate name for the container, and click on Create. A new container will be created.
Now, click on Access keys from the left side navigation menu.
For one of the keys, either key1 or key2, click on Show for the Connection string, and click on Copy to clipboard button.
Note down the connection string with you. We will require this for configuring the storage backend.
Edit the Kestra storage configuration in the docker-compose.yml file.
yaml
kestra:
  storage:
    type: azure
    azure:
      container: ""<your-container>""
      endpoint: ""https://<your-storage-account>.blob.core.windows.net/""
      connectionString: ""<your-connection-string>""
In order for the changes to take effect, restart the docker services with sudo docker compose restart or sudo docker compose up -d.
For more information on Azure Blob storage configuration, check out the guide here.
Next steps
This guide walked you through installing Kestra on a Azure Virtual Machine with Azure Database for PostgreSQL servers and Azure Blob Storage as storage backend.
This setup provides a simple starting point for running Kestra in production on a single machine. For a deployment to a distributed Kubernetes cluster, check the Azure AKS deployment guide.
Reach out via Slack if you encounter any issues or if you have any questions regarding deploying Kestra to production.
Make sure to also check the CI/CD guide to automate your workflow deployments based on changes in Git.
Was this page helpful?
Yes
No
Installation
GCP VM with Cloud SQL and GCS
Installation
DigitalOcean Droplet with Managed Database""""""",1747,8510,kestra
https://kestra.io/docs/installation/digitalocean-droplet,"""""""DocsInstallation GuideDigitalOcean Droplet with Managed Database
DigitalOcean Droplet with Managed Database
Table of Contents
Create a DigitalOcean Droplet
Install Docker
Install Kestra
Launch DigitalOcean Database
Configure Spaces Object Storage
Next steps
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Install Kestra on DigitalOcean Droplet with DigitalOcean Database as a database backend.
This guide provides instructions for deploying Kestra on DigitalOcean Droplet with Managed Database from DigitalOcean as a database backend.
Prerequisites:
basic knowledge about using a command line interface
basic knowledge about DigitalOcean and PostgreSQL
Create a DigitalOcean Droplet
First, we will create a virtual machine known as a Droplet in DigitalOcean. To do so, go to the DigitalOcean portal and choose Droplets from the left navigation bar.
On the Droplets page, click on Create Droplet button. This will navigate you to the ""Create Droplets"" page.
Choose an appropriate region.
Choose Ubuntu as the OS image with the latest version.
Kestra needs at least 4GiB Memory and 2vCPU to run correctly. You can go with Shared or Dedicated CPU configuraton options as per your requirement. Here, we are choosing Basic plan with Regular CPU option, and a plan that provides us with 4GiB Memory and 2vCPU.
You can choose an appropriate authentication method: SSH Key or Password based.
Provide an appropriate hostname, and click on the Create Droplet button at the bottom.
Wait until the virtual machine is up and running. From the Droplets page, you can navigate to the recently created Droplet. From here, you can open the machine's console by clicking on the Console button at the top.
Install Docker
Once in the console terminal, you can run the commands to install Kestra.
Kestra can be started directly from a .jar binary or using Docker. We‚Äôll use Docker here for a quick setup:
Install Docker on the Droplet. You can find the last updated instruction on the Docker website.
Install docker compose.
To check your installation, run sudo docker version and sudo docker compose version. You're now ready to download and launch the Kestra server.
Install Kestra
Download the official Docker-Compose file: curl -o docker-compose.yml https://raw.githubusercontent.com/kestra-io/kestra/develop/docker-compose.yml
Use an editor such as Vim to modify the docker-compose.yml, set basic authentication to true, and configure your basic authentication credentials to secure your Kestra instance.
yaml
kestra:
  server:
    basicAuth:
      enabled: true
      username: admin@kestra.io # it must be a valid email address
      password: kestra
Then, use the following command to start the Kestra server:
bash
sudo docker compose up -d
You can now access the Kestra UI at http://<public_droplet_ip>:8080 and start developing flows.
Launch DigitalOcean Database
This first installation relies on a PostgreSQL database running alongside the Kestra server - on the VM instance (see the PostgreSQL service running thanks to the docker-compose).
For a simple proof of concept (PoC), you can keep the PostgreSQL database running in Docker.
However, for a production-grade installation, we recommend a managed database service such as DigitalOcean Database.
Launch a PostgreSQL database using DigitalOcean Database
Go to the DigitalOcean Databases.
Click on Create Database button on the top.
Choose an appropriate region and select PostgreSQL as the database engine (Kestra also supports MySQL, but PostgreSQL is recommended).
Choose the database configuration as per your requirement.
Provide an appropriate database cluster name.
Click on the Create Database Cluster button at the bottom of the page.
Wait for the database to be provisioned. Generally, this takes around 5 minutes.
Once the database is ready, you can click on the Get Started button.
In the Add trusted sources dropbox, you can select your computer (in case you want to connect to this database from the PostgreSQL client running on your computer), and the kestra-host droplet created in the earlier section.
Click on Allow these inbound sources only.
On this page, ensure Public network is selected on the top. Take a note of the Connection Details that appear, and click on Continue.
On the next page, click on Great, I'm done button.
Create a Kestra database
Go to the database overview page, navigate to Users & Databases tab.
Under Databases, type an appropriate database name, and click on Save.
Update Kestra configuration
In the docker-compose configuration, edit the datasources property of the Kestra service to point Kestra to your Azure database:
yaml
datasources:
  postgres:
    url: jdbc:postgresql://<your-db-host>:25060/<db_name>
    driverClassName: org.postgresql.Driver
    username: doadmin
    password: <your-password>
Because you now use the database powered by ""DigitalOcean Database"", you don't need the PostgreSQL Docker service anymore. Remove it from the docker-compose.yml file. You'll also need to delete the depends_on section at the end of the YAML file:
yaml
depends_on:
  postgres:
    condition: service_started
In order for the changes to take effect, restart the docker services with sudo docker compose restart or sudo docker compose up -d.
Configure Spaces Object Storage
By default, internal storage is implemented using the local file system. This section will guide you on how to change the storage backend to Spaces Object Storage to ensure more reliable, durable, and scalable storage.
Firstly, we will create the access key and secret key that can be used to connect to Spaces Object Storage.
Navigate to the API from the left navigation menu.
Go to the Spaces Keys tab.
Click on Generate New Key button.
Provide an appropriate name for the spaces access key, and click on Create Access Key.
A new access key with the given name will be generated. Take a note of the secret key as you will not be able to retrieve it later.
Let's create a bucket in the Spaces Object Storage.
Go to the Spaces Object Storage. You can also navigate to the Spaces Object Storage from the left navigation menu.
Click on Create Spaces Bucket button.
Choose an appropriate data center region.
Put an appropriate unique Spaces Bucket name, and select the corresponding project in which the Spaces Bucket needs to be created.
Click on Create a Spaces Bucket at the bottom to create the Spaces Bucket.
Once the bucket is created, you can go to the bucket's page, and note down the Original Endpoint.
Edit the Kestra storage configuration in the docker-compose.yml file.
yaml
kestra:
  storage:
    type: minio
    minio:
      endpoint: ""<bucket-original-endpoint>""
      port: ""443""
      secure: true
      accessKey: ""<spaces-access-key>""
      secretKey: ""<spaces-secret-key>""
      region: ""FRA1""
      bucket: ""<bucket-name>""
In order for the changes to take effect, restart the docker services with sudo docker compose restart or sudo docker compose up -d.
Next steps
This guide walked you through installing Kestra on a DigitalOcean Droplet with DigitalOcean Database.
This setup provides a simple starting point for running Kestra in production on a single machine.
Reach out via Slack if you encounter any issues or if you have any questions regarding deploying Kestra to production.
Make sure to also check the CI/CD guide to automate your workflow deployments based on changes in Git.
Was this page helpful?
Yes
No
Installation
Azure VM with Azure Database
Installation
Standalone Server""""""",1578,7503,kestra
https://kestra.io/docs/installation/standalone-server,"""""""DocsInstallation GuideStandalone Server
Standalone Server
Table of Contents
Overview
systemd
Install plugins from a Docker image
Installation on Windows
Configuration
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Install Kestra on a standalone server with a simple executable file.
Overview
To deploy Kestra without Docker, there's a standalone JAR available that allows deployment in any environment that has JVM version 21+.
Make sure that you have Java installed on your machine.
The latest JAR can be downloaded via Kestra API.
This is an executable JAR:
For Linux & MacOS, run it with ./kestra-VERSION <command>.
For Windows, rename the file ./kestra-VERSION to ./kestra-VERSION.bat, and run it from CMD.
For example, to launch Kestra:
in local mode (with an H2 local file database), you will run ./kestra-VERSION server local.
in standalone mode (you need to provide a configuration with a connection to a database) , you will run ./kestra-VERSION server standalone.
Running the jar version will come without any plugins. You need to install them manually with the kestra plugins install directory_with_plugins/ command. Alternatively, point to a directory with the plugins in the configuration file or an environment variable KESTRA_PLUGINS_PATH e.g. KESTRA_PLUGINS_PATH=/Users/anna/dev/plugins.
systemd
On systemd-based systems, Kestra can be deployed as a systemd service. Here is a basic unit file template:
systemd
[Unit]
Description=Kestra Event-Driven Declarative Orchestrator
Documentation=https://kestra.io/docs/
After=network-online.target
[Service]
Type=simple
ExecStart=/bin/sh <PATH_TO_YOUR_KESTRA_JAR>/kestra-<VERSION> server standalone
User=<KESTRA_UNIX_USER>
Group=<KESTRA_UNIX_GROUP>
RestartSec=5
Restart=always
[Install]
WantedBy=multi-user.target
Install plugins from a Docker image
To copy the plugins from a Docker container to your local machine, you can use the following commands:
bash
id=$(docker create kestra/kestra:develop)
docker cp $id:/app/kestra kestra
docker cp $id:/app/plugins plugins
docker rm $id
./kestra server local
Installation on Windows
Here is how you can launch a Standalone Kestra server on Windows:
Install Java JRE 21 -- use the x64 version in the MSI format.
Go to the Releases page on the main Kestra repository.
Select the desired version and download the binary from the Assets section.
Rename the downloaded file to kestra.bat.
Install the plugins you need from the following list using the command kestra.bat plugins install io.kestra.plugin:plugin-script-powershell:LATEST io.kestra.plugin:plugin-script-python:LATEST or copy the plugins from a Docker container to your local machine, as described in the section above.
Start the server using the command kestra.bat server local.
Configuration
You can either put your whole configuration in the environment variable KESTRA_CONFIGURATION or you can specify a configuration file to read through --config (or -c) option. If neither of these option is used, Kestra will read from ${HOME}/.kestra/config.yml.
If you are using KESTRA_CONFIGURATION environment variable, you'll need to have a directory called confs in the directory where you run Kestra.
Configuration options are available in the Administrator Guide, you can also see the default configuration available on GitHub.
Was this page helpful?
Yes
No
Installation
DigitalOcean Droplet with Managed Database
Installation
Podman Compose""""""",779,3429,kestra
https://kestra.io/docs/installation/podman-compose,"""""""DocsInstallation GuidePodman Compose
Podman Compose
Table of Contents
Before you begin
Download the Docker Compose file
Launch Kestra in Root Mode
Adjusting the Configuration
Use a configuration file
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Start Kestra with a PostgreSQL database backend using Podman Compose.
Before you begin
Make sure you have already installed:
Podman
Podman Compose
Download the Docker Compose file
Download the Docker Compose file using the following command:
bash
curl -o docker-compose.yml \
https://raw.githubusercontent.com/kestra-io/kestra/develop/docker-compose.yml
If you don't have curl installed, you can download the Docker Compose file manually and save it as docker-compose.yml.
Podman Compose will work using the provided Docker Compose file out of the box.
Launch Kestra in Root Mode
Use the following command to create a Podman machine, start it up and launch Kestra on it:
bash
podman machine init --cpus 2 --rootful -v /tmp:/tmp -v $PWD:$PWD
podman machine start
podman compose up -d
Podman executes containers through a VM on your local machine. In order to access local volumes from your container you need to ensure you mount these to the podman VM, hence the -v /tmp:/tmp -v $PWD:$PWD arguments.
Note: Check if you have an existing podman VM on your local machine by navigating to the 'Resources' tab in podman desktop or running the command podman machine list in your terminal. If you have an existing VM, ensure the required volumes are mounted as expected. If that does not work, you can recreate the podman VM with volumes mounted and then run Kestra.
Open the URL http://localhost:8080 in your browser to launch the UI.
Adjusting the Configuration
The command above starts a standalone server (all architecture components in one JVM).
The configuration will be done inside the KESTRA_CONFIGURATION environment variable of the Kestra container. You can update the environment variable inside the Docker compose file, or pass it via the Docker command line argument.
If you want to extend your Docker Compose file, modify container networking, or if you have any other issues using this Docker Compose file, check the Troubleshooting Guide.
Use a configuration file
If you want to use a configuration file instead of the KESTRA_CONFIGURATION environment variable to configure Kestra you can update the default docker-compose.yml.
First, create a configuration file, for example named application.yaml and put inside the content of the KESTRA_CONFIGURATION environment variable defined in the docker-compose.yml file.
Then update kestra service in the docker-compose.yml file to mount this file into the container and make Kestra using it via the --config option:
yaml
# [...]
  kestra:
    image: kestra/kestra:latest
    pull_policy: always
    # Note that this is meant for development only. Refer to the documentation for production deployments of Kestra which runs without a root user.
    user: ""root""
    command: server standalone --worker-thread=128 --config /etc/config/application.yaml
    volumes:
      - kestra-data:/app/storage
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/kestra-wd:/tmp/kestra-wd
      - $PWD/application.yaml:/etc/config/application.yaml
    ports:
      - ""8080:8080""
      - ""8081:8081""
    depends_on:
      postgres:
        condition: service_started
Was this page helpful?
Yes
No
Installation
Standalone Server
Installation
Kestra Cloud (Alpha)""""""",791,3483,kestra
https://kestra.io/docs/installation/kestra-cloud,"""""""DocsInstallation GuideKestra Cloud (Alpha)
Kestra Cloud (Alpha)
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Sign up for a free Kestra Cloud account to get started.
Kestra Cloud is currently in private Alpha. If you are interested in trying it out, sign up here.
Was this page helpful?
Yes
No
Installation
Podman Compose
Docs
User Interface""""""",94,370,kestra
https://kestra.io/docs/ui,"""""""DocsUser Interface
User Interface
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Kestra comes with a rich web user interface located by default on port 8080.
When you first navigate to the Kestra UI, you will see the Welcome page.
On this page, you can click on Create my first flow to open the Kestra Guided Tour which will guide you step by step through creating and executing your first flow.
On the left menu, you will see the following UI pages:
The Home page contains a dashboard of flow executions.
The Flows page shows you all of your flows, allowing you to create, edit and execute them.
The Executions page allows you to view and manage previous executions.
The Logs page allows access to all task logs from previous executions.
The Namespace page allows setting specific configurations at the namespace level.
The Blueprints page provides a catalog of ready-to-use flow examples.
The Plugins page provides a catalog of plugins you can use inside of your flows.
The Administration page helps troubleshoot administrative issues, such as worker status, triggers, and depending on your Kestra edition, also features such as audit logs, and user management.
The Settings page allows you to configure the Kestra UI.
The Kestra Enterprise Edition comes with additional functionalities provided by the Kestra UI:
The Task Runs page contains a dashboard of task runs, providing a full-text search engine to search for specific task run logs.
The Users page allows the management of Kestra users.
The Groups page allows the management of Kestra user groups.
The Roles page allows the management of Kestra user roles.
The Audit Logs page allows access to Kestra audit logs.
The Tenants page lets you manage your tenants (page accessible only by users with admin permissions).
The Custom Blueprints page allows you to add custom flow examples that you can reuse code and share best practices in your team.
The expanded Namespaces page adds enforcing authentication and role-based access control per namespace as well.
Dashboard
Get insights into your workflows with the Dashboard.
Flows
Manage your flows in one place.
Executions
Manage Executions of your Flows in one place.
Logs
Manage Logs generated by tasks.
Namespaces
Manage resources associated with a namespace in one place.
Blueprints
Ready-to-use examples designed to kickstart your workflow.
Settings
Configure Settings for Kestra.
Administration
Manage your Kestra Instance.
Task Runs
Manage Task Runs in one place.
Was this page helpful?
Yes
No
Installation
Kestra Cloud (Alpha)
Ui
Dashboard""""""",536,2581,kestra
https://kestra.io/docs/ui/dashboard,"""""""DocsUser InterfaceDashboard
Dashboard
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Get insights into your workflows with the Dashboard.
The first time you access the main Dashboard, you'll see the Welcome Page and you can click Create my first flow to launch a Guided Tour.
Once you have executed a flow, you will see your flow executions in the dashboard.
The Dashboard provides a load of useful data right at your finger tips, including:
Executions over time
Execution Status for Today, Yesterday as well as Last 30 days
Executions per namespace
Execution errors per namespace
List of failed Executions
List of error logs
The dashboard is interactive so you can click on any element to get more information about it.
Was this page helpful?
Yes
No
Docs
User Interface
Ui
Flows""""""",175,807,kestra
https://kestra.io/docs/ui/flows,"""""""DocsUser InterfaceFlows
Flows
Table of Contents
Editor
Topology View
Documentation View
Blueprints View
Revisions
Dependencies
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage your flows in one place.
On the Flows page, you will see a list of flows which you can edit and execute. You can also create a new flow in the top right hand corner.
By clicking on a flow id or on the eye icon, you can open a flow.
A Flow page will have multiple tabs that allow you to: see the flow topology, all flow executions, edit the flow, view its revisions, logs, metrics, and dependencies. You'll also be able to edit namespace files in the Flow editor as well.
Editor
The Editor gives you a rich view of your workflow, as well as Namespace Files. The Editor allows you to add multipl views to the side:
Documentation
Topology
Blueprints
Topology View
The Topology View allows you to visualize the structure of your flow. This is especially useful when you have complex flows with multiple branches of logic.
Documentation View
The documentation view allows you to see Kestra's documentation right inside of the editor. As you move your type cursor around the Editor, the documentation page will update to reflect the specific task type documentation.
Note that if you use the Brave browser, you may need to disable the Brave Shields to make the Editor work as expected. Specifically, to view the task documentation, you need to set the Block cookies option to Disabled in the Shields settings: brave://settings/shields.
Blueprints View
The blueprint view allows you to copy example flows directly into your flow. Especially useful if you're using a new plugin where you want to work off of an existing example.
Revisions
You can view the history of your flow under the Revisions tab. Read more about revisions here.
Dependencies
The Dependencies page allows you to view what other flows depend on the selected flow, as well as flows that the selected flow depends on. It gives you an easy way to navigate between them as well.
The Dependencies View on the Namespaces page shows all the flows in the namespace and how they each relate to one another, if at all, whereas the Flow Dependencies view is only for the selected flow.
Was this page helpful?
Yes
No
Ui
Dashboard
Ui
Executions""""""",490,2302,kestra
https://kestra.io/docs/ui/executions,"""""""DocsUser InterfaceExecutions
Executions
Table of Contents
Gantt
Logs
Topology
Outputs
Metrics
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage Executions of your Flows in one place.
On the Executions page, you will see a list of previous flow executions.
By clicking on an execution id or on the eye icon, you can open an execution.
An Execution page will allow you to access the details of a flow execution, including logs, outputs, and metrics.
Gantt
The Gantt tab allows you to see each task's durations. From this interface, you can replay a specific task, see task source code, change task status, or look at task metrics and outputs.
Logs
The Logs tab allows to access task's logs. You can filter by log level, copy logs in your clipboard, or download logs as a file.
Topology
Similar to the Editor view, you can see your execution topology. From this, you can access specific task logs, replay certain tasks or change task status.
Outputs
The Outputs tab inside of an execution page allows to see each task's outputs.
The ""Debug Outputs"" box allows to evaluate expressions on those task outputs. It's a great way to debug your flows.
Note: You have to select one task to be able to use the ""Debug Outputs"" button.
For example, you can use the ""Render expression"" feature to deep-dive into your tasks' outputs and play directly with expressions.
Metrics
The Metrics tab shows every metric exposed by tasks after execution.
Was this page helpful?
Yes
No
Ui
Flows
Ui
Logs""""""",342,1508,kestra
https://kestra.io/docs/ui/logs,"""""""DocsUser InterfaceLogs
Logs
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage Logs generated by tasks.
On the Logs page, you will have access to all task logs.
On here, you can filter by:
Namespace
Log level
Time period
You can search for key words too.
Was this page helpful?
Yes
No
Ui
Executions
Ui
Namespaces""""""",89,343,kestra
https://kestra.io/docs/ui/namespaces,"""""""DocsUser InterfaceNamespaces
Namespaces
Table of Contents
Overview
Editor
Flows
Dependencies
KV Store
Additional Enterprise Pages
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage resources associated with a namespace in one place.
Starting 0.18.0, Kestra has introduced the Namespaces tab in the Kestra UI for OSS. In this tab, you can see all the namespaces associated with the different flows in Kestra.
Overview
This is the default landing page of the Namespace. This page contains the dashboards and summary about the executions of different flows in this namespace.
Editor
The in-built editor where you can add/edit namespace files. This makes it easier to edit just your namespace files without needing to select a flow inside of the namespace.
Flows
Shows all the flows in the namespace. It gives a brief about each of the flows including the flow ID, labels, last execution date and last execution status, and the execution statistics. By selecting the details button on the right of the flow, you can navigate to that flow's page.
Dependencies
Shows all the flows and which ones are dependent on each other (for example through Subflows or Flow Triggers).
This is similar to the Dependencies page in the Flow Editor, but this shows you how all flows within a namespace even if some of them don't depend on any others.
KV Store
Manage the key-values pairs associated with this namespace. More details on KV Store can be found here.
Additional Enterprise Pages
In the Enterprise Edition, there's a number of additional pages that give you richer insight and control over your namespaces. To read more about them, check out the page below:
Enterprise Namespace Pages
Manage specific enterprise features within a namespace.
Was this page helpful?
Yes
No
Ui
Logs
Namespaces
Enterprise Namespace Pages""""""",383,1837,kestra
https://kestra.io/docs/ui/namespaces/ee,"""""""DocsUser InterfaceNamespacesEnterprise Namespace Pages
Enterprise Namespace Pages
Table of Contents
Edit
Variables
Plugin Defaults
Secrets
Audit Logs
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Manage specific enterprise features within a namespace.
This feature requires a commercial license.
There's a number of extra namespace pages available in the enterprise edition:
Edit
Namespace-wide Variables
Namespace-wide Plugin Defaults
Secrets
Audit Logs
Edit
Manage the namespace description, worker group and permissions.
Variables
Variables defined at the namespace level can be used in any flow defined under the same namespace using the syntax: {{ namespace.variable_name }}.
Read more about Variables here
Plugin Defaults
Plugin Defaults can also be defined at the namespace level. These plugin defaults are then applied for all tasks of the corresponding type defined in the flows under the same namespace.
Read more about Plugin Defaults here
Secrets
Configure Secrets directly from the UI. These secrets are available to all flows inside of the namespace.
Read more about Secrets here
Audit Logs
Audit Logs record all activities performed in your Kestra instance by users and service accounts. You can view all of the audit logs related to the selected namespace in this view.
Read more about Audit Logs here.
Was this page helpful?
Yes
No
Ui
Namespaces
Ui
Blueprints""""""",283,1438,kestra
https://kestra.io/docs/ui/blueprints,"""""""DocsUser InterfaceBlueprints
Blueprints
Table of Contents
Custom Blueprints
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Ready-to-use examples designed to kickstart your workflow.
Blueprints are a curated, organized, and searchable catalog of ready-to-use examples designed to help you kickstart your workflow. Each Blueprint combines code and documentation, and can be assigned several tags for organization and discoverability.
All Blueprints are validated and documented. You can easily customize and integrate them into your new or existing flows with a single click on the ""Use"" button.
Custom Blueprints
You can also create custom blueprints, shared within your organization.
Custom blueprints require a commercial license.
Check the Blueprints documentation for more details.
Was this page helpful?
Yes
No
Namespaces
Enterprise Namespace Pages
Ui
Settings""""""",177,892,kestra
https://kestra.io/docs/ui/settings,"""""""DocsUser InterfaceSettings
Settings
Table of Contents
Main Configuration
Theme Preferences
Language and Region
Export
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Configure Settings for Kestra.
On the Settings page, you will be able to configure the Kestra UI. These configuration options are on a per-user basis.
Main Configuration
Options you can configure under Main Configuration include:
Default Namespace: e.g. company.team
Default Log Level: e.g. TRACE
Default Log Display: Expand all, Collapse all or Expand only failed tasks
Execute the Flow: In the same tab or in a new tab
Theme Preferences
Kestra allows you to have a Light or Dark mode.
You can also specify the Editor to be a separate Light or Dark mode too. In addition, you can adjust the font size and family for the Editor too.
There's also the option to change the environment name and color to help you identify if you have multiple Kestra instances, e.g. dev and prod.
Below is a detailed list of the Theme Preferences you can configure:
Theme Mode: Dark or Light
Chart Color Scheme: Classic (red-green) or Kestra (pink-purple)
Editor Theme: Dark or Light
Editor Font Size: e.g. 12 ‚Äî arbitrary integer number
Editor Font Family: one of the following:
Source Code Pro
Courier
Times New Roman
Book Antiqua
Times New Roman Arabic
SimSun
Automatic Code Folding in the Editor: a toggle, by default toggled off
Environment Name: e.g. dev, staging, prod
Environment Color: select a color from the color picker
Language and Region
Language: English, German, Spanish, French, Hindi, Italian, Japanese, Korean, Polish, Portuguese, Russian, or Chinese
Time Zone: e.g. Europe/Berlin (UTC+02:00)
Date Format: choose one of the following formats:
2024-09-30T12:44:34+02:00
2024-09-30 12:44:34
30/09/2024 12:44:34
Sep 30, 2024 12:44 PM
Mon, Sep 30, 2024 12:44 PM
September 30, 2024 12:44 PM
Monday, September 30, 2024 12:44 PM
You can change the date and time of your Kestra instance. However, note that this does not affect Schedule triggers or the time that your Kestra flows will execute on. By default, those will run on UTC. This setting is only for the UI display.
Export
You can also export all of your flows as a .zip file. This allows you to back up your flows or migrate them to another instance of Kestra.
Was this page helpful?
Yes
No
Ui
Blueprints
Ui
Administration""""""",609,2364,kestra
https://kestra.io/docs/ui/administration,"""""""DocsUser InterfaceAdministration
Administration
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage your Kestra Instance.
Each page under the Administration Section is available below as a dedicated page:
Triggers
Manage Triggers in Kestra.
Workers
Manage Workers in Kestra.
Stats
Manage Stats in Kestra.
Users
Manage Users in Kestra
Service Accounts
Manage Service Accounts in Kestra.
Groups
Manage Groups in Kestra.
Roles
Manage Roles in Kestra.
Audit Logs
Manage Audit Logs in Kestra
Tenants
Manage Tenants in Kestra
Was this page helpful?
Yes
No
Ui
Settings
Administration
Triggers""""""",154,615,kestra
https://kestra.io/docs/ui/administration/triggers,"""""""DocsUser InterfaceAdministrationTriggers
Triggers
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage Triggers in Kestra.
The Triggers page provides a concise overview of all triggers and their status, and allows you to disable, re-enable, or unlock triggers.
The API-side state of a trigger takes precedence over the state defined in the flow code. The state shown on this page is the authoritative source of truth for any trigger. Thus, if a trigger is marked as disabled: true in the source code but the UI toggle is on, the trigger is considered active despite being disabled in the code.
Was this page helpful?
Yes
No
Ui
Administration
Administration
Workers""""""",150,693,kestra
https://kestra.io/docs/ui/administration/workers,"""""""DocsUser InterfaceAdministrationWorkers
Workers
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage Workers in Kestra.
On the Cluster page, navigate to Services tab. You will see the list of available workers by filtering Worker from the Type dropdown.
Was this page helpful?
Yes
No
Administration
Triggers
Administration
Stats""""""",78,357,kestra
https://kestra.io/docs/ui/administration/stats,"""""""DocsUser InterfaceAdministrationStats
Stats
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage Stats in Kestra.
The Stats page provides a dashboard of Kestra usage statistics, including the number of namespaces, flows, tasks, triggers, executions, and the total execution duration (in minutes). In the Enterprise Edition, this page also shows the number of users, groups and roles.
The main goal of that section is to keep security in mind ‚Äî you can either consider upgrading to the Enterprise Edition or activate basic authentication for a single user directly from the UI. Here is how this page looks like in the Open Source Edition:
And here is how it looks like in the Enterprise Edition:
In both cases, when you click on the üîç magnifying glass icon, you can dive into the details of the specific stats.
Was this page helpful?
Yes
No
Administration
Workers
Administration
Users""""""",192,912,kestra
https://kestra.io/docs/ui/administration/users,"""""""DocsUser InterfaceAdministrationUsers
Users
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Manage Users in Kestra
This feature requires a commercial license.
On the Users page, you will see the list of users.
By clicking on a user id or on the eye icon, you can open the page of a user.
The Create button allows creating a new user and managing that user's access to Kestra.
Users can be attached to Groups and/or Namespaces.
Was this page helpful?
Yes
No
Administration
Stats
Administration
Service Accounts""""""",129,569,kestra
https://kestra.io/docs/ui/administration/service-accounts,"""""""DocsUser InterfaceAdministrationService Accounts
Service Accounts
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Manage Service Accounts in Kestra.
This feature requires a commercial license.
To create a new service account, go to the Service Accounts page under the Administration section and click on the Create button. Fill in the form with the required information including the name and description, and click Save:
Once you have created a service account, you can add a Role that will grant the service account permissions to specific resources. To do this, click on the Add button and select the role you want to assign to the service account.
Finally, you can generate an API token for the service account by clicking on the Create button. This will generate a token that you can use to authenticate the service account with Kestra from external applications such as CI/CD pipelines (e.g. in Terraform provider configuration or GitHub Actions secrets).
Note how you can configure the token to expire after a certain period of time, or to never expire. Also, there is a toggle called Extended that will automatically prolong the token's expiration date by the specified number of days (Max Age) if the token is actively used. That toggle is disabled by default.
Once you confirm the API token creation via the Generate button, the token will be generated and displayed in the UI. Make sure to copy the token and store it in a secure location as it will not be displayed again.
Note that you can create an API token also as a regular User. While Service Accounts are generally recommended for programmatic API access to Kestra from CI/CD or other external applications, often it's useful to create an API token for a regular user, so that programmatic actions performed by that user can be tracked and audited.
Was this page helpful?
Yes
No
Administration
Users
Administration
Groups""""""",389,1950,kestra
https://kestra.io/docs/ui/administration/groups,"""""""DocsUser InterfaceAdministrationGroups
Groups
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Manage Groups in Kestra.
This feature requires a commercial license.
On the Groups page, you will see the list of groups.
By clicking on a group id or on the eye icon, you can open the page of a group.
The Create button allows creating a new group and managing its access to Kestra.
It's a collection of users who require the same set of permissions. It's useful to assign the same permissions to multiple users who belong to the same team or project.
Was this page helpful?
Yes
No
Administration
Service Accounts
Administration
Roles""""""",150,688,kestra
https://kestra.io/docs/ui/administration/roles,"""""""DocsUser InterfaceAdministrationRoles
Roles
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Manage Roles in Kestra.
This feature requires a commercial license.
On the Roles page, you will see the list of roles.
By clicking on a role id or on the eye icon, you can open the page of a role.
The Create button allows creating a new role.
Roles manage CRUD (CREATE, READ, UPDATE, DELETE) access to Kestra resources such as flows, executions, or secrets. They can be attached to groups or users.
Was this page helpful?
Yes
No
Administration
Groups
Administration
Audit Logs""""""",144,628,kestra
https://kestra.io/docs/ui/administration/audit-logs,"""""""DocsUser InterfaceAdministrationAudit Logs
Audit Logs
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Manage Audit Logs in Kestra
This feature requires a commercial license.
Audit logs record all activities made by all users on the resources created inside Kestra.
On the Audit Logs page, you will have access to all Kestra audit logs.
By reviewing audit logs, system administrators can track user activity, and security teams can investigate breaches and ensure compliance with regulatory requirements.
Was this page helpful?
Yes
No
Administration
Roles
Administration
Tenants""""""",129,637,kestra
https://kestra.io/docs/ui/administration/tenants,"""""""DocsUser InterfaceAdministrationTenants
Tenants
Table of Contents
Create
Edit
Overview
Users
Service Accounts
Groups
Access
Roles
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Manage Tenants in Kestra
This feature requires a commercial license.
A tenant represents an isolated environment within a single Kestra instance.
Read more about Tenants here.
Create
When you create a tenant, you can give it an ID, name and Worker Group. Other properties can be configured afterwards.
Edit
When you select a Tenant, there are a number of pages:
Overview
Users
Service Accounts
Groups
Access
Roles
Overview
This is where you can edit the same
Users
You can create and edit users inside of your tenant. Once a user has been created, you can also:
Select the type of authentication they can use (e.g. SSO)
Select the access and role they have on the tenant
Generate API Tokens for the user
Create User
When you create a user, you can give them:
Username
First name
Last name
Email
Groups
Toggle for Super Admin
Once you've saved them, you can access the other tabs.
Authentication
Under Authentication, you can set the users password, or authentication type. For example, if you have Single Sign-On (SSO) configured, you can select that as the authentication method.
API Token
You can also generate API Tokens for users for authenticating with the Kestra API.
When you create an API Token, you can give it a name, description as well as an age.
You will only be able to copy the API Token at the time of creation.
Service Accounts
Similar to Users, you can create Service Accounts. Difference is you can't select an Authentication Method - instead you must use an API Token.
Groups
You can create groups to make it easier to assign multiple users specific access at the same time.
When you create a group, you can give it a name and a description.
Once created, you can assign users to groups.
Access
This is where you can assign users to your roles.
Roles
You can also create new roles in your tenant and adjust the permissions existing roles have.
When you create a new role, you can select the appropriate permissions and which level they should be. More information on permissions here.
Was this page helpful?
Yes
No
Administration
Audit Logs
Ui
Task Runs""""""",512,2311,kestra
https://kestra.io/docs/ui/task-runs,"""""""DocsUser InterfaceTask Runs
Task Runs
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Manage Task Runs in one place.
This feature requires a commercial license and backend with the Elasticsearch repository.
On the Task Runs page, you will see the list of task runs and some charts.
This page only exists when using the Elasticsearch repository, as it requires a full-text search engine.
Was this page helpful?
Yes
No
Administration
Tenants
Docs
Concepts""""""",110,513,kestra
https://kestra.io/docs/concepts,"""""""DocsConcepts
Concepts
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
This section lists key concepts and templating expressions. You can treat this section as a lookup reference anytime you need more details about a specific concept or expression.
Namespace Files
Manage Namespace Files and how to use them in your flows.
Revision
Manage versions of flows.
Secret
Store sensitive information securely.
Key Value (KV) Store
Build stateful workflows with the KV Store.
Pebble Templating Engine
Dynamically render variables, inputs and outputs.
Blueprints
Ready-to-use examples designed to kickstart your workflow.
Backfill
Backfills are replays of missed schedule intervals between a defined start and end date.
Replay
Replay allows you to re-run a workflow execution from any chosen task run.
Data storage and processing
Manage data processed by tasks.
Caching
Manage file caching inside of Kestra.
System Flows
Automate maintenance workflows with System Flows.
Was this page helpful?
Yes
No
Ui
Task Runs
Concepts
Namespace Files""""""",228,1056,kestra
https://kestra.io/docs/concepts/namespace-files,"""""""DocsConceptsNamespace Files
Namespace Files
Table of Contents
What are Namespace Files
Why use Namespace Files
How to add Namespace Files
Embedded Code Editor
PushNamespaceFiles and SyncNamespaceFiles Tasks
GitHub Actions CI/CD
Terraform Provider
Deploy Namespace Files from Git via CLI
How to use Namespace Files in your flows
The read() function
namespaceFiles.enabled on supported tasks
Namespace Tasks
Include / Exclude Namespace Files
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage Namespace Files and how to use them in your flows.
What are Namespace Files
Namespace Files are files tied to a given namespace. You can think of Namespace Files as equivalent of a project in your local IDE or a copy of your Git repository.
Namespace Files can hold Python files, R or Node.js scripts, SQL queries, dbt or Terraform projects, and many more.
You can synchronize your Git repository with a specific namespace to orchestrate dbt, Terraform or Ansible, or any other project that contains code and configuration files.
Once you add any file to a namespace, you can reference it inside of your flows using the read() function in EVERY task or trigger from the same namespace.
For instance, if you add a SQL query called my_query.sql to the queries directory in the company.team namespace, you can reference it in any Query task or any JDBC Trigger like so: {{ read('queries/my_query.sql') }}.
Here is an example showing how you can use the read() function in a ClickHouse Trigger to read a SQL query stored as a Namespace File:
yaml
id: jdbc_trigger
namespace: company.team
tasks:
  - id: for_each_row
    type: io.kestra.plugin.core.flow.ForEach
    values: ""{{ trigger.rows }}""
    tasks:
      - id: return
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ json(taskrun.value) }}""
triggers:
  - id: query_trigger
    type: io.kestra.plugin.jdbc.clickhouse.Trigger
    interval: ""PT5M""
    url: jdbc:clickhouse://127.0.0.1:56982/
    username: ""{{ secret('CLICKHOUSE_USERNAME') }}""
    password: ""{{ secret('CLICKHOUSE_PASSWORD') }}""
    sql: ""{{ read('queries/my_query.sql') }}"" # üöÄ The read() function reads the content of the file as a string!
    fetchType: FETCH
Note: we didn't have to use the namespaceFiles.enabled: true property ‚Äî that property is only required to inject the entire directory of files from the namespace into the working directory of a script (e.g. a Python task). More on that in the subsequent sections of this page.
Why use Namespace Files
Namespace Files offer a simple way to organize your code and configuration files. Before Namespace Files, you had to store your code and configuration files in a Git repository and then clone that repository at runtime using the git.Clone task. With Namespace Files, you can store your code and configuration files directly in the Kestra's internal storage backend. That storage backend can be your local directory or an S3 bucket to ensure maximum security and privacy.
Namespace Files make it easy to:
orchestrate Python, R, Node.js, SQL, and more, without having to worry about code dependencies, packaging and deployments ‚Äî simply add your code in the embedded Code Editor or sync your Git repository with a given namespace
manage your code for a given project or team in one place, even if those files are stored in different Git repositories, or even different Git providers
share your code and configuration files between workflows and team members in your organization
orchestrate complex projects that require the code to be separated into multiple scripts, queries or modules.
How to add Namespace Files
Embedded Code Editor
The easiest way to get started with Namespace Files is to use the embedded Code Editor. This allows you to easily add custom scripts, queries and configuration files along with your flow YAML configuration files.
Get started by selecting a namespace from the dropdown menu. If you type a name of a namespace that doesn't exist yet, Kestra will create it for you.
Then, add a new file, e.g., a Python script. Add a folder named scripts and a file called hello.py with the following content:
python
print(""Hello from the Editor!"")
Once you added a file, you can use it in your flow:
yaml
id: editor
namespace: company.team
tasks:
  - id: hello
    type: io.kestra.plugin.scripts.python.Commands
    namespaceFiles:
      enabled: true
    commands:
      - python scripts/hello.py
The Execute button allows you to run your flow directly from the Code Editor. Click on the Execute button to run your flow. You should then see the Execution being created in a new browser tab and once you navigate to the Logs tab, you should see a friendly message Hello from the Editor! in the logs.
PushNamespaceFiles and SyncNamespaceFiles Tasks
There's 2 tasks to help you automatically manage your namespace files with Git. This allows you to sync the latest changes from a Git repository.
This example will push Namespace Files you already have in Kestra to a Git repository for you:
yaml
id: push_to_git
namespace: system
tasks:
  - id: commit_and_push
    type: io.kestra.plugin.git.PushNamespaceFiles
    username: git_username
    password: ""{{ secret('GITHUB_ACCESS_TOKEN') }}""
    url: https://github.com/git_username/scripts
    branch: dev
    namespace: company.team
    files:
      - ""example.py""
    gitDirectory: _files
    commitMessage: ""add namespace files""
    dryRun: true
This example will sync Namespace Files inside of a Git repository to your Kestra instance:
yaml
id: sync_files_from_git
namespace: system
tasks:
  - id: sync_files
    type: io.kestra.plugin.git.SyncNamespaceFiles
    username: git_username
    password: ""{{ secret('GITHUB_ACCESS_TOKEN') }}""
    url: https://github.com/git_username/scripts
    branch: main
    namespace: git
    gitDirectory: _files
    dryRun: true
Check out the dedicated guides for more information:
PushNamespaceFiles
SyncNamespaceFiles
GitHub Actions CI/CD
You can leverage our official GitHub Action called deploy-action to synchronize your Git repository with a given namespace. This is useful if you want to orchestrate complex Python modules, dbt projects, Terraform or Ansible infrastructure, or any other project that contains code and configuration files with potentially multiple nested directories and files.
Here is a simple example showing how you can deploy all scripts from the scripts directory in your Git branch to the prod namespace:
yaml
name: Kestra CI/CD
on:
  push:
    branches:
      - main
jobs:
  prod:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: deploy-scripts-to-prod
        uses: kestra-io/deploy-action@master
        with:
          resource: namespace_files
          namespace: prod
          directory: ./scripts # directory in the Git repository
          to: ./scripts # remote directory in the namespace
          server: https://demo.kestra.io/
          user: your_username
          password: ${{secrets.KESTRA_PASSWORD}}
When creating a service account role for the GitHub Action in the Enterprise Edition, you need to grant the FLOWS permission to the Role.
Terraform Provider
You can use the kestra_namespace_file resource from the official Kestra Terraform Provider to deploy all your custom script files from a specific directory to a given Kestra namespace.
Here is a simple example showing how you can synchronize an entire directory of scripts from the directory src with the company.team namespace using Terraform:
hcl
resource ""kestra_namespace_file"" ""prod_scripts"" {
  for_each  = fileset(path.module, ""src/**"")
  namespace = ""company.team""
  filename   = each.value # or ""/${each.value}""
  content   = file(each.value)
}
Deploy Namespace Files from Git via CLI
You can also use the Kestra CLI to deploy all your custom script files from a specific directory to a given Kestra namespace. Here is a simple example showing how you can synchronize an entire directory of local scripts with the prod namespace using the Kestra CLI:
bash
./kestra namespace files update prod /Users/anna/gh/KESTRA_REPOS/scripts --server=http://localhost:8080 --user=rick:password
In fact, you can even use that command directly in a flow. You can attach a schedule or a webhook trigger to automatically execute that flow anytime you push/merge changes to your Git repository, or on a regular schedule.
Here is an example of a flow that synchronizes an entire directory of local scripts with the prod namespace:
yaml
id: ci
namespace: company.team
variables:
  host: http://host.docker.internal:28080/
tasks:
  - id: deploy
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: clone
        type: io.kestra.plugin.git.Clone
        url: https://github.com/kestra-io/scripts
        branch: main
      - id: deploy_files
        type: io.kestra.plugin.scripts.shell.Commands
        warningOnStdErr: false
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        commands:
          - /app/kestra namespace files update prod . . --server={{vars.host}}
Note that the two dots in the command /app/kestra namespace files update prod . . indicate that we want to sync an entire directory of files cloned from the Git repository to the root directory of the prod namespace. If you wanted to e.g. sync that repository to the scripts directory, you would use the following command: /app/kestra namespace files update prod . scripts. The syntax of that command follows the structure:
bash
/app/kestra namespace files update <namespace> <local_directory> <remote_directory>
To reproduce that flow, start Kestra using the following command:
bash
docker run --pull=always --rm -it -p 28080:8080  kestra/kestra:latest  server local
Then, open the Kestra UI at http://localhost:28080 and create a new flow with the content above. Once you execute the flow, you should see the entire directory from the scripts repository being synchronized with the prod namespace.
How to use Namespace Files in your flows
There are multiple ways to use Namespace Files in your flows. You can use the read() function to read the content of a file as a string, point to the file path in the supported tasks or use a dedicated task to retrieve it as an output.
Usually, pointing to a file location, rather than reading the file's content, is required when you want to use a file as an input to a CLI command, e.g. in a Commands task such as io.kestra.plugin.scripts.python.Commands or io.kestra.plugin.scripts.node.Commands. In all other cases, the read() function can be used to read the content of a file as a string e.g. in Query or Script tasks.
You can also use the io.kestra.plugin.core.flow.WorkingDirectory task to read namespace files there and then use them in child tasks that require reading the file path in CLI commands e.g. python scipts/hello.py.
The read() function
Note how the script in the first section used the read() function to read the content of the scripts/hello.py file as a string using the expression ""{{ read('scripts/hello.py') }}"". It'a important to remeber that this function reads the content of the file as a string. Therefore, you should use that function only in tasks that expect a string as an input, e.g., io.kestra.plugin.scripts.python.Script or io.kestra.plugin.scripts.node.Script, rather than io.kestra.plugin.scripts.python.Commands or io.kestra.plugin.scripts.node.Commands.
The read() function allows you to read the content of a Namespace File stored in the Kestra's internal storage backend. The read() function takes a single argument, which is the absolute path to the file you want to read. The path must point to a file stored in the same namespace as the flow you are executing.
In this example, we have a namespace file called example.txt that contains the text Hello, World!. We can print the content to the logs by using {{ read('example.txt') }}:
yaml
id: files
namespace: company.team
tasks:
  - id: log
    type: io.kestra.plugin.core.log.Log
    message: ""{{ read('example.txt') }}""
namespaceFiles.enabled on supported tasks
With supported tasks, such as the io.kestra.plugin.scripts group, we can access files using their path and enabling the task to read namespace files.
Here is a simple weather.py script that reads a secret to talk to a Weather Data API:
python
import requests
api_key = '{{ secret(""WEATHER_DATA_API_KEY"") }}'
url = f""https://api.openweathermap.org/data/2.5/weather?q=Paris&APPID={api_key}""
weather_data = requests.get(url)
print(weather_data.json())
And here is the flow that uses the script:
yaml
id: weather_data
namespace: company.team
tasks:
  - id: get_weather
    type: io.kestra.plugin.scripts.python.Commands
    namespaceFiles:
      enabled: true
      include:
        - scripts/weather.py
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: ghcr.io/kestra-io/pydata:latest
    commands:
      - python scripts/weather.py
namespaceFiles property
The example above uses the include field to only allow the scripts/weather.py file to be accessible by the task.
We can control what namespace files are available to our flow with the namespaceFiles property.
namespaceFiles has 3 attributes:
enabled: when set to true enables all files in that namespace to be visible to the task
include: allows you to specify files you want to be accessible by the task
exclude: allows you to specify files you don't want to be accessible by the task
Namespace Tasks
You can use the Namespace Tasks to upload, download and delete tasks in Kestra.
In the example below, we have a namespace file called example.ion that we want to convert to a csv file. We can use the DownloadFiles task to generate an output that contains the file so we can easily pass it dynamically to the IonToCsv task.
yaml
id: files
namespace: company.team
tasks:
  - id: namespace
    type: io.kestra.plugin.core.namespace.DownloadFiles
    namespace: company.team
    files:
      - example.ion
  - id: ion_to_csv
    type: io.kestra.plugin.serdes.csv.IonToCsv
    from: ""{{ outputs.namespace.files['/example.ion'] }}""
Read more about the tasks below:
UploadFiles
DownloadFiles
DeleteFiles
Include / Exclude Namespace Files
You can selectively include or exclude namespace files.
Say you have multiple namespace files present: file1.txt, file2.txt, file3.json, file4.yml. You can selectively include multiple files using include attribute under namespaceFiles as shown below:
yaml
id: include_namespace_files
namespace: company.team
tasks:
  - id: include_files
    type: io.kestra.plugin.scripts.shell.Commands
    namespaceFiles:
      enabled: true
      include:
        - file1.txt
        - file3.json
    commands:
      - ls
The include_files task will list all the included files, i.e. file1.txt and file3.json as only those got included from the namespace through include.
The exclude, on the other hand, includes all the namespace files except those specified under exclude.
yaml
id: exclude_namespace_files
namespace: company.team
tasks:
  - id: exclude_files
    type: io.kestra.plugin.scripts.shell.Commands
    namespaceFiles:
      enabled: true
      exclude:
        - file1.txt
        - file3.json
    commands:
      - ls
The exclude_files task from the above flow will list file2.txt and file4.yml, i.e. all the namespace files except those that were excluded using exclude.
Was this page helpful?
Yes
No
Docs
Concepts
Concepts
Revision""""""",3456,15447,kestra
https://kestra.io/docs/concepts/revision,"""""""DocsConceptsRevision
Revision
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage versions of flows.
Flows are versioned by default. Whenever you make any changes to your flows, a new revision is created. This allows you to rollback to a previous version of your flow if needed.
If you navigate to a specific flow and go to the Revisions tab, you will see a list of all revisions of that flow. You can then compare the differences between two revisions side-by-side or line-by-line and rollback to a previous revision if needed.
Was this page helpful?
Yes
No
Concepts
Namespace Files
Concepts
Secret""""""",141,629,kestra
https://kestra.io/docs/concepts/secret,"""""""DocsConceptsSecret
Secret
Table of Contents
Secrets in the Enterprise Edition
Adding a new Secret from the UI
Using Secrets in your flows
Secret Management backends
Secrets in the Open-Source version
Manual encoding using a CLI command
Convert all variables in an .env file
Use a macro within your .env file
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Store sensitive information securely.
Secret is a mechanism that allows you to securely store sensitive information, such as passwords and API keys, and retrieve them in your flows.
To retrieve secrets in a flow, use the secret() function, e.g. ""{{ secret('API_TOKEN'') }}"". You can leverage your existing secrets manager as a secrets backend.
Your flows often need to interact with external systems. To do that, they need to programmatically authenticate using passwords or API keys. Secrets help you securely store such variables and avoid hard-coding sensitive information within your workflow code.
You can leverage the secret() function to retrieve sensitive variables within your flow code.
Secrets in the Enterprise Edition
Adding a new Secret from the UI
If you are using a managed Kestra version, you can add new Secrets directly from the UI. In the left navigation menu, go to Namespaces, select the namespace to which you want to add a new secret. Then, add a new secret within the Secrets tab.
Here, we add a new secret with a key MY_SECRET:
Using Secrets in your flows
For a concrete example of using secrets in flows, check out our dedicated How-To Guide on Secrets.
Secret Management backends
Kestra Enterprise Edition provides additional secret management backends and integrations with secrets managers. See the Secrets Manager page for more details.
Secrets in the Open-Source version
When using the open-source version, sensitive variables can be managed using base64-encoded environment variables. The section below demonstrates several ways to encode those values and use them in your Kestra instance.
Manual encoding using a CLI command
Imagine that so far, you were setting the following environment variable:
bash
export MYPASSWORD=myPrivateCode
Here is how you can encode the sensitive value of that environment variable:
bash
echo -n ""myPrivateCode"" | base64
This should output the value: bXlQcml2YXRlQ29kZQ==
To use that value as a Secret in your Kestra instance, you would need to add a prefix SECRET_ to the variable key (here: SECRET_MYPASSWORD) and set that key to the encoded value:
bash
export SECRET_MYPASSWORD=bXlQcml2YXRlQ29kZQ==
If you would add the environment variable to the kestra container section in a Docker Compose file, it would look as follows:
yaml
  kestra:
    image: kestra/kestra:latest
    environment:
      SECRET_MYPASSWORD: bXlQcml2YXRlQ29kZQ==
This secret can then be used in a flow using the {{ secret('MYPASSWORD') }} syntax, and it will base64-decoded during flow execution. Make sure to not include the prefix SECRET_ when calling the secret('MYPASSWORD') function, as this prefix is only there in the environment variable definition to prevent Kestra from treating other system variables as secrets (for better performance and increased security).
Lastly, shall you wish to reference any non_encoded environment variables in your flows definition, you can always use the syntax {{envs.lowercase_environment_variable_key}}.
Note that Kestra has built-in protection to prevent its logs from revealing any encoded secret you would have defined.
Convert all variables in an .env file
The previous section showed the process for one Secret. But what if you have tens or hundreds of them? This is where .env file can come in handy.
Let's assume that you have an .env file with the following content:
bash
MYPASSWORD=password
GITHUB_ACCESS_TOKEN=mypat
AWS_ACCESS_KEY_ID=myawsaccesskey
AWS_SECRET_ACCESS_KEY=myawssecretaccesskey
Make sure to keep the last line empty, otherwise the bash script below won't encode the last secret AWS_SECRET_ACCESS_KEY correctly.
Using the bash script shown below, you can:
Encode all values using base64-encoding
Add a SECRET_ prefix to all environment variable names
Store the result as .env_encoded
bash
while IFS='=' read -r key value; do
    echo ""SECRET_$key=$(echo -n ""$value"" | base64)"";
done < .env > .env_encoded
The .env_encoded file should look as follows:
bash
SECRET_MYPASSWORD=cGFzc3dvcmQ=
SECRET_GITHUB_ACCESS_TOKEN=bXlwYXQ=
SECRET_AWS_ACCESS_KEY_ID=bXlhd3NhY2Nlc3NrZXk=
SECRET_AWS_SECRET_ACCESS_KEY=bXlhd3NzZWNyZXRhY2Nlc3NrZXk=
Then, in your Docker Compose file, you can replace:
yaml
  kestra:
    image: kestra/kestra:latest
    env_file:
      - .env
with the encoded version of the file:
yaml
  kestra:
    image: kestra/kestra:latest
    env_file:
      - .env_encoded
Use a macro within your .env file
As an alternative to replacing values in your environment variables by encoded counterparts, you may also leverage the base64encode macro and keep the values intact.
The original .env file:
bash
MYPASSWORD=password
GITHUB_ACCESS_TOKEN=mypat
AWS_ACCESS_KEY_ID=myawsaccesskey
AWS_SECRET_ACCESS_KEY=myawssecretaccesskey
can be modified to the following format:
bash
SECRET_MYPASSWORD={{ ""password"" | base64encode }}
SECRET_GITHUB_ACCESS_TOKEN={{ ""mypat"" | base64encode }}
SECRET_AWS_ACCESS_KEY_ID={{ ""myawsaccesskey"" | base64encode }}
SECRET_AWS_SECRET_ACCESS_KEY={{ ""myawssecretaccesskey"" | base64encode }}
Was this page helpful?
Yes
No
Concepts
Revision
Concepts
Key Value (KV) Store""""""",1295,5477,kestra
https://kestra.io/docs/concepts/kv-store,"""""""DocsConceptsKey Value (KV) Store
Key Value (KV) Store
Table of Contents
Overview
How KV Store fits into Kestra's architecture
Keys and Values
Namespace binding
UI: How to Create, Read, Update and Delete KV pairs from the UI
Create new KV pairs from the UI
Update and Delete KV pairs from the UI
CODE: How to Create, Read, Update and Delete KV pairs in your flow code
Create a new KV pair with the Set task in a flow
Read KV pairs with Pebble
Read KV pairs with the Get task
Read and parse JSON-type values from KV pairs
Read keys by prefix with the GetKeys task
Delete a KV pair with the Delete task
API: How to Create, Read, Update and Delete KV pairs via REST API
Create a KV pair
Read the value by key
Read all keys in the namespace
Delete a KV pair
TERRAFORM: How to Create, Read, Update and Delete KV pairs via Terraform
Create a KV pair
Read a KV pair
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
>= 0.18.0
Build stateful workflows with the KV Store.
Overview
Kestra's workflows are stateless by design. All workflow executions and task runs are isolated from each other by default to avoid any unintended side effects. When you pass data between tasks, you do so explicitly by passing outputs from one task to another and that data is stored transparently in Kestra's internal storage. This stateless execution model ensures that workflows are idempotent and can be executed anywhere in parallel at scale.
However, in certain scenarios, your workflow might need to share data beyond passing outputs from one task to another. For example, you might want to persist data across executions or even across different workflows. This is where the Key Value (KV) store comes into play.
KV Store allows you to store any data in a convenient key-value format. You can create them directly from the UI, via dedicated tasks, Terraform or through the API.
The KV store is a powerful tool that allows you to build stateful workflows and share data across executions and workflows.
How KV Store fits into Kestra's architecture
Kestra's architecture has been designed to offer a transparent separation between the orchestration and data processing capabilities. Kestra's Executor is responsible for executing tasks and workflows without directly interacting with the user's infrastructure. The Executor relies on Workers, which are stateless processes that carry out the computation of runnable tasks and polling triggers. For privacy reasons, workers are the only components that interact with the user's infrastructure, including the internal storage and external services.
Given that data persisted in the KV Store might contain sensitive information, the KV Store has been built on top of Kestra's internal storage. This ensures that all values are stored in the your private cloud storage bucket, and Kestra's database only contains metadata about the object, such as the key, file URI, any attached metadata about the object like TTL, creation date, last updated timestamp, etc.
In short, the KV Store gives you full control and privacy over your data, and Kestra only stores metadata about the KV pairs.
Keys and Values
Keys are arbitrary strings. Keys can contain:
characters in uppercase and or lowercase
standard ASCII characters
Values are stored as ION files in Kestra's internal storage. Values are strongly typed, and can be of one of the following types:
string
number
boolean
datetime
date
duration
JSON.
For each KV pair, you can set a Time to Live (TTL) to avoid cluttering your storage with data that may only be relevant for a limited time.
Namespace binding
Key value pairs are defined at a namespace level and you can access them from the namespace page in the UI in the KV Store tab.
You can create and read KV pairs across namespaces as long as those namespaces are allowed.
UI: How to Create, Read, Update and Delete KV pairs from the UI
Kestra follows a philosophy of Everything as Code and from the UI. Therefore, you can create, read, update, and delete KV pairs both from the UI and Code.
Here is a list of the different ways to manage KV pairs:
Kestra UI: select a Namespace and go to the KV Store tab ‚Äî from here, you can create, edit, and delete KV pairs.
Task in a flow: use the io.kestra.plugin.core.kv.Set, io.kestra.plugin.core.kv.Get, and io.kestra.plugin.core.kv.Delete tasks to create, read, and delete KV pairs in a flow.
Kestra's API: use our HTTP REST API to create, read, and delete KV pairs.
Kestra's Terraform provider: use the kestra_kv resource to create, read, and delete KV pairs.
Pebble function: use the kv() function to retrieve a value by key in a flow.
GitHub Actions: create, read, and delete KV pairs in your CI/CD pipeline.
The sections below provide detailed instructions on how to create and manage KV pairs using each of these methods.
Create new KV pairs from the UI
You can create, read, update, and delete KV pairs from the UI in the following way:
Navigate to the Namespaces page from the left navigation menu and select the namespace where you want to create the KV pair.
Go to the KV Store tab. This is where you can see all the KV pairs associated with this namespace.
Click on New Key-Value button in the top right corner to create a new KV pair. Enter a name for the Key and assign a suitable Type for the value ‚Äî it can be a string, number, boolean, datetime, date, duration, or JSON.
Enter the value in the Value field.
Optionally, you can configure a Time to Live (TTL) for the KV pair. The dropdown contains some standard durations. You can also select Custom duration to enter a custom duration as a string in ISO 8601 duration format.
Finally, Save the changes. Your new KV pair should now be displayed in the list of KV pairs for that namespace.
Update and Delete KV pairs from the UI
You can edit or delete any KV pair by clicking on the Edit button on the right side of each KV pair.
CODE: How to Create, Read, Update and Delete KV pairs in your flow code
Create a new KV pair with the Set task in a flow
To create a KV pair from a flow, you can use the io.kestra.plugin.core.kv.Set task. Here's an example of how to create a KV pair in a flow:
yaml
id: add_kv_pair
namespace: company.team
tasks:
  - id: download
    type: io.kestra.plugin.core.http.Download
    uri: https://huggingface.co/datasets/kestra/datasets/raw/main/csv/orders.csv
  - id: set_kv
    type: io.kestra.plugin.core.kv.Set
    key: my_key
    value: ""{{ outputs.download.uri }}""
    namespace: company.team # the current namespace of the flow is used by default
    overwrite: true # whether to overwrite or fail if a value for that key already exists; default true
    ttl: P30D # optional Time to Live (TTL) for the KV pair
  - id: set_simple_kv
    type: io.kestra.plugin.core.kv.Set
    key: simple_string
    value: hello from Kestra
  - id: set_json_kv
    type: io.kestra.plugin.core.kv.Set
    key: json_kv
    value: |
      {
        ""author"": ""Rick Astley"",
        ""song"": ""Never Gonna Give You Up""
      }
  - id: get_kv
    type: io.kestra.plugin.core.output.OutputValues
    values:
      my_key: ""{{ kv('my_key') }}""
      simple_string: ""{{ kv('simple_string') }}""
      favorite_song: ""{{ json(kv('json_kv')).song }}""
You can use the io.kestra.plugin.core.kv.Set task to create or modify any KV pair. When modifying existing values, you can leverage the overwrite boolean parameter to control whether to overwrite the existing value or fail if a value for that key already exists. By default, the overwrite parameter is set to true so that the existing value is always updated.
Read KV pairs with Pebble
The easiest way to retrieve a value by key is to use the {{ kv('YOUR_KEY'') }} Pebble function.
Here is the full syntax of that function:
{{ kv(key='your_key_name', namespace='your_namespace_name', errorOnMissing=false) }}
Assuming that you retrieve the key in a flow in the same namespace as the one for which the key was created, you can simply use ""{{ kv('my_key') }}"" to retrieve the value:
yaml
id: read_kv_pair
namespace: company.team
tasks:
  - id: log_key
    type: io.kestra.plugin.core.log.Log
    message: ""{{ kv('my_key') }}""
When retrieving the key from another namespace, you can use the following syntax:
yaml
id: read_kv_pair_from_another_namespace
namespace: company.team
tasks:
  - id: log_key_from_another_namespace
    type: io.kestra.plugin.core.log.Log
    message: ""{{ kv('my_key', 'kestra.engineering.myproject') }}""
By default, when you try to retrieve a key that doesn't exist, the task using the ""{{ kv('non_existing_key') }}"" expression will run without errors ‚Äî that expression will simply return null. If you prefer to instead throw an error when the key doesn't exist, you can set the errorOnMissing parameter to true:
yaml
id: read_non_existing_kv_pair
namespace: company.team
tasks:
  - id: log_key_from_another_namespace
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ kv('non_existing_key', errorOnMissing=true) }}""
The function arguments such as the errorOnMissing keyword can be skipped for brevity as long as you fill in all positional arguments i.e. {{ kv(key='your_key_name', namespace='your_namespace_name', errorOnMissing=false) }} ‚Äî the version below will have the same effect:
yaml
id: read_non_existing_kv_pair
namespace: company.team
tasks:
  - id: log_key_from_another_namespace
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ kv('my_key', 'kestra.engineering.myproject', true) }}""
Read KV pairs with the Get task
You can also retrieve the value of any KV pair using the Get task. The Get task will produce the value output, which you can use in subsequent tasks. This option is a little more verbose but it has two benefits:
More declarative syntax.
Useful when you need to pass the current state of that value to multiple downstream tasks.
yaml
id: get_kv_pair
namespace: company.team
tasks:
  - id: get
    type: io.kestra.plugin.core.kv.Get
    key: my_key
    namespace: company.team
    errorOnMissing: false
  - id: log_key_get
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.get.value }}""
Read and parse JSON-type values from KV pairs
To parse JSON values in Kestra's templated expressions, make sure to wrap the kv() call in the json() function, e.g. ""{{ json(kv('your_json_key')).json_property }}"".
The following example demonstrates how to parse values from JSON-type KV pairs in a flow:
yaml
id: kv_json_flow
namespace: company.team
tasks:
  - id: set_json_kv
    type: io.kestra.plugin.core.kv.Set
    key: favorite_song
    value: |
      {
        ""author"": ""Rick Astley"",
        ""song"": ""Never Gonna Give You Up"",
        ""album"": {
          ""name"": ""Whenever You Need Somebody"",
          ""release_date"": ""1987-11-16""
        }
      }
  - id: parse_json_kv
    type: io.kestra.plugin.core.log.Log
    message:
      - ""Author: {{ json(kv('favorite_song')).author }}""
      - ""Song: {{ json(kv('favorite_song')).song }}""
      - ""Album name: {{ json(kv('favorite_song')).album.name }}""
      - ""Album release date: {{ json(kv('favorite_song')).album.release_date }}""
  - id: get
    type: io.kestra.plugin.core.kv.Get
    key: favorite_song
  - id: parse_json_from_kv
    type: io.kestra.plugin.core.log.Log
    message: ""Country: {{ json(outputs.get.value).album.name }}""
Read keys by prefix with the GetKeys task
If you want to check if some values already exist for a given key, you can search keys by prefix:
yaml
id: get_keys_by_prefix
namespace: company.team
tasks:
  - id: get
    type: io.kestra.plugin.core.kv.GetKeys
    prefix: ""test_""
    namespace: company.team
  - id: log_key_prefix
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.get.keys }}""
The output will be a list of keys - if no keys were found, an empty list will be returned.
Delete a KV pair with the Delete task
The io.kestra.plugin.core.kv.Delete task will produce the boolean output deleted to confirm whether a given KV pair was deleted or not.
yaml
id: delete_kv_pair
namespace: company.team
tasks:
  - id: kv
    type: io.kestra.plugin.core.kv.Delete
    key: my_key
    namespace: company.team
    errorOnMissing: false
  - id: check_if_deleted
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.kv.deleted }}""
API: How to Create, Read, Update and Delete KV pairs via REST API
Let's look at how you can interact with the KV Store via the REST API.
Create a KV pair
The API call to set the KV pair follows the structure:
bash
curl -X PUT -H ""Content-Type: application/json"" http://localhost:8080/api/v1/namespaces/{namespace}/kv/{key} -d '<value>'
For example:
bash
curl -X PUT -H ""Content-Type: application/json"" http://localhost:8080/api/v1/namespaces/company.team/kv/my_key -d '""Hello World""'
The above curl command will create the KV pair with key my_key and the Hello World string value in the company.team namespace. The API does not return any response.
Read the value by key
You can get any particular KV pair using:
bash
curl -X GET -H ""Content-Type: application/json"" http://localhost:8080/api/v1/namespaces/{namespace}/kv/{key}
For example:
bash
curl -X GET -H ""Content-Type: application/json"" http://localhost:8080/api/v1/namespaces/company.team/kv/my_key
This will retrieve a KV pair with the key my_key in the company.team namespace. The output of the API will contain the data type of the value and the retrieved value of the KV pair:
json
{""type"": ""STRING"", ""value"": ""Hello World""}
Read all keys in the namespace
You can list all keys in the namespace as follows:
bash
curl -X GET -H ""Content-Type: application/json"" http://localhost:8080/api/v1/namespaces/{namespace}/kv
The curl command below will return all keys in the company.team namespace:
bash
curl -X GET -H ""Content-Type: application/json"" http://localhost:8080/api/v1/namespaces/company.team/kv
The output will be returned as a JSON array of all keys in the namespace:
json
[
  {""key"":""my_key"",""creationDate"":""2024-07-27T06:10:33.422Z"",""updateDate"":""2024-07-27T06:11:08.911Z""},
  {""key"":""test_key"",""creationDate"":""2024-07-27T04:37:18.196Z"",""updateDate"":""2024-07-27T04:37:18.196Z""}
]
Delete a KV pair
You can delete any KV pair using the following API call:
bash
curl -X DELETE -H ""Content-Type: application/json"" http://localhost:8080/api/v1/namespaces/{namespace}/kv/{key}
This call returns a boolean indicating whether the key was deleted.
For example, the following curl command will return false because the key non_existing_key does not exist:
bash
curl -X DELETE -H ""Content-Type: application/json"" http://localhost:8080/api/v1/namespaces/company.team/kv/non_existing_key
However, when we try to delete a key my_key which exists in the company.team namespace, the same API call will return true:
bash
curl -X DELETE -H ""Content-Type: application/json"" http://localhost:8080/api/v1/namespaces/company.team/kv/my_key
TERRAFORM: How to Create, Read, Update and Delete KV pairs via Terraform
Create a KV pair
You can create a KV pair via Terraform by using the kestra_kv resource.
Here is an example of how to create a KV pair:
hcl
resource ""kestra_kv"" ""my_key"" {
  namespace = ""company.team""
  key       = ""my_key""
  value     = ""Hello Woprld""
  type      = ""STRING""
}
Read a KV pair
You can read a KV pair via Terraform by using the kestra_kv data source.
Here is an example of how to read a KV pair:
hcl
data ""kestra_kv"" ""new"" {
  namespace = ""company.team""
  key       = ""my_key""
}
As with anything in Terraform, you can manage the state of your KV resources by adjusting the Terraform code and running the terraform apply command to create, update, or delete your KV pairs.
Was this page helpful?
Yes
No
Concepts
Secret
Concepts
Pebble Templating Engine""""""",3829,15666,kestra
https://kestra.io/docs/concepts/pebble,"""""""DocsConceptsPebble Templating Engine
Pebble Templating Engine
Table of Contents
Reading inputs
Reading task ouputs
Dynamically render a task with TemplatedTask
Date formatting
Coalesce operator to conditionally use trigger or execution date
Parsing objects & lists using jq
Using conditions in Pebble
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Dynamically render variables, inputs and outputs.
Pebble is a Java templating engine inspired by Twig and similar to the Python Jinja Template Engine syntax. Kestra uses it to dynamically render variables, inputs and outputs within the execution context.
Reading inputs
When using inputs property in a Flow, you can access the corresponding values just by using inputs variable in your tasks.
yaml
id: input_string
namespace: company.team
inputs:
  - id: name
    type: STRING
tasks:
  - id: say_hello
    type: io.kestra.plugin.core.log.Log
    message: ""Hello üëã, my name is {{ inputs.name }}""
Reading task ouputs
Most of Kestra's tasks expose output values. You can access those outputs in other tasks by using outputs.<task_name>.<output_name>. Every task output can be found in the corresponding task documentation.
In the example below, we use the value outputs of the io.kestra.plugin.core.debug.Return task in the downstream task.
yaml
id: input_string
namespace: company.team
inputs:
  - id: name
    type: STRING
tasks:
  - id: say_hello
    type: io.kestra.plugin.core.debug.Return
    format: ""Hello üëã, my name is {{ inputs.name }}""
  - id: can_you_repeat
    type: io.kestra.plugin.core.log.Log
    message: '{{ outputs.say_hello.value }}'
Dynamically render a task with TemplatedTask
Since Kestra 0.16.0, you can use the TemplatedTask task which allows you to fully template all task properties using Pebble. This way, all task properties and their values can be dynamically rendered based on your custom inputs, variables, and outputs from other tasks.
Here is an example of how to use the TemplatedTask to create a Databricks job using dynamic properties:
yaml
id: templated_databricks_job
namespace: company.team
inputs:
  - id: host
    type: STRING
  - id: clusterId
    type: STRING
  - id: taskKey
    type: STRING
  - id: pythonFile
    type: STRING
  - id: sparkPythonTaskSource
    type: ENUM
    defaults: WORKSPACE
    values:
      - GIT
      - WORKSPACE
  - id: maxWaitTime
    type: STRING
    defaults: ""PT30M""
tasks:
  - id: templated_spark_job
    type: io.kestra.plugin.core.templating.TemplatedTask
    spec: |
      type: io.kestra.plugin.databricks.job.CreateJob
      authentication:
        token: ""{{ secret('DATABRICKS_API_TOKEN') }}""
      host: ""{{ inputs.host }}""
      jobTasks:
        - existingClusterId: ""{{ inputs.clusterId }}""
          taskKey: ""{{ inputs.taskKey }}""
          sparkPythonTask:
            pythonFile: ""{{ inputs.pythonFile }}""
            sparkPythonTaskSource: ""{{ inputs.sparkPythonTaskSource }}""
      waitForCompletion: ""{{ inputs.maxWaitTime }}""
Note how in this example, the waitForCompletion property is templated using Pebble even though that property is not dynamic. The same is true for the sparkPythonTaskSource property. Without the TemplatedTask task, you would not be able to pass those values from inputs.
Date formatting
Pebble can be very useful to make small transformation on the fly - without the need to use Python or some dedicated programming language.
For instance, we can use the date filter to format date values: '{{ inputs.my_date | date(""yyyyMMdd"") }}'
Coalesce operator to conditionally use trigger or execution date
Most of the time, a flow will be triggered automatically. Either on schedule or based on external events. It‚Äôs common to use the date of the execution to process the corresponding data and make the flow dependent on time.
With Pebble you can use the trigger.date to get the date of the executed trigger. Still, sometimes you want to manually execute a flow. Then the trigger.date variable won‚Äôt work anymore. For this you can use the execution.startDate variable that returns the execution start date.
To support both use cases, use the coalesce operator ??. The example below shows how to apply it in a flow.
yaml
id: pebble_date_trigger
namespace: company.team
tasks:
  - id: return_date
    type: io.kestra.plugin.core.debug.Return
    format: '{{ trigger.date ?? execution.startDate | date(""yyyy-MM-dd"")}}'
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""* * * * *""
Parsing objects & lists using jq
Sometimes, outputs return nested objects or lists. To parse those elements, you may leverage jq. You can use jQuery to slice, filter, map, and transform structured data with the same ease that sed, awk, grep, and similar Linux commands let you manipulate strings.
Consider the following flow:
yaml
id: object_example
namespace: company.team
inputs:
  - id: data
    type: JSON
    defaults: '{""value"": [1, 2, 3]}'
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: ""{{ inputs.data }}""
The expression {{ inputs.data.value }} will return the list [1, 2, 3]
The expression {{ inputs.data.value | jq("".[1]"") | first }} will return 2.
jq("".[1]"") accesses the second value of the list and returns an array with one element. We then use first to access the value itself.
Note: we could have used {{ inputs | jq("".data.value[1]"") | first }}, jq allows to parse any object in Kestra context.
You can troubleshoot complex Pebble expressions using the Debug Outputs button in the outputs tab of a Flow execution page in the UI. It's helpful to validate how complex objects will be parsed.
Using conditions in Pebble
In some tasks, such as the If or Switch tasks, you will need to provide some conditions. You can use the Pebble syntax to use previous task outputs within those conditions:
yaml
id: test-object
namespace: company.team
inputs:
  - id: data
    type: JSON
    defaults: '{""value"": [1, 2, 3]}'
tasks:
  - id: if
    type: io.kestra.plugin.core.flow.If
    condition: '{{ inputs.data.value | jq("".[2]"") | first == 3}}'
    then:
      - id: when_true
        type: io.kestra.plugin.core.log.Log
        message: 'Condition was true'
    else:
      - id: when_false
        type: io.kestra.plugin.core.log.Log
        message: 'Condition was false'
Was this page helpful?
Yes
No
Concepts
Key Value (KV) Store
Concepts
Blueprints""""""",1532,6386,kestra
https://kestra.io/docs/concepts/blueprints,"""""""DocsConceptsBlueprints
Blueprints
Table of Contents
Community Blueprints
Where to find Blueprints
How to find the right Blueprint
Custom Blueprints
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
>= 0.10.0
Ready-to-use examples designed to kickstart your workflow.
Blueprints are a curated, organized, and searchable catalog of ready-to-use examples designed to help you kickstart your workflow.
Each Blueprint combines code and documentation and can be assigned several tags for organization and discoverability.
All Blueprints are validated and documented. You can easily customize and integrate them into your new or existing flows with a single click on the ""Use"" button.
View the Blueprints library here.
Community Blueprints
We refer to all Blueprints available in the open-source product as Community Blueprints, as they are guided by the community feedback and represent common usage patterns we see among open-source users and contributors.
Community Blueprints are particularly helpful when you're getting started with a new use case, integration, or with Kestra in general because they reflect fairly standardized workflow patterns. All Blueprints are verified by the Kestra team, but everyone is welcome to contribute new Blueprints or suggest improvements to the existing ones using the following GitHub issue template.
Where to find Blueprints
Blueprints are accessible from two places in the UI:
The left navigation sidebar
A dedicated tab in the code editor named ""Source and blueprints"", showing your source code and Blueprints side by side.
How to find the right Blueprint
Once you are on the Blueprints page, you can:
Search Blueprints for a specific use case or integration, e.g., Snowflake, BigQuery, DuckDB, Slack, ETL, ELT, Pandas, GPU, Git, Python, Docker, Redis, MongoDB, dbt, Airbyte, Fivetran, etc.
Filter by a tag, e.g., filter for Docker, to see various ways to run containers in your flow. Or filter for Notifications to see several options for configuring alerts on success or failure.
Custom Blueprints
This feature requires a commercial license.
Apart from Community Blueprints, you can create custom Blueprints available only to your organization. You can use them to share, centralize, and document commonly used workflows in your team. Read more in the Custom Blueprints documentation.
Was this page helpful?
Yes
No
Concepts
Pebble Templating Engine
Concepts
Backfill""""""",514,2444,kestra
https://kestra.io/docs/concepts/backfill,"""""""DocsConceptsBackfill
Backfill
Table of Contents
Trigger Backfill via an API call
Using cURL
Using Python requests
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Backfills are replays of missed schedule intervals between a defined start and end date.
Let's take the following flow as an example:
yaml
id: scheduled_flow
namespace: company.team
tasks:
  - id: external_system_export
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - echo ""processing data for {{ execution.startDate ?? trigger.date }}""
      - sleep $((RANDOM % 5 + 1))
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/30 * * * *""
This flow will run every 30 minutes. However, imagine that your source system had an outage for 5 hours. The flow will miss 10 executions. To replay these missed executions, you can use the backfill feature.
All missed schedules are automatically recovered by default.
You can use Backfill if it's configured differently, e.g. to not recover missed schedules or only the most recent. Read more in the dedicated documentation.
To backfill the missed executions, go to the Triggers tab on the Flow's detail page and click on the Backfill executions button.
You can then select the start and end date for the backfill. Additionally, you can set custom labels for the backfill executions to help you identify them in the future.
You can pause and resume the backfill process at any time, and by clicking on the Details button, you can see more details about that backfill process:
Trigger Backfill via an API call
Using cURL
You can invoke the backfill exections using the cURL call as follows:
sh
curl -XPUT http://localhost:8080/api/v1/triggers -H 'Content-Type: application/json' -d '{
  ""backfill"": {
    ""start"": ""2024-03-28T06:30:00.000Z"",
    ""end"": null,
    ""inputs"": null,
    ""labels"": [
      {
        ""key"": ""reason"",
        ""value"": ""outage""
      }
    ]
  },
  ""flowId"": ""scheduled_flow"",
  ""namespace"": ""dev"",
  ""triggerId"": ""schedule""
}'
In the backfill attribute, you need to provide the start time for the backfill. The end time can be optinally provided. You can provide inputs to the flow, if any. You can attach labels to the backfill executions by providing key-value pairs in the labels section. Other attributes to this PUT call are flowId, namespace and triggerId corresponding to the flow that is to backfilled.
Using Python requests
You can invoke the backfill exections using the Python requests as follows:
python
import requests
import json
url = 'http://localhost:8080/api/v1/triggers'
headers = {
    'Content-Type': 'application/json'
}
data = {
  ""backfill"": {
    ""start"": ""2024-03-28T06:30:00.000Z"",
    ""end"": None,
    ""inputs"": None,
    ""labels"": [
      {
        ""key"": ""reason"",
        ""value"": ""outage""
      }
    ]
  },
  ""flowId"": ""scheduled_flow"",
  ""namespace"": ""dev"",
  ""triggerId"": ""schedule""
}
response = requests.put(url, headers=headers, data=json.dumps(data))
print(response.status_code)
print(response.text)
With this code, you will be invoking the backfill for scheduled_flow flow under company.team namespace based on schedule trigger ID within the flow. The number of backfills that will be executed will depend on the schedule present in the schedule trigger, and the start and end times mentioned in the backfill. When the end time is null, as in this case, the end time would be considered as the present time.
Was this page helpful?
Yes
No
Concepts
Blueprints
Concepts
Replay""""""",875,3589,kestra
https://kestra.io/docs/concepts/replay,"""""""DocsConceptsReplay
Replay
Table of Contents
What is a Replay
Why Replay is useful
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Replay allows you to re-run a workflow execution from any chosen task run.
What is a Replay
By using Replay, you can re-run a workflow execution from any selected task run. To do that, simply go to the Gantt view of the chosen workflow execution (it doesn't need to be a Failed execution, it can be an execution in any state) and click on the task run you want to re-run.
Why Replay is useful
Replays are extremely useful for iterative development and reprocessing data.
Imagine the following scenario: you have a workflow that extracts a large compressed CSV dataset and you want to transform it into a Parquet file with a specific schema.
yaml
id: divvy_tripdata
namespace: company.team
variables:
  file_id: ""{{ execution.startDate | dateAdd(-3, 'MONTHS') | date('yyyyMM') }}""
tasks:
  - id: get_zipfile
    type: io.kestra.plugin.core.http.Download
    uri: ""https://divvy-tripdata.s3.amazonaws.com/{{ render(vars.file_id) }}-divvy-tripdata.zip""
  - id: unzip
    type: io.kestra.plugin.compress.ArchiveDecompress
    algorithm: ZIP
    from: ""{{ outputs.get_zipfile.uri }}""
  - id: convert
    type: io.kestra.plugin.serdes.csv.CsvToIon
    from: ""{{outputs.unzip.files[render(vars.file_id) ~ '-divvy-tripdata.csv']}}""
  - id: to_parquet
    type: io.kestra.plugin.serdes.avro.IonToAvro # render(vars.file_id)
    from: ""{{ outputs.convert.uri }}""
    datetimeFormat: ""yy-MM-dd' 'HH:mm:ss""
    schema: |
      {
        ""type"": ""record"",
        ""name"": ""Ride"",
        ""namespace"": ""com.example.bikeshare"",
        ""fields"": [
          {""name"": ""ride_id"", ""type"": ""string""},
          {""name"": ""rideable_type"", ""type"": ""string""},
          {""name"": ""started_at"", ""type"": {""type"": ""long"", ""logicalType"": ""timestamp-millis""}},
          {""name"": ""ended_at"", ""type"": {""type"": ""long"", ""logicalType"": ""timestamp-millis""}},
          {""name"": ""start_station_name"", ""type"": ""string""},
          {""name"": ""start_station_id"", ""type"": ""string""},
          {""name"": ""end_station_name"", ""type"": ""string""},
          {""name"": ""end_station_id"", ""type"": ""string""},
          {""name"": ""start_lat"", ""type"": ""double""},
          {""name"": ""start_lng"", ""type"": ""double""},
          {
            ""name"": ""end_lat"",
            ""type"": [""null"", ""double""],
            ""default"": null
          },
          {
            ""name"": ""end_lng"",
            ""type"": [""null"", ""double""],
            ""default"": null
          },
          {""name"": ""member_casual"", ""type"": ""string""}
        ]
      }
When you run the above workflow, you should see an error in the to_parquet task.
From the logs, you will be able to see that the error is due to a misconfigured date format in the datetimeFormat field ‚Äî in fact, the date format should have a full year, not just a two-digit year: ""yyyy-MM-dd' 'HH:mm:ss"".
You correct the error in the workflow code and save it.
Full corrected flow code
Now you can go to the previously failed Execution and click on the to_parquet task run to re-run it (either from the Gantt or from the Logs view).
Now select the new revision of the flow code that contains the fix and confirm with the OK button.
This will re-run the task with the new (corrected!) revision of the flow code.
You can inspect the logs and verify that the task now completes successfully. The Attempt number will be incremented to show that this is a new run of the task.
The Overview tab will additionally show the new Attempt number and the new revision of the flow code that was used during Replay.
The replay feature allowed us to re-run a failed task with the corrected version of the flow code. You didn't have to rerun tasks that had already completed successfully. This is a huge time-saver when iterating on your workflows! ‚ö°Ô∏è
Was this page helpful?
Yes
No
Concepts
Backfill
Concepts
Data storage and processing""""""",980,3956,kestra
https://kestra.io/docs/concepts/storage,"""""""DocsConceptsData storage and processing
Data storage and processing
Table of Contents
Storing data
Storing data inside the flow execution context
Storing data inside the internal storage
Storing data inside the KV store
Processing data
Converting files
Processing data using scripts
Processing data using file transform
Purging data
FAQ
Internal Storage FAQ
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage data processed by tasks.
Kestra's primary purpose is to orchestrate data processing via tasks, so data is central to each flow's execution.
Depending on the task, data can be stored inside the execution context or inside Kestra's internal storage. You can also manually store data inside Kestra's KV store by using dedicated tasks.
Some tasks give you the choice of where you want to store the data, usually using a fetchType property or the three fetch/fetchOne/store properties.
For example, using the DynamoDB Query task:
yaml
id: query
type: io.kestra.plugin.aws.dynamodb.Query
tableName: persons
keyConditionExpression: id = :id
expressionAttributeValues:
  :id: ""1""
fetchType: FETCH
The fetchType property can have four values:
FETCH_ONE: will fetch the first row and set it in a task output attribute (the row attribute for DynamoDB); the data will be stored inside the execution context.
FETCH: will fetch all rows and set them in a task output attribute (the rows attribute for DynamoDB); the data will be stored inside the execution context.
STORE: will store all rows inside Kestra's internal storage. The internal storage will return a URI usually set in the task output attribute uri and that can be used to retrieve the file from the internal storage.
NONE: will do nothing.
The three fetch/fetchOne/store properties will do the same but using three different task properties instead of a single one.
Storing data
Storing data inside the flow execution context
Data can be stored as variables inside the flow execution context. This can be convenient for sharing data between tasks.
To do so, tasks store data as output attributes that are then available inside the flow via Pebble expressions like {{outputs.taskName.attributeName}}.
Be careful that when the size of the data is significant, this will increase the size of the flow execution context, which can lead to slow execution and increase the size of the execution storage inside Kestra's repository.
Depending on the Kestra internal queue and repository implementation, there can be a hard limit on the size of the flow execution context as it is stored as a single row/message. Usually, this limit is around 1MB, so this is important to avoid storing large amounts of data inside the flow execution context.
Storing data inside the internal storage
Kestra has an internal storage that can store data of any size. By default, the internal storage uses the host filesystem, but plugins exist to use other implementations like Amazon S3, Google Cloud Storage, or Microsoft Azure Blobs storage. See internal storage configuration.
When using the internal storage, data is, by default, stored using Amazon Ion format.
Tasks that can store data inside the internal storage usually have an output attribute named uri that can be used to access this file in following tasks.
The following example uses the DynamoDB Query task to query a table and the FTP Upload task to send the retrieved rows to an external FTP server.
yaml
tasks:
- id: query
  type: io.kestra.plugin.aws.dynamodb.Query
  tableName: persons
  keyConditionExpression: id = :id
  expressionAttributeValues:
    :id: ""1""
  fetchType: STORE
- id: upload
  type: io.kestra.plugin.fs.ftp.Upload
  host: localhost
  port: 80
  from: ""{{ outputs.query.uri }}""
  to: ""/upload/file.ion""
If you need to access data from the internal storage, you can use the read() function to read the file's content as a string.
Dedicated tasks allow managing the files stored inside the internal storage:
Concat: concat multiple files.
Delete: delete a file.
Size: get the size of a file.
Split: split a file into multiple files depending on the size of the file or the number of rows.
This should be the main method for storing and carrying large data from task to task. As an example, if you know that a HTTP Request will return a heavy payload, you should consider using HTTP Download along with a Serdes instead of carrying raw data in Flow Execution Context
Storing data inside the KV store
Dedicated tasks can store data inside Kestra's KV store. The KV store transparently uses Kestra's internal storage as its backend store.
The KV store allows storing data that will be shared by all executions of the same namespace. You can think of it as a key/value store dedicated to a namespace.
The following tasks are available:
Set: set data in key/value pair.
Get: get data from key/value pair.
Delete: delete a key/value pair.
Example:
yaml
tasks:
- id: set_data
  type: io.kestra.plugin.core.kv.Set
  key: name
  value: John Doe
- id: get_data
  type: io.kestra.plugin.core.kv.Get
  key: name
In the next example, the flow will Set, Get and Delete the data:
Example Flow
Processing data
For basic data processing, you can leverage Kestra's Pebble templating engine.
For more complex data transformations, Kestra offers various data processing plugins incl. transform tasks or custom scripts.
Converting files
Files from the internal storage can be converted from/to the Ion format to/from another format using the Serdes plugin.
The following formats are currently available: Avro, JSON, XML, and Parquet.
Each format offers a reader to read an Ion serialized data file and write it in the target format and a writer to read a file in a specific format and write it as an Ion serialized data file.
For example, to convert an Ion file to CSV, then back to Ion:
yaml
tasks:
- id: query
  type: io.kestra.plugin.aws.dynamodb.Query
  tableName: persons
  keyConditionExpression: id = :id
  expressionAttributeValues:
    :id: ""1""
  fetchType: STORE
- id: convertToCsv
  type: io.kestra.plugin.serdes.csv.IonToCsv
  from: ""{{outputs.query.uri}}""
- id: convertBackToIon
  type: io.kestra.plugin.serdes.csv.CsvToIon
  from: ""{{outputs.convertToCsv.uri}}""""
Processing data using scripts
Kestra can launch scripts written in Python, R, Node.js, Shell and Powershell. Depending on the runner, they can run directly in a local process on the host or inside Docker containers.
Those script tasks are available in the Scripts Plugin. Here is documentation for each of them:
The Python task will run a Python script in a Docker container or in a local process.
The Node task will run a Node.js script in a Docker container or in a local process.
The R task will run an R script in a Docker container or in a local process.
The Shell task will execute a single Shell command, or a list of commands that you provide.
The PowerShell task will execute a single PowerShell command, or a list of commands that you provide.
The following example will query the BigQuery public dataset with Wikipedia page views to find the top 10 pages, convert it to CSV, and use the CSV file inside a Python task for further transformations using Pandas.
yaml
id: wikipedia-top-ten-python-panda
namespace: company.team
description: analyze top 10 Wikipedia pages
tasks:
  - id: query
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      SELECT DATETIME(datehour) as date, title, views FROM `bigquery-public-data.wikipedia.pageviews_2023`
      WHERE DATE(datehour) = current_date() and wiki = 'en'
      ORDER BY datehour desc, views desc
      LIMIT 10
    store: true
    projectId: geller
    serviceAccount: ""{{envs.gcp_creds}}""
  - id: write-csv
    type: io.kestra.plugin.serdes.csv.IonToCsv
    from: ""{{outputs.query.uri}}""
  - id: wdir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    inputFiles:
      data.csv: ""{{outputs['write-csv'].uri}}""
    tasks:
    - id: pandas
      type: io.kestra.plugin.scripts.python.Script
      warningOnStdErr: false
      containerImage: ghcr.io/kestra-io/pydata:latest
      script: |
        import pandas as pd
        from kestra import Kestra
        df = pd.read_csv(""data.csv"")
        views = df['views'].sum()
        Kestra.outputs({'views': int(views)})
Kestra offers several plugins for ingesting and transforming data ‚Äî check the Plugin list for more details.
Make sure to also check:
The Script documentation for a detailed overview of how to work with Python, R, Node.js, Shell and Powershell scripts and how to integrate them with Git and Docker.
The Blueprints catalog ‚Äî simply search for the relevant language (e.g. Python, R, Rust) or use case (ETL, Git, dbt, etc.) to find the relevant examples.
Processing data using file transform
Kestra can process data row by row using file transform tasks. The transformation will be done with a small script written in Python, JavaScript, or Groovy.
The Jython FileTransform task allows transforming rows with Python.
The Nashorn FileTransform task allows transforming rows with JavaScript.
The Groovy FileTransform task allows transforming rows with Groovy.
The following example will query the BigQuery public dataset for Wikipedia pages, convert it row by row with the Nashorn FileTransform, and write it in a CSV file.
yaml
id: wikipedia-top-ten-file-transform
namespace: company.team
description: A flow that loads wikipedia top 10 EN pages
tasks:
  - id: query-top-ten
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      SELECT DATETIME(datehour) as date, title, views FROM `bigquery-public-data.wikipedia.pageviews_2023`
      WHERE DATE(datehour) = current_date() and wiki = 'en'
      ORDER BY datehour desc, views desc
      LIMIT 10
    store: true
  - id: file-transform
    type: io.kestra.plugin.scripts.nashorn.FileTransform
    from: ""{{outputs['query-top-ten'].uri}}""
    script: |
      logger.info('row: {}', row)
      if (row['title'] === 'Main_Page' || row['title'] === 'Special:Search' || row['title'] === '-') {
        // remove un-needed row
        row = null
      } else {
        // add a 'time' column
        row['time'] = String(row['date']).substring(11)
        // modify the 'date' column to only keep the date part
        row['date'] = String(row['date']).substring(0, 10)
      }
  - id: write-csv
    type: io.kestra.plugin.serdes.csv.IonToCsv
    from: ""{{outputs['file-transform'].uri}}""
The script can access a logger to log messages. Each row is available in a row variable where each column is accessible using the dictionary notation row['columnName'].
Purging data
The PurgeExecution task can purge all the files stored inside the internal context by a flow execution. It can be used at the end of a flow to purge all its generated files.
yaml
tasks:
  - id: ""purge-execution""
    type: ""io.kestra.plugin.core.storage.PurgeExecution""
The execution context itself will not be available after the end of the execution and will be automatically deleted from Kestra's repository after a retention period (by default, seven days) that can be changed; see configurations.
Also, the Purge task can be used to purge storages, logs, executions of previous execution. For example, this flow will purge all of these every day:
yaml
id: purge
namespace: company.team
tasks:
  - id: ""purge""
    type: ""io.kestra.plugin.core.storage.Purge""
    endDate: ""{{ now() | dateAdd(-1, 'MONTHS') }}""
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 0 * * *""
FAQ
Internal Storage FAQ
How to read a file from the internal storage as a string?
The 'read' function expects an argument 'path' that is a path to a namespace file or an internal storage URI. Note that when using inputs, outputs or trigger variables, you don't need any extra quotation marks. Here is how you can use such variables along with the 'read' function:
{{ read(inputs.file) }} for a FILE-type input variable named file
{{ read(outputs.mytaskid.uri) }} for an output uri from a task named mytaskid
{{ read(trigger.uri) }} for a uri of many triggers incl. Kafka, AWS SQS, GCP PubSub, etc.
{{ read(trigger.objects | jq('.[].uri')) }} for a uri of a trigger that returns a list of detected objects, e.g. AWS S3, GCP GCS, etc.
Note that the read function can only read files within the same execution. If you try to read a file from a previous execution, you will get an Unauthorized error.
Example using a FILE-type inputs variable
Example with the ForEachItem task reading file's content as a string
How to read a Namespace File as a string?
So far, you've seen how to read a file from the internal storage as a string. However, you can use the same read() function to read a Namespace File as a string. This is especially useful when you want to execute a Python script or a long SQL query stored in a dedicated SQL file.
The read() function takes the absolute path to the file you want to read. The path must point to a file stored in the same namespace as the flow you are executing.
Here is a simple example showing how you can read a file named hello.py stored in the scripts directory of the company.team namespace:
yaml
id: hello
namespace: company.team
tasks:
  - id: my_python_script
    type: io.kestra.plugin.scripts.python.Script
    script: ""{{ read('scripts/hello.py') }}""
The same syntax applies to SQL queries, custom scripts, and many more. Check the Namespace Files documentation for more details.
How to read a file from the internal storage as a JSON object?
You can use the Pebble function {{ fromJson(myvar) }} and a {{ myvar | toJson }} filter to process JSON data.
The fromJson() function
The json filter
Was this page helpful?
Yes
No
Concepts
Replay
Concepts
Caching""""""",3180,13676,kestra
https://kestra.io/docs/concepts/caching,"""""""DocsConceptsCaching
Caching
Table of Contents
Cache files in a WorkingDirectory task
Use cases for file caching
How does it work under the hood
Node.js example
Python example
How to invalidate the cache
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage file caching inside of Kestra.
Kestra provides a file caching, which is especially useful when you work with sizeable package dependencies that don't change often.
Cache files in a WorkingDirectory task
The file caching functionality on the WorkingDirectory task allows you to cache a subset of files to speed up your workflow execution. This is especially useful when you work with sizeable package dependencies that don't change often.
Kestra can only cache files installed or created as part of the script tasks if the script uses a PROCESS runner. If the script uses a DOCKER runner, the files will not be cached and the WorkingDirectory task will throw an error: Unable to execute WorkingDirectory post actions.
Use cases for file caching
The file caching is useful if you want to install some pip or npm packages before running your script. You can cache the node_modules or Python venv folder to avoid re-installing the dependencies on each run.
To do that, add a cache to your WorkingDirectory task. The cache property accepts a list of glob patterns to match files to cache. The cache will be automatically invalidated after a specified time-to-live using the ttl property accepting a duration.
yaml
id: caching_files
namespace: company.team
tasks:
  - id: working_dir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    cache:
      patterns:
        - some_directory/**
      ttl: PT1H
How does it work under the hood
Kestra packages the files that need to be cached and stores them in the internal storage. When the task is executed again, the cached files are retrieved, initializing the working directory with their contents.
Node.js example
Here's an example of a flow that installs the colors package before running a Node.js script. The node_modules folder is cached for one hour.
yaml
id: node_cached_dependencies
namespace: company.team
tasks:
  - id: working_dir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    cache:
      patterns:
        - node_modules/**
      ttl: PT1H
    tasks:
    - id: node_script
      type: io.kestra.plugin.scripts.node.Script
      beforeCommands:
        - npm install colors
      script: |
        const colors = require(""colors"");
        console.log(colors.red(""Hello""));
Python example
Here's an example of a flow that installs the pandas package before running a Python script. The venv folder is cached for one day.
yaml
id: python_cached_dependencies
namespace: company.team
tasks:
  - id: working_dir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: python_script
        type: io.kestra.plugin.scripts.python.Script
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        warningOnStdErr: false
        beforeCommands:
          - python -m venv venv
          - source venv/bin/activate
          - pip install pandas
        script: |
          import pandas as pd
          print(pd.__version__)
    cache:
      patterns:
        - venv/**
      ttl: PT24H
How to invalidate the cache
Here's how that works:
After the first run, the files are cached
The next time the task is executed:
if the ttl didn't pass, the files are retrieved from cache
If the ttl passed, the cache is invalidated and no files will be retrieved from cache; because cache is no longer present, the npm install command from the beforeCommands property will take a bit longer to execute
If you edit the task and change the ttl to:
a longer duration e.g. PT5H ‚Äî the files will be cached for five hours using the new ttl duration
a shorter duration e.g. PT5M ‚Äî the cache will be invalidated after five minutes using the new ttl duration.
The ttl is evaluated at runtime. If the most recently set ttl duration has passed as compared to the last task run execution date, the cache is invalidated and the files are no longer retrieved from cache.
Was this page helpful?
Yes
No
Concepts
Data storage and processing
Concepts
System Flows""""""",926,4223,kestra
https://kestra.io/docs/concepts/system-flows,"""""""DocsConceptsSystem Flows
System Flows
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Open Source Edition
Enterprise Edition
>= 0.19.0
Automate maintenance workflows with System Flows.
System Flows periodically execute background operations that keep your platform running, but which you would generally prefer to keep out of sight. These flows automate maintenance workflows, such as:
Sending alert notifications
Creating automated support tickets when critical workflows fail
Purging logs and removing old executions or internal storage files to save space
Syncing code from Git or pushing code to Git
Automatically releasing flows from development to QA and staging environments
We refer to these as System Flows because by default they are hidden from end users and are only visible within the system namespace. If you prefer, you can use a different namespace name instead of system by overwriting the following configuration:
yaml
kestra:
  systemFlows:
    namespace: system
To access System Flows, navigate to the Namespaces section in the UI. The system namespace is pinned at the top for quick access.
Here, you‚Äôll find the System Blueprints tab, which provides fully customizable templates which you can modify to suit your organization‚Äôs needs.
Keep in mind that System Flows are not restricted to System Blueprints ‚Äî any valid Kestra flow can become a System Flow if it's added to the system namespace.
System Flows are intentionally hidden from the main UI, appearing only in the system namespace. The Dashboard, Flows, and Executions pages offer a multi-select filter with options for User (default) and System (visible by default only within the system namespace). This makes it easy to toggle between user-facing workflows and background system flows and their executions, or view both simultaneously.
In terms of permissions, system namespace is open by default, but using the namespace-level RBAC functionality in the Enterprise Edition, you can restrict access to the system namespace only to Admins, while assigning company.* namespaces to your general user base.
Was this page helpful?
Yes
No
Concepts
Caching
Docs
Workflow Components""""""",439,2197,kestra
https://kestra.io/docs/workflow-components,"""""""DocsWorkflow Components
Workflow Components
Table of Contents
Components of a flow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Flow is a container for tasks and and their orchestration logic, as well as labels, variables, inputs, outputs and triggers.
Components of a flow
A flow is a container for tasks, their inputs, outputs, handling errors and overall orchestration logic. It defines the order in which tasks are executed and how they are executed, e.g. sequentially, in parallel, based on upstream task dependencies and their state, etc.
You can define a flow declaratively using a YAML file.
A flow must have:
identifier (id)
namespace
list of tasks
Flows can also have a variety of optional properties, which you can read more about below:
Flow
Flow is a container for tasks and their orchestration logic.
Tasks
Tasks are the steps within a flow.
Namespace
Namespace is a logical grouping of flows.
Execution
Execute your flows and view the outcome.
Variables
Variables are key-value pairs that help reuse some values across tasks.
Inputs
Inputs is a list of dynamic values passed to the flow at runtime.
Outputs
Outputs allow you to pass data between tasks and flows.
Triggers
Trigger is a mechanism that automates the execution of a flow.
Labels
Labels are key-value pairs used to organize flows and executions.
Plugin Defaults
Plugin defaults are a list of default values applied to each task of a certain type within your flow(s).
Subflows
Subflows allow you to build modular and reusable workflow components.
Errors
Allow your flow to continue to operate despite errors.
Retries
Retries handle transient failures in your workflows.
Timeout
Timeout allows you to set a maximum duration for a task run.
Concurrency limits
Control concurrent executions of a given flow.
Descriptions
You can document your flows, inputs, outputs, tasks and triggers by adding a description property.
Disabled flag
The disabled flag is a boolean property that allows you to skip a flow, task or trigger.
States
States control the status of your workflow execution.
Was this page helpful?
Yes
No
Concepts
System Flows
Workflow Components
Flow""""""",449,2163,kestra
https://kestra.io/docs/workflow-components/flow,"""""""DocsWorkflow ComponentsFlow
Flow
Table of Contents
Components of a flow
Flow sample
Plugin defaults
Variables
List of tasks
Disable a flow
Task
Runnable Task
Flowable Task
Labels
Inputs
Outputs
Revision
Triggers
Flow variable expressions
Listeners (deprecated)
Templates (deprecated)
FAQ
Where does Kestra store flows?
How to load flows at server startup?
Can I sync a local flows directory to be continuously loaded into Kestra?
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Flow is a container for tasks and their orchestration logic.
Components of a flow
A flow is a container for tasks, their inputs, outputs, handling of errors and overall orchestration logic. It defines the order in which tasks are executed and how they are executed, e.g. sequentially, in parallel, based on upstream task dependencies and their state, etc.
You can define a flow declaratively using a YAML file.
A flow must have:
identifier (id)
namespace
list of tasks
Optionally, a flow can also have:
inputs
outputs
variables
triggers
labels
pluginDefaults
errors
retries
timeout
concurrency
descriptions
disabled
revision
Flow sample
Here is a sample flow definition. It uses tasks available in Kestra core for testing purposes, such as the Return or Log tasks, and demonstrates how to use labels, inputs, variables, triggers and various descriptions.
yaml
id: hello-world
namespace: company.team
description: flow **documentation** in *Markdown*
labels:
  env: prod
  team: engineering
inputs:
  - id: my-value
    type: STRING
    required: false
    defaults: ""default value""
    description: This is a not required my-value
variables:
  first: ""1""
  second: ""{{vars.first}} > 2""
tasks:
  - id: date
    type: io.kestra.plugin.core.debug.Return
    description: ""Some tasks **documentation** in *Markdown*""
    format: ""A log line content with a contextual date variable {{taskrun.startDate}}""
pluginDefaults:
  - type: io.kestra.plugin.core.log.Log
    values:
      level: ERROR
Plugin defaults
You can also define pluginDefaults in your flow. This is a list of default task properties that will be applied to each task of a certain type inside your flow. The pluginDefaults property can be handy to avoid repeating the same values when leveraging the same task multiple times.
Variables
You can set flow variables that will be accessible by each task using {{ vars.key }}. Flow variables is a map of key/value pairs.
List of tasks
The most important part of a flow is the list of tasks that will be run sequentially when the flow is executed.
Disable a flow
By default, all flows are active and will execute whether or not a trigger has been set.
You have the option to disable a Flow, which is particularly useful when you want to temporarily stop a Flow from executing e.g. when troubleshooting a failure.
Task
A task is a single action in a flow. A task can have properties, use flow inputs and other task's outputs, perform an action, and produce an output.
There are two kinds of tasks in Kestra:
Runnable Tasks
Flowable Tasks
Runnable Task
Runnable Tasks handle computational work in the flow. For example, file system operations, API calls, database queries, etc. These tasks can be compute-intensive and are handled by workers.
By default, Kestra only includes a few Runnable Tasks. However, many of them are available as plugins, and if you use our default Docker image, plenty of them will already be included.
Flowable Task
Flowable Tasks only handle flow logic (branching, grouping, parallel processing, etc.) and start new tasks. For example, the Switch task decides the next task to run based on some inputs.
A Flowable Task is handled by an executor and can be called very often. Because of that, these tasks cannot include intensive computations, unlike Runnable Tasks. Most of the common Flowable Tasks are available in the default Kestra installation.
Labels
Labels are key-value pairs that you can add to flows. Labels are used to organize flows and can be used to filter executions of any given flow from the UI.
Inputs
Inputs are parameters sent to a flow at execution time. It's important to note that inputs in Kestra are strongly typed.
The inputs can be declared as either optional or mandatory. If the flow has required inputs, you'll have to provide them before the execution of the flow. You can also provide default values to the inputs.
Inputs can have validation rules that are enforced at execution time.
Inputs of type FILE will be uploaded to Kestra's internal storage and made available for all tasks.
Flow inputs can be seen in the Overview tab of the Execution page.
Outputs
Each task (or flow) can produce outputs that may contain multiple properties. This output is described in the plugin documentation task and can then be accessible by all following tasks via expressions.
Some outputs are of a special type and will be stored in Kestra's internal storage. Kestra will automatically make these outputs available for all tasks.
You can view:
task outputs in the Outputs tab of the Execution page.
flow outputs in the Overview tab of the Execution page.
If an output is a file from the internal storage, it will be available to download.
For more details on both task and flow outputs, see the Outputs page.
Revision
Changing the source of a flow will produce a new revision for the flow. The revision is an incremental number that will be updated each time you change the flow.
Internally, Kestra will track and manage all the revisions of the flow. Think of it as version control for your flows integrated inside Kestra.
You can access old revisions inside the Revisions tab of the Flows page.
Triggers
Triggers are a way to start a flow from external events. For example, a trigger might initiate a flow at a scheduled time or based on external events (webhooks, file creation, message in a broker, etc.).
Flow variable expressions
Flows have a number of variable expressions giving you information about them dynamically, a few examples include:
Parameter Description
{{ flow.id }} The identifier of the flow.
{{ flow.namespace }} The name of the flow namespace.
{{ flow.tenantId }} The identifier of the tenant (EE only).
{{ flow.revision }} The revision of the flow.
Listeners (deprecated)
Listeners are special tasks that can listen to the current flow, and launch tasks outside the flow, meaning launch tasks that are not part of the flow.
The result of listeners will not change the execution status of the flow. Listeners are mainly used to send notifications or handle special behavior outside the primary flow.
Templates (deprecated)
Templates are lists of tasks that can be shared between flows. You can define a template and call it from other flows. Templates allow you to share a list of tasks and keep them updated without changing all flows that use them.
FAQ
Where does Kestra store flows?
Flows are stored in a serialized format directly in the Kestra backend database.
The easiest way to add new flows is to add them directly from the Kestra UI. You can also use the Git Sync pattern or CI/CD integration to add flows automatically after a pull request is merged to a given Git branch.
To see how flows are represented in a file structure, you can leverage the _flows directory in the Namespace Files editor.
How to load flows at server startup?
If you want to load a given local directory of flows to be loaded into Kestra (e.g. during local development), you can use the -f or --flow-path flag when starting Kestra:
bash
./kestra server standalone -f /path/to/flows
That path should point to a directory containing YAML files with the flow definition. These files will be loaded to the Kestra repository at startup. Kestra will make sure to add flows to the right namespace, as declared in the flow YAML definition.
For more information about the Kestra server CLI, check the Server CLI Reference section.
Can I sync a local flows directory to be continuously loaded into Kestra?
At the time of writing, there is no syncing of a flows directory to Kestra. However, we are aware of that need and we are working on a solution. You can follow up in this GitHub issue.
Was this page helpful?
Yes
No
Docs
Workflow Components
Workflow Components
Tasks""""""",1773,8222,kestra
https://kestra.io/docs/workflow-components/tasks,"""""""DocsWorkflow ComponentsTasks
Tasks
Table of Contents
Flowable Tasks
Runnable Tasks
Core task properties
Dynamic vs. static task properties
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Tasks are the steps within a flow.
Tasks are discrete actions within a flow, capable of taking inputs and variables from the flow, and producing outputs for downstream consumption by end users and other tasks.
Flowable Tasks
Kestra orchestrates your flows using Flowable Tasks. These tasks do not perform any heavy computation. Instead, they control the orchestration behavior, allowing you to implement more advanced workflow patterns.
Example Flowable tasks include:
io.kestra.plugin.core.flow.Parallel
io.kestra.plugin.core.flow.Switch
io.kestra.plugin.core.flow.ForEachItem
Read the full list on the Flowable tasks page.
Runnable Tasks
In Kestra, most data processing workloads are executed using Runnable Tasks.
In contrast to Flowable Tasks, Runnable Tasks are responsible for performing the actual work. For example, file system operations, API calls, database queries, etc. These tasks can be compute-intensive and are handled by workers.
Example runnable tasks include:
io.kestra.plugin.scripts.python.Commands
io.kestra.plugin.core.http.Request
io.kestra.plugin.notifications.slack.SlackExecution
Core task properties
The table below lists the core task properties available to all tasks.
Field Description
id The flow identifier, must be unique inside a flow.
type The Java Fully Qualified Class Name of the task.
description The description of the task
retry Task retry behavior
timeout Task timeout expressed in ISO 8601 Durations.
disabled Set it to true to disable execution of the task.
workerGroup.key To execute this task on a specific Worker Group (EE).
allowFailure Boolean flag allowing to continue the execution even if this task fails.
logLevel To define the log level granularity for which logs will be inserted into the backend database. By default, all logs are stored. However, if you restrict that to e.g., the INFO level, all lower log levels such as DEBUG and TRACE won't be persisted.
logToFile Boolean flag that lets you store logs as a file in internal storage. That file can be previewed and downloaded from the Logs and Gantt Execution tabs. When set to true, logs aren‚Äôt saved in the database, which is useful for tasks that produce a large amount of logs that would otherwise take up too much space. The same property can be set on triggers.
Dynamic vs. static task properties
Task properties can be static or dynamic. Dynamic task properties can be set using expressions. To find out whether a given task property is static or dynamic, check the task documentation available on the plugin's homepage as well as in the UI when you hover over a task and click on the documentation tab on the right.
Often some task properties are marked as not dynamic because they are complex types (e.g. maps, list of strings, list of maps), meaning that they are placeholders for other dynamic properties. Let's take the runTasks property of Databrick's SubmitRun task as an example. This property is not dynamic because it's an array of RunSubmitTaskSetting.
On top of that, RunSubmitTaskSetting is a group of other properties which are also either dynamic or of complex type (placeholder for other properties). It's therefore useful to always drill down to the lowest level ‚Äî most properties at the lowest level are dynamic and can be templated using expressions.
Flowable Tasks
Control your orchestration logic.
Runnable Tasks
Data processing tasks handled by the workers.
Script Tasks (Code in Any Language)
Kestra is language agnostic. Write your business logic in any language.
Task Runs
A Task Run is a single run of an individual task within an Execution, where an Execution is a single run of a flow. This means an Execution can have many Task Runs.
Was this page helpful?
Yes
No
Workflow Components
Flow
Tasks
Flowable Tasks""""""",816,3970,kestra
https://kestra.io/docs/workflow-components/tasks/flowable-tasks,"""""""DocsWorkflow ComponentsTasksFlowable Tasks
Flowable Tasks
Table of Contents
Sequential
Parallel
Switch
If
ForEach
ForEachItem
AllowFailure
Fail
Subflow
Worker
WorkingDirectory
Pause
DAG
Template (deprecated)
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Control your orchestration logic.
Flowable tasks control the orchestration logic ‚Äî run tasks or subflows in parallel, create loops and conditional branching.
Flowable Tasks don't run heavy operations ‚Äî those are handled by workers.
Flowable Tasks are used for branching, grouping, running tasks in parallel, and more.
Flowable Tasks use expressions from the execution context to define the next tasks to run. For example, you can use the outputs of a previous task in a Switch task to decide which task to run next.
Sequential
This task processes tasks one after another sequentially. It is used to group tasks.
yaml
id: sequential
namespace: company.team
tasks:
  - id: sequential
    type: io.kestra.plugin.core.flow.Sequential
    tasks:
      - id: 1st
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ task.id }} > {{ taskrun.startDate }}""
      - id: 2nd
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ task.id }} > {{ taskrun.id }}""
  - id: last
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ task.id }} > {{ taskrun.startDate }}""
You can access the output of a sibling task using the syntax {{ outputs.sibling.value }}.
Sequential Task documentation
Parallel
This task processes tasks in parallel. It makes it convenient to process many tasks at once.
yaml
id: parallel
namespace: company.team
tasks:
  - id: parallel
    type: io.kestra.plugin.core.flow.Parallel
    tasks:
      - id: 1st
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ task.id }} > {{ taskrun.startDate }}""
      - id: 2nd
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ task.id }} > {{ taskrun.id }}""
  - id: last
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ task.id }} > {{ taskrun.startDate }}""
You cannot access the output of a sibling task as tasks will be run in parallel.
Parallel Task documentation
Switch
This task processes a set of tasks conditionally depending on a contextual variable's value.
In the following example, an input will be used to decide which task to run next.
yaml
id: switch
namespace: company.team
inputs:
  - id: param
    type: BOOLEAN
tasks:
  - id: decision
    type: io.kestra.plugin.core.flow.Switch
    value: ""{{ inputs.param }}""
    cases:
      true:
        - id: is_true
          type: io.kestra.plugin.core.log.Log
          message: ""This is true""
      false:
        - id: is_false
          type: io.kestra.plugin.core.log.Log
          message: ""This is false""
Switch Task documentation
If
This task processes a set of tasks conditionally depending on a condition. The condition must coerce to a boolean. Boolean coercion allows 0, -0, null and '' to coerce to false, all other values to coerce to true. The else branch is optional.
In the following example, an input will be used to decide which task to run next.
yaml
id: if_condition
namespace: company.team
inputs:
  - id: param
    type: BOOLEAN
tasks:
  - id: if
    type: io.kestra.plugin.core.flow.If
    condition: ""{{ inputs.param }}""
    then:
      - id: when_true
        type: io.kestra.plugin.core.log.Log
        message: ""This is true""
    else:
      - id: when_false
        type: io.kestra.plugin.core.log.Log
        message: ""This is false""
If Task documentation
ForEach
This task will execute a group of tasks for each value in the list.
In the following example, the variable is static, but it can be generated from a previous task output and starts an arbitrary number of subtasks.
yaml
id: foreach_example
namespace: company.team
tasks:
  - id: for_each
    type: io.kestra.plugin.core.flow.ForEach
    values: [""value 1"", ""value 2"", ""value 3""]
    tasks:
      - id: before_if
        type: io.kestra.plugin.core.debug.Return
        format: ""Before if {{ taskrun.value }}""
      - id: if
        type: io.kestra.plugin.core.flow.If
        condition: '{{ taskrun.value == ""value 2"" }}'
        then:
          - id: after_if
            type: io.kestra.plugin.core.debug.Return
            format: ""After if {{ parent.taskrun.value }}""
You can access the output of a sibling task using the syntax {{ outputs.sibling[taskrun.value].value }}.
This example shows how to run tasks in parallel for each value in the list. All child tasks of the parallel task will run in parallel. However, due to the concurrencyLimit property set to 2, only two parallel task groups will run at any given time.
yaml
id: parallel_tasks_example
namespace: company.team
tasks:
  - id: for_each
    type: io.kestra.plugin.core.flow.ForEach
    values: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    concurrencyLimit: 2
    tasks:
      - id: parallel
        type: io.kestra.plugin.core.flow.Parallel
        tasks:
        - id: log
          type: io.kestra.plugin.core.log.Log
          message: Processing {{ parent.taskrun.value }}
        - id: shell
          type: io.kestra.plugin.scripts.shell.Commands
          commands:
            - sleep {{ parent.taskrun.value }}
For processing items, or forwarding processing to a subflow, ForEachItem is better suited.
ForEach Task documentation
ForEachItem
This task allows you to iterate over a list of items and run a subflow for each item, or for each batch containing multiple items.
Syntax:
yaml
  - id: each
    type: io.kestra.plugin.core.flow.ForEachItem
    items: ""{{ inputs.file }}"" # could be also an output variable {{ outputs.extract.uri }}
    inputs:
      file: ""{{ taskrun.items }}"" # items of the batch
    batch:
      rows: 4
    namespace: company.team
    flowId: subflow
    revision: 1 # optional (default: latest)
    wait: true # wait for the subflow execution
    transmitFailed: true # fail the task run if the subflow execution fails
    labels: # optional labels to pass to the subflow to be executed
      key: value
This will execute the subflow company.team.subflow for each batch of items. To pass the batch of items to a subflow, you can use inputs. The example above uses an input of FILE type called file that takes the URI of an internal storage file containing the batch of items.
The next example shows you how you can access the outputs from each subflow executed. The ForEachItem automatically merges the URIs of the outputs from each subflow into a single file. The URI of this file is available through the subflowOutputs output.
yaml
id: for_each_item
namespace: company.team
tasks:
  - id: generate
    type: io.kestra.plugin.scripts.shell.Script
    script: |
      for i in $(seq 1 10); do echo ""$i"" >> data; done
    outputFiles:
      - data
  - id: for_each_item
    type: io.kestra.plugin.core.flow.ForEachItem
    items: ""{{ outputs.generate.outputFiles.data }}""
    batch:
      rows: 4
    wait: true
    flowId: my_subflow
    namespace: company.team
    inputs:
       value: ""{{ taskrun.items }}""
  - id: for_each_outputs
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.forEachItem_merge.subflowOutputs }}"" # Log the URI of the file containing the URIs of the outputs from each subflow
ForEachItem Task documentation
ForEach vs ForEachItem
Both ForEach and ForEachItem are similar, but there are specific use cases that suit one over the other:
ForEach generates a lot of Task Runs which can impact performance.
ForEachItem generates separate executions using Subflows for the group of tasks. This scales better for larger datasets.
Read more about performance optimization here.
AllowFailure
This task will allow child tasks to fail. If any child task fails:
The AllowFailure failed task will be marked as status WARNING.
All children's tasks inside the AllowFailure will be stopped immediately.
The Execution will continue for all others tasks.
At the end, the execution as a whole will also be marked as status WARNING.
In the following example:
allow_failure will be labelled as WARNING.
ko will be labelled as FAILED.
next will not be run.
end will be run and labelled SUCCESS.
yaml
id: each
namespace: company.team
tasks:
  - id: allow_failure
    type: io.kestra.plugin.core.flow.AllowFailure
    tasks:
      - id: ko
        type: io.kestra.plugin.core.execution.Fail
      - id: next
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ task.id }} > {{ taskrun.startDate }}""
  - id: end
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ task.id }} > {{ taskrun.startDate }}""
AllowFailure Task documentation
Fail
This task will fail the flow; it can be used with or without conditions.
Without conditions, it can be used, for example, to fail on some switch value.
yaml
id: fail_on_switch
namespace: company.team
inputs:
  - id: param
    type: STRING
    required: true
tasks:
  - id: switch
    type: io.kestra.plugin.core.flow.Switch
    value: ""{{ inputs.param }}""
    cases:
      case1:
        - id: case1
          type: io.kestra.plugin.core.log.Log
          message: Case 1
      case2:
        - id: case2
          type: io.kestra.plugin.core.log.Log
          message: Case 2
      notexist:
        - id: fail
          type: io.kestra.plugin.core.execution.Fail
      default:
        - id: default
          type: io.kestra.plugin.core.log.Log
          message: default
With conditions, it can be used, for example, to validate inputs.
yaml
id: fail_on_condition
namespace: company.team
inputs:
  - id: param
    type: STRING
    required: true
tasks:
  - id: before
    type: io.kestra.plugin.core.log.Log
    message: ""I'm before the fail on condition""
  - id: fail
    type: io.kestra.plugin.core.execution.Fail
    condition: ""{{ inputs.param == 'fail' }}""
  - id: after
    type: io.kestra.plugin.core.log.Log
    message: ""I'm after the fail on condition""
Fail Task documentation
Subflow
This task will trigger another flow. This allows you to decouple the first flow from the second and monitor each flow individually.
You can pass flow outputs as inputs to the triggered subflow (those must be declared in the subflow).
yaml
id: subflow
namespace: company.team
tasks:
  - id: ""subflow""
    type: io.kestra.plugin.core.flow.Subflow
    namespace: company.team
    flowId: my-subflow
    inputs:
      file: ""{{ inputs.myFile }}""
      store: 12
Subflow Task documentation
Worker
The Worker task is deprecated in favor of theWorkingDirectory task. The next section explains how you can use theWorkingDirectory task in order to allow multiple tasks to share a file system during the flow's Execution.
WorkingDirectory
By default, Kestra will launch each task in a new working directory, possibly on different workers if multiple ones exist.
The example below will run all tasks nested under the WorkingDirectory task sequentially. All those tasks will be executed in the same working directory, allowing the reuse of the previous tasks' output files in the downstream tasks. In order to share a working directory, all tasks nested under the WorkingDirectory task will be launched on the same worker.
This task can be particularly useful for compute-intensive file system operations.
yaml
id: working_dir_flow
namespace: company.team
tasks:
  - id: working_dir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: first
        type: io.kestra.plugin.scripts.shell.Commands
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        commands:
          - 'echo ""{{ taskrun.id }}"" > {{ workingDir }}/stay.txt'
      - id: second
        type: io.kestra.plugin.scripts.shell.Commands
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        commands:
          - |
            echo '::{""outputs"": {""stay"":""'$(cat {{ workingDir }}/stay.txt)'""}}::'
This task can also cache files inside the working directory, for example, to cache script dependencies like the node_modules of a node Script task.
yaml
id: node_with_cache
namespace: company.team
tasks:
  - id: working_dir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    cache:
      patterns:
        - node_modules/**
      ttl: PT1H
    tasks:
      - id: script
        type: io.kestra.plugin.scripts.node.Script
        beforeCommands:
          - npm install colors
        script: |
          const colors = require(""colors"");
          console.log(colors.red(""Hello""));
This task can also fetch files from namespace files and make them available to all child tasks.
yaml
id: node_with_cache
namespace: company.team
tasks:
  - id: working_dir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    namespaceFiles:
      enabled: true
      include:
        - dir1/*.*
      exclude:
        - dir2/*.*
    tasks:
      - id: shell
        type: io.kestra.plugin.scripts.shell.Commands
        commands:
          - cat dir1/file1.txt
WorkingDirectory Task documentation
Pause
Kestra flows run until all tasks complete, but sometimes you need to:
Add a manual validation before continuing the execution.
Wait for some duration before continuing the execution.
For this, you can use the Pause task.
On the following example, the validation will pause until a manual modification of the task step, and the wait will wait for 5 minutes.
yaml
id: pause
namespace: company.team
tasks:
  - id: validation
    type: io.kestra.plugin.core.flow.Pause
    tasks:
      - id: ok
        type: io.kestra.plugin.scripts.shell.Commands
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        commands:
          - 'echo ""started after manual validation""'
  - id: wait
    type: io.kestra.plugin.core.flow.Pause
    delay: PT5M
    tasks:
      - id: waited
        type: io.kestra.plugin.scripts.shell.Commands
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        commands:
          - 'echo ""start after 5 minutes""'
A Pause task without delay will wait indefinitely until the task state is changed to Running. For this: go to the Gantt tab of the Execution page, click on the task, select Change status on the contextual menu and select Mark as RUNNING on the form. This will make the task run until its end.
Pause Task documentation
DAG
This task allows defining dependencies between tasks by creating a directed acyclic graph (DAG). Instead of an explicit DAG structure, this task allows you to only define upstream dependencies for each task using the dependsOn property. This way, you can set dependencies more implicitly for each task, and Kestra will figure out the overall flow structure.
yaml
id: dag
namespace: company.team
tasks:
  - id: dag
    description: ""my task""
    type: io.kestra.plugin.core.flow.Dag
    tasks:
      - task:
          id: task1
          type: io.kestra.plugin.core.log.Log
          message: I'm the task 1
      - task:
          id: task2
          type: io.kestra.plugin.core.log.Log
          message: I'm the task 2
        dependsOn:
          - task1
      - task:
          id: task3
          type: io.kestra.plugin.core.log.Log
          message: I'm the task 3
        dependsOn:
          - task1
      - task:
          id: task4
          type: io.kestra.plugin.core.log.Log
          message: I'm the task 4
        dependsOn:
          - task2
      - task:
          id: task5
          type: io.kestra.plugin.core.log.Log
          message: I'm the task 5
        dependsOn:
          - task4
          - task3
Dag Task documentation
Template (deprecated)
Templates are lists of tasks that can be shared between flows. You can define a template and call it from other flows, allowing them to share a list of tasks and keep these tasks updated without changing your flow.
The following example uses the Template task to use a template.
yaml
id: template
namespace: company.team
tasks:
  - id: template
    type: io.kestra.plugin.core.flow.Template
    namespace: company.team
    templateId: template
Was this page helpful?
Yes
No
Workflow Components
Tasks
Tasks
Runnable Tasks""""""",3797,16059,kestra
https://kestra.io/docs/workflow-components/tasks/runnable-tasks,"""""""DocsWorkflow ComponentsTasksRunnable Tasks
Runnable Tasks
Table of Contents
Example
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Data processing tasks handled by the workers.
Runnable tasks are data processing tasks incl. file system operations, API calls, database queries, etc. These tasks can be compute-intensive and are processed by workers.
Each task must have an identifier (id) and a type. The type is the task's Java Fully Qualified Class Name (FQCN).
Tasks have properties specific to the type of the task; check each task's documentation for the list of available properties.
Most available tasks are Runnable Tasks except special ones that are Flowable Tasks.
By default, Kestra only includes a few Runnable Tasks. However, many of them are available as plugins, and if you use our default Docker image, plenty of them will already be included.
Example
In this example, we have 2 Runnable Tasks: one which makes a HTTP request and another that logs the output of that request.
yaml
id: runnable_http
namespace: company.team
tasks:
  - id: make_request
    type: io.kestra.plugin.core.http.Request
    uri: https://reqres.in/api/products
    method: GET
    contentType: application/json
  - id: print_status
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.make_request.body }}""
Was this page helpful?
Yes
No
Tasks
Flowable Tasks
Tasks
Script Tasks (Code in Any Language)""""""",318,1429,kestra
https://kestra.io/docs/workflow-components/tasks/scripts,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)
Script Tasks (Code in Any Language)
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Kestra is language agnostic. Write your business logic in any language.
You can orchestrate custom business logic written in any language, and you can also build custom plugins in Java.
There are dedicated plugins for Python, R, Julia, Ruby, Node.js, Powershell and Shell. You can also run any language using the Shell plugin too.
By default, these tasks run in individual Docker containers (taskRunner type: io.kestra.plugin.scripts.runner.docker.Docker). You can overwrite that default behavior if you prefer that your scripts run in a local process (taskRunner type: io.kestra.plugin.core.runner.Process) instead.
If you use a commercial version of Kestra, you can also run your scripts on dedicated remote workers by specifying a workerGroup property or using other Task Runner types for AWS, GCP, Azure and Kubernetes.
The following pages dive into details of each task runner, supported programming languages and how to manage dependencies.
Programming Languages
Kestra is language agnostic. Use any programming language inside of your workflows.
Commands and Script tasks
Types of tasks for executing programming languages.
Inline Scripts in Docker
Writing code directly inside your task.
DOCKER and PROCESS runners
Manage the environment your code is executed with runner.
Building a Custom Docker Image
Build a custom Docker image for your script tasks.
Installing Dependencies at Runtime
Install dependencies at runtime using beforeCommands.
Outputs and Metrics
Send Outputs and Metrics back to Kestra.
Input and Output Files
Manage Input and Output files with your scripts.
Logging
Send logs back to Kestra.
Bind Mount
Use bind-mount to execute locally stored scripts.
Git Clone task
Clone a Git repository and use the files in your tasks.
Working Directory
Run multiple tasks in the same working directory sequentially.
Was this page helpful?
Yes
No
Tasks
Runnable Tasks
Scripts
Programming Languages""""""",418,2087,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/languages,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Programming Languages
Programming Languages
Table of Contents
Dedicated Plugins
Script Example
Commands Example
Run any language using the Shell task
Go
Rust
Java
C
C++
TypeScript
PHP
Scala
Perl
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Kestra is language agnostic. Use any programming language inside of your workflows.
Kestra works with any programming language with some having dedicated plugins to make it easier to use as well as libraries to make sending outputs and metrics back to Kestra easy.
Dedicated Plugins
Kestra currently supports the following programming languages with their own dedicated plugins:
Python
R
Node.js
Shell
Powershell
Julia
Ruby
Each of them have the following subgroup of plugins:
Commands: Execute scripts from a command line interface (good for longer files that may be written separately)
Script: Write your code directly inside of your YAML (good for short scripts that don't need a dedicated file)
Script Example
In this example, the Python script is inline:
yaml
id: myflow
namespace: company.team
tasks:
  - id: ""script""
    type: ""io.kestra.plugin.scripts.python.Script""
    script: |
      from kestra import Kestra
      import requests
      response = requests.get('https://google.com')
      print(response.status_code)
      Kestra.outputs({'status': response.status_code, 'text': response.text})
    beforeCommands:
      - pip install requests kestra
Commands Example
In this example, the shell task is running dedicated commands, similar to how you would inside of your terminal.
yaml
id: myflow
namespace: company.team
tasks:
  - id: ""commands""
    type: ""io.kestra.plugin.scripts.shell.Commands""
    outputFiles:
      - first.txt
      - second.txt
    commands:
      - echo ""1"" >> first.txt
      - echo ""2"" >> second.txt
Run any language using the Shell task
Using Commands, you can run arbitrary commands in a Docker container. This means that you can use other languages as long as:
Their dependencies can be packaged into a Docker image
Their execution can be triggered from a Shell command line.
Below are a number of examples showing how you can do this with different programming languages.
For handling outputs and metrics, you can use the same approach that the Shell task uses by using ::{}:: syntax in log messages. Read more about it here.
Go
Here is an example flow that runs a Go file inside of a container using a golang image:
yaml
id: golang
namespace: company.team
tasks:
  - id: go
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: golang:latest
    namespaceFiles:
      enabled: true
    commands:
      - go run hello_world.go
The Go code is saved as a namespace file called hello_world.go:
go
package main
import ""fmt""
func main() {
    fmt.Println(""Hello, World!"")
}
When executed, we can see the print statement in the Kestra logs:
Check out the full guide which includes using outputs and metrics.
Rust
Here is an example flow that runs a Rust file inside of a container using a rust image:
yaml
id: rust
namespace: company.team
tasks:
  - id: rust
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: rust:latest
    namespaceFiles:
      enabled: true
    commands:
      - rustc hello_world.rs
      - ./hello_world
The Rust code is saved as a namespace file called hello_world.rs:
rust
fn main() {
    println!(""Hello, World!"");
}
When executed, we can see the print statement in the Kestra logs:
Check out the full guide which includes using outputs and metrics.
Java
You can build custom plugins in Java which will allow you to add custom tasks to your workflows. If you're looking to execute something simpler, you can use the Shell task with a Docker container.
Here is an example flow that runs a Java file inside of a container using a eclipse-temurin image:
yaml
id: java
namespace: company.team
tasks:
  - id: java
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: eclipse-temurin:latest
    namespaceFiles:
      enabled: true
    commands:
      - javac HelloWorld.java
      - java HelloWorld
The Java code is saved as a namespace file called HelloWorld.java:
java
class HelloWorld {
    public static void main(String[] args) {
        System.out.println(""Hello, World!"");
    }
}
When executed, we can see the print statement in the Kestra logs:
C
Here is an example flow that runs a C file inside of a container using a gcc image:
yaml
id: c
namespace: company.team
tasks:
  - id: c
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: gcc:latest
    namespaceFiles:
      enabled: true
    commands:
      - gcc hello_world.c
      - ./a.out
The C code is saved as a namespace file called hello_world.c:
c
#include <stdio.h>
int main() {
   printf(""Hello, World!"");
   return 0;
}
When executed, we can see the print statement in the Kestra logs:
C++
Here is an example flow that runs a C++ file inside of a container using a gcc image:
yaml
id: cplusplus
namespace: company.team
tasks:
  - id: cpp
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: gcc:latest
    namespaceFiles:
      enabled: true
    commands:
      - g++ hello_world.cpp
      - ./a.out
The C++ code is saved as a namespace file called hello_world.cpp:
cpp
#include <iostream>
int main() {
    std::cout << ""Hello World!"";
    return 0;
}
When executed, we can see the print statement in the Kestra logs:
TypeScript
You can execute TypeScript using the NodeJS plugin. To do so, we'll need to install TypeScript and compile our code to JavaScript using tsc.
Once we've done this, we can then execute it as we normally would with NodeJS. However, do note that our file is now a .js file.
yaml
id: typescript
namespace: company.team
tasks:
  - id: ts
    type: io.kestra.plugin.scripts.node.Commands
    namespaceFiles:
      enabled: true
    commands:
      - npm i -D typescript
      - npx tsc example.ts
      - node example.js
This example can be found in the Node.js docs. We're going to save it as example.ts.
typescript
type User = {
  name: string;
  age: number;
};
function isAdult(user: User): boolean {
  return user.age >= 18;
}
const justine: User = {
  name: 'Justine',
  age: 23,
};
const isJustineAnAdult: boolean = isAdult(justine);
console.log(isJustineAnAdult)
When executed, we can see the print statement in the Kestra logs:
You can read more about Node.js with TypeScript here.
PHP
Here is an example flow that runs a PHP file inside of a container using a php image:
yaml
id: php
namespace: company.team
tasks:
  - id: php
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: php:8.4-rc-alpine
    namespaceFiles:
      enabled: true
    commands:
      - php hello_world.php
The PHP code is saved as a namespace file called hello_world.php:
php
<?php
echo ""Hello, World!"";
?>
When executed, we can see the print statement in the Kestra logs:
Scala
Here is an example flow that runs a Scala file inside of a container using a sbtscala/scala-sbt image:
yaml
id: scala
namespace: company.team
tasks:
  - id: scala
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: sbtscala/scala-sbt:eclipse-temurin-17.0.4_1.7.1_3.2.0
    namespaceFiles:
      enabled: true
    commands:
      - scalac HelloWorld.scala
      - scala HelloWorld
The Scala code is saved as a namespace file called HelloWorld.scala:
scala
object HelloWorld {
    def main(args: Array[String]) = {
        println(""Hello, World!"")
    }
}
When executed, we can see the print statement in the Kestra logs:
Perl
Here is an example flow that runs a Perl file inside of a container using a perl image:
yaml
id: perl
namespace: company.team
tasks:
  - id: perl
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: perl:5.41.2
    namespaceFiles:
      enabled: true
    commands:
      - perl hello_world.pl
The Perl code is saved as a namespace file called hello_world.pl:
perl
#!/usr/bin/perl
use warnings;
print(""Hello, World!\n"");
When executed, we can see the print statement in the Kestra logs:
Was this page helpful?
Yes
No
Tasks
Script Tasks (Code in Any Language)
Scripts
Commands and Script tasks""""""",2156,8793,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/commands-vs-scripts,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Commands and Script tasks
Commands and Script tasks
Table of Contents
When to use Script over Commands?
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Types of tasks for executing programming languages.
For each of the supported languages (e.g. Python, R, Node.js, Shell), Kestra provides two types of tasks: Script and Commands.
The Script tasks ‚Äî typically written inline in the YAML flow configuration. They are best suited for short scripts and they make it easy to pass data from flow inputs and other tasks to your custom scripts.
The Commands tasks ‚Äî best suited for more complex and longer scripts, typically integrated into kestra as namespace files.
The following table gives an overview of all script tasks and their configuration.
Language Default image beforeCommands example Script example Commands example
Python python pip install requests kestra print(""Hello World!"") python hello.py
R r-base Rscript -e ""install.packages('dplyr')"" print(""Hello World!"") Rscript hello.R
Julia julia julia -e 'using Pkg; Pkg.add(""CSV"")' println(""Hello World!"") julia hello.jl
Ruby ruby gem install httparty puts ""Hello World!"" ruby hello.rb
Node.js node npm install json2csv console.log('Hello World!'); node hello.js
Shell ubuntu apt-get install curl echo ""Hello World!"" ./hello.bash
Powershell powershell Install-Module -Name ImportExcel Write-Output ""Hello World!"" .\hello.ps1
Full class names:
io.kestra.plugin.scripts.python.Commands
io.kestra.plugin.scripts.python.Script
io.kestra.plugin.scripts.r.Commands
io.kestra.plugin.scripts.r.Script
io.kestra.plugin.scripts.julia.Commands
io.kestra.plugin.scripts.julia.Script
io.kestra.plugin.scripts.ruby.Commands
io.kestra.plugin.scripts.ruby.Script
io.kestra.plugin.scripts.node.Commands
io.kestra.plugin.scripts.node.Script
io.kestra.plugin.scripts.shell.Commands
io.kestra.plugin.scripts.shell.Script
io.kestra.plugin.scripts.powershell.Commands
io.kestra.plugin.scripts.powershell.Script
Check available blueprints to get started with those tasks.
When to use Script over Commands?
The Script pattern has several advantages:
Simplicity: the script code is stored and versioned using Kestra's revision history along with your orchestration logic.
Easier integration with the templating engine: when the entire workflow is defined in one configuration file, it can be easier to access flow inputs, variable definitions, pass outputs to downstream tasks, etc.
However, the Script tasks also have some disadvantages as compared to the Commands tasks:
Readability: adding scripts into a YAML configuration file makes the scripts less readable, especially if they get long. Inline scripts also lack the syntax highlighting and testability that you would get when leveraging our embedded Code Editor instead.
Complex use cases: if your business logic comprises multiple files importing classes and functions from other modules, you will need to use the Commands tasks instead.
Overall, we recommend using Commands tasks for advanced production workloads. However, the Script tasks offer a great alternative for simple use cases.
Was this page helpful?
Yes
No
Scripts
Programming Languages
Scripts
Inline Scripts in Docker""""""",692,3260,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/inline-scripts-in-docker,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Inline Scripts in Docker
Inline Scripts in Docker
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Writing code directly inside your task.
To get started with a Script task, paste your custom script inline in your YAML workflow definition along with any other configuration.
yaml
id: api_json_to_mongodb
namespace: company.team
tasks:
  - id: extract
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:3.11-slim
    beforeCommands:
      - pip install requests kestra > /dev/null
    warningOnStdErr: false
    outputFiles:
      - ""*.json""
    script: |
      import requests
      import json
      from kestra import Kestra
      response = requests.get(""https://api.github.com"")
      data = response.json()
      with open(""output.json"", ""w"") as output_file:
          json.dump(data, output_file)
      Kestra.outputs({""status"": response.status_code})
  - id: load
    type: io.kestra.plugin.mongodb.Load
    connection:
      uri: mongodb://host.docker.internal:27017/
    database: local
    collection: github
    from: ""{{ outputs.extract.outputFiles['output.json'] }}""
    description: ""you can start MongoDB using: docker run -d mongo""
The example above uses a Python script added as a multiline string into the script property. The script fetches data from an API and stores it as a JSON file in Kestra's internal storage using the outputFiles property. The Kestra.outputs method allows to capture additional output variables, such as the API response status code.
The image argument of the docker property allows to optionally specify the Docker image to use for the script. If you don't specify an image, Kestra will use the default image for the language you are using. In this example, we use the python:3.11-slim image.
You can also optionally use the beforeCommands property to install libraries used in your inline script. Here, we use the command pip install requests kestra to install pip packages not available in the base image python:3.11-slim.
The warningOnStdErr property allows to specify whether to set the task run to a WARNING status if the script writes to the standard error stream. By default, this property is set to true. Keep in ming that a script that generates an error will always set the task run to a FAILED status, regardless of the value of this property.
Was this page helpful?
Yes
No
Scripts
Commands and Script tasks
Scripts
DOCKER and PROCESS runners""""""",558,2512,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/runners,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)DOCKER and PROCESS runners
DOCKER and PROCESS runners
Table of Contents
runner: DOCKER
runner: PROCESS
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Deprecated since:
0.18.0
Migration Guide
Manage the environment your code is executed with runner.
Kestra supports two runners for scripting tasks: DOCKER and PROCESS.
The runner property is being replaced with Task Runners to give you more control and flexibility. Read more about Task Runners here.
You can configure your scripts to run either in local processes or in Docker containers by using the runner property:
By default all scripting tasks run in isolated containers using the DOCKER runner.
Setting the runner property to PROCESS will execute your task in a local process on the worker without relying on Docker for container isolation.
runner: DOCKER
Docker is the default option for all script tasks. There are many arguments that can be provided here, including credentials to private Docker registries:
yaml
id: python_in_container
namespace: company.team
tasks:
  - id: wdir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: cloneRepository
        type: io.kestra.plugin.git.Clone
        url: https://github.com/kestra-io/examples
        branch: main
      - id: gitPythonScripts
        type: io.kestra.plugin.scripts.python.Commands
        warningOnStdErr: false
        outputFiles:
          - ""*.csv""
          - ""*.parquet""
        commands:
          - python scripts/etl_script.py
        runner: DOCKER
        docker:
          image: annageller/kestra:latest
          config: |
            {
              ""auths"": {
                  ""https://index.docker.io/v1/"": {
                      ""username"": ""annageller"",
                      ""password"": ""{{ secret('DOCKER_PAT') }}""
                  }
              }
            }
Head over to the Secrets section to learn more about secrets in Kestra.
runner: PROCESS
The PROCESS runner is useful if your Kestra instance is running locally without Docker and you want to access your local files and environments, for example, to take advantage of locally configured Conda virtual environments.
yaml
id: local_python_script
namespace: company.team
tasks:
  - id: conda_example
    type: io.kestra.plugin.scripts.python.Commands
    runner: PROCESS
    beforeCommands:
      - conda activate myCondaEnv
    commands:
      - python /Users/you/scripts/etl_script.py
Running scripts in a local process is particularly beneficial when using remote Worker Groups. The example below ensures that a script will be picked up only by Kestra workers that have been started with the key gpu, effectively delegating processing of scripts that require demanding computational requirements to the right server, rather than running them directly in a local container:
yaml
id: gpu_task
namespace: company.team
tasks:
  - id: gpu
    type: io.kestra.plugin.scripts.python.Commands
    runner: PROCESS
    commands:
      - python ml_on_gpu.py
    workerGroup:
      key: gpu
Was this page helpful?
Yes
No
Scripts
Inline Scripts in Docker
Scripts
Building a Custom Docker Image""""""",693,3208,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/custom-docker-image,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Building a Custom Docker Image
Building a Custom Docker Image
Table of Contents
Building a custom Docker image for your script tasks
1) Installing pandas in the beforeCommands property
2) Using one of our pre-built images
3) Building a custom Docker image
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Build a custom Docker image for your script tasks.
You can bake all dependencies needed for your script tasks directly into the Kestra's base image. Here is an example installing Python dependencies:
dockerfile
FROM kestra/kestra:latest
USER root
RUN apt-get update -y && apt-get install pip -y
RUN pip install --no-cache-dir pandas requests boto3
Then, point to that Dockerfile in your docker-compose.yml file:
yaml
services:
  kestra:
    build:
      context: .
      dockerfile: Dockerfile
    image: kestra-python:latest
Once you start Kestra containers using docker compose up -d, you can create a flow that directly runs Python tasks with your custom dependencies using the PROCESS runner:
yaml
id: python_process
namespace: company.team
tasks:
  - id: custom_dependencies
    type: io.kestra.plugin.scripts.python.Script
    runner: PROCESS
    script: |
      import pandas as pd
      import requests
      import boto3
      print(f""Pandas version: {pd.__version__}"")
      print(f""Requests version: {requests.__version__}"")
      print(f""Boto3 version: {boto3.__version__}"")
Building a custom Docker image for your script tasks
Imagine you use the following flow:
yaml
id: zip_to_python
namespace: company.team
variables:
  file_id: ""{{ execution.startDate | dateAdd(-3, 'MONTHS') | date('yyyyMM') }}""
tasks:
  - id: get_zipfile
    type: io.kestra.plugin.core.http.Download
    uri: ""https://divvy-tripdata.s3.amazonaws.com/{{ render(vars.file_id) }}-divvy-tripdata.zip""
  - id: unzip
    type: io.kestra.plugin.compress.ArchiveDecompress
    algorithm: ZIP
    from: ""{{ outputs.get_zipfile.uri }}""
  - id: parquet_output
    type: io.kestra.plugin.scripts.python.Script
    warningOnStdErr: false
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: ghcr.io/kestra-io/pydata:latest
    env:
      FILE_ID: ""{{ render(vars.file_id) }}""
    inputFiles: ""{{ outputs.unzip.files }}""
    script: |
      import os
      import pandas as pd
      file_id = os.environ[""FILE_ID""]
      file = f""{file_id}-divvy-tripdata.csv""
      df = pd.read_csv(file)
      df.to_parquet(f""{file_id}.parquet"")
    outputFiles:
      - ""*.parquet""
The Python task requires pandas to be installed. Pandas is a large library and it's not included in the default python image. In this case, you have the following options:
Install pandas in the beforeCommands property of the Python task.
Use one of our pre-built images that already include pandas, such as the ghcr.io/kestra-io/pydata:latest image.
Build your own custom Docker image that includes pandas.
1) Installing pandas in the beforeCommands property
yaml
id: install_pandas_at_runtime
namespace: company.team
tasks:
  - id: custom_dependencies
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    beforeCommands:
      - pip install pyarrow pandas
    script: |
      import pandas as pd
      print(f""Pandas version: {pd.__version__}"")
2) Using one of our pre-built images
yaml
id: use_prebuilt_image
namespace: company.team
tasks:
  - id: custom_dependencies
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: ghcr.io/kestra-io/pydata:latest
    script: |
      import pandas as pd
      print(f""Pandas version: {pd.__version__}"")
3) Building a custom Docker image
If you want to build a custom Docker image for some of your scripts, first create a Dockerfile:
dockerfile
FROM python:3.11-slim
RUN pip install --upgrade pip
RUN pip install --no-cache-dir kestra requests pyarrow pandas amazon-ion
Then, build the image:
bash
docker build -t kestra-custom:latest .
Finally, use that image in your flow:
yaml
id: zip_to_python
namespace: company.team
variables:
  file_id: ""{{ execution.startDate | dateAdd(-3, 'MONTHS') | date('yyyyMM') }}""
tasks:
  - id: get_zipfile
    type: io.kestra.plugin.core.http.Download
    uri: ""https://divvy-tripdata.s3.amazonaws.com/{{ render(vars.file_id) }}-divvy-tripdata.zip""
  - id: unzip
    type: io.kestra.plugin.compress.ArchiveDecompress
    algorithm: ZIP
    from: ""{{ outputs.get_zipfile.uri }}""
  - id: parquet_output
    type: io.kestra.plugin.scripts.python.Script
    warningOnStdErr: false
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      pullPolicy: NEVER # ‚ö°Ô∏è Use the local image instead of pulling it from DockerHub
    containerImage: kestra-custom:latest # ‚ö°Ô∏è Use your custom image here
    env:
      FILE_ID: ""{{ render(vars.file_id) }}""
    inputFiles: ""{{ outputs.unzip.files }}""
    script: |
      import os
      import pandas as pd
      file_id = os.environ[""FILE_ID""]
      file = f""{file_id}-divvy-tripdata.csv""
      df = pd.read_csv(file)
      df.to_parquet(f""{file_id}.parquet"")
    outputFiles:
      - ""*.parquet""
Note how we use the pullPolicy: NEVER property to make sure that Kestra uses the local image instead of trying to pull it from DockerHub.
Was this page helpful?
Yes
No
Scripts
DOCKER and PROCESS runners
Scripts
Installing Dependencies at Runtime""""""",1375,5504,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/installing-dependencies,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Installing Dependencies at Runtime
Installing Dependencies at Runtime
Table of Contents
Installing dependencies using beforeCommands
pip install package
pip install -r requirements.txt
Using Kestra's prebuilt images
Example: running R script in Docker
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Install dependencies at runtime using beforeCommands.
There are several ways of installing custom packages for your workflows. This page shows how to install dependencies at runtime using the beforeCommands property.
Installing dependencies using beforeCommands
While you could bake all your package dependencies into a custom container image, often it's convenient to install a couple of additional packages at runtime without having to build separate images. The beforeCommands can be used for that purpose.
pip install package
Here is a simple example installing pip packages requests and kestra before starting the script:
yaml
id: pip
namespace: company.team
tasks:
  - id: before_commands
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:3.11-slim
    beforeCommands:
      - pip install requests kestra > /dev/null
    script: |
      import requests
      import kestra
      kestra_modules = [i for i in dir(kestra.Kestra) if not i.startswith(""_"")]
      print(f""Requests version: {requests.__version__}"")
      print(f""Kestra modules: {kestra_modules}"")
pip install -r requirements.txt
This example clones a Git repository that contains a requirements.txt file. The script task uses beforeCommands to install those packages. We then list recently installed packages to validate that this process works as expected:
yaml
id: python_requirements_file
namespace: company.team
tasks:
  - id: wdir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: cloneRepository
        type: io.kestra.plugin.git.Clone
        url: https://github.com/kestra-io/examples
        branch: main
      - id: print_requirements
        type: io.kestra.plugin.scripts.shell.Commands
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        commands:
          - cat requirements.txt
      - id: list_installed_packages
        type: io.kestra.plugin.scripts.python.Commands
        warningOnStdErr: false
        containerImage: python:3.11-slim
        beforeCommands:
          - pip install -r requirements.txt > /dev/null
        commands:
          - ls -lt $(python -c ""import site; print(site.getsitepackages()[0])"") | head -n 20
And here is a simple version where we add the requirements.txt file using the inputFiles property:
yaml
id: python_requirements_file
namespace: company.team
tasks:
  - id: list_installed_packages
    type: io.kestra.plugin.scripts.python.Script
    env:
      PIP_ROOT_USER_ACTION: ignore
    inputFiles:
      requirements.txt: |
        polars
        requests
        kestra
    containerImage: python:3.11-slim
    beforeCommands:
      - pip install --upgrade pip
      - pip install -r requirements.txt > /dev/null
    script: |
      from kestra import Kestra
      import pkg_resources
      import re
      with open('requirements.txt', 'r') as file:
          # find package names without versions
          required_packages = {re.match(r'^\s*([a-zA-Z0-9_-]+)', line).group(1) for line in file if line.strip()}
      installed_packages = [(d.project_name, d.version) for d in pkg_resources.working_set]
      kestra_outputs = {}
      for name, version in installed_packages:
          if name in required_packages:
              kestra_outputs[name] = version
      Kestra.outputs(kestra_outputs)
As you can see here, the WorkingDirectory task is usually only needed if you use the git.Clone task. In most other cases, you can use the inputFiles property to add files to the script's working directory.
Using Kestra's prebuilt images
Many data engineering use cases require performing fairly standardized tasks such as:
processing data with pandas
transforming data with dbt-core (using a dbt adapter for your data warehouse)
making API calls with the requests library, etc.
To solve those common challenges, the kestra-io/examples repository provides several public Docker images with the latest versions of those common packages. Many Blueprints use those public images by default. The images are hosted in GitHub Container Registry managed by Kestra's team and those images follow the naming ghcr.io/kestra-io/packageName:latest.
Example: running R script in Docker
Here is a simple example using the ghcr.io/kestra-io/rdata:latest Docker image provided by Kestra to analyze the built-in mtcars dataset using dplyr and arrow R libraries:
yaml
id: rCars
namespace: company.team
tasks:
  - id: r
    type: io.kestra.plugin.scripts.r.Script
    warningOnStdErr: false
    containerImage: ghcr.io/kestra-io/rdata:latest
    outputFiles:
      - ""*.csv""
      - ""*.parquet""
    script: |
      library(dplyr)
      library(arrow)
      data(mtcars) # Load mtcars data
      print(head(mtcars))
      final <- mtcars %>%
        summarise(
          avg_mpg = mean(mpg),
          avg_disp = mean(disp),
          avg_hp = mean(hp),
          avg_drat = mean(drat),
          avg_wt = mean(wt),
          avg_qsec = mean(qsec),
          avg_vs = mean(vs),
          avg_am = mean(am),
          avg_gear = mean(gear),
          avg_carb = mean(carb)
        )
      final %>% print()
      write.csv(final, ""final.csv"")
      mtcars_clean <- na.omit(mtcars) # remove rows with NA values
      write_parquet(mtcars_clean, ""mtcars_clean.parquet"")
Installation of R libraries is time-consuming. From a technical standpoint, you could install custom R packages at runtime as follows:
yaml
id: rCars
namespace: company.team
tasks:
  - id: r
    type: io.kestra.plugin.scripts.r.Script
    warningOnStdErr: false
    containerImage: ghcr.io/kestra-io/rdata:latest
    beforeCommands:
      - Rscript -e ""install.packages(c('dplyr', 'arrow'))"" > /dev/null 2>&1
However, that flow above might take up to 30 minutes, depending on the R packages you install.
Prebuilt Docker images such as ghcr.io/kestra-io/rdata:latest can help you iterate much faster. Before moving to production, you can build your custom images with the exact package versions that you need.
Was this page helpful?
Yes
No
Scripts
Building a Custom Docker Image
Scripts
Outputs and Metrics""""""",1499,6449,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/outputs-metrics,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Outputs and Metrics
Outputs and Metrics
Table of Contents
How to emit outputs and metrics from script tasks
Outputs and metrics in Script and Commands tasks
Metric types: counter and timer
Python
Node.js
Shell
When to use metrics and when to use outputs?
Use cases for outputs: results of a task of any data type
Using outputs to pass data between tasks
Use cases for metrics: numerical values that can be aggregated and visualized across Executions
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Send Outputs and Metrics back to Kestra.
Your scripts can send outputs and metrics to Kestra's backend during flow execution. This allows you to track custom metadata and visualize it across multiple executions of a flow.
How to emit outputs and metrics from script tasks
The outputFiles is useful to send files generated in a script to Kestra's internal storage so that these files can be used in downstream tasks or exposed as downloadable artifacts. However, outputs can also be simple key-value pairs that contain metadata generated in your scripts.
Many tasks from Kestra plugins emit certain outputs by default. You can inspect which outputs are generated by each task or trigger from the respective plugin documentation. For instance, follow this plugin documentation link to see the outputs generated by the HTTP Download task. Once the flow is executed, the Outputs tab will list the output metadata as key-value pairs. Run the example below to see it in action:
yaml
id: download
namespace: company.team
tasks:
  - id: http
    type: io.kestra.plugin.core.http.Download
    uri: https://huggingface.co/datasets/kestra/datasets/raw/main/csv/orders.csv
This example automatically emits output metadata, such as the status code, file uri and request headers because those properties have been preconfigured on that plugin's task. However, in your custom script, you can decide what metadata you want to send to Kestra to make that metadata visible in the UI.
Outputs and metrics in Script and Commands tasks
The Scripts Plugin provides convenient methods to send outputs and metrics to the Kestra backend during flow Execution. Under the hood, Kestra tracks outputs and metrics from script tasks by searching standard output and standard error for ::{}:: patterns that allow you to specify outputs and metrics using a JSON request payload:
::{}:: for JSON objects.
Note that outputs require a dictionary, while metrics expect a list of dictionaries.
Below is an example showing outputs with key-value pairs:
json
""outputs"": {
    ""key"": ""value"",
    ""exampleList"": [1, 2, 3],
    ""tags"": {
        ""s3Bucket"": ""declarative-orchestration"",
        ""region"": ""us-east-1""
    }
}
Here is the representation of a metrics object. It's a list of dictionaries:
json
""metrics"": [
    {
        ""name"": ""myMetric"", // mandatory, the name of the metrics
        ""type"": ""counter"", // mandatory, ""counter"" or ""timer"" metric type
        ""value"": 42, // mandatory, Double or Integer value
        ""tags"": { // optional list of tags
          ""readOnly"": true,
          ""location"": ""US""
        }
    }
]
Both, outputs and metrics can optionally include a list of tags that expose internal details.
Metric types: counter and timer
There are two metric types:
counter, expressed in Integer or Double data type, measures a countable number of rows/bytes/objects processed in a given task
timer, expressed in Double data type, measures the number of seconds to process specific computation in your flow.
Below you can find examples of outputs and metrics definition for each language.
Python
The example below shows how you can add simple key-value pairs in your Python script to send custom metrics and outputs to Kestra's backend at runtime:
python
from kestra import Kestra
Kestra.outputs({'data': data, 'nr': 42})
Kestra.counter('nr_rows', len(df), tags={'file': filename})
Kestra.timer('ingestion_duration', duration, tags={'file': filename})
The Kestra.outputs({""key"": ""value""}) takes a dictionary of key-value pairs, while the metrics such as Counter and Timer take the metric name, metric value and a dictionary of tags as positional arguments, for example:
Kestra.counter(""countable_int_metric_name"", 42, tags={""key"": ""value""})
Kestra.timer(""countable_double_metric_name"", 42.42, tags={""key"": ""value""})
Here is a more comprehensive example in a flow:
yaml
id: outputsMetricsPython
namespace: company.team
inputs:
  - id: attempts
    type: INT
    defaults: 10
tasks:
  - id: py
    type: io.kestra.plugin.scripts.python.Script
    warningOnStdErr: false
    containerImage: ghcr.io/kestra-io/pydata:latest
    script: |
      import timeit
      from kestra import Kestra
      attempts = {{inputs.attempts}}
      modules = ['pandas', 'requests', 'kestra', 'faker', 'csv', 'random']
      results = {}
      for module in modules:
          time_taken = timeit.timeit(f'import {module}', number=attempts)
          results[module] = time_taken
          Kestra.timer(module, time_taken, tags=dict(nr_attempts=attempts))
      Kestra.outputs(results)
Node.js
Node.js follows the same syntax for sending outputs and metrics as in Python. Here is an example:
You need to install the npm package, that can be done with a beforeCommands:
yaml
beforeCommands:
 - npm i @kestra-io/libs
The just require or import the package:
js
const Kestra = require(""@kestra-io/libs"");
Kestra.outputs({data: 'data', nr: 42, mybool: true, myfloat: 3.65});
Kestra.counter('metric_name', 100, {partition: 'file1'});
Kestra.timer('timer1', (callback) => {setTimeout(callback, 1000)}, {tag1: 'hi'});
Kestra.timer('timer2', 2.12, {tag1: 'from', tag2: 'kestra'});
Shell
To send outputs and metrics from a Shell task, wrap a JSON payload (i.e. a map/dictionary) with double colons '::{""outputs"": {""key"":""value""}}::' or '::{""metrics"": [{""name"":""count"",""type"":""counter"",""value"":1,""tags"":{""key"":""value""}::' as shown in the following examples:
shell
# 1. send outputs with different data types
echo '::{""outputs"":{""test"":""value"",""int"":2,""bool"":true,""float"":3.65}}::'
# 2. send a counter with tags
echo '::{""metrics"":[{""name"":""count"",""type"":""counter"",""value"":1,""tags"":{""tag1"":""i"",""tag2"":""win""}}]}::'
# 3. send a timer with tags
echo '::{""metrics"":[{""name"":""time"",""type"":""timer"",""value"":2.12,""tags"":{""tag1"":""i"",""tag2"":""destroy""}}]}::'
The JSON payload should be provided without any spaces.
Here is a comprehensive example in a flow:
yaml
id: shell_script
namespace: company.team
tasks:
  - id: shell_script
    type: io.kestra.plugin.scripts.shell.Script
    containerImage: ubuntu
    script: |
      echo '{""outputs"":{""test"":""value"",""int"":2,""bool"":true,""float"":3.65}}'
      echo '::{""metrics"":[{""name"":""count"",""type"":""counter"",""value"":1,""tags"":{""tag1"":""i"",""tag2"":""win""}}]}::'
      echo '::{""metrics"":[{""name"":""time"",""type"":""timer"",""value"":2.12,""tags"":{""tag1"":""i"",""tag2"":""destroy""}}]}::'
When to use metrics and when to use outputs?
If you want to track task-run metadata across multiple executions of a flow, and this metadata is of an arbitrary data type (it might be a string, a list of dictionaries, or even a file), use outputs rather than metrics. Metrics can only be used with numerical values.
Use cases for outputs: results of a task of any data type
Outputs are task-run artifacts. They are generated as a result of a given task. Outputs can be used for two reasons:
To pass data between tasks
To generate result artifacts for observability and auditability e.g. to track specific metadata or to share downloadable file artifacts with business stakeholders.
Using outputs to pass data between tasks
Outputs can be used to pass data between tasks. One task can generate some outputs and other task can use that value:
yaml
id: outputsInputs
namespace: company.team
tasks:
    - id: passOutput
      type: io.kestra.plugin.core.debug.Return
      format: ""hello world!""
    - id: takeInput
      type: io.kestra.plugin.core.debug.Return
      format: ""data from previous task - {{ outputs.passOutput.value }}""
Use cases for metrics: numerical values that can be aggregated and visualized across Executions
Metrics are intended to track custom numeric (metric type: counter) or duration (metric type: timer) attributes that you can visualize across flow executions, such as number of rows or bytes processed in a task. Metrics are expressed as numerical values of integer or double data type.
Examples of metadata you may want to track as metrics:
the number of rows processed in a given task (e.g. during data ingestion or transformation),
the accuracy score of a trained ML model in order to compare this result across multiple workflow runs (e.g. you can see the average or max value across multiple executions),
other pieces of metadata that you can track across executions of a flow (e.g. a duration of a certain function execution within a Python ETL script).
Was this page helpful?
Yes
No
Scripts
Installing Dependencies at Runtime
Scripts
Input and Output Files""""""",2123,9036,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/input-output-files,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Input and Output Files
Input and Output Files
Table of Contents
Input Files
Using input files to pass data from a trigger to a script task
Output Files
Generating outputs from a script task using outputFiles
Generating outputs from a script task
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage Input and Output files with your scripts.
Input Files
You can pass additional files to any script or CLI task using the inputFiles property:
yaml
id: ansible
namespace: company.team
tasks:
  - id: ansible_task
    type: io.kestra.plugin.ansible.cli.AnsibleCLI
    inputFiles:
      inventory.ini: |
        localhost ansible_connection=local
      myplaybook.yml: |
        ---
        - hosts: localhost
          tasks:
            - name: Print Hello World
              debug:
                msg: ""Hello, World!""
    containerImage: cytopia/ansible:latest-tools
    commands:
      - ansible-playbook -i inventory.ini myplaybook.yml
You can also leverage Namespace Files as follows:
yaml
id: ansible
namespace: company.team
tasks:
  - id: ansible_task
    type: io.kestra.plugin.ansible.cli.AnsibleCLI
    namespaceFiles:
      enabled: true
    inputFiles:
      inventory.ini: ""{{ read('inventory.ini') }}""
      myplaybook.yml: ""{{ read('myplaybook.yml') }}""
    containerImage: cytopia/ansible:latest-tools
    commands:
      - ansible-playbook -i inventory.ini myplaybook.yml
Using input files to pass data from a trigger to a script task
Another use case for input files is when your custom scripts need input coming from other tasks or triggers.
Consider the following example flow that runs when a new object with the prefix ""raw/"" arrives in the S3 bucket ""declarative-orchestration"":
yaml
id: s3TriggerCommands
namespace: company.team
description: process CSV file from S3 trigger
tasks:
  - id: wdir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    inputFiles:
      data.csv: ""{{ trigger.objects | jq('.[].uri') | first }}""
    outputFiles:
      - ""*.csv""
      - ""*.parquet""
    tasks:
      - id: cloneRepo
        type: io.kestra.plugin.git.Clone
        url: https://github.com/kestra-io/examples
        branch: main
      - id: python
        type: io.kestra.plugin.scripts.python.Commands
        description: this script reads a file `data.csv` from the S3 trigger
        taskRunner:
          type: io.kestra.plugin.scripts.runner.docker.Docker
        containerImage: ghcr.io/kestra-io/pydata:latest
        warningOnStdErr: false
        commands:
          - python scripts/clean_messy_dataset.py
triggers:
  - id: waitForS3object
    type: io.kestra.plugin.aws.s3.Trigger
    bucket: declarative-orchestration
    maxKeys: 1
    interval: PT1S
    filter: FILES
    action: MOVE
    prefix: raw/
    moveTo:
      key: archive/raw/
    accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID') }}""
    secretKeyId: ""{{ secret('AWS_SECRET_ACCESS_KEY') }}""
    region: ""{{ secret('AWS_DEFAULT_REGION') }}""
Note that we didn't have to hardcode anything specific to Kestra in the Python script from GitHub. That script remains pure Python that you can run anywhere. Kestra's trigger logic is stored along with orchestration and infrastructure configuration in the YAML flow definition.
This separation of concerns (i.e. not mixing orchestration and business logic) makes your code easier to test and keeps your business logic vendor-agnostic.
Output Files
If you want to generate files in your script to make them available for download and use in downstream tasks, you can leverage either the outputFiles property.
Generating outputs from a script task using outputFiles
The outputFiles property allows to specify a list of files to be persisted in Kestra's internal storage. Here is an example:
yaml
id: output_text_files
namespace: company.team
tasks:
  - id: python_output
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    outputFiles:
      - ""*.txt""
    script: |
      f = open(""myfile.txt"", ""a"")
      f.write(""Hi, this is output from a script üëã"")
      f.close()
  - id: read_output
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - cat {{ outputs.python_output.outputFiles['myfile.txt'] }}
Note how the outputFiles property is used to specify the list of files to be persisted in Kestra's internal storage. The outputFiles property supports glob patterns.
The subsequent task can access the output file by leveraging the syntax {{outputs.yourTaskId.outputFiles['yourFileName.fileExtension']}}.
Generating outputs from a script task
From 0.17.0, outputDir has been depreciated. Use the outputFiles property instead.
This is an alternative to the outputDir property. Files stored in the outputFiles property will be persisted in Kestra's internal storage. Here is an example:
yaml
id: output_text_files
namespace: company.team
tasks:
  - id: python_output
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    outputFiles:
      - myfile.txt
    script: |
      with open(""myfile.txt"", ""a"") as f:
          f.write(""Hi, this is output from a script üëã"")
  - id: read_output
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - cat {{ outputs.python_output.outputFiles['myfile.txt'] }}
The first task creates a file 'myfile.txt' and the next task can access it by leveraging the syntax {{ outputs.yourTaskId.outputFiles['yourFileName.fileExtension'] }}.
Was this page helpful?
Yes
No
Scripts
Outputs and Metrics
Scripts
Logging""""""",1347,5752,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/logging,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Logging
Logging
Table of Contents
How to log from script tasks
Logging from Script and Commands tasks
Python
Node.js
Shell
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Send logs back to Kestra.
Your scripts can log to Kestra's backend during flow execution. This allows you to log events occuring during execution of a flow.
How to log from script tasks
Logging from Script and Commands tasks
The Scripts Plugin provides convenient methods to log to the Kestra backend during flow Execution. Under the hood, Kestra tracks logs from script tasks by searching standard output and standard error for ::{}:: patterns that allow you to specify log messages using a JSON request payload.
Below is an example showing logs as list of dictionaries:
json
{
    ""logs"": [
        {
            ""level"": ""DEBUG"",
            ""message"": ""Hello World from logs!""
        },
        {
            ""level"": ""INFO"",
            ""message"": ""Hello World!""
        }
    ]
}
Python
The example below shows how you can log from your Python script to Kestra's backend at runtime:
python
from kestra import Kestra
logger = Kestra.logger()
logger.debug(""Hello World from logs!"")
logger.info(""Hello World!"")
Here is a more comprehensive example in a flow:
yaml
id: logFromPython
namespace: company.team
tasks:
  - id: py
    type: io.kestra.plugin.scripts.python.Script
    script: |
      from kestra import Kestra
      logger = Kestra.logger()
      logger.info(""Py task is alive!"")
Node.js
Node.js follows the same syntax for sending logs as in Python. Here is an example:
You need to install the npm package, that can be done with a beforeCommands:
yaml
beforeCommands:
 - npm i @kestra-io/libs
Then, simply use the require function to import the Kestra package and emit logs:
js
const Kestra = require(""@kestra-io/libs"");
const logger = Kestra.logger();
logger.debug(""Hello World from logs!"");
logger.info(""Hello World!"");
Shell
To log from a Shell task, wrap the JSON payload with double colons '::{""logs"": [{""level"":""DEBUG"",""message"":""Hello World!""}]}::' as shown in the following examples:
bash
echo '::{""logs"": [{""level"":""DEBUG"",""message"":""Hello World from logs!""},{""level"":""INFO"",""message"":""Hello World!""}]}::'
The JSON payload should be provided without any spaces.
Here is a comprehensive example in a flow:
yaml
id: shell_script
namespace: company.team
tasks:
  - id: shell_script
    type: io.kestra.plugin.scripts.shell.Script
    containerImage: ubuntu
    script: |
      echo '::{""logs"": [{""level"":""INFO"",""message"":""Shell task is alive!""}]}::'
Was this page helpful?
Yes
No
Scripts
Input and Output Files
Scripts
Bind Mount""""""",640,2710,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/bind-mount,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Bind Mount
Bind Mount
Table of Contents
Bind-mounting local scripts
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use bind-mount to execute locally stored scripts.
To run a script stored locally, you can bind-mount it to your Kestra container.
Bind-mounting local scripts
Bind-mounting local scripts to the Kestra server can also make the local scripts available to the Docker containers running the script tasks. This is useful when you want to test a script and you don't want to use Namespace Files.
First, make sure that your Kestra configuration in the Docker Compose file allows volume mounting. Here is how you can configure it:
yaml
  kestra:
    image: kestra/kestra:latest
    pull_policy: always
    user: ""root""
    env_file:
      - .env
    command: server standalone --worker-thread=128
    volumes:
      - kestra-data:/app/storage
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/kestra-wd:/tmp/kestra-wd:rw
    environment:
      KESTRA_CONFIGURATION: |
        datasources:
          postgres:
            url: jdbc:postgresql://postgres:5432/kestra
            driverClassName: org.postgresql.Driver
            username: kestra
            password: k3str4
        kestra:
          server:
            basicAuth:
              enabled: false
              username: ""admin@kestra.io"" # it must be a valid email address
              password: kestra
          repository:
            type: postgres
          storage:
            type: local
            local:
              basePath: ""/app/storage""
          queue:
            type: postgres
          tasks:
            tmpDir:
              path: /tmp/kestra-wd/tmp
          plugins:
            configurations:
              - type: io.kestra.plugin.scripts.runner.docker.Docker
                values:
                  volume-enabled: true # üëà this is the relevant setting
With that setting, you can point the script task to any script on your local file system:
yaml
id: pythonVolume
namespace: company.team
tasks:
  - id: anyPythonScript
    type: io.kestra.plugin.scripts.python.Commands
    runner: DOCKER
    containerImage: ghcr.io/kestra-io/pydata:latest
      volumes:
        - /Users/anna/gh/KESTRA_REPOS/scripts:/app
    commands:
      - python /app/etl/parametrized.py
This flow points the Python task running in a Docker container to this ETL script.
Was this page helpful?
Yes
No
Scripts
Logging
Scripts
Git Clone task""""""",585,2519,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/git-clone,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Git Clone task
Git Clone task
Table of Contents
Git plugin
Add io.kestra.plugin.git.Clone as the first task in a WorkingDirectory
Private Git repositories
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Clone a Git repository and use the files in your tasks.
This task allows you to clone a Git repository into a working directory and then use the files from that repository in downstream tasks.
Git plugin
To use the io.kestra.plugin.git.Clone task in your flow, make sure to add it as the first child task of the WorkingDirectory task. Otherwise, you‚Äôll get an error: Destination path ""xyz"" already exists and is not an empty directory. This happens because you can only clone a GitHub repository into an empty working directory.
Add io.kestra.plugin.git.Clone as the first task in a WorkingDirectory
Adding the io.kestra.plugin.git.Clone task directly as the first child task of the WorkingDirectory task will ensure that you clone your repository into an empty directory before any other task would generate any output artifacts.
Private Git repositories
Typically, you would want to use io.kestra.plugin.git.Clone with a private GitHub repository. Make sure to:
Add your organization/user name as username
Generate your access token and provide it on the password property.
Below you can find links to instructions on how to generate an access token for the relevant Git platform:
GitHub
GitLab
Bitbucket
AWS CodeCommit
Azure DevOps
Was this page helpful?
Yes
No
Scripts
Bind Mount
Scripts
Working Directory""""""",334,1602,kestra
https://kestra.io/docs/workflow-components/tasks/scripts/working-directory,"""""""DocsWorkflow ComponentsTasksScript Tasks (Code in Any Language)Working Directory
Working Directory
Table of Contents
When to use the WorkingDirectory task
Example
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Run multiple tasks in the same working directory sequentially.
This task allows you to run multiple tasks sequentially in the same working directory. It is useful when you want to share files from Namespace Files or from a Git repository across multiple tasks.
When to use the WorkingDirectory task
By default, all Kestra tasks are stateless. If one task generates files, those files won‚Äôt be available in downstream tasks unless they are persisted in internal storage. Upon each task completion, the temporary directory for the task is purged. This behavior is generally useful as it keeps your environment clean and dependency free, and it avoids potential privacy or security issues when exposing some data generated by a task to other processes.
Despite the benefits of the stateless execution, in certain scenarios, statefulness is desirable. Imagine that you want to execute several Python scripts, and each of them generates some output data. Another script combines that data as part of an ETL/ML process. Executing those related tasks in the same working directory and sharing state between them is helpful for the following reasons:
You can attach namespace files to the WorkingDirectory task and use them in all downstream tasks. This allows you to work the same way you would work on your local machine, where you can import modules from the same directory.
Within a WorkingDirectory, you can clone your entire GitHub branch with multiple modules and configuration files needed to run several scripts and reuse them across multiple downstream tasks.
You can execute multiple scripts sequentially on the same worker or in the same container, minimizing latency.
Output artifacts of each task (such as CSV, JSON or Parquet files you generate in your script) are directly available to other tasks without having to persist them within the internal storage. This is because all child tasks of the WorkingDirectory task share the same file system.
The WorkingDirectory task allows you to:
Share files from Namespace Files or from a Git repository across multiple tasks
Run multiple tasks sequentially in the same working directory
Share data across multiple tasks without having to persist it in internal storage.
For more detail, check out the plugin documentation
Example
In this example, the flow sequentially executes Shell Scripts and Shell Commands in the same working directory using a local Process Task Runner.
yaml
id: shell_scripts
namespace: company.team
tasks:
  - id: working_directory
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: create_csv_file
        type: io.kestra.plugin.scripts.shell.Script
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        script: |
          #!/bin/bash
          echo ""Column1,Column2,Column3"" > file.csv
          for i in {1..10}
          do
            echo ""$i,$RANDOM,$RANDOM"" >> file.csv
          done
      
      - id: inspect_file
        type: io.kestra.plugin.scripts.shell.Commands
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        commands:
          - cat file.csv  
      
      - id: filter_file
        type: io.kestra.plugin.scripts.shell.Commands
        description: select only the first five rows of the second column
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        commands:
          - cut -d ',' -f 2 file.csv | head -n 6
Was this page helpful?
Yes
No
Scripts
Git Clone task
Tasks
Task Runs""""""",755,3731,kestra
https://kestra.io/docs/workflow-components/tasks/taskruns,"""""""DocsWorkflow ComponentsTasksTask Runs
Task Runs
Table of Contents
Attempts
States
Expression
Task Run Values
Parent Task Run Values
Parent vs. Parents in Nested Flowable Tasks
Task Runs Page (EE)
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
A Task Run is a single run of an individual task within an Execution, where an Execution is a single run of a flow. This means an Execution can have many Task Runs.
Each Task Run has associated data such as:
Execution ID
State
Start Date
End Date
Attempts
Each task run can have one or more attempts. Most task runs will have only one attempt, but you can configure retries for a task. If retries have been configured, a task failure will generate new attempts until the retry maxAttempt or maxDuration threshold is hit.
States
Similar to Executions, Task Runs cans be in a particular state.
State Description
CREATED The Execution or Task Run is waiting to be processed. This state usually means that the Execution is in a queue and is yet to be started.
RUNNING The Execution or Task Run is currently being processed.
SUCCESS The Execution or Task Run has been completed successfully.
WARNING The Execution or Task Run exhibited unintended behavior, but the execution continued and was flagged with a warning.
FAILED The Execution or Task Run exhibited unintended behavior that caused the execution to fail.
RETRYING The Execution or Task Run is currently being retried.
RETRIED An Execution or Task Run exhibited unintended behavior, stopped, and created a new execution as defined by its flow-level retry policy. The policy was set to the CREATE_NEW_EXECUTION behavior.
KILLING A command was issued that asked for the Execution or Task Run to be killed. The system is in the process of killing the associated tasks.
KILLED An Execution or Task Run was killed (upon request), and no more tasks will run.
For a detailed overview of how each Task Run transition through different states, see the States page.
Expression
You can access information about a taskrun using the {{ taskrun }} expression.
This example returns the information from {{ taskrun }}:
yaml
id: taskrun
namespace: company.team
tasks:
  - id: return
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ taskrun }}""
The logs show the following:
json
{
    ""id"": ""61TxwXQjkXfwTd4ANK6fhv"",
    ""startDate"": ""2024-11-13T14:38:38.355668Z"",
    ""attemptsCount"": 0
}
Task Run Values
Some Flowable Tasks, such as ForEach and ForEachItem, group tasks together. You can use the expression {{ taskrun.value }} to access the value for that task run.
In the example below, foreach will iterate twice over the values [1, 2]:
yaml
id: loop
namespace: company.team
tasks:
  - id: foreach
    type: io.kestra.plugin.core.flow.ForEach
    values: [1, 2]
    tasks:
      - id: log
        type: io.kestra.plugin.core.log.Log
        message:
        - ""{{ taskrun }}""
        - ""{{ taskrun.value }}""
        - ""{{ taskrun.id }}""
        - ""{{ taskrun.startDate }}""
        - ""{{ taskrun.attemptsCount }}""
        - ""{{ taskrun.parentId }}""
This outputs two separate log tasks, one with 1 and the other with 2.
Parent Task Run Values
You can also use the {{ parent.taskrun.value }} expression to access a task run value from a parent task within nested flowable child tasks:
yaml
id: loop
namespace: company.team
tasks:
  - id: foreach
    type: io.kestra.plugin.core.flow.ForEach
    values: [1, 2]
    tasks:
      - id: log
        type: io.kestra.plugin.core.log.Log
        message: ""{{ taskrun.value }}""
      - id: if
        type: io.kestra.plugin.core.flow.If
        condition: ""{{ true }}""
        then:
          - id: log_parent
            type: io.kestra.plugin.core.log.Log
            message: ""{{ parent.taskrun.value }}""
This will iterate through the log and if tasks twice as there are two items in values property. The log_parent task will log the parent task run value as 1 and then 2.
Parent vs. Parents in Nested Flowable Tasks
When using nested Flowable tasks, only the direct parent task is accessible via taskrun.value. To access a parent task higher up the tree, you can use the parent and the parents expressions.
The following flow shows a more complex example with nested flowable parent tasks:
yaml
id: each_switch
namespace: company.team
tasks:
  - id: simple
    type: io.kestra.plugin.core.log.Log
    message:
      - ""{{ task.id }}""
      - ""{{ taskrun.startDate }}""
  - id: hierarchy_1
    type: io.kestra.plugin.core.flow.ForEach
    values: [""caseA"", ""caseB""]
    tasks:
      - id: hierarchy_2
        type: io.kestra.plugin.core.flow.Switch
        value: ""{{ taskrun.value }}""
        cases:
          caseA:
            - id: hierarchy_2_a
              type: io.kestra.plugin.core.debug.Return
              format: ""{{ task.id }}""
          caseB:
            - id: hierarchy_2_b_first
              type: io.kestra.plugin.core.debug.Return
              format: ""{{ task.id }}""
            - id: hierarchy_2_b_second
              type: io.kestra.plugin.core.flow.ForEach
              values: [""case1"", ""case2""]
              tasks:
                - id: switch
                  type: io.kestra.plugin.core.flow.Switch
                  value: ""{{ taskrun.value }}""
                  cases:
                    case1:
                      - id: switch_1
                        type: io.kestra.plugin.core.log.Log
                        message:
                          - ""{{ parents[0].taskrun.value }}""
                          - ""{{ parents[1].taskrun.value }}""
                    case2:
                      - id: switch_2
                        type: io.kestra.plugin.core.log.Log
                        message:
                          - ""{{ parents[0].taskrun.value }}""
                          - ""{{ parents[1].taskrun.value }}""
  - id: simple_again
    type: io.kestra.plugin.core.log.Log
    message:
      - ""{{ task.id }}""
      - ""{{ taskrun.startDate }}""
The parent variable gives direct access to the first parent, while the parents[INDEX] gives you access to the parent higher up the tree.
Task Run JSON Object Example
Task Runs Page (EE)
This feature is only available on the Enterprise Edition
If you have Kestra setup using the Kafka and Elasticsearch backend, you can view Task Runs in the UI.
It's similar to the Execution View but only shows Task Runs.
Was this page helpful?
Yes
No
Scripts
Working Directory
Workflow Components
Namespace""""""",1449,6451,kestra
https://kestra.io/docs/workflow-components/namespace,"""""""DocsWorkflow ComponentsNamespace
Namespace
Table of Contents
Hierarchical structure when using nested namespaces
Namespace name
Using namespaces to organize flows and files
Namespace Tab
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Namespace is a logical grouping of flows.
Namespaces are used to organize workflows and manage access to secrets, plugin defaults and variables.
You can think of a namespace as a folder for your flows. Similar to folders on your file system, namespaces can be used to organize flows into logical categories. Similar to filesystems, namespaces can be indefinitely nested.
If you're looking to completely isolate environments with their own resources on the same Kestra instance, you should look at Tenants that are part of the Enterprise Edition.
Hierarchical structure when using nested namespaces
Using the dot . symbol, you can add a hierarchical structure to your namespaces which allows you to logically separate environments, projects, teams and departments. This way, your product, engineering, marketing, finance, and data teams can all use the same Kestra instance, while keeping their flows organized and separated. Various stakeholders can have their own child namespaces that belong to a parent namespace grouping them by environment, project, or team.
Namespace name
A namespace name can be built from alphanumerical characters, optionally separated by .. The hierarchy depth for namespaces is unlimited. Here are some examples of namespaces:
project_one
company.project_two
company.team.project_three
Using namespaces to organize flows and files
When you create a flow, you can assign a namespace to it:
yaml
id: hello_world
namespace: company.team
tasks:
  - id: log_task
    type: io.kestra.plugin.core.log.Log
    message: hi from {{ flow.namespace }}
Note: Once you've saved your flow, you won't be able to change its namespace. You'll need to make a new flow in order to change the namespace.
Here, the flow is assigned to the marketing namespace. This assignment of a namespace to a flow already provides a benefit of improved organization and filtering:
Additionally, you can organize your code on a namespace-level using the embedded Code editor and Namespace Files, with the option to sync those files from Git:
Namespace Tab
Starting 0.18.0, Kestra has introduced the Namespaces tab in the Kestra UI for OSS. In this tab, you can see all the namespaces associated with the different flows in Kestra.
You can open the details about any namespace by clicking on the name or details button to the right of that namespace.
When you select the details button for any namespace, the namespace overview page opens which details the executions of flows in that namespace.
On the top of this page, you have different tabs:
Overview: This is the default landing page of the Namespace. This page contains the dashboards and summary about the executions of different flows in this namespace.
Editor: the in-built editor where you can add/edit the namespaceFiles.
Flows: shows all the flows in the namespace. It gives a brief about each of the flows including the flow ID, labels, last execution date and last execution status, and the execution statistics. By selecting the details button on the right of the flow, you can navigate to that flow's page.
Dependencies: shows all the flows and which ones are dependent on each other (for example through Subflows or Flow Triggers).
KV Store: manage the key-values pairs associated with this namespace. More details on KV Store can be found here.
The other tabs: Edit, Variables, Plugin Defaults, Secrets and Audit Logs are only available for Kestra EE. More details about them can be found here.
Was this page helpful?
Yes
No
Tasks
Task Runs
Workflow Components
Execution""""""",767,3791,kestra
https://kestra.io/docs/workflow-components/execution,"""""""DocsWorkflow ComponentsExecution
Execution
Table of Contents
Task Run
Attempts
Outputs
Metrics
State
Execution expressions
Execute a flow from the UI
Use automatic triggers
Execute a flow via an API call
Execute a specific revision of a flow
Execute a flow with inputs
Execute a flow with FILE-type inputs
Execute a flow via an API call in Python
Get URL to follow the Execution progress
Webhook vs. API call
Execute a flow from Python
Execute with ForEachItem
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Execute your flows and view the outcome.
Execution is a single run of a flow in a specific state.
Task Run
A task run is a single run of an individual task within an execution.
Each task run has associated data such as:
Execution ID
State
Start Date
End Date
Read more about Task Runs on the dedicated docs page.
Attempts
Each task run can have one or more attempts. Most task runs will have only one attempt, but you can configure retries for a task. If retries have been configured, a task failure will generate new attempts until the retry maxAttempt or maxDuration threshold is hit.
Outputs
Each task can generate output data that other tasks of the current flow execution can use.
These outputs can be variables or files that will be stored inside Kestra's internal storage.
Outputs are described on each task documentation page and can be seen in the Outputs tab of the Execution page.
You can read more about Outputs on the Outputs page.
Metrics
Each task can expose metrics that may be useful in understanding the internals of a task. Metrics may include, file size, number of returned rows, or query duration. You can view the available metrics for a task type on its documentation page.
Metrics can be seen in the Metrics tab of the Executions page.
Below is an example of a flow generating metrics:
yaml
id: load_data_to_bigquery
namespace: company.team
tasks:
  - id: http_download
    type: io.kestra.plugin.core.http.Download
    uri: https://huggingface.co/datasets/kestra/datasets/raw/main/csv/orders.csv
  - id: load_biqquery
    type: io.kestra.plugin.gcp.bigquery.Load
    description: Load data into BigQuery
    autodetect: true
    csvOptions:
      fieldDelimiter: "",""
    destinationTable: kestra-dev.demo.orders
    format: CSV
    from: ""{{ outputs.http_download.uri }}""
We can see the list of metrics that the BigQuery Load task type will generate in the documentation here.
After executing the flow, you can see the metrics generated by the BigQuery Load task in the Metrics tab.
State
An Execution or a Task Run can be in a particular state.
There are multiple possible states:
State Description
CREATED The Execution or Task Run is waiting to be processed. This state usually means that the Execution is in a queue and is yet to be started.
RUNNING The Execution or Task Run is currently being processed.
PAUSED The Execution or Task Run has been paused. This status is used for two reasons: Manual validation and Delay (for a specified duration before continuing the execution).
SUCCESS The Execution or Task Run has been completed successfully.
WARNING The Execution or Task Run exhibited unintended behavior, but the execution continued and was flagged with a warning.
FAILED The Execution or Task Run exhibited unintended behavior that caused the execution to fail.
KILLING A command was issued that asked for the Execution or Task Run to be killed. The system is in the process of killing the associated tasks.
KILLED An Execution or Task Run was killed (upon request), and no more tasks will run.
RESTARTED This status is transitive. It is the same as CREATED, but for a flow that has already been executed, failed, and has been restarted.
CANCELLED An Execution or Task Run has been aborted because it has reached its defined concurrency limit. The limit was set to the CANCEL behavior.
QUEUED An Execution or Task Run has been put on hold because it has reached its defined concurrency limit. The limit was set to the QUEUE behavior.
RETRYING The Execution or Task Run is currently being retried.
RETRIED An Execution or Task Run exhibited unintended behavior, stopped, and created a new execution as defined by its flow-level retry policy. The policy was set to the CREATE_NEW_EXECUTION behavior.
For a detailed overview of how each Execution and Task Run transition through different states, see the States page.
Execution expressions
There are a number of execution expressions which you can use inside of your flow.
Parameter Description
{{ execution.id }} The execution ID, a generated unique id for each execution.
{{ execution.startDate }} The start date of the current execution, can be formatted with {{ execution.startDate | date(""yyyy-MM-dd HH:mm:ss.SSSSSS"") }}.
{{ execution.originalId }} The original execution ID, this id will never change even in case of replay and keep the first execution ID.
Execute a flow from the UI
You can trigger a flow manually from the Kestra UI by clicking the Execute button on the flow's page. This is useful when you want to test a flow or run it on demand.
Use automatic triggers
You can add a Schedule trigger to automatically launch a flow execution at a regular time interval.
Alternatively, you can add a Flow trigger to automatically launch a flow execution when another flow execution is completed. This pattern is particularly helpful when you want to:
Implement a centralized namespace-level error handling strategy, e.g. to send a notification when any flow execution fails in a production namespace. Check the Alerting & Monitoring section for more details.
Decouple your flows by following an event-driven pattern, in a backwards direction (backwards because the flow is triggered by the completion of another flow; this is in contrast to the subflow pattern, where a parent flow starts the execution of child flows and waits for the completion of each of them).
Lastly, you can use the Webhook trigger to automatically launch a flow execution when a given HTTP request is received. You can leverage the {{ trigger.body }} variable to access the request body and the {{ trigger.headers }} variable to access the request headers in your flow.
To launch a flow and send data to the flow's execution context from an external system using a webhook, you can send a POST request to the Kestra API using the following URL:
bash
http://<kestra-host>:<kestra-port>/api/v1/executions/webhook/<namespace>/<flow-id>/<webhook-key>
Here is an example:
bash
http://localhost:8080/api/v1/executions/webhook/dev/hello-world/secretWebhookKey42
You can also pass inputs to the flow using the inputs query parameter.
Execute a flow via an API call
You can trigger a flow execution by calling the API directly. This is useful when you want to start a flow execution from another application or service.
Let's use the following flow as example:
yaml
id: hello_world
namespace: company.team
inputs:
  - id: greeting
    type: STRING
    defaults: hey
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: ""{{ inputs.greeting }}""
triggers:
  - id: webhook
    type: io.kestra.plugin.core.trigger.Webhook
    key: test1234
Assuming that you run Kestra locally, you can trigger a flow execution by calling the /api/v1/executions/{namespace}/{flowId} endpoint. This example uses curl but you could use something else like Postman to test this too:
bash
curl -X POST \
http://localhost:8080/api/v1/executions/company.team/hello_world
The above command will trigger an execution of the latest revision of the hello_world flow from the company.team namespace.
Execute a specific revision of a flow
If you want to trigger an execution for a specific revision, you can use the revision query parameter:
bash
curl -X POST \
http://localhost:8080/api/v1/executions/company.team/hello_world?revision=2
Execute a flow with inputs
You can also trigger a flow execution with inputs by adding the inputs as form data (the -F flag in the curl command):
bash
curl -X POST \
http://localhost:8080/api/v1/executions/company.team/hello_world \
-F greeting=""hey there""
You can pass inputs of different types, such as STRING, INT, FLOAT, DATETIME, FILE, BOOLEAN, and more.
yaml
curl -v ""http://localhost:8080/api/v1/executions/company.team/kestra-inputs"" \
    -H ""Transfer-Encoding:chunked"" \
    -H ""Content-Type:multipart/form-data"" \
    -F string=""a string""  \
    -F optional=""an optional string""  \
    -F int=1  \
    -F float=1.255  \
    -F boolean=true  \
    -F instant=""2023-12-24T23:00:00.000Z"" \
    -F ""files=@/tmp/128M.txt;filename=file""
Execute a flow with FILE-type inputs
You can also pass files as an input. All files must be sent as multipart form data named files with a header filename=your_kestra_input_name indicating the name of the input.
Let's look at an example to make this clearer. Suppose you have a flow that takes a JSON file as input and reads the file's content:
yaml
id: large_json_payload
namespace: company.team
inputs:
  - id: myCustomFileInput
    type: FILE
tasks:
  - id: hello
    type: io.kestra.plugin.scripts.shell.Commands
    inputFiles:
      myfile.json: ""{{ inputs.myCustomFileInput }}""
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - cat myfile.json
Assuming you have a file myfile.json in the current working directory, you can invoke the flow using the following curl command:
bash
curl -X POST -F ""files=@./myfile.json;filename=myCustomFileInput"" 'http://localhost:8080/api/v1/executions/company.team/large_json_payload'
We recommend this pattern if you need to pass large payloads to a flow. Passing a large payload directly in the request body (e.g. as JSON-type input or as a raw JSON webhook body) is not recommended for privacy, performance and maintenability reasons. Such large payloads would be stored directly in your Kestra's database backend, cluttering valuable storage space and leading to potential performance or privacy issues. However, if you pass it as a JSON file using a FILE-type input, it will be stored in internal storage (such as S3, GCS, Azure Blob), making it more performant and cost-effective to store and retrieve.
Execute a flow via an API call in Python
You can also use the requests library in Python to make requests to the Kestra API. Here's an example:
python
import io
import requests
from requests_toolbelt.multipart.encoder import MultipartEncoder
with open(""/tmp/128M.txt"", 'rb') as fh:
  url = ""http://kestra:8080/api/v1/executions/company.team/hello_world""
  mp_encoder = MultipartEncoder(fields={
    ""string"": ""a string"",
    ""int"": 1,
    ""float"": 1.255,
    ""datetime"": ""2025-04-20T13:00:00.000Z"",
    ""files"": (""file"", fh, ""text/plain"")
  })
  result = requests.post(
      url,
      data=mp_encoder,
      headers={""Content-Type"": mp_encoder.content_type},
  )
Get URL to follow the Execution progress
Starting from Kestra 0.19.0, the Executions endpoint additionally returns a URL allowing to follow the Execution progress from the UI. This is particularly helpful for externally triggered long-running executions that require users to follow the workflow progress. Here is how you can use it:
First, create a flow:
yaml
id: myflow
namespace: company.team
tasks:
  - id: long_running_task
    type: io.kestra.plugin.scripts.shell.Commands
    commands:
      - sleep 90
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
Execute the flow via an API call:
shell
curl -X POST http://localhost:8080/api/v1/executions/company.team/myflow
You will see output similar to the following:
bash
{
  ""id"": ""1ZiZQWCHj7bf9XLtgvAxyi"",
  ""namespace"": ""company.team"",
  ""flowId"": ""myflow"",
  ""flowRevision"": 1,
  ""state"": {
    ""current"": ""CREATED"",
    ""histories"": [
      {
        ""state"": ""CREATED"",
        ""date"": ""2024-09-24T13:35:32.983335847Z""
      }
    ],
    ""duration"": ""PT0.017447417S"",
    ""startDate"": ""2024-09-24T13:35:32.983335847Z""
  },
  ""originalId"": ""1ZiZQWCHj7bf9XLtgvAxyi"",
  ""deleted"": false,
  ""metadata"": {
    ""attemptNumber"": 1,
    ""originalCreatedDate"": ""2024-09-24T13:35:32.983420055Z""
  },
  ""url"": ""http://localhost:8080/ui/executions/company.team/myflow/1ZiZQWCHj7bf9XLtgvAxyi""
}
You can click directly on that last URL to follow the execution progress from the UI, or you can return that URL from your application to the user who initiated the flow.
Keep in mind that you need to configure the URL of your kestra instance within your configuration file to have a full URL rather than just the suffix /ui/executions/company.team/myflow/uuid. Here is how you can do it:
yaml
kestra:
  url: http://localhost:8080
Webhook vs. API call
When sending a POST request to the /api/v1/executions/{namespace}/{flowId} endpoint, you can send data to the flow's execution context using inputs. If you want to send arbitrary metadata to the flow's execution context based on some event happening in your application, you can leverage a Webhook trigger.
Here is how you can adjust the previous hello_world example to use the webhook trigger instead of an API call:
yaml
id: hello_world
namespace: company.team
inputs:
  - id: greeting
    type: STRING
    defaults: hey
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: ""{{ trigger.body ?? inputs.greeting }}""
triggers:
  - id: webhook
    type: io.kestra.plugin.core.trigger.Webhook
    key: test1234
You can now send a POST request to the /api/v1/executions/webhook/{namespace}/{flowId}/{webhookKey} endpoint to trigger an execution and pass any metadata to the flow using the request body. In this example, the webhook URL would be http://localhost:8080/api/v1/executions/webhook/company.team/hello_world/test1234.
You can test the webhook trigger using a tool like Postman or cURL. Paste the webhook URL in the URL field and a sample JSON payload in the request body. Make sure to set:
the request method to POST
the request body type to raw and a JSON format.
Finally, click the Send button to trigger the flow execution. You should get a response with the execution ID and status code 200 OK.
‚ö°Ô∏è When to use a webhook trigger vs. an API call to create an Execution? To decide whether to use a webhook trigger or an API call to create an Execution, consider the following:
Use the webhook trigger when you want to send arbitrary metadata to the flow's execution context based on some event happening in your application.
Use the webhook trigger when you want to create new executions based on some event happening in an external application, such as a GitHub event (e.g. a Pull Request is merged) or a new record in a SaaS application, and you want to send the event metadata (header and body) to the flow to act on it.
Use an API call to create an Execution when you don't need to send any payload (apart from inputs) to the flow's execution context.
Execute a flow from Python
You can also execute a flow using the kestra pip package. This is useful when you want to trigger a flow execution from a Python application without creating an API request from scratch as shown in the earlier example.
First, install the package:
bash
pip install kestra
Then, you can trigger a flow execution by calling the execute() method. Here is an example for the same hello_world flow in the namespace company.team as above:
python
from kestra import Flow
flow = Flow()
flow.execute('company.team', 'hello_world', {'greeting': 'hello from Python'})
Now imagine that you have a flow that takes a FILE-type input and reads the file's content:
yaml
id: myflow
namespace: company.team
inputs:
  - id: myfile
    type: FILE
tasks:
  - id: print_data
    type: io.kestra.plugin.core.log.Log
    message: ""file's content {{ read(inputs.myfile) }}""
Assuming you have a file called example.txt in the same directory as your Python script, you can pass a file as an input to the flow using the following Python code:
python
import os
from kestra import Flow
os.environ[""KESTRA_HOSTNAME""] = ""http://host.docker.internal:8080"" # # Set this when executing this Python code inside Kestra
flow = Flow()
with open('example.txt', 'rb') as fh:
    flow.execute('company.team', 'myflow', {'files': ('myfile', fh, 'text/plain')})
Keep in mind that files is a tuple with the following structure: ('input_id', file_object, 'content_type').
Execute with ForEachItem
The ForEachItem task allows you to iterate over a list of items and run a subflow for each item, or for each batch containing multiple items. This is useful when you want to process a large list of items in parallel, e.g. to process millions of records from a database table or an API payload.
The ForEachItem task is a Flowable task, which means that it can be used to define the flow logic and control the execution of the flow.
Syntax:
yaml
id: each_example
namespace: company.team
tasks:
  - id: each
    type: io.kestra.plugin.core.flow.ForEachItem
    items: ""{{ inputs.file }}"" # could be also an output variable {{ outputs.extract.uri }}
    inputs:
      file: ""{{ taskrun.items }}"" # items of the batch
    batch:
      rows: 4
      bytes: ""1024""
      partitions: 2
    namespace: company.team
    flowId: subflow
    revision: 1 # optional (default: latest)
    wait: true # wait for the subflow execution
    transmitFailed: true # fail the task run if the subflow execution fails
    labels: # optional labels to pass to the subflow to be executed
      key: value
Full Example
Was this page helpful?
Yes
No
Workflow Components
Namespace
Workflow Components
Variables""""""",4102,17463,kestra
https://kestra.io/docs/workflow-components/variables,"""""""DocsWorkflow ComponentsVariables
Variables
Table of Contents
How to configure variables
How are variables rendered
Dynamic Variables
FAQ
How do I escape a block in Pebble syntax to ensure that it won't be parsed?
Which order are inputs and variables resolved?
Can I transform variables with Pebble expressions?
Can I use nested variables?
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Variables are key-value pairs that help reuse some values across tasks.
You can also store variables on a namespace level so that they can be reused across multiple flows in a given namespace.
How to configure variables
Here is how you can configure variables in your flow:
yaml
id: hello_world
namespace: company.team
variables:
  myvar: hello
  numeric_variable: 42
tasks:
  - id: log
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ vars.myvar }} world {{ vars.numeric_variable }}""
You can see the syntax for using variables is {{ vars.variable_name }}.
How are variables rendered
You can use variables in any task property that is documented as dynamic.
Dynamic variables will be rendered thanks to the Pebble templating engine. Pebble templating engine allows you to process various expressions with filters and functions. More information on variable processing can be found under Expressions.
Since 0.14, Variables are no longer rendered recursively. You can read more about this change and how to change this behaviour here.
Dynamic Variables
If you want to have an expression inside of your variable, you will need to wrap it in render when you use it in a task.
For example, this variable will only display the current time in the log message when wrapped in render. Otherwise, the log message will just contain the expression as a string:
yaml
id: dynamic_variable
namespace: company.team
variables:
  time: ""{{ now() }}""
tasks:
  - id: log
    type: io.kestra.plugin.core.log.Log
    message: ""{{ render(vars.time) }}""
You will need to wrap the variable expression in render every time you want to use it in a task.
FAQ
How do I escape a block in Pebble syntax to ensure that it won't be parsed?
To ensure that a block of code won't be parsed by Pebble, you can use the {% raw %} and {% endraw %} Pebble tags. For example, the following Pebble expression will return the string {{ myvar }} instead of the value of the myvar variable:
yaml
{% raw %}{{ myvar }}{% endraw %}
Which order are inputs and variables resolved?
Inputs are resolved first, even before the execution starts. In fact, if you try to create a flow with an invalid input value, the execution will not be created.
Therefore, you can use inputs within variables, but you can't use variables or Pebble expressions within inputs.
Expressions are rendered recursively, meaning that if a variable contains another variable, the inner variable will be resolved first.
When it comes to triggers, they are handled similarly to inputs as they are known before the execution starts (they trigger the execution). This means that you can't use inputs (unless they have defaults attached) or variables within triggers, but you can use trigger variables within variables.
To make it clearer, let's look at some examples.
Examples
This flow uses inputs, trigger and execution variables which are resolved before variables:
yaml
id: upload_to_s3
namespace: company.team
inputs:
  - id: bucket
    type: STRING
    defaults: declarative-data-orchestration
tasks:
  - id: get_zip_file
    type: io.kestra.plugin.core.http.Download
    uri: https://wri-dataportal-prod.s3.amazonaws.com/manual/global_power_plant_database_v_1_3.zip
  - id: unzip
    type: io.kestra.plugin.compress.ArchiveDecompress
    algorithm: ZIP
    from: ""{{outputs.get_zip_file.uri}}""
  - id: csv_upload
    type: io.kestra.plugin.aws.s3.Upload
    from: ""{{ outputs.unzip.files['global_power_plant_database.csv'] }}""
    bucket: ""{{ inputs.bucket }}""
    key: ""powerplant/{{ trigger.date ?? execution.startDate | date('yyyy_MM_dd__HH_mm_ss') }}.csv""
triggers:
  - id: hourly
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""@hourly""
This flow will start a task conditionally based on whether the input is provided or not:
yaml
id: conditional_branching
namespace: company.team
inputs:
  - id: parameter
    type: STRING
    required: false
tasks:
  - id: if
    type: io.kestra.plugin.core.flow.If
    condition: ""{{inputs.customInput ?? false }}""
    then:
      - id: if_not_null
        type: io.kestra.plugin.core.log.Log
        message: Received input {{inputs.parameter}}
    else:
      - id: if_null
        type: io.kestra.plugin.core.log.Log
        message: No input provided
Here is an example that uses a trigger variable within a trigger itself (that's allowed!):
yaml
id: backfill_past_mondays
namespace: company.team
tasks:
  - id: log_trigger_or_execution_date
    type: io.kestra.plugin.core.log.Log
    message: ""{{ trigger.date ?? execution.startDate }}""
triggers:
  - id: first_monday_of_the_month
    type: io.kestra.plugin.core.trigger.Schedule
    timezone: Europe/Berlin
    backfill:
      start: 2023-11-11T00:00:00Z
    cron: ""0 11 * * MON"" # at 11 on every Monday
    conditions: # only first Monday of the month
      - type: io.kestra.plugin.core.condition.DayWeekInMonthCondition
        date: ""{{ trigger.date }}""
        dayOfWeek: ""MONDAY""
        dayInMonth: ""FIRST""
Can I transform variables with Pebble expressions?
Yes. Kestra uses Pebble Templates along with the execution context to render dynamic properties. This means that you can use Pebble expressions (such as filters, functions, and operators to transform inputs and variables.
The example below illustrates how to use variables and Pebble expressions to transform string values in dynamic task properties:
yaml
id: variables_demo
namespace: company.team
variables:
  DATE_FORMAT: ""yyyy-MM-dd""
tasks:
  - id: seconds_of_day
    type: io.kestra.plugin.core.debug.Return
    format: '{{60 * 60 * 24}}'
  - id: start_date
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ execution.startDate | date(vars.DATE_FORMAT) }}""
  - id: curr_date_unix
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ now() | date(vars.DATE_FORMAT) | timestamp() }}""
  - id: next_date
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ now() | dateAdd(1, 'DAYS') | date(vars.DATE_FORMAT) }}""
  - id: next_date_unix
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ now() | dateAdd(1, 'DAYS') | date(vars.DATE_FORMAT) | timestamp() }}""
  - id: pass_downstream
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - echo {{outputs.next_date_unix.value}}
Can I use nested variables?
Yes! However, keep in mind that depending on the task, you may need to wrap the root variable in a json() function in order to access specific keys. Here is an example using a list of maps as a variable:
yaml
id: vars
namespace: company.myteam
variables:
  servers:
    - fqn: server01.mydomain.io
      user: root
    - fqn: server02.mydomain.io
      user: guest
    - fqn: server03.mydomain.io
      user: rick
tasks:
  - id: parallel
    type: io.kestra.plugin.core.flow.EachParallel
    value: ""{{ vars.servers }}""
    tasks:
      - id: log
        type: io.kestra.plugin.core.log.Log
        message:
           - ""{{ taskrun.value }}"" # for each element in the servers list, this will print the full JSON object e.g. {‚Äúfqn‚Äù:‚Äúserver01.mydomain.io‚Äù,‚Äúuser‚Äù:‚Äúroot‚Äù}
           - ""{{ json(taskrun.value).fqn }}"" # prints the value for that key e.g. server01.mydomain.io
           - ""{{ json(taskrun.value).user }}"" # prints the value for that key e.g. root
Was this page helpful?
Yes
No
Workflow Components
Execution
Workflow Components
Inputs""""""",1864,7796,kestra
https://kestra.io/docs/workflow-components/inputs,"""""""DocsWorkflow ComponentsInputs
Inputs
Table of Contents
What are inputs
Declaring inputs
Input types
Input Properties
Input validation
Example: using input validators in your flows
Nested Inputs
Array Inputs
Using an input value in a flow
Set input values at flow execution
Set inputs from the web UI
Set inputs when executing the flow using the API
Set inputs when executing the flow in Python
Set inputs when executing the flow in Java
Difference between inputs and variables
Dynamic inputs
Conditional Inputs for Interactive Workflows
How It Works
Custom Values in the SELECT and MULTISELECT Inputs
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Inputs is a list of dynamic values passed to the flow at runtime.
What are inputs
A flow can be parameterized using inputs to allow multiple executions of the same flow, each with different input values. Flow inputs are stored as variables within the flow execution context and can be accessed within the flow using the syntax {{ inputs.parameter_name }}.
You can use inputs to make your tasks more dynamic. For instance, you can use an input to dynamically define the path of a file that needs to be processed within a flow.
You can inspect the input values in the Overview tab of the Execution page.
You can set a custom displayName for each input to make the Execution interface more user-friendly.
Declaring inputs
You can declare as many inputs as necessary for any flow. Inputs can be required or optional.
If an input is required, we recommend using the defaults property to set default values. The flow cannot start if the input is not provided during the creation of the Execution.
Every input will be parsed during the creation of the execution, and any invalid inputs will deny the creation of the execution.
If the execution is not created due to invalid or missing inputs, no execution will be found on the list of executions.
Below is an example flow using several inputs:
yaml
id: inputs
namespace: company.team
inputs:
  - id: string
    type: STRING
    defaults: ""Hello World!""
    displayName: ""A string input""
  - id: optional
    type: STRING
    required: false
    displayName: ""An optional string""
  - id: int
    type: INT
    defaults: 100
    displayName: ""An integer input""
  - id: list_of_int
    type: ARRAY
    itemType: INT
    defaults: [1, 2, 3]
    displayName: ""A list of integers""
  - id: bool
    type: BOOLEAN
    defaults: true
    displayName: ""A boolean input""
  - id: float
    type: FLOAT
    defaults: 100.12
    displayName: ""A float input""
  - id: dropdown
    type: SELECT
    displayName: ""A dropdown input""
    defaults: VALUE_1
    values:
      - VALUE_1
      - VALUE_2
      - VALUE_3
  - id: dropdown_multi
    type: MULTISELECT
    values:
      - VALUE_1
      - VALUE_2
      - VALUE_3
  - id: instant
    type: DATETIME
    defaults: ""2013-08-09T14:19:00Z""
    displayName: ""A datetime input""
  - id: date
    type: DATE
    defaults: ""2013-10-25""
    displayName: ""A date input""
  - id: time
    type: TIME
    displayName: ""A time input""
    defaults: ""14:19:00""
  - id: duration
    type: DURATION
    defaults: ""PT5M6S""
    displayName: ""A duration input""
  - id: file
    type: FILE
    displayName: ""Upload a file""
  - id: json
    type: JSON
    displayName: ""A JSON input""
    defaults: |
      [{""name"": ""kestra"", ""rating"": ""best in class""}]
  - id: uri
    type: URI
    defaults: ""https://huggingface.co/datasets/kestra/datasets/raw/main/csv/orders.csv""
    displayName: ""A URI input""
  - id: secret
    type: SECRET
    displayName: ""A secret input""
  - id: yaml
    type: YAML
    defaults:
      - user: john
        email: john@example.com
      - user: will
        email: will@example.com
    displayName: YAML
  - id: nested.string
    type: STRING
    defaults: ""Hello World!""
    displayName: ""A nested string input""
Note: FILE type does not support defaults currently.
Input types
Inputs in Kestra are strongly typed and validated before starting the flow execution.
Here is the list of supported data types:
STRING: It can be any string value ‚Äî inputs of type STRING are passed to the execution in its raw format without parsing; for additional validation, you can add a custom regex validator to allow only specific string patterns.
INT: Must be a valid integer value (without any decimals).
FLOAT: Must be a valid float value (with decimals).
SELECT: Must be a valid string value from a predefined list of values. You can either pass those values directly using the values property or use the expression property to fetch the values dynamically from a KV store. Additionally, if allowCustomValue is set to true, the user can provide a custom value that is not in the predefined list.
MULTISELECT: Must be one or more valid string values from a predefined list of values. You can either pass those values directly using the values property or use the expression property to fetch the values dynamically from a KV store. Additionally, if allowCustomValue is set to true, the user can provide a custom value that is not in the predefined list.
BOOLEAN: Must be true or false passed as strings.
DATETIME: Must be a valid full ISO 8601 date and time with the timezone expressed in UTC format; pass input of type DATETIME in a string format following the pattern 2042-04-02T04:20:42.00Z.
DATE: Must be a valid full ISO 8601 date without the timezone from a text string such as 2042-12-03.
TIME: Must be a valid full ISO 8601 time without the timezone from a text string such as 10:15:30.
DURATION: Must be a valid full ISO 8601 duration from a text string such as PT5M6S.
FILE: Must be a file sent as Content-Type: multipart/form-data with Content-Disposition: form-data; name=""files""; filename=""my-file"", where my-file is the name of the input.
JSON: Must be a valid JSON string and will be converted to a typed form.
YAML: Must be a valid YAML string.
URI: Must be a valid URI and will be kept as a string.
SECRET: a SECRET input is a string that is encrypted and stored in the database. It is decrypted at runtime and can be used in all tasks. The value of a SECRET input is masked in the UI and in the execution context. Note that you need to set the encryption key in your Kestra configuration before using it.
ARRAY: Must be a valid JSON array or a YAML list. The itemType property is required to ensure validation of the type of the array items.
All inputs of type FILE will be automatically uploaded to Kestra's internal storage and accessible to all tasks. After the upload, the input variable will contain a fully qualified URL of the form kestra:///.../.../ that will be automatically managed by Kestra and can be used as-is within any task.
Input Properties
Below is the list of available properties for all inputs regardless of their types:
id: The input parameter identifier ‚Äî this property is important as it's used to reference the input variables in your flow, e.g. {{ inputs.user }} will reference the input parameter named user.
type: The data type of the input parameter, as described in the previous section.
required: Whether the input is required or optional; if required is set to true and no default value is configured and also no input is provided at runtime, the execution will not be created as Kestra cannot know what value to use.
defaults: The default value that will be used if no custom input value is provided at runtime; this value must be provided as a string and will be coerced to the desired data type specified using the type property.
dependsOn: Allows you to make the input dependent on another input to be inputted first.
displayName: A different name that will display in the Execution interface instead of the id.
description: A markdown description to document the input.
Input validation
Kestra validates the type of each input. In addition to the type validation, some input types can be configured with validation rules that will be enforced at execution time.
STRING: A validator property allows the addition of a validation regex.
INT: min and max properties allow the addition of minimum and maximum value ranges.
FLOAT: min and max properties allow the addition of minimum and maximum ranges.
DURATION: min and max properties allow the addition of minimum and maximum ranges.
DATE: after and before properties help you ensure that the input value is within the allowed date range.
TIME: after and before properties help you ensure that the input value is within the allowed time range.
DATETIME: after and before properties help you ensure that the input value is within the allowed date range.
Example: using input validators in your flows
To ensure that your input value is within a certain integer value range, you can use the min and max properties. Similarly, to ensure that your string input matches a regex pattern, you can provide a custom regex validator. The following flow demonstrates how this can be accomplished:
yaml
id: regex_input
namespace: company.team
inputs:
  - id: age
    type: INT
    defaults: 42
    required: false
    min: 18
    max: 64
  - id: user
    type: STRING
    defaults: student
    required: false
    validator: ^student(\d+)?$
  - id: float
    type: FLOAT
    defaults: 3.2
    min: 0.2
    max: 5.3
  - id: duration
    type: DURATION
    min: ""PT5M6S""
    max: ""PT12H58M46S""
  - id: date
    type: DATE
    defaults: ""2024-04-12""
    after: ""2024-04-10""
    before: ""2024-04-15""
  - id: time
    type: TIME
    after: ""11:01:01""
    before: ""11:04:01""
  - id: datetime
    type: DATETIME
    defaults: ""2024-04-13T14:17:00Z""
    after: ""2024-04-10T14:19:00Z""
    before: ""2024-04-15T14:19:00Z""
tasks:
  - id: validator
    type: io.kestra.plugin.core.log.Log
    message: User {{ inputs.user }}, age {{ inputs.age }}
The age, float, and duration input must be within a valid range between min and max values. Specifically for the age input, we specify that this input will be by default set to 42, but it can be overwritten at runtime to a value between 18 and 64. If you attempt to execute the flow with the age input set to 17 or 65, the validation will fail and the execution won't start.
Similarly, the Regex expression ^student(\d+)?$ is used to validate that the input argument user of type STRING follows the following pattern:
^student: This part of the regex asserts that the string must begin with the lowercase string value student.
\d: This part of the regex matches any digit (0-9).
+: This part of the regex asserts that there is one or more of the preceding token (i.e., one or more digits are allowed after the value student).
()?: The parentheses group the digits together, and the question mark makes the entire group optional ‚Äî this means that the digits after the word student are optional.
$: This part of the regex asserts the end of the string. This ensures that the string doesn't contain any additional characters after the optional digits.
With this pattern:
""student"" would be a match.
""student123"" would be a match.
""studentabc"" would not be a match because ""abc"" isn't a sequence of digits.
""student123abc"" would not be a match because no more characters are allowed after the sequence of ""students"" with the following numbers.
Lastly, the date, time, and datetime inputs must be within a valid range between after and before. In the date example, the date provided must be between 10th May 2024 and 15th May 2024. Anything outside of this range will fail and the execution won't start.
Try running this flow with various inputs or adjust the regex pattern to see how the input validation works.
Nested Inputs
If you use a . inside the name of an input, the input will be nested.
Here's an example that includes 2 nested inputs:
yaml
id: nested_inputs
namespace: company.team
inputs:
  - id: nested.string
    type: STRING
    required: false
  - id: nested.int
    type: INT
tasks:
  - id: log_inputs
    type: io.kestra.plugin.core.log.Log
    message: ""{{ inputs.nested.string }} and {{ inputs.nested.int }}""
You can access the first input value using {{ inputs.nested.string }}. This syntax provides a convenient type validation of nested inputs without using raw JSON that would not be validated (JSON-type input values are passed as strings).
Array Inputs
Array inputs are used to pass a list of values to a flow. The itemType property is required to ensure validation of the type of the array items.
It's particularly useful when you want the end-user triggering the workflow to provide multiple values of a specific type, e.g. a list of integers, strings, booleans, datetimes, etc. You can provide the default values as a JSON array or as a YAML list ‚Äî both are supported.
yaml
id: array_demo
namespace: company.team
inputs:
  - id: my_numbers_json_list
    type: ARRAY
    itemType: INT
    defaults: [1, 2, 3]
  - id: my_numbers_yaml_list
    type: ARRAY
    itemType: INT
    defaults:
      - 1
      - 2
      - 3
tasks:
  - id: print_status
    type: io.kestra.plugin.core.log.Log
    message: received inputs {{ inputs }}
Here is how the array inputs are rendered in the UI when you create an execution:
Using an input value in a flow
Every input is available with dynamic variables such as: {{ inputs.name }} or {{ inputs['name'] }}. If you use characters inside of your input id such as -, you'll need to use the {{ inputs['name-example']}} format.
For example, if you declare the following inputs:
yaml
inputs:
  - id: mystring
    type: STRING
    required: true
  - id: my-file
    type: FILE
You can use the value of the input mystring inside dynamic task properties with {{ inputs.mystring }} but my-file would have to use {{ inputs['my-file'] }} because of the -.
We can see a full example here where inputFiles property is set to {{ inputs['my-file'] }}:
yaml
id: input_files
namespace: company.team
description: This flow shows how to pass files between inputs and tasks in Shell scripts.
inputs:
  - id: my-file
    type: FILE
tasks:
  - id: rename
    type: io.kestra.plugin.scripts.shell.Commands
    commands:
      - mv file.tmp output.tmp
    inputFiles:
      file.tmp: ""{{ inputs['my-file'] }}""
    outputFiles:
      - ""*.tmp""
Since 0.14, Inputs are no longer rendered recursively. You can read more about this change and how to change this behaviour here.
Set input values at flow execution
When you execute a flow with inputs, you must set all inputs (unless optional or with a default value) to be able to create the execution.
Let's consider the following example that defines multiple inputs:
yaml
id: kestra_inputs
namespace: company.team
inputs:
  - id: string
    type: STRING
    defaults: hello
  - id: optional
    type: STRING
    required: false
  - id: int
    type: INT
  - id: float
    type: FLOAT
  - id: instant
    type: DATETIME
  - id: file
    type: FILE
Here, the inputs {{ inputs.string }} and {{ inputs.optional }} can be skipped because the string input has a default value and the optional input is not required. All other inputs must be specified at runtime.
Set inputs from the web UI
When creating an execution from the web UI, you must set the inputs in the UI form. Kestra's UI will generate a dedicated form based on your inputs definition. For example, datetime input properties will have a date picker.
The input form for the inputs above looks as follows:
Once the inputs are set, you can trigger an execution of the flow.
Set inputs when executing the flow using the API
To create an execution with these inputs using the API, we can use the curl command to make an API request:
bash
curl -v ""http://localhost:8080/api/v1/executions/example/kestra-inputs"" \
    -H ""Transfer-Encoding:chunked"" \
    -H ""Content-Type:multipart/form-data"" \
    -F string=""a string""  \
    -F optional=""an optional string""  \
    -F int=1  \
    -F float=1.255  \
    -F instant=""2023-12-24T23:00:00.000Z"" \
    -F ""files=@/tmp/128M.txt;filename=file""
All files must be sent as multipart form data named files with a header filename=my-file which will be the name of the input.
Set inputs when executing the flow in Python
To create an execution with these inputs in Python, you can use the following script:
python
import io
import requests
from kestra import Flow
flow = Flow()
with open('/tmp/example.txt', 'rb') as fh:
  flow.execute('example',
               'kestra-inputs',
               {'string': 'a string',
                'optional': 'an optional string',
                'int': 1,
                'float': str(1.255),
                'instant': '2020-01-14T23:00:00.000Z',
                'files': ('file', fh, 'text/plain')})
Floats need to be wrapped in str() otherwise you will run into a bytes-like object error when passing a file as an input too.
You can also use the requests library in Python to make requests to the Kestra API. Here's an example to execute a flow with multiple inputs:
python
import io
import requests
from requests_toolbelt.multipart.encoder import MultipartEncoder
with open(""/tmp/128M.txt"", 'rb') as fh:
  url = f""http://kestra:8080/api/v1/executions/io.kestra.docs/my-flow""
  mp_encoder = MultipartEncoder(fields={
    ""string"": ""a string"",
    ""optional"": ""an optionnal string"",
    ""int"": 1,
    ""float"": 1.255,
    ""instant"": ""2020-01-14T23:00:00.000Z"",
    ""files"": (""file"", fh, ""text/plain"")
  })
  result = requests.post(
      url,
      data=mp_encoder,
      headers={""Content-Type"": mp_encoder.content_type},
  )
Set inputs when executing the flow in Java
To create an execution with these inputs in Java (with Apache Http Client 5), you can use the following script:
java
import org.apache.hc.client5.http.classic.methods.HttpPost;
import org.apache.hc.client5.http.entity.mime.FileBody;
import org.apache.hc.client5.http.entity.mime.MultipartEntityBuilder;
import org.apache.hc.client5.http.entity.mime.StringBody;
import org.apache.hc.client5.http.impl.classic.CloseableHttpClient;
import org.apache.hc.client5.http.impl.classic.CloseableHttpResponse;
import org.apache.hc.client5.http.impl.classic.HttpClientBuilder;
import org.apache.hc.core5.http.ContentType;
import org.apache.hc.core5.http.HttpEntity;
import java.io.File;
class Application {
  public static void main(String[] args) {
    HttpEntity multipartEntity = MultipartEntityBuilder.create()
        .addPart(""string"", new StringBody(""test"", ContentType.DEFAULT_TEXT))
        .addPart(""int"", new StringBody(""1"", ContentType.DEFAULT_TEXT))
        .addPart(""files"", new FileBody(new File(""/tmp/test.csv""), ContentType.DEFAULT_TEXT, ""file""))
        .build();
    try (CloseableHttpClient httpclient = HttpClientBuilder.create().build()) {
      HttpPost request = new HttpPost(""http://kestra:8080/api/v1/executions/com.kestra.lde/inputs"");
      request.setEntity(multipartEntity);
      CloseableHttpResponse response = httpclient.execute(request);
      System.out.println(""Response "" + response);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
  }
}
Difference between inputs and variables
Variables are similar to constant values. They have the same behaviour as an input during execution but they can't be overridden once the execution starts. Variables must be defined before execution whereas inputs can be set at execution.
Variables are best suited for values that you don't want to change, and are used in multiple places within the flow. For example, a URL you will use for an API request that won't change would be best as a variable whereas an email address that changes every time you execute your flow would be best as an input.
Dynamic inputs
Inputs in kestra are strongly typed. Currently, it's not possible to enforce strong types and simultaneously use dynamically rendered Pebble expressions. However, you can use Pebble expressions in default values within STRING inputs.
This example wouldn't work:
yaml
id: test
namespace: company.team
inputs:
  - id: date
    type: DATETIME
    defaults: ""{{ now() }}""
tasks:
  - id: print_date
    type: io.kestra.plugin.core.log.Log
    message: hello on {{ inputs.date }}
However, if you change the input type to STRING, you can use Pebble expressions such as {{ now() }} in the default value:
yaml
id: test
namespace: company.team
inputs:
  - id: date
    type: STRING
    defaults: ""{{ now() }}""
tasks:
  - id: print_date
    type: io.kestra.plugin.core.log.Log
    message: hello on {{ render(inputs.date) }}
Keep in mind that since Kestra 0.14, inputs are no longer rendered recursively. Therefore, you need to use the {{ render(inputs.date) }} syntax to render the Pebble expression specified within the STRING input value. This improves security by preventing the execution of arbitrary code within the Pebble expression.
You can read more about this change in the Migration Guide.
Conditional Inputs for Interactive Workflows
Starting in Kestra 0.19.0, you can set up inputs that depend on other inputs, letting further inputs to be conditionally displayed based on user choices. This is useful for use cases such as approval workflows or dynamic resource provisioning.
How It Works
You can create inputs that change based on conditions using the dependsOn and condition properties. Here's an example where different inputs show up depending on the resource type a user selects:
yaml
id: request_resources
namespace: company.team
inputs:
  - id: resource_type
    displayName: Resource Type
    type: SELECT
    values:
      - Access permissions
      - SaaS application
      - Development tool
      - Cloud VM
  - id: access_permissions
    displayName: Access Permissions
    type: SELECT
    expression: ""{{ kv('access_permissions') }}""
    dependsOn:
      inputs:
        - resource_type
      condition: ""{{ inputs.resource_type == 'Access permissions' }}""
  - id: saas_applications
    displayName: SaaS Application
    type: MULTISELECT
    expression: ""{{ kv('saas_applications') }}""
    dependsOn:
      inputs:
        - resource_type
      condition: ""{{ inputs.resource_type == 'SaaS application' }}""
  - id: cloud_provider
    displayName: Cloud Provider
    type: SELECT
    values:
      - AWS
      - GCP
      - Azure
    dependsOn:
      inputs:
        - resource_type
      condition: ""{{ inputs.resource_type == 'Cloud VM' }}""
  - id: cloud_vms
    displayName: Cloud VM
    type: SELECT
    expression: ""{{ kv('cloud_vms')[inputs.cloud_provider] }}""
    dependsOn:
      inputs:
        - resource_type
        - cloud_provider
      condition: ""{{ inputs.resource_type == 'Cloud VM' }}""
In this example:
The resource_type input controls which additional inputs (like access_permissions, saas_applications, and cloud_vms) appear.
The dependsOn property links the inputs, and the condition property defines when to display the related input.
Before running the above flow, you need to set up the key-value pairs for each input. Expand the example below to see how to set up the key-value pairs for all inputs using a flow.
Flow adding key-value pairs
You could also add those key-value pairs using the API or from the UI.
Custom Values in the SELECT and MULTISELECT Inputs
If you want to allow users to enter other value if the predefined values shown in the dropdown don't fit their needs, you can set allowCustomValue to true on any input. This enables you to provide a list of default values but still (optionally) allow users to enter custom ones.
In the example below, the cloud_provider input allows users to select from a list of the most common cloud providers (AWS, GCP, Azure) or enter a custom value if they use some less common cloud provider e.g. Oracle Cloud.
yaml
id: custom_values
namespace: company.team
inputs:
  - id: cloud_provider
    displayName: Cloud Provider
    type: SELECT
    allowCustomValue: true
    values:
      - AWS
      - GCP
      - Azure
tasks:
  - id: print_status
    type: io.kestra.plugin.core.log.Log
    message: selected cloud provider {{ inputs.cloud_provider }}
Was this page helpful?
Yes
No
Workflow Components
Variables
Workflow Components
Outputs""""""",5674,23971,kestra
https://kestra.io/docs/workflow-components/outputs,"""""""DocsWorkflow ComponentsOutputs
Outputs
Table of Contents
What are outputs
Using outputs
Internal storage
Dynamic variables (Each tasks)
Current taskrun value
Loop over a list of JSON objects
Specific outputs for dynamic tasks
Previous task lookup
Lookup in sibling tasks
Pass data between flows using flow outputs
Outputs Preview
Using Debug Outputs
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Outputs allow you to pass data between tasks and flows.
What are outputs
A workflow execution can generate outputs. Outputs are stored in the flow's execution context (i.e. in memory) and can be used by all downstream tasks and flows.
Outputs can have multiple attributes ‚Äî check the documentation of each task to see their output attributes.
You can retrieve outputs from other tasks within all dynamic properties.
Don't use Outputs to fetch any sensitive data (passwords, secrets, API tokens, ...).
Fetching Secrets from an external Secrets Manager via a task imposes a significant security risk. All data fetched via outputs is stored in clear text in multiple places (incl. the backend database, internal storage, logs, API requests).
For secure handling of secrets, exclusively use Secrets. Kestra EE and Kestra Cloud offer reliable secrets management including native integrations with various Secrets Managers.
Using outputs
Here is how to use the output of the produce_output task in the use_output task. Here we use the Return task that has one output attribute named value.
yaml
id: task_outputs_example
namespace: company.team
tasks:
  - id: produce_output
    type: io.kestra.plugin.core.debug.Return
    format: my output {{ execution.id }}
  - id: use_output
    type: io.kestra.plugin.core.log.Log
    message: The previous task output is {{ outputs.produce_output.value }}
In the example above, the first task produces an output based on the task property format. This output attribute is then used in the second task message property.
The expression {{ outputs.produce_output.value }} references the previous task output attribute.
In the example above, the Return task produces an output attribute value. Every task produces different output attributes. You can look at each task outputs documentation or use the Outputs tab of the Executions page to find out about specific task output attributes.
The Outputs tab will have the output for produce_output task. There is no output for use_output task as it only logs a message.
In the next example, we can see a file is passed between an input and a task, where the task generates a new file as an output:
yaml
id: bash_with_files
namespace: company.team
description: This flow shows how to pass files between inputs and tasks in Shell scripts.
inputs:
  - id: file
    type: FILE
tasks:
  - id: rename
    type: io.kestra.plugin.scripts.shell.Commands
    commands:
      - mv file.tmp output.tmp
    inputFiles:
      file.tmp: ""{{ inputs.file }}""
    outputFiles:
      - ""*.tmp""
Since 0.14, Outputs are no longer rendered recursively. You can read more about this change and how to change this behaviour here.
Internal storage
Each task can store data in Kestra's internal storage. If an output attribute is stored in internal storage, the attribute will contain a URI that points to a file in the internal storage. This output attribute could be used by other tasks to access the stored data.
The following example stores the query results in internal storage, then accesses it in the write_to_csv task:
yaml
id: output_sample
namespace: company.team
tasks:
  - id: output_from_query
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      SELECT * FROM `bigquery-public-data.wikipedia.pageviews_2023`
      WHERE DATE(datehour) = current_date()
      ORDER BY datehour desc, views desc
      LIMIT 10
    store: true
  - id: write_to_csv
    type: io.kestra.plugin.serdes.csv.IonToCsv
    from: ""{{ outputs.output_from_query.uri }}""
Dynamic variables (Each tasks)
Current taskrun value
In dynamic flows (using ""Each"" loops for example), variables will be passed to task dynamically. You can access the current taskrun value with {{ taskrun.value }} like this:
yaml
id: taskrun_value_example
namespace: company.team
tasks:
  - id: each
    type: io.kestra.plugin.core.flow.EachSequential
    value: [""value 1"", ""value 2"", ""value 3""]
    tasks:
      - id: inner
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ task.id }} > {{ taskrun.value }} > {{ taskrun.startDate }}""
The Outputs tab would contain the output for each of the inner task.
Loop over a list of JSON objects
Within the loop, the value is always a JSON string, so the {{ taskrun.value }} is the current element as JSON string. To access properties, you need to wrap it in the fromJson() function to have a JSON object allowing to access each property easily.
yaml
id: loop_sequentially_over_list
namespace: company.team
tasks:
  - id: each
    type: io.kestra.plugin.core.flow.EachSequential
    value:
      - {""key"": ""my-key"", ""value"": ""my-value""}
      - {""key"": ""my-complex"", ""value"": {""sub"": 1, ""bool"": true}}
    tasks:
      - id: inner
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ fromJson(taskrun.value).key }} > {{ fromJson(taskrun.value).value }}""
Specific outputs for dynamic tasks
Dynamic tasks are tasks that will run other tasks a certain number of times. A dynamic task will run multiple iterations of a set of sub-tasks.
For example, EachSequential and EachParallel produce other tasks dynamically depending on their value property.
It is possible to reach each iteration output of dynamic tasks by using the following syntax:
yaml
id: output_sample
namespace: company.team
tasks:
  - id: each
    type: io.kestra.plugin.core.flow.EachSequential
    value: [""s1"", ""s2"", ""s3""]
    tasks:
      - id: sub
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ task.id }} > {{ taskrun.value }} > {{ taskrun.startDate }}""
  - id: use
    type: io.kestra.plugin.core.debug.Return
    format: ""Previous task produced output: {{ outputs.sub.s1.value }}""
The outputs.sub.s1.value variable reaches the value of the sub task of the s1 iteration.
Previous task lookup
It is also possible to locate a specific dynamic task by its value:
yaml
id: dynamic_looping
namespace: company.team
tasks:
  - id: each
    type: io.kestra.plugin.core.flow.EachSequential
    value: [""value 1"", ""value 2"", ""value 3""]
    tasks:
      - id: inner
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ taskrun.value }}""
  - id: end
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ task.id }} > {{ outputs.inner['value 1'].value }}""
It uses the format outputs.TASKID[VALUE].ATTRIBUTE. The special bracket [] in [VALUE] is called the subscript notation; it enables using special chars like space or '-' in task identifiers or output attributes.
Lookup in sibling tasks
Sometimes, it can be useful to access previous outputs on the current task tree, what is called sibling tasks.
If the task tree is static, for example when using the Sequential task, you can use the {{ outputs.sibling.value }} notation where siblingis the identifier of the sibling task.
If the task tree is dynamic, for example when using the EachSequential task, you need to use {{ sibling[taskrun.value] }} to access the current tree task. taskrun.value is a special variable that holds the current value of the EachSequential task.
For example:
yaml
id: loop_with_sibling_tasks
namespace: company.team
tasks:
  - id: each
    type: io.kestra.plugin.core.flow.EachSequential
    value: [""value 1"", ""value 2"", ""value 3""]
    tasks:
      - id: first
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ taskrun.value }}""
      - id: second
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ outputs.first[taskrun.value].value }}""
  - id: end
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ task.id }} > {{ outputs.second['value 1'].value }}""
When there are multiple levels of EachSequential tasks, you can use the parents variable to access the taskrun.value of the parent of the current EachSequential. For example, for two levels of EachSequential you can use outputs.sibling[parents[0].taskrun.value][taskrun.value].value.
The latter can become very complex when parents exist (multiple imbricated EachSequential). For this, you can use the currentEachOutput() function. No matter the number of parents, the following example will retrieve the correct output attribute: currentEachOutput(outputs.sibling).value thanks to this function.
Accessing sibling task outputs is impossible on Parallel or EachParallel as they run tasks in parallel.
Pass data between flows using flow outputs
Since 0.15.0, the flow can also produce strongly typed outputs simply by defining them in the flow file. Here is an example of a flow that produces an output:
yaml
id: flow_outputs
namespace: company.team
tasks:
  - id: mytask
    type: io.kestra.plugin.core.debug.Return
    format: this is a task output used as a final flow output
outputs:
  - id: final
    type: STRING
    value: ""{{ outputs.mytask.value }}""
You can see that outputs are defined as a list of key-value pairs. The id is the name of the output attribute (must be unique within a flow), and the value is the value of the output. You can also add a description to the output.
You will see the output of the flow on the Executions page in the Overview tab.
Here is how you can access the flow output in the parent flow:
yaml
id: parent_flow
namespace: company.team
tasks:
  - id: subflow
    type: io.kestra.plugin.core.flow.Subflow
    flowId: flow_outputs
    namespace: company.team
    wait: true
  - id: log_subflow_output
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.subflow.outputs.final }}""
In the example above, the subflow task produces an output attribute final. This output attribute is then used in the log_subflow_output task.
Note how the outputs are set twice within the ""{{outputs.subflow.outputs.final}}"":
once to access outputs of the subflow task
once to access the outputs of the subflow itself ‚Äî specifically, the final output.
Here is what you will see in the Outputs tab of the Executions page in the parent flow:
Outputs Preview
Kestra provides preview option for output files that get stored on Kestra internal storage. Lets see this with the help of the following flow:
yaml
id: get_employees
namespace: company.team
tasks:
  - id: download
    type: io.kestra.plugin.core.http.Download
    uri: https://huggingface.co/datasets/kestra/datasets/raw/main/ion/employees.ion
On executing this flow, the file will be downloaded onto the Kestra internal storage. When you go to the Outputs tab for this execution, the uri attribute of the download task contains the file location on Kestra's internal storage, and would have a Download and a Preview button.
On clicking the Preview button, you can preview the contents of the file in a tabular format, making it extremely easy to check the contents of the file without downloading it.
Using Debug Outputs
You can evaluate the output further using the Debug Outputs functionality in the Outputs tab. Consider the following flow:
yaml
id: json_values
namespace: company.team
tasks:
- id: sample_json
  type: io.kestra.plugin.core.debug.Return
  format: '{""data"": [1, 2, 3]}'
When you run this flow, the Outputs tab will contain the output for the sample_json task, as shown below:
You can select the task from the drop-down menu. Here, we will select ""sample_json"" and select Debug Outputs:
You can now use pebble expressions and evaluate different expressions based on the output data to analyse it further.
Note: This was previously called Render expression
Was this page helpful?
Yes
No
Workflow Components
Inputs
Workflow Components
Triggers""""""",2699,11845,kestra
https://kestra.io/docs/workflow-components/triggers,"""""""DocsWorkflow ComponentsTriggers
Triggers
Table of Contents
Trigger types
Trigger Common Properties
Trigger Variables
Conditions
Unlocking, enabling and disabling triggers
Disabling a trigger in the source code
Disabling a trigger from the UI
Toggle or unlock triggers from the Administation page
Troubleshooting a trigger from the UI
The stopAfter property
Pause the schedule trigger after a failed execution
Disable the HTTP trigger after the first successful execution
Locked triggers
Setting inputs inside of triggers
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Trigger is a mechanism that automates the execution of a flow.
Triggers can be scheduled or event-based providing lots of flexibility in how you can automate the execution of your workflows.
Trigger types
Kestra supports both scheduled and external events.
Kestra provides five types of triggers:
Schedule trigger allows you to execute your flow on a regular cadence e.g. using a CRON expression and custom scheduling conditions
Flow trigger allows you to execute your flow when another flow finishes its execution (based on a configurable list of states)
Webhook trigger allows you to execute your flow based on an HTTP request emitted by a webhook.
Polling trigger allows you to execute your flow by polling external systems for the presence of data.
Realtime trigger allows you to execute your flow when events happen with millisecond latency.
Many other triggers are available from the plugins, such as triggers based on file detection events, e.g. the S3 trigger, or a new message arrival in a message queue, such as the SQS or Kafka trigger.
Trigger Common Properties
Following trigger properties can be set.
Field Description
id The flow identifier, must be unique inside a flow.
type The Java FQDN of the trigger.
description The description of the trigger.
disabled Set it to true to disable execution of the trigger.
workerGroup.key To execute this trigger on a specific Worker Group (EE)
Trigger Variables
Triggers allow you to access trigger metadata through expressions e.g. {{ trigger.date }} to access the current date of the Schedule trigger, {{ trigger.uri }} to access the file or message from any file detection or message arrival event, as well as {{ trigger.rows }} for all Query triggers e.g. the PostgreSQL Query trigger.
This example will log the date when the trigger executes the flow:
yaml
id: variables
namespace: company.team
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: ""Hello World on {{ trigger.date }}! üöÄ""
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""@hourly""
Note that the above-mentioned templated variables are only available when the execution is created automatically by the trigger. You'll get an error if you try to run a flow containing such variables manually.
Also, note that you don't need an extra task to consume the file or message from the event. Kestra downloads those automatically to the internal storage and makes those available in your flow using {{ trigger.uri }} variable. Therefore, you don't need any additional task to e.g. consume a message from the SQS queue or to download a file from S3 when using those event triggers. The trigger already consumes and downloads those, making them directly available for further processing. Check the documentation of a specific trigger and Blueprints with the Trigger tag for more details and examples.
Triggers restrict parallel execution for a given trigger ID to one active run. For instance, if an Execution from a flow with a Schedule trigger with ID hourly is still in a Running state, another one will not be started. However, you can still trigger the same flow manually (from the UI or API), and the scheduled Executions will not be affected.
yaml
id: hourlyFlow
namespace: company.team
tasks:
  - id: important-task
    type: io.kestra.plugin.core.log.Log
    message: If this runs for longer than 1h, next Executions will be queued rather than being started immediately
triggers:
  - id: hourly
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""@hourly""
Conditions
Conditions are specific criteria or events that determine when a specific triggers should create a new execution. Usually, they limit the scope of a trigger to a specific set of cases.
For example, you can restrict a Flow trigger to a specific namespace prefix or execution status, and you can restrict a Schedule trigger to a specific time of the week or month.
You can pass a list of conditions; in this case, all the conditions must match to enable the current action.
Available conditions include:
HasRetryAttemptCondition
MultipleCondition
NotCondition
OrCondition
ExecutionFlowCondition
ExecutionNamespaceCondition
ExecutionLabelsCondition
ExecutionStatusCondition
ExecutionOutputsCondition
ExpressionCondition
You can also find datetime related conditions on the Schedule trigger page.
Unlocking, enabling and disabling triggers
Disabling a trigger in the source code
If you want to temporarily disable a trigger, you could do so by setting the disabled property to true, as you can see in the example below:
yaml
id: hello_world
namespace: company.team
tasks:
  - id: sleep
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - sleep 30
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/1 * * * *""
    disabled: true
However, this approach requires changing the source code. A better approach is to use the Enabled toggle from the UI.
Disabling a trigger from the UI
You can disable or re-enable a trigger from the UI. Here is how you can do it:
Go to the Flows page and click on the flow you want to disable the trigger for.
Go to the Triggers tab and click on the Enabled toggle next to the trigger you want to disable. You can re-enable it by clicking the toggle again.
If your trigger is locked due to an execution in progress, you can unlock it by clicking the Unlock trigger button.
The Unlock trigger functionality is useful for troubleshooting, e.g. if a process is stuck due to infrastructure issues. Note that manually unlocking triggers may result in multiple concurrent (potentially duplicated) executions ‚Äî use it with caution.
Toggle or unlock triggers from the Administation page
You can also disable, re-enable, or unlock triggers from the Administration page. Here is how you can do it:
Troubleshooting a trigger from the UI
Let's say you misconfigured a trigger, and as a result, no Executions are created.
The example flow below illustrates this scenario. Note how the sqs_trigger trigger is misconfigured with invalid AWS credentials:
yaml
id: bad_trigger_example
namespace: company.team
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: Hello World!
triggers:
  - id: sqs_trigger
    type: io.kestra.plugin.aws.sqs.Trigger
    accessKeyId: ""nonExistingKey""
    secretKeyId: ""nonExistingSecret""
    region: ""us-east-1""
    queueUrl: ""https://sqs.us-east-1.amazonaws.com/123456789/testQueue""
    maxRecords: 10
When you add that flow to Kestra, you'll see that no Executions are created. To troubleshoot this, you can go to the Triggers tab on the Flow's page and expand the logs of the trigger that is causing the issue. You'll see a detailed error message that will help you identify the problem:
The stopAfter property
Kestra 0.15 introduced a generic stopAfter property which is a list of states that will disable the trigger after the flow execution has reached one of the states in the list.
This property is meant to be used primarily for a Schedule trigger and triggers that poll for conditions including the HTTP, JDBC, or File Detection triggers. However, you can use it with all triggers.
Note that we don't handle any automatic trigger reenabling logic. After a trigger has been disabled due to the stopAfter state condition, you can take some action based on it and manually reenable the trigger.
Pause the schedule trigger after a failed execution
The stopAfter property can be used to pause a schedule trigger after a failed execution. Here is an example of how to use it:
yaml
id: business_critical_flow
namespace: company.team
tasks:
 - id: important_task
   type: io.kestra.plugin.core.log.Log
   message: if this fails, we want to stop the flow from running until we fix it
triggers:
 - id: stopAfter
   type: io.kestra.plugin.core.trigger.Schedule
   cron: ""0 9 * * *""
   stopAfter:
     - FAILED
The above flow will be triggered every day at 9:00 AM, but if it fails, the schedule will be paused so that you can manually reenable the trigger once the issue is fixed. This is useful for business-critical flows that should not continue running the next scheduled executions if a previous execution has failed.
Disable the HTTP trigger after the first successful execution
The example below shows how to use the stopAfter property with the HTTP trigger condition. The use case is to poll an API endpoint and send a Slack alert if the price is below $110. If the condition is met, the trigger will be disabled so that you don't get alerted every 30 seconds about the same condition.
yaml
id: http
namespace: company.team
tasks:
  - id: slack
    type: io.kestra.plugin.notifications.slack.SlackIncomingWebhook
    url: ""{{ secret('SLACK_WEBHOOK') }}""
    payload: |
      {
        ""channel"": ""#price-alerts"",
        ""text"": ""The price is now: {{ json(trigger.body).price }}""
      }
triggers:
  - id: http
    type: io.kestra.plugin.fs.http.Trigger
    uri: https://fakestoreapi.com/products/1
    responseCondition: ""{{ json(response.body).price <= 110 }}""
    interval: PT30S
    stopAfter:
      - SUCCESS
Let's break down the above example:
The HTTP trigger will poll the API endpoint every 30 seconds to check if the price of a product is below $110.
If the condition is met, the Execution will be created
Within that execution, the slack task will send a Slack message to the #price-alerts channel to notify about the price change
After that execution finishes successfully, the stopAfter property condition is met ‚Äî it will disable the trigger ensuring that you don't get alerted every 30 seconds about the same condition.
Locked triggers
Flow, Schedule and Polling triggers have locks to avoid concurrent trigger evaluation and concurrent execution of a flow for a trigger.
To see a list of triggers and inspect their current status, go to the Administration -> Triggers section in the Kestra UI. From here, you can unlock a trigger if it is locked. Keep in mind that there is a risk or concurrent trigger evaluation or flow execution for this trigger if you unlock it manually.
Setting inputs inside of triggers
You can easily pass inputs to triggers by using the inputs property and passing them as a key-value pair.
In this example, the user input is set to ""John Smith"" inside of the schedule trigger:
yaml
id: myflow
namespace: company.team
inputs:
  - id: user
    type: STRING
    defaults: Rick Astley
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: ""Hello {{ inputs.user }}! üöÄ""
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/1 * * * *""
    inputs:
      user: John Smith
Was this page helpful?
Yes
No
Workflow Components
Outputs
Triggers
Schedule Trigger""""""",2497,11383,kestra
https://kestra.io/docs/workflow-components/triggers/schedule-trigger,"""""""DocsWorkflow ComponentsTriggersSchedule Trigger
Schedule Trigger
Table of Contents
Example: A schedule that runs every quarter of an hour.
Schedule Conditions
Recover Missed Schedules
Automatically
Using Backfill
Setting Inputs inside of the Schedule trigger
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Schedule flows with cron expressions.
The Schedule trigger generates new executions on a regular cadence based on a Cron expression or custom scheduling conditions.
yaml
type: ""io.kestra.plugin.core.trigger.Schedule""
Kestra is able to trigger flows based on a Schedule (aka the time). If you need to wait for another system to be ready and cannot use any event mechanism, you can schedule one or more time the current flow.
Kestra will optionally handle schedule backfills if any executions are missed.
Check the Schedule task documentation for the list of the task properties and outputs.
Example: A schedule that runs every quarter of an hour.
yaml
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/15 * * * *""
A schedule that runs only the first monday of every month at 11 AM.
yaml
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 11 * * 1""
    conditions:
      - type: io.kestra.plugin.core.condition.DayWeekInMonthCondition
        date: ""{{ trigger.date }}""
        dayOfWeek: ""MONDAY""
        dayInMonth: ""FIRST""
A schedule that runs daily at midnight US Eastern time.
yaml
triggers:
  - id: daily
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""@daily""
    timezone: America/New_York
Schedules cannot overlap. This means that we cannot have any concurrent schedules. If the previous schedule is not ended when the next one must start, the scheduler will wait until the end of the previous one. The same applies during backfills.
Most of the time, schedule execution will depend on the trigger.date (looking at files for today, SQL query with the schedule date in the where clause, ...). This works well but prevents you from executing your flow manually (since these variables are only available during the schedule).
You can use this expression to make your manual execution work: {{ trigger.date ?? execution.startDate | date(""yyyy-MM-dd"") }}. It will use the current date if there is no schedule date making it possible to start the flow manually.
Schedule Conditions
When the cron is not sufficient to determine the date you want to schedule your flow, you can use conditions to add additional conditions, (for example, only the first day of the month, only the weekend, ...).
You must use the {{ trigger.date }} expression on the property date of the current schedule.
This condition will be evaluated and {{ trigger.previous }} and {{ trigger.next }} will reflect the date with the conditions applied.
The list of core conditions that can be used are:
DateTimeBetweenCondition
DayWeekCondition
DayWeekInMonthCondition
NotCondition
OrCondition
WeekendCondition
PublicHolidayCondition
TimeBetweenCondition
Here's an example using the DayWeekCondition:
yaml
id: conditions
namespace: company.team
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: This will execute only on Thursday!
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""@hourly""
    conditions:
      - type: io.kestra.plugin.core.condition.DayWeekCondition
        dayOfWeek: ""THURSDAY""
Recover Missed Schedules
Automatically
If a schedule is missed, Kestra will automatically recover it by default. This means that if the Kestra server is down, the missed schedules will be executed as soon as the server is back up. However, this behavior is not always desirable, e.g. during a planned maintenance window. In Kestra 0.15 and higher, this behavior can be disabled by setting the recoverMissedSchedules configuration to NONE.
Kestra 0.15 introduced a new configuration allowing you to choose whether you want to recover missed schedules or not:
yaml
kestra:
  plugins:
    configurations:
      - type: io.kestra.plugin.core.trigger.Schedule
        values:
          # available options: LAST | NONE | ALL -- default: ALL
          recoverMissedSchedules: NONE
The recoverMissedSchedules configuration can be set to ALL, NONE or LAST:
ALL: Kestra will recover all missed schedules. This is the default value.
NONE: Kestra will not recover any missed schedules.
LAST: Kestra will recover only the last missed schedule for each flow.
Note that this is a global configuration that will apply to all flows, unless other behavior is explicitly defined within the flow definition:
yaml
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/15 * * * *""
    recoverMissedSchedules: NONE
In this example, the recoverMissedSchedules is set to NONE, which means that Kestra will not recover any missed schedules for this specific flow regardless of the global configuration.
Using Backfill
Backfills are replays of missed schedule intervals between a defined start and end date.
To backfill the missed executions, go to the Triggers tab on the Flow's detail page and click on the Backfill executions button.
For more information on Backfill, check out the dedicated documentation.
Disabling the trigger
If you're unsure what how you want to proceed and need to time to decide, you can disable the trigger by either adding the disabled: true property to your YAML or by toggling on the Triggers page.
This is useful if you're figuring out what to do before the next schedule is due to run.
For more information on Disabled, check out the dedicated documentation.
Setting Inputs inside of the Schedule trigger
You can easily pass inputs to the Schedule Trigger by using the inputs property and passing them as a key-value pair.
In this example, the user input is set to ""John Smith"" inside of the schedule trigger:
yaml
id: myflow
namespace: company.team
inputs:
  - id: user
    type: STRING
    defaults: Rick Astley
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: ""Hello {{ inputs.user }}! üöÄ""
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/1 * * * *""
    inputs:
      user: John Smith
Was this page helpful?
Yes
No
Workflow Components
Triggers
Triggers
Flow Trigger""""""",1417,6323,kestra
https://kestra.io/docs/workflow-components/triggers/flow-trigger,"""""""DocsWorkflow ComponentsTriggersFlow Trigger
Flow Trigger
Table of Contents
Conditions
Example
Example: Alerting
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Trigger flows from another flow execution.
Flow triggers allows you to trigger a flow after another flow execution, enabling event-driven patterns.
yaml
type: ""io.kestra.plugin.core.trigger.Flow""
Kestra is able to trigger one flow after another one. This allows the chaining of flows without the need to update the base flows. With this capacity, you can break responsibility between different flows to different teams.
Check the Flow trigger documentation for the list of all properties.
Conditions
You can provide conditions to determine when your Flow should be executed. Along with the core trigger conditions, you can use the following:
ExecutionFlowCondition
ExecutionNamespaceCondition
ExecutionLabelsCondition
ExecutionStatusCondition
ExecutionOutputsCondition
ExpressionCondition
Example
This flow will be triggered after each successful execution of the flow io.kestra.tests.trigger-flow and forward the uri output of the my-task task.
yaml
id: trigger_flow_listener
namespace: company.team
inputs:
  - id: fromParent
    type: STRING
tasks:
  - id: onlyNoInput
    type: io.kestra.plugin.core.debug.Return
    format: ""v1: {{ trigger.executionId }}""
triggers:
  - id: listenFlow
    type: io.kestra.plugin.core.trigger.Flow
    inputs:
      fromParent: '{{ outputs.myTask.uri }}'
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionFlowCondition
        namespace: company.team
        flowId: trigger_flow
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - SUCCESS
Parent flow:
yaml
id: trigger_flow
namespace: company.team
tasks:
  - id: myTask
    type: io.kestra.plugin.core.http.Download
    uri: https://dummyjson.com/products
This flow will be triggered after the successful execution of both flows flow-a and flow-b during the current day. When the conditions are met, the counter is reset and can be re-triggered during the same day. See MultipleCondition for more details
yaml
id: trigger-multiplecondition-listener
namespace: company.team
tasks:
  - id: onlyListener
    type: io.kestra.plugin.core.debug.Return
    format: ""let's go ""
triggers:
  - id: multipleListenFlow
    type: io.kestra.plugin.core.trigger.Flow
    conditions:
      - id: multiple
        type: io.kestra.plugin.core.condition.MultipleCondition
        window: P1D
        windowAdvance: P0D
        conditions:
          flow-a:
            type: io.kestra.plugin.core.condition.ExecutionFlowCondition
            namespace: company.team
            flowId: trigger-multiplecondition-flow-a
          flow-b:
            type: io.kestra.plugin.core.condition.ExecutionFlowCondition
            namespace: company.team
            flowId: trigger-multiplecondition-flow-b
Simply execute the two flows below to trigger trigger-multiplecondition-listener:
yaml
id: trigger-multiplecondition-flow-a
namespace: company.team
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: Trigger A
yaml
id: trigger-multiplecondition-flow-b
namespace: company.team
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: Trigger B
Example: Alerting
In this example, the Flow Trigger conditions are set to execute the flow when any workflow execution has a warning or failed status. We can configure this flow to send a notification to Slack (or any other platform) with information around the failure. Using this pattern, you can manage alerts on failure all in one place.
yaml
id: failure_alert_slack
namespace: system
tasks:
  - id: send_alert
    type: io.kestra.plugin.notifications.slack.SlackExecution
    url: ""{{ secret('SLACK_WEBHOOK') }}""
    channel: ""#general""
    executionId: ""{{ trigger.executionId }}""
triggers:
  - id: on_failure
    type: io.kestra.plugin.core.trigger.Flow
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - FAILED
          - WARNING
Check out the Blueprint here.
Was this page helpful?
Yes
No
Triggers
Schedule Trigger
Triggers
Webhook Trigger""""""",939,4210,kestra
https://kestra.io/docs/workflow-components/triggers/webhook-trigger,"""""""DocsWorkflow ComponentsTriggersWebhook Trigger
Webhook Trigger
Table of Contents
Example
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Trigger flows based on web-based events.
Webhook triggers generates a unique URL that you can use to automatically create new executions based on events in another application such as GitHub or Amazon EventBridge.
In order to use that URL, you have to add a secret key that will secure your webhook URL.
yaml
type: ""io.kestra.plugin.core.trigger.Webhook""
A Webhook trigger allows triggering a flow from a webhook URL. At trigger creation a key must be set that will be used on the URL that triggers the flow: /api/v1/executions/webhook/{namespace}/{flowId}/{key}. We advise to use a non-easy to find or remember key like a generated sequence of characters. Kestra accepts GET, POST and PUT requests on this URL The whole request body and headers will be available as variables.
Example
yaml
id: trigger
namespace: company.team
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: ""Hello World! üöÄ""
triggers:
  - id: webhook
    type: io.kestra.plugin.core.trigger.Webhook
    key: 4wjtkzwVGBM9yKnjm3yv8r
After the trigger is created, the key must be explicitly set in the webhook URL. You can execute the flow using the following URL:
bash
https://{kestra_domain}/api/v1/executions/webhook/{namespace}/{flowId}/4wjtkzwVGBM9yKnjm3yv8r
Make sure to replace kestra_domain, namespace and flowId.
Check the Webhook task documentation for the list of the task properties and outputs.
Was this page helpful?
Yes
No
Triggers
Flow Trigger
Triggers
Polling Trigger""""""",406,1638,kestra
https://kestra.io/docs/workflow-components/triggers/polling-trigger,"""""""DocsWorkflow ComponentsTriggersPolling Trigger
Polling Trigger
Table of Contents
Example
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Trigger flows by polling external systems.
Polling triggers are a type of triggers that are provided by our plugins. They allow polling an external system for the presence of data. In case data is ready to be processed, a flow execution is started.
Kestra provides polling triggers for a wide variety of external systems, for example: databases, message brokers, ftp, ...
Polling triggers will poll the external system at a fixed interval defined by the interval property, the triggered flow will have the outputs of the polling trigger available on the trigger variable.
Example
For example, the following flow will be triggered when rows are available on the my_table PostgreSQL table, and when triggered, it will delete the rows (to avoid processing them again on the next poll) and log them.
yaml
id: jdbc-trigger
namespace: company.team
inputs:
  - id: db_url
    type: STRING
tasks:
- id: update
  type: io.kestra.plugin.jdbc.postgresql.Query
  url: ""{{ inputs.db_url }}""
  sql: DELETE * FROM my_table
- id: log
  type: io.kestra.plugin.core.log.Log
  message: ""{{ trigger.rows }}""
triggers:
  - id: watch
    type: io.kestra.plugin.jdbc.postgresql.Trigger
    url: myurl
    interval: ""PT5M""
    sql: ""SELECT * FROM my_table""
Polling triggers can be evaluated on a specific Worker Group (EE), thanks to the workerGroup.key property.
Was this page helpful?
Yes
No
Triggers
Webhook Trigger
Triggers
Realtime Trigger""""""",369,1584,kestra
https://kestra.io/docs/workflow-components/triggers/realtime-trigger,"""""""DocsWorkflow ComponentsTriggersRealtime Trigger
Realtime Trigger
Table of Contents
What are Realtime Triggers
How Realtime Triggers Work
Use Cases
When to use Triggers vs. Realtime Triggers
How to Use Realtime Triggers
Comparison with Realtime Data Processing Engines
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
>= 0.17.0
React to events as they happen with millisecond latency.
Triggers in Kestra can listen to external events and start a workflow execution when the event occurs. Most of these triggers poll external systems for new events at regular intervals e.g. every second. This works well for data processing use cases. However, business-critical workflows often require reacting to events as they happen with millisecond latency and this is where Realtime Triggers come into play.
What are Realtime Triggers
Realtime triggers listen to events in real time and start a workflow execution as soon as:
a new message is published to a Kafka topic
a new message is published to a Pulsar topic
a new message is published to an AMQP queue
a new message is published to an MQTT queue
a new message is published to an AWS SQS queue
a new message is published to Google Pub/Sub
a new message is published to Azure Event Hubs
a new message is published to a NATS subject
a new item is added to a Redis list
a new row is added, modified or deleted in Postgres, MySQL, or SQL Server.
How Realtime Triggers Work
As soon as you add a Realtime Trigger to your workflow, Kestra starts an always-on thread that listens to the external system for new events. When a new event occurs, Kestra starts a workflow execution to process the event.
Use Cases
Using Realtime Triggers, you can orchestrate business-critical processes and microservices in real time. This covers scenarios such as:
fraud and anomaly detection,
order processing,
realtime predictions or recommendations,
reacting to stock price changes,
shipping and delivery notifications,
...and many more use cases that require reacting to events as they happen.
In addition, Realtime Triggers can be used for data orchestration, especially for Change Data Capture use cases. The Debezium Postgres RealtimeTrigger plugin can listen to changes in a database table and start a workflow execution as soon as a new row is inserted, updated, or deleted.
When to use Triggers vs. Realtime Triggers
The table below compares Triggers with Realtime Triggers to help you choose the right trigger type for your use case:
Criteria Trigger Realtime Trigger
Implementation Micro-batch Realtime
Event Processing Batch-process all events received until the poll interval has elapsed Process each event immediately as it happens
Latency Second(s) or minute(s) Millisecond(s)
Execution Model Each execution processes one or many events Each execution processes exactly one event
Data Handling Store all received events in a file Store each event in a raw format
Output format URI of a file in internal storage Raw data of the event payload and related metadata
Application Data applications processing data in batch Business-critical operations reacting to events in real time
Use cases Data orchestration for analytics and building data products Process and microservice orchestration (real time updates, anomaly detection, order processing)
How to Use Realtime Triggers
To use Realtime Triggers, simply choose the RealtimeTrigger as a trigger type of your desired service. Here, we use the RealtimeTrigger to listen to new messages in an AWS SQS queue:
yaml
id: sqs
namespace: company.team
tasks:
  - id: log
    type: io.kestra.plugin.core.log.Log
    message: ""{{ trigger }}""
triggers:
  - id: realtime_trigger
    type: io.kestra.plugin.aws.sqs.RealtimeTrigger
    region: eu-north-1
    accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID')}}""
    secretKeyId: ""{{ secret('AWS_SECRET_ACCESS_KEY') }}""
    queueUrl: https://sqs.eu-north-1.amazonaws.com/123456789/MyQueue
Comparison with Realtime Data Processing Engines
It's important to note that Kestra's Realtime Triggers are not intended to be used as a replacement for real-time data processing engines such as Apache Flink, Apache Beam or Google Dataflow.
Those data processing engines excel at stateful streaming applications and complex SQL transformations over real-time data streams.
In contrast, Kestra's Realtime Triggers are stateless, meaning they trigger one workflow execution per event. They are designed primarily to react to events in real time to orchestrate business-critical processes.
How-to Guide on Realtime Triggers
Was this page helpful?
Yes
No
Triggers
Polling Trigger
Workflow Components
Labels""""""",1005,4644,kestra
https://kestra.io/docs/workflow-components/labels,"""""""DocsWorkflow ComponentsLabels
Labels
Table of Contents
The purpose of labels
Benefits of labels
Execution labels propagated from flow labels
Set execution labels when executing a flow from the UI
Set labels based on flow inputs and task outputs
Overriding flow labels at runtime
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Labels are key-value pairs used to organize flows and executions.
Labels are key-value pairs that you can use to organize (and search for) your flows and executions based on your project, maintainers, or any other criteria.
The purpose of labels
Labels can be used to organize and filter flows and their executions. You can add labels to your flows to sort their executions across multiple dimensions.
Here is a simple example of a flow with labels:
yaml
id: flow_with_labels
namespace: company.team
labels:
  song: never_gonna_give_you_up
  artist: rick_astley
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: hello from a flow with labels
Benefits of labels
Labels provide a simple and effective way to organize and filter flows and their executions. Here are some of the benefits of using labels:
Observability: labels set during execution provide help in monitoring and troubleshooting.
Filtering: labels make it easier to find specific executions; you can use it to track ML experiments, track responses from external APIs, or label executions based on runtime-specific flow inputs.
Organization: labels help organize and manage workflow executions at scale, especially in complex environments and large-scale deployments. You can create custom dashboards based on labels to monitor specific executions, e.g. http://localhost:8080/ui/executions?labels=team:finance. You can use that pattern to build custom dashboards for specific teams, projects, flow maintainers or environments.
Execution labels propagated from flow labels
When you execute a flow with labels, the labels will be propagated to the created executions:
Set execution labels when executing a flow from the UI
When executing flows manually from the UI, you can override and define new labels at the flow execution start by expanding the Advanced configuration section:
Since Kestra 0.15.0, you can also set labels from the UI after the execution has completed. This feature is useful for collaboration and troubleshooting in the team. For example, you can add a label to a failed execution to indicate that it has been acknowledged and someone is working on a resolution, or that it has been resolved.
To set labels from the UI, go to the Overview tab of an Execution and click on the ""Set labels"" button. You can add multiple labels at once.
You can even set labels for multiple executions at once from the UI. This feature is helpful for bulk operations, such as acknowledging multiple failed executions at once after an outage.
Set labels based on flow inputs and task outputs
In Kestra 0.14.0, we introduced the ability to set execution labels from a dedicated Labels task. This task provides a dynamic way to label your flows, helping with observability, debugging, and monitoring of failures.
By using this task, you can set custom execution labels based on flow inputs, task outputs, or any other dynamic data within the workflow. There are two ways to set labels in this task:
Using a Map (Key-Value Pairs): ideal when the key is static and the value is dynamic. The key is the label name, and the value is a dynamic label value that might be derived from the flow inputs or task outputs. In the example below, the task update_labels overrides the default label song with the output of the get task, and adds a new label called artist.
yaml
id: labels_override
namespace: company.team
labels:
  song: never_gonna_give_you_up
tasks:
  - id: get
    type: io.kestra.plugin.core.debug.Return
    format: never_gonna_stop
  - id: update_labels
    type: io.kestra.plugin.core.execution.Labels
    labels:
      song: ""{{ outputs.get.value }}""
      artist: rick_astley # new label
Using a List of Key-Value Pairs: particularly useful if both the key and the value are dynamic properties.
yaml
id: labels
namespace: company.team
inputs:
  - id: user
    type: STRING
    defaults: Rick Astley
  - id: url
    type: STRING
    defaults: song_url
tasks:
  - id: update_labels_with_map
    type: io.kestra.plugin.core.execution.Labels
    labels:
      customerId: ""{{ inputs.user }}""
  - id: get
    type: io.kestra.plugin.core.debug.Return
    format: https://t.ly/Vemr0
  - id: update_labels_with_list
    type: io.kestra.plugin.core.execution.Labels
    labels:
      - key: ""{{ inputs.url }}""
        value: ""{{ outputs.get.value }}""
Overriding flow labels at runtime
You can set default labels at the flow level and override them at runtime. This approach is useful for overriding label values dynamically during execution based on the results of specific tasks.
The example below shows how to override the default label song with the output of the get task:
yaml
id: flow_with_labels
namespace: company.team
labels:
  song: never_gonna_give_you_up
  artist: rick-astley
  genre: pop
tasks:
  - id: get
    type: io.kestra.plugin.core.debug.Return
    format: never_gonna_stop
  - id: update-list
    type: io.kestra.plugin.core.execution.Labels
    labels:
      song: ""{{ outputs.get.value }}""
In this example, the default label song is overridden by the output of the get task.
Was this page helpful?
Yes
No
Triggers
Realtime Trigger
Workflow Components
Plugin Defaults""""""",1223,5528,kestra
https://kestra.io/docs/workflow-components/plugin-defaults,"""""""DocsWorkflow ComponentsPlugin Defaults
Plugin Defaults
Table of Contents
Plugin defaults on a flow-level
forced attribute in pluginDefaults
Plugin defaults in a global configuration
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Plugin defaults are a list of default values applied to each task of a certain type within your flow(s).
Plugin defaults are like default function arguments ‚Äî they help avoid repetition when a given task or plugin is often called with the same values.
Plugin defaults on a flow-level
You can add plugin defaults to avoid repeating task properties on multiple occurrences of the same task in a pluginDefaults properties. For example:
yaml
id: api_python_sql
namespace: company.team
tasks:
  - id: api
    type: io.kestra.plugin.core.http.Request
    uri: https://dummyjson.com/products
  - id: hello
    type: io.kestra.plugin.scripts.python.Script
    script: |
      print(""Hello World!"")
  - id: python
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - pip install polars
    warningOnStdErr: false
    outputFiles:
      - ""products.csv""
    script: |
      import polars as pl
      data = {{outputs.api.body | jq('.products') | first}}
      df = pl.from_dicts(data)
      df.glimpse()
      df.select([""brand"", ""price""]).write_csv(""products.csv"")
  - id: sql_query
    type: io.kestra.plugin.jdbc.duckdb.Query
    inputFiles:
      in.csv: ""{{ outputs.python.outputFiles['products.csv'] }}""
    sql: |
      SELECT brand, round(avg(price), 2) as avg_price
      FROM read_csv_auto('{{workingDir}}/in.csv', header=True)
      GROUP BY brand
      ORDER BY avg_price DESC;
    store: true
pluginDefaults:
  - type: io.kestra.plugin.scripts.python.Script
    values:
      taskRunner:
        type: io.kestra.plugin.scripts.runner.docker.Docker
        pullPolicy: ALWAYS # set it to NEVER to use a local image
      containerImage: python:slim
Here, we avoid repeating Docker and Python configurations in each task by directly setting those within the pluginDefaults property. This approach helps to streamline the configuration process and reduce the chances of errors caused by inconsistent settings across different tasks.
Note that when you move some required task attributes into the pluginDefaults property, the code editor within the UI will complain that the required task argument is missing. The editor shows this message because pluginDefaults are resolved at runtime and the editor is not aware of those default attributes until you run your flow. As long as pluginDefaults contains the relevant arguments, you can save the flow and ignore the warning displayed in the editor.
forced attribute in pluginDefaults
In the pluginDefaults, if you set forced: true, the plugin default will take precedence over properties defined in the task. By default, the value of the forced attribute is false.
Plugin defaults in a global configuration
You can also set plugin defaults in your global Kestra configuration. This is useful when you want to apply the same defaults across multiple flows. Let's say that you want to centrally manage the default values for the io.kestra.plugin.aws plugin to reuse the same credentials and region across all your flows. You can add the following to your Kestra configuration:
yaml
kestra:
  plugins:
    defaults:
      - type: io.kestra.plugin.aws
        values:
          accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID') }}""
          secretKeyId: ""{{ secret('AWS_SECRET_ACCESS_KEY') }}""
          region: ""us-east-1""
If you want to set defaults only for a specific task, you can do that too:
yaml
kestra:
  plugins:
    defaults:
      - type: io.kestra.plugin.aws.s3.Upload
        values:
          accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID') }}""
          secretKeyId: ""{{ secret('AWS_SECRET_ACCESS_KEY') }}""
          region: ""us-east-1""
If you are using the Enterprise Edition or Kestra Cloud, you can configure plugin defaults from the UI. Go to the Namespace to which you want to apply that configuration, and within the Plugin Defaults tab, paste the following code:
yaml
- type: io.kestra.plugin.aws
  values:
    accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID') }}""
    secretKeyId: ""{{ secret('AWS_SECRET_ACCESS_KEY') }}""
    region: ""us-east-1""
Was this page helpful?
Yes
No
Workflow Components
Labels
Workflow Components
Subflows""""""",962,4366,kestra
https://kestra.io/docs/workflow-components/subflows,"""""""DocsWorkflow ComponentsSubflows
Subflows
Table of Contents
Why use a subflow?
How to declare a subflow
Practical Example
Subflow properties
Passing data between parent and child flows
Accessing Outputs from a subflow execution
Passing inputs to a subflow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Subflows allow you to build modular and reusable workflow components.
They work similarly to calling functions. A subflow execution is created when you call a flow from another flow.
Why use a subflow?
Subflows allow you to build modular and reusable components that you can use across multiple flows. For example, you might have a subflow dedicated to alerting errors to Slack and email. By using a Subflow, you can reuse these two tasks together for all flows that you want to send error notifications, instead of having to copy the individual tasks for every flow.
How to declare a subflow
To call a flow from another flow, use the io.kestra.plugin.core.flow.Subflow task and in that task, specify the flowId and namespace of the subflow that you want to execute. Optionally, you can also specify custom input values, in the same way as you would pass arguments in a function call.
The optional properties wait and transmitFailed control the execution behavior. By default, if wait is not set or set to false, the parent flow continues execution without waiting for the subflow's completion. The transmitFailed property determines whether a failure in the subflow execution should cause the parent flow to fail.
Practical Example
Consider a subflow that encapsulates critical business logic. This subflow can be called from various flows, allowing for code reuse and isolated testing.
Here is a simple example of a subflow:
yaml
id: critical_service
namespace: company.team
tasks:
  - id: return_data
    type: io.kestra.plugin.jdbc.duckdb.Query
    sql: |
      INSTALL httpfs;
      LOAD httpfs;
      SELECT sum(total) as total, avg(quantity) as avg_quantity
      FROM read_csv_auto('https://huggingface.co/datasets/kestra/datasets/raw/main/csv/orders.csv', header=True);
    store: true
outputs:
  - id: some_output
    type: STRING
    value: ""{{ outputs.return_data.uri }}""
In this example, return_data outputs uri of the query output. That URI is a reference to the Internal Storage location of the stored file. This output can be used in the parent flow to perform further processing.
yaml
id: parent_service
namespace: company.team
tasks:
  - id: subflow_call
    type: io.kestra.plugin.core.flow.Subflow
    namespace: company.team
    flowId: critical_service
    wait: true
    transmitFailed: true
  - id: log_subflow_output
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - cat ""{{ outputs.subflow_call.outputs.some_output }}""
The outputs map task IDs to their outputs. In this case, we are accessing the outputs.some_output output of the subflow_call task.
Subflow properties
Below is a full list of all properties of the io.kestra.plugin.core.flow.Subflow task. Don't worry, you don't need to memorize them all, you can always open the task documentation to see the full list of Subflow task properties:
Field Description
flowId The subflow's identifier.
namespace The namespace where the subflow is located.
inheritLabels Determines if the subflow inherits labels from the parent (default: false).
inputs Inputs passed to the subflow.
labels Labels assigned to the subflow.
outputs (deprecated) Allows passing outputs from the subflow execution to the parent flow.
revision The subflow revision to execute (defaults to the latest).
wait If true, parent flow waits for subflow completion (default: false).
transmitFailed If true, parent flow fails on subflow failure (requires wait to be true).
Passing data between parent and child flows
Flows can emit outputs that can be accessed by the parent flow. Using the io.kestra.plugin.core.flow.Subflow task you can call any flow as a subflow and access its outputs in downstream tasks. For more details and examples, check the Outputs page.
Accessing Outputs from a subflow execution
Outputs include the execution ID, extracted outputs, and the final state (if wait is true).
To sum up, subflows improve maintainability of complex workflows. They allow you to build modular and reusable workflow components and share them across multiple namespaces, projects, and teams.
Here's an example of a subflow with outputs explictly defined.
yaml
id: flow_outputs
namespace: company.team
tasks:
  - id: mytask
    type: io.kestra.plugin.core.debug.Return
    format: this is a task output used as a final flow output
outputs:
  - id: final
    type: STRING
    value: ""{{ outputs.mytask.value }}""
We can access these outputs from a parent task as seen in the example below:
yaml
id: parent_flow
namespace: company.team
tasks:
  - id: subflow
    type: io.kestra.plugin.core.flow.Subflow
    flowId: flow_outputs
    namespace: company.team
    wait: true
  - id: log_subflow_output
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.subflow.outputs.final }}""
More information available here.
Passing inputs to a subflow
You can pass inputs to a Subflow task. The example below passes 2 inputs to a subflow.
Subflow:
yaml
id: subflow_example
namespace: company.team
inputs:
  - id: http_uri
    type: STRING
tasks:
  - id: download
    type: io.kestra.plugin.core.http.Request
    uri: ""{{ inputs.http_uri }}""
  - id: log
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.download.body }}""
outputs:
  - id: data
    type: STRING
    value: ""{{ outputs.download.body }}""
Parent flow:
yaml
id: inputs_subflow
namespace: company.team
inputs:
  - id: url
    type: STRING
tasks:
  - id: subflow
    type: io.kestra.plugin.core.flow.Subflow
    flowId: subflow_example
    namespace: company.team
    inputs:
      http_uri: ""{{ inputs.url }}""
    wait: true
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.subflow.outputs.data }}""
We can see that the parent flow was able to pass an input down to the subflow.
Nested Inputs
In the example below, the flow extracts JSON data from a REST API and passes it to a subflow as a nested input:
yaml
id: extract_json
namespace: company.team
tasks:
  - id: api
    type: io.kestra.plugin.core.http.Request
    uri: https://dummyjson.com/users
  - id: read_json
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.api.body }}""
  - id: subflow
    type: io.kestra.plugin.core.flow.Subflow
    namespace: company.team
    flowId: subflow
    inputs:
      users.firstName: ""{{ outputs.api.body | jq('.users') | first | first | jq('.firstName') | first }}""
      users.lastName: ""{{ outputs.api.body | jq('.users') | first | first | jq('.lastName') | first }}""
    wait: true
    transmitFailed: true
To provide type validation to extracted JSON fields, you can use nested inputs in the subflow definition:
yaml
id: subflow
namespace: company.team
inputs:
  - id: users.firstName
    type: STRING
    defaults: Rick
  - id: users.lastName
    type: STRING
    defaults: Astley
tasks:
  - id: process_user_data
    type: io.kestra.plugin.core.log.Log
    message: hello {{ inputs.users }}
Note how you can then pass the entire users object to any task in the subflow including all nested fields.
Was this page helpful?
Yes
No
Workflow Components
Plugin Defaults
Workflow Components
Errors""""""",1742,7466,kestra
https://kestra.io/docs/workflow-components/errors,"""""""DocsWorkflow ComponentsErrors
Errors
Table of Contents
errors Component
Global Error Handler
Local Error Handler
allowFailure Property
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Allow your flow to continue to operate despite errors.
There are multiple ways to handle errors in Kestra, to both help you identify them and allow flows to continue to operate despite errors.
errors Component
errors is a list of tasks set at the flow level that will be executed when an error occurs. You can add multiple tasks, and they will be executed sequentially. This is useful for sending alerts when errors occur.
The example below sends a flow-level failure alert via Slack using the SlackIncomingWebhook task defined using the errors property.
yaml
id: errors
namespace: company.team
description: This will always fail
tasks:
  - id: failed_task
    type: io.kestra.plugin.core.execution.Fail
errors:
  - id: alert_on_failure
    type: io.kestra.plugin.notifications.slack.SlackIncomingWebhook
    url: secret('SLACK_WEBHOOK')
    payload: |
      {
        ""channel"": ""#alerts"",
        ""text"": ""Failure alert for flow {{ flow.namespace }}.{{ flow.id }} with ID {{ execution.id }}""
      }
Two kinds of error handlers can be defined:
Global: error handling global to a flow that must be at the root of the flow.
Local: error handling local to a Flowable Task, will handle errors for the flowable task and its children.
Global Error Handler
This flow example has a single task that fails immediately. The global error handler will then be called so the 2nd task will run.
yaml
id: errors
namespace: company.team
tasks:
  - id: failed
    type: io.kestra.plugin.core.execution.Fail
errors:
  - id: 2nd
    type: io.kestra.plugin.core.log.Log
    message: I'm failing {{task.id}}
    level: INFO
Local Error Handler
In this flow example, the error branch will be used only if a child of the task t2 has an error. If the task t1 failed, the error branch would not be used.
This can be useful to restrict error handling for a specific part of the flow and perform specific tasks like resource cleanup.
yaml
id: errors
namespace: company.team
tasks:
  - id: parent-seq
    type: io.kestra.plugin.core.flow.Sequential
    tasks:
      - id: t1
        type: io.kestra.plugin.core.debug.Return
        format: ""{{task.id}} > {{taskrun.startDate}}""
      - id: t2
        type: io.kestra.plugin.core.flow.Sequential
        tasks:
          - id: t2-t1
            type: io.kestra.plugin.core.execution.Fail
        errors:
          - id: error-t1
            type: io.kestra.plugin.core.debug.Return
            format: ""Error Trigger ! {{task.id}}""
allowFailure Property
When you execute a flow and one of its tasks fails, downstream tasks won't be executed. This may not always be desirable, especially for non-critical tasks. You can resolve this by adding the allowFailure property to the task, which will allow downstream tasks to continue despite the error. In this case, the execution will end in a WARNING state.
yaml
id: allow_failure
namespace: company.team
description: This flow will allow a failure of a task (imagine a flaky unit test) and will continue processing the last task, leaving the execution in a `WARNING` state.
tasks:
  - id: first
    type: io.kestra.plugin.core.debug.Return
    format: ""{{task.id}} > {{taskrun.startDate}}""
  - id: allow_failure
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    allowFailure: true
    commands:
      - exit 1
  - id: last
    type: io.kestra.plugin.core.debug.Return
    format: ""{{task.id}} > {{taskrun.startDate}}""
Was this page helpful?
Yes
No
Workflow Components
Subflows
Workflow Components
Retries""""""",878,3752,kestra
https://kestra.io/docs/workflow-components/retries,"""""""DocsWorkflow ComponentsRetries
Retries
Table of Contents
What are retries
Example
Retry options for all retry types
Duration
Retry types
constant
exponential
random
Configuring retries globally
Flow-level retries
Retry vs. Restart vs. Replay
Automatic vs. manual
Restart vs. Replay
Summary: Retries vs. Restart vs. Replay
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Retries handle transient failures in your workflows.
They are defined at the task level and can be configured to retry a task a certain number of times, or with a certain delay between each retry.
What are retries
Kestra provides a task retry functionality. This makes it possible to add retry behavior for any failed task run based on configurations in the flow description.
A retry on a task run will create a new task run attempt.
Example
The following example defines a retry for the retry-sample task with a maximum of 5 attempts every 15 minutes:
yaml
- id: retry_sample
  type: io.kestra.plugin.core.log.Log
  message: my output for task {{task.id}}
  timeout: PT10M
  retry:
    type: constant
    maxAttempt: 5
    interval: PT15M
In next example, the flow will be retried four times every 0.25 ms, with each attempt executing for a maximum of 1 minute before being failed.
Due to the shell command logic used, it will succeed at the 5th attempt as we can track how many times it retries with {{ taskrun.attemptsCount }}
yaml
id: retry
namespace: company.team
description:
  This flow will be retry 4 times and will success at the 5th attempts
tasks:
- id: failed
  type: io.kestra.plugin.scripts.shell.Commands
  taskRunner:
    type: io.kestra.plugin.core.runner.Process
  commands:
  - 'if [ ""{{taskrun.attemptsCount}}"" -eq 4 ]; then exit 0; else exit 1; fi'
  retry:
    type: constant
    interval: PT0.25S
    maxAttempt: 5
    maxDuration: PT1M
    warningOnRetry: true
errors:
  - id: never_happen
    type: io.kestra.plugin.core.debug.Return
    format: Never happened {{task.id}}
Retry options for all retry types
name type description
type string Retry behavior to apply. Can be one of constant, exponential, random.
maxAttempt integer Number of retries performed before the system stops retrying.
maxDuration Duration Maximum delay the execution is retried. Once passed, the task is no more processed.
warningOnRetry Boolean Flag the execution as warning if any retry was done on this task. Default false.
Duration
Some options above have to be filled with a duration notation. Durations are expressed in the ISO 8601 Durations format, here are some examples:
name description
PT0.250S 250 milliseconds delay
PT2S 2 seconds delay
PT1M 1 minute delay
PT3.5H 3 hours and a half delay
Retry types
constant
This establishes constant retry times: if the interval property is set to 10 minutes, it retries every 10 minutes.
name type description
interval Duration Duration between each retry.
exponential
This establishes retry behavior that waits longer between each retry e.g. 1s, 5s, 15s, ...
name type description
interval Duration Duration between each retry.
maxInterval Duration Max Duration between each retry.
delayFactor Double Multiplier for the interval on between retry, default is 2. For example, with an interval of 30s and a delay factor of 2, retry will append at 30s, 1m30, 3m30, ...
random
This establishes retries with a random delay between minimum and maximum limits.
name type description
minInterval Duration Minimal duration between each retry.
maxInterval Duration Maximum duration between each retry.
Configuring retries globally
You can also configure retries globally for all tasks in a flow by using the plugins configuration:
yaml
kestra:
  plugins:
    configurations:
      - type: io.kestra
        values:
          retry:
            type: constant
            maxAttempt: 3
            interval: PT30S
This configuration will apply a constant retry with a maximum of 3 attempts every 30 seconds to all tasks across all flows.
Flow-level retries
You can also set a flow-level retry policy to restart the execution if any task fails. The retry behavior is customizable ‚Äî you can choose to:
Create a new execution: CREATE_NEW_EXECUTION
Retry the failed task only: RETRY_FAILED_TASK
Flow-level retries are particularly useful when you want to retry the entire flow if any task fails. This way, you don't need to configure retries for each task individually.
Here's an example of how you can set a flow-level retry policy:
yaml
id: flow_level_retry
namespace: company.team
retry:
  maxAttempt: 3
  behavior: CREATE_NEW_EXECUTION # RETRY_FAILED_TASK
  type: constant
  interval: PT1S
tasks:
  - id: fail_1
    type: io.kestra.plugin.core.execution.Fail
    allowFailure: true
  - id: fail_2
    type: io.kestra.plugin.core.execution.Fail
    allowFailure: false
The behavior property can be set to CREATE_NEW_EXECUTION or RETRY_FAILED_TASK. Only with the CREATE_NEW_EXECUTION behavior, the attempt of the execution is incremented. Otherwise, only the failed task run is restarted (incrementing the attempt of the task run rather than the execution).
Apart from the behavior property, the retry policy is identical to the one you already know from task retries.
Note: Flow-level retries will also restart Subflow as a new execution.
Retry vs. Restart vs. Replay
Automatic vs. manual
Retries ensure that failed task runs are automatically rerun within the same Execution. Apart from retries, defined within your flow code, you can also manually rerun the flow from the Flow Execution page in the UI using the Restart or Replay buttons.
Restart vs. Replay
While Restart will rerun failed tasks within the current Execution (i.e., without creating a new execution), a Replay would result in a completely new run with a different Execution ID than the initial run.
When you replay an Execution, a new execution gets created for the same flow. However, you can still track which Execution triggered this new run thanks to the Original Execution field:
Replay can be executed from any task, even if that task executed successfully. But note that when you trigger a replay from a specific failed task, it will still result in a new Execution running all tasks downstream of your chosen start task:
When you want to rerun only failed tasks, use Restart.
Summary: Retries vs. Restart vs. Replay
The table below summarizes the differences between a retry, restart and replay.
Concept Flow or task level Automatic or manual Does it create a new execution?
Retry Task level Automatic No, it only reruns a given task within the same Execution. Each retry results in a new attempt number, allowing you to see how many times a given task run was retried.
Restart Flow level Manual No, it only reruns all failed tasks within the same Execution. It's meant to handle unanticipated, transient failures. The UI shows a new attempt number for all task runs that were restarted.
Replay Either flow or task level Manual Yes. You can pick an arbitrary step from which a new execution should be triggered. If you select a task in the middle that needs outputs from a previous task, its output is retrieved from cache.
Was this page helpful?
Yes
No
Workflow Components
Errors
Workflow Components
Timeout""""""",1623,7220,kestra
https://kestra.io/docs/workflow-components/timeout,"""""""DocsWorkflow ComponentsTimeout
Timeout
Table of Contents
What is timeout
Format
Example
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Timeout allows you to set a maximum duration for a task run.
What is timeout
If the task run exceeds the specified duration, Kestra will automatically stop the task run and mark it as failed. This is useful for tasks that may hang and run indefinitely.
Timeout is often used as a cost control mechanism for cloud-based workflows. Imagine a Snowflake query or an AWS Batch job that runs for hours leading to unexpected costs. By setting a timeout, you can ensure that the task run will not exceed a certain duration.
Format
Similar to durations in retries, timeouts use the ISO 8601 Durations format. Below are some examples:
name description
PT0.250S 250 milliseconds delay
PT2S 2 seconds delay
PT1M 1 minute delay
PT3.5H 3 hours and a half delay
Example
In this example, the costly_query task will sleep for 10 seconds, but the timeout is set to 5 seconds, leading to a failed task run.
yaml
id: timeout
namespace: company.team
description: This flow will always fail because of a timeout.
tasks:
  - id: costly_query
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - sleep 10
    timeout: PT5S
Was this page helpful?
Yes
No
Workflow Components
Retries
Workflow Components
Concurrency limits""""""",339,1442,kestra
https://kestra.io/docs/workflow-components/concurrency,"""""""DocsWorkflow ComponentsConcurrency limits
Concurrency limits
Table of Contents
behavior property
Tracking Concurrency Slots from the UI
How to Troubleshoot Concurrency Issues
Check the Concurrency Tab
Edit the Concurrency Property
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
>= 0.13.0
Control concurrent executions of a given flow.
The flow level concurrency property allows you to control the number of concurrent executions of a given flow by setting the limit key.
You can treat concurrency as a global concurrency limit for that specific flow. The concurrency limit and behavior is then applied to all executions of that flow, regardless of whether those executions have been started automatically via a trigger, webhook, an API call or manually created from the UI.
For example, if you set the concurrency limit to 2, only two executions of that flow will be allowed to run at the same time. If you try to trigger a third execution, it will be queued until one of the two running executions is completed.
yaml
id: concurrency_example
namespace: company.team
concurrency:
  limit: 2
tasks:
  - id: wait
    type: io.kestra.plugin.scripts.shell.Commands
    commands:
      - sleep 10
As you can see in the UI, the third execution has been queued while the first two have finished successfully.
behavior property
You can customize the execution behavior to CANCEL or FAIL an execution if the concurrency limit is reached. To do that, set the behavior Enum-type property to one of the following values:
QUEUE
CANCEL
FAIL.
Let's say you set the concurrency.limit to 2, and you use the CANCEL or FAIL behavior. The third execution's state will be immediately set to CANCELLED or FAILED status respectively without running any task.
Here is a full flow example that uses the concurrency property to limit the number of concurrent executions to 2. The bash task will sleep for 10 seconds, so you can trigger multiple executions of that flow and see how the concurrency property behaves.
yaml
id: concurrency_limited_flow
namespace: company.team
concurrency:
  behavior: FAIL # QUEUE, CANCEL or FAIL
  limit: 2 # can be any integer >= 1
tasks:
  - id: wait
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - sleep 10
As you can see in the UI, the third execution failed as the first two executions were still running.
Tracking Concurrency Slots from the UI
The Concurrency tab in the Flow UI page allows you to track and troubleshoot concurrency issues. This UI tab added in Kestra 0.19.0 shows a progress bar with the number of active slots compared to the total number of slots available. Below that progress bar, you can see a table showing currently running and queued Executions, providing a clear overview of the flow's concurrency status.
To see the concurrency behavior in action, you can configure a flow with a concurrency limit as follows:
yaml
id: concurrent
namespace: company.team
concurrency:
  behavior: QUEUE
  limit: 5
tasks:
  - id: long_running_task
    type: io.kestra.plugin.scripts.shell.Commands
    commands:
      - sleep 90
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
Then trigger multiple Executions of that flow and watch the Concurrency tab showing the active slots and queued Executions.
How to Troubleshoot Concurrency Issues
Imagine that you encounter a situation where the concurrency limit is reached, and some executions are stuck in the QUEUED state. Here are some steps to troubleshoot and resolve the issue.
Check the Concurrency Tab
The Concurrency tab on the Flow UI page described above allows you to see which executions are RUNNING and which are QUEUED (i.e. waiting or stuck). This page can help you troubleshoot which Executions are taking concurrency slots and which are waiting to be processed.
In the future, you'll be able to use this page to run any stuck Executions while ignoring concurrency limits (i.e., run them as if concurrency limits wouldn't exist).
Edit the Concurrency Property
You can edit the concurrency property within the flow (or remove that property entirely to get rid of any limits) and Save the flow code. The modified concurrency limit and behavior will be immediately taken into account for all Executions in progress because the Executor checks this for the latest flow revision rather than for the revision of the Execution.
Under any circumstances, do NOT delete the executions as this will only make the issue worse ‚Äî the no longer existing (i.e. deleted) executions will keep occupying the concurrency slots forever. You can select stuck Executions and hit the Kill button to cancel them and free up the concurrency slots, but please don't delete them.
Was this page helpful?
Yes
No
Workflow Components
Timeout
Workflow Components
Descriptions""""""",1031,4871,kestra
https://kestra.io/docs/workflow-components/descriptions,"""""""DocsWorkflow ComponentsDescriptions
Descriptions
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
You can document your flows, inputs, outputs, tasks and triggers by adding a description property.
The description property is a string that supports Markdown syntax.
You can add a description property on:
Flows
Inputs
Outputs
Tasks
Triggers
All markdown descriptions will be rendered in the UI.
Here is an example flow with descriptions in different components:
yaml
id: myflow
namespace: company.team
description: |
  This is the **Flow Description**.
  You can look at `input description`, `task description`, `output description` and `trigger description` as well in this example.
labels:
  env: dev
  project: myproject
inputs:
  - id: payload
    type: JSON
    description: JSON request payload to the API # Input description
    defaults: |
      [{""name"": ""kestra"", ""rating"": ""best in class""}]
tasks:
  - id: send_data
    type: io.kestra.plugin.core.http.Request
    description: Task for sending POST API request to https://reqres.in/api/products # Task description
    uri: https://reqres.in/api/products
    method: POST
    contentType: application/json
    body: ""{{ inputs.payload }}""
  - id: print_status
    type: io.kestra.plugin.core.debug.Return
    description: Task printing the API request date # Task description
    format: hello on {{ outputs.send_data.headers.date | first }}
outputs:
  - id: final
    type: STRING
    description: This is a task output used as a final flow output
    value: ""{{ outputs.print_status.value }}""
triggers:
  - id: daily
    type: io.kestra.plugin.core.trigger.Schedule
    description: Trigger the flow at 09:00am every day # Trigger description
    cron: ""0 9 * * *""
Was this page helpful?
Yes
No
Workflow Components
Concurrency limits
Workflow Components
Disabled flag""""""",431,1855,kestra
https://kestra.io/docs/workflow-components/disabled,"""""""DocsWorkflow ComponentsDisabled flag
Disabled flag
Table of Contents
Disabled flow
Disabled trigger
Disabled task
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
The disabled flag is a boolean property that allows you to skip a flow, task or trigger.
This is helpful when trying to debug or test a certain part of your flow without needing to remove any of the existing logic. Instead of deleting parts of your YAML, you can add the disabled property.
Disabled flow
When a flow is disabled, it will not be executed ‚Äî even if a trigger is set. If you have an active trigger on a disabled flow, it will be ignored. You don't even need to disable the trigger ‚Äî it will be ignored automatically. Setting a flow to disabled will effectively prevent any future executions of the flow until it is re-enabled.
Try adding the following flow and try to both run it and observe the scheduled executions:
yaml
id: disabled_flow
namespace: company.team
disabled: true
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: Kestra team wishes you a great day! üëã
triggers:
  - id: fail_every_minute
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/1 * * * *""
You will see that you cannot run the flow and that the trigger is ignored ‚Äî no executions are created.
When trying to execute a disabled flow from a subflow:
yaml
id: parent_runs_disabled_flow
namespace: company.team
tasks:
  - id: disabled_subflow
    type: io.kestra.plugin.core.flow.Subflow
    flowId: disabled_flow
    namespace: company.team
When you execute the parent flow, it will immediately fail with the error message: Cannot execute a flow which is disabled.
Similarly, try running a disabled flow via an API call:
bash
curl -X POST http://localhost:8080/api/v1/executions/trigger/example/parent_runs_disabled_flow
The API call itself will be successful:
bash
{""id"":""5ScXvrnOkjfKIXqYylRYME"",""namespace"":""example"",""flowId"":""parent_runs_disabled_flow"",""flowRevision"":1,""state"":{""current"":""CREATED"",""histories"":[{""state"":""CREATED"",""date"":""2024-01-19T20:38:48.474047013Z""}],""duration"":""PT0.011094958S"",""startDate"":""2024-01-19T20:38:48.474047013Z""},""originalId"":""5ScXvrnOkjfKIXqYylRYME""}%
However, that execution will be immediately marked as failed with the error message: Cannot execute a flow which is disabled.
Disabled trigger
Often, when you use a Schedule trigger, it's useful to disable it temporarily. For example, you may want to disable a trigger while you are debugging a flow. You can do this by setting the disabled flag to true on the trigger:
yaml
id: myflow
namespace: company.team
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: hello from a scheduled flow
triggers:
  - id: daily
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 9 * * *""
    disabled: true
You will see that no scheduled executions are created for this flow. Once you are done debugging, you can re-enable the trigger by setting the disabled flag to false or simply by removing the disabled flag:
yaml
id: myflow
namespace: company.team
tasks:
  - id: hello
    type: io.kestra.plugin.core.log.Log
    message: hello from a scheduled flow
triggers:
  - id: daily
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 9 * * *""
Disabled task
In contrast to preventing the entire flow from being executed by setting the flow or trigger to disabled, you can also disable a single task. This is useful when you want to temporarily disable a single task without deleting it e.g. when troubleshooting a failure. You can do this by setting the disabled flag to true on the task:
yaml
id: myflow
namespace: company.team
tasks:
  - id: enabled
    type: io.kestra.plugin.core.log.Log
    message: this task will run
  - id: disabled
    type: io.kestra.plugin.core.debug.Return
    format: this task will be skipped
    disabled: true
You will see in the UI that disabled tasks are greyed out:
Was this page helpful?
Yes
No
Workflow Components
Descriptions
Workflow Components
States""""""",982,4017,kestra
https://kestra.io/docs/workflow-components/states,"""""""DocsWorkflow ComponentsStates
States
Table of Contents
Overview
Execution States
What is the difference between the CANCELLED and KILLED states?
How are task run states different from execution states?
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
States control the status of your workflow execution.
Overview
Execution is a single run of a flow in a specific state. Each state represents a particular point in the workflow in which Kestra's orchestration system determines what happens next based on the control flow logic defined in the flow.
You can read more about executions here.
Execution States
Each Kestra execution can transition through several states during its lifecycle. The following diagram illustrates the possible states an execution can be in:
Here is a brief description of each state:
CREATED: The execution has been created but not yet started. This transient state indicates that the execution is waiting to be processed, and it should usually quickly transition to the RUNNING, CANCELLED or QUEUED state. If you see executions stuck in this state, it may indicate a problem with the system.
QUEUED: The execution is waiting for a free slot to start running. This transient state is only used when the flow has concurrency limits and all available slots are taken.
RUNNING: The execution is currently in progress. This transient state continues until all task runs are completed.
SUCCESS: The execution has completed successfully. This terminal state indicates that the execution has completed successfully and all tasks have finished without errors (or were allowed to fail).
WARNING: This terminal state is used when the execution has completed successfully, but one or more tasks have emitted warnings.
FAILED: This state indicates that one or more tasks have failed and will not be retried. If there is an errors branch defined in the flow, the error tasks will be executed before permanently ending the execution, e.g. to send an alert about failure. Without any additional orchestration action, this state is usually considered as a terminal state. However, when the flow has a flow-level retry policy set to the RETRY_FAILED_TASK behavior, the execution will transition to the RETRYING state.
RETRYING: This transient state indicates that the execution is currently retrying one or more failed task runs. After all retry attempts are exhausted, the execution will transition to the terminal SUCCESS, WARNING or FAILED state.
RETRIED: This terminal state indicates that the execution has been retried according to the flow-level retry policy set to the CREATE_NEW_EXECUTION behavior. This means that the original execution (which failed and has been retried) is marked as RETRIED, and a new execution is created to run the flow again.
PAUSED: This transient state indicates that the execution is awaiting manual approval or has been paused for a fixed duration before continuing the execution. Note that there is no RESUMING or RESUMED states as the execution will transition directly from the PAUSED to a RUNNING state as soon as the paused execution is resumed.
RESTARTED: This transient state is equivalent to the CREATED state, but for a failed execution that has been restarted e.g. from the UI. Such execution will transition to the RUNNING state as soon as the restarted execution is processed.
CANCELLED: This terminal state indicates that the execution has been automatically cancelled by the system, usually because the concurrency limit was reached and the concurrency behavior was set to CANCEL in order to cancel all executions that exceed the concurrency limit.
KILLING: This transient state indicates that the user has issued a command to kill the execution, e.g. via a task or by clicking on the Kill button in the UI. The system is in the process of terminating (aka killing) the task runs associated with the execution which are still in progress. As soon as all task runs are terminated, the execution will transition to the KILLED state.
KILLED: This terminal state indicates that the execution has been killed upon request by the user. No more tasks will be able to run, and the execution is considered terminated.
Mermaid source code for the Execution States diagram
What is the difference between the CANCELLED and KILLED states?
The CANCELLED state is used when the system automatically cancels an execution due to the concurrency limit being reached.
The KILLING state is used when the user manually kills an execution and the system is in the process of terminating the task runs associated with the execution.
The KILLED state is used when the execution has been killed upon request by the user.
How are task run states different from execution states?
Task run states represent the status of a single task run within an execution.
Each task runs can be set to one of the following states:
CREATED: The task run has been created but not yet started.
RUNNING: The task run is currently in progress.
SUCCESS: The task run has completed successfully.
WARNING: The task run has completed successfully but with warnings.
FAILED: The task run has failed.
RETRYING: The task run is currently being retried.
RETRIED: The task run has been retried.
KILLING: The task run is in the process of being killed.
KILLED: The task run has been killed upon request by the user.
Note how there is no QUEUED, CANCELLED, PAUSED or RESTARTED states for task runs.
Mermaid source code for the Task Run States diagram
Was this page helpful?
Yes
No
Workflow Components
Disabled flag
Docs
Version Control & CI/CD""""""",1116,5572,kestra
https://kestra.io/docs/version-control-cicd,"""""""DocsVersion Control & CI/CD
Version Control & CI/CD
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Version Control & CI/CD Pipelines
Version Control with Git
Setup Version Control with Git to store your flows and namespace files.
CI/CD Pipeline
Kestra provides several ways to create a CI/CD pipeline for your flows.
Was this page helpful?
Yes
No
Workflow Components
States
Version Control Cicd
Version Control with Git""""""",107,447,kestra
https://kestra.io/docs/version-control-cicd/git,"""""""DocsVersion Control & CI/CDVersion Control with Git
Version Control with Git
Table of Contents
Git SyncFlows and SyncNamespaceFiles
CI/CD
Git PushFlows and PushNamespaceFiles
Git Clone
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Setup Version Control with Git to store your flows and namespace files.
Kestra supports version control with Git. You can use one or more Git repositories to store your Flows and Namespace Files, and track changes to them over time via Git commit history.
There are multiple ways to use Git with Kestra:
The git.SyncFlows pattern allows you to implement GitOps and use Git as a single source of truth for your flows.
The git.SyncNamespaceFiles pattern allows you to implement GitOps and use Git as a single source of truth for your namespace files.
The git.PushFlows pattern allows you to edit your flows from the UI and regularly commit and push changes to Git; this pattern is useful if you want to use the built-in Editor in the UI and still have your code in Git.
The git.PushNamespaceFiles pattern allows you to edit your namespace files from the UI and regularly commit and push changes to Git; this pattern is useful if you want to use the built-in Editor in the UI and still have your files in Git.
The CI/CD pattern is useful if you want to manage the CI/CD process yourself e.g. via GitHub Actions or Terraform, and keep Git as a single source of truth for your code.
The image below shows how to choose the right pattern based on your needs:
Let's dive into each of these patterns, and when to use them.
Git SyncFlows and SyncNamespaceFiles
The Git SyncFlows pattern implements GitOps and uses Git as a single source of truth. It allows you to store your flows in Git and use a system flow that automatically syncs changes from Git to Kestra. You can also sync namespace files using the Git SyncNamespaceFiles pattern in the same way.
Here's how that works:
You store your flows and Namespace Files in Git
You create a system flow that runs on a schedule and syncs changes from Git to Kestra
When you want to make a change to a flow or a namespace file, you modify the file in Git
The system flow syncs changes from Git to Kestra so that even if you make changes to any flows or Namespace Files from the UI, the changes are overwritten by the changes from Git.
This pattern is useful if you want to use Git as a single source of truth and avoid making changes to flows and Namespace Files from the UI. Using this pattern, you don't need to manage any CI/CD pipelines.
If your team follows the GitOps methodology, or you're coming from a Kubernetes background, this pattern is for you.
Here is an example system flow that you can use to declaratively sync changes from Git to Kestra:
yaml
id: sync_from_git
namespace: system
tasks:
  - id: git
    type: io.kestra.plugin.git.SyncFlows
    url: https://github.com/kestra/scripts
    branch: main
    username: git_username
    password: ""{{ secret('GITHUB_ACCESS_TOKEN') }}""
    targetNamespace: git
    includeChildNamespaces: true # optional; by default, it's set to false to allow explicit definition
    gitDirectory: your_git_dir
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/1 * * * *"" # every minute
You can choose to commit this flow to Git or add it from the built-in Editor in Kestra UI ‚Äî this flow won't be overwritten by the Git reconciliation process.
You can also sync namespace files with the example below:
yaml
id: sync_from_git
namespace: system
tasks:
  - id: git
    type: io.kestra.plugin.git.SyncNamespaceFiles
    namespace: prod
    gitDirectory: _files # optional; set to _files by default
    url: https://github.com/kestra-io/flows
    branch: main
    username: git_username
    password: ""{{ secret('GITHUB_ACCESS_TOKEN') }}""
This flow can also be triggered anytime you push changes to Git via a GitHub webhook:
yaml
id: sync_from_git
namespace: system
tasks:
  - id: git
    type: io.kestra.plugin.git.SyncFlows
    url: https://github.com/kestra/scripts
    branch: main
    targetNamespace: git
    username: git_username
    password: ""{{ secret('GITHUB_ACCESS_TOKEN') }}""
triggers:
  - id: github_webhook
    type: io.kestra.plugin.core.trigger.Webhook
    key: ""{{ secret('WEBHOOK_KEY') }}""
Note that the webhook key is used to authenticate webhook requests and prevent unauthorized access to your Kestra instance. For the above flow, you would paste the following URL in your GitHub repository settings in the Webhooks section:
bash
https://us.kestra.cloud/api/v1/your_tenant/executions/webhook/prod/sync_from_git/your_secret_key
Following the pattern:
bash
https://<host>/api/v1/<tenant>/executions/webhook/<namespace>/<flow>/<webhook_key>
CI/CD
The CI/CD pattern allows you to use Git as a single source of truth and push code changes to Kestra anytime you merge a pull request. However, in contrast to the Git Sync pattern, you need to manage the CI/CD process yourself e.g. via GitHub Actions or Terraform. Check the CI/CD documentation for more details on how to set up CI/CD for Kestra flows and Namespace Files.
Git PushFlows and PushNamespaceFiles
The Git PushFlows pattern allows you to edit your flows from the UI, and regularly push changes to Git. It's particularly helpful if you want to use the built-in Editor in the UI and have your code change history managed via Git. You can also push namespace files using the Git PushNamespaceFiles pattern in the same way.
Here is example flow that you can use to push flow changes from Kestra to Git:
yaml
id: push_to_git
namespace: system
tasks:
  - id: commit_and_push
    type: io.kestra.plugin.git.PushFlows
    url: https://github.com/kestra-io/scripts
    sourceNamespace: dev
    targetNamespace: pod
    flows: ""*""
    branch: kestra
    username: github_username
    password: ""{{ secret('GITHUB_ACCESS_TOKEN') }}""
    commitMessage: add namespace files changes
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""* */1 * * *"" # every hour
Here is an example you can use to push namespace files from Kestra to Git:
yaml
id: push_to_git
namespace: system
tasks:
  - id: commit_and_push
    type: io.kestra.plugin.git.PushNamespaceFiles
    namespace: dev
    files: ""*""
    gitDirectory: _files
    url: https://github.com/kestra-io/scripts # required string
    username: git_username
    password: ""{{ secret('GITHUB_ACCESS_TOKEN') }}""
    branch: dev
    commitMessage: ""add namespace files""
triggers:
  - id: schedule_push_to_git
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/15 * * * *""
You can use that pattern to push changes to a feature branch and create a pull request for review. Once the pull request is approved, you can merge it to the main branch.
Git Clone
The Git Clone pattern allows you to clone a Git repository at runtime. This pattern can be used to orchestrate code maintained in a different code repository (potentially managed by a different team) in the following scenarios:
dbt projects orchestrated via dbt CLI task
infrastructure deployments orchestrated via Terraform CLI or Ansible CLI
Docker builds orchestrated via Docker Build task.
Was this page helpful?
Yes
No
Docs
Version Control & CI/CD
Version Control Cicd
CI/CD Pipeline""""""",1719,7274,kestra
https://kestra.io/docs/version-control-cicd/cicd,"""""""DocsVersion Control & CI/CDCI/CD Pipeline
CI/CD Pipeline
Table of Contents
Introduction
Why a CI/CD pipeline?
CI/CD for Kestra workflows
Kestra CLI
Deploy flows... from a flow!
Deploy flows from a GitHub Action
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Kestra provides several ways to create a CI/CD pipeline for your flows.
This section explains how to automate the validation and deployment of your workflows using CI/CD.
Introduction
Manual deployments are often not desirable. CI/CD pipelines are a great way to automate the validation and deployment of your workflows to production environments. This section explains several ways of creating a CI/CD pipeline for your Kestra resources.
Why a CI/CD pipeline?
A CI/CD process helps ensure fast and reliable deployments. Your changes get deployed automatically, as soon as they get peer-reviewed and merged to a VCS (Version Control System) like Git.
CI/CD for Kestra workflows
There are several ways to create a CI/CD pipeline for your flows in Kestra. Pick one of the options listed below that best suits your needs.
Kestra CLI
Kestra CLI provides several commands for validating and deploying your flows:
bash
# validate a single flow
./kestra flow validate flow_directory/myflow.yml --server http://localhost:8080 --api-token <your-api-token>
# deploy a single flow to a namespace without deleting existing flows
./kestra flow namespace update namespace_name flow_directory/myflow.yml --no-delete --server http://localhost:8080 --api-token <your-api-token>
Note that the --api-token option is available only in the Enterprise Edition. In the open-source version, you can leverage the basic authentication using the --user flag:
bash
./kestra flow namespace update namespace_name flow_directory/myflow.yml --no-delete --server http://localhost:8080 --user=KESTRA_USER:KESTRA_PASSWORD
If you run Kestra in a Docker container, you can access the CLI as follows:
bash
docker exec -it kestra-container-name /bin/bash
./kestra flow --help
To validate and deploy multiple flows within a directory named flows, you can provide a path to that directory:
bash
./kestra flow validate flows/ --server http://localhost:8080 --api-token <your-api-token>
./kestra flow namespace update namespace_name flows/ --no-delete --server http://localhost:8080 --api-token <your-api-token>
The --no-delete flag is used to preserve existing flows already stored within your Kestra instance. Don't include that flag if you want that a specific Git repository or a local directory is used as the single source of truth for your production workflows. This way, all previously stored flows get deleted, and only those flows maintained in Git (or that directory) are kept and updated.
CLI options
The CLI provides several options to customize your validation and deployment process. CLI options you should be aware of include:
--local: performs the validation locally using the client. By default, Kestra validates flows server-side (a remote API call to your Kestra webserver/standalone server).
--server: allows you to specify the remote Kestra webserver/standalone server URL. The default URL is http://localhost:8080.
For all available CLI options on both flow validate and flow namespace update commands, use the -h or --help flag:
bash
./kestra flow validate -h
./kestra flow namespace update -h
Templates (deprecated)
Templates can be validated and deployed in the same way as flows:
bash
./kestra template validate path-to-template-directory
./kestra template namespace update template-namespace-to-update path-to-template-directory
Note that templates are deprecated and will be removed in a future release. Use subflows instead.
Deploy flows... from a flow!
The CLI commands explained above can be used in a Shell script within a flow. This way, your CI/CD pipeline can be managed directly from your Kestra instance directly.
yaml
id: ci-cd
namespace: company.team
tasks:
  - id: github-ci-cd
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: clone-repository
        type: io.kestra.plugin.git.Clone
        url: https://github.com/anna-geller/kestra-ci-cd
        branch: main
      - id: validate-flows
        type: io.kestra.plugin.scripts.shell.Commands
        description: ""Validate flows from Git before deploying them.""
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        warningOnStdErr: false
        commands:
          - /app/kestra flow validate flows/ --server http://localhost:8080 --api-token ""{{ secret('KESTRA_API_TOKEN') }}""
      - id: deploy-flows
        type: io.kestra.plugin.scripts.shell.Commands
        description: ""Deply flows to a Kestra namespace.""
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        warningOnStdErr: false
        commands:
          - /app/kestra flow namespace update prod flows/prod/ --server http://localhost:8080 --api-token ""{{ secret('KESTRA_API_TOKEN') }}""
          - /app/kestra flow namespace update prod.marketing flows/prod.marketing/ --server http://localhost:8080 --api-token ""{{ secret('KESTRA_API_TOKEN') }}""
triggers:
  - id: github
    type: io.kestra.plugin.core.trigger.Webhook
    key: ""yourSecretKey1234""
While you can trigger that deployment pipeline manually using Kestra UI or API (i.e. just like any other Kestra flow), it's better to combine that with a push event emitted by your Git repository. The above flow leverages the Webhook trigger so that your CI/CD flow runs as soon as you push changes to your Git branch.
To configure the webhook for your GitHub repository, go to Settings, and then select Webhooks. The URL in your browser should look as follows:
bash
https://github.com/your_username/your_repository_name/settings/hooks
Select ""Add webhook"":
Paste Kestra's webhook URL into the Payload URL field, as shown below. The webhook to trigger a Kestra flow should be in the following format:
bash
https://kestra_host_url/api/v1/executions/webhook/namespace/flow_id/webhook_key
Note that we configured this webhook to be sent upon a push event to the default branch, but you can choose the option ""Let me select individual events"" for further customization e.g. to trigger the flow any time there is a new pull request.
Deploy flows from a GitHub Action
The official Kestra's GitHub Actions leverage the same CLI commands to:
Validate flows and templates using the Validate Action
Deploy flows and templates using the Deploy Action.
Here is a full example validating and deploying flows within a GitHub Actions workflow:
yaml
name: Kestra CI/CD
on:
  push:
    branches:
      - main
jobs:
  prod:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: validate-all flows
        uses: kestra-io/validate-action@master
        with:
          directory: ./flows/prod
          resource: flow
          server: ${{secrets.KESTRA_HOSTNAME}}
          user: ${{secrets.KESTRA_USER}}
          password: ${{secrets.KESTRA_PASSWORD}}
      - name: deploy-prod
        uses: kestra-io/deploy-action@develop
        with:
          namespace: prod
          directory: ./flows/prod
          resource: flow
          server: ${{secrets.KESTRA_HOSTNAME}}
          user: ${{secrets.KESTRA_USER}}
          password: ${{secrets.KESTRA_PASSWORD}}
          delete: false
      - name: deploy-prod-marketing
        uses: kestra-io/deploy-action@develop
        with:
          namespace: prod.marketing
          directory: ./flows/prod.marketing
          resource: flow
          server: ${{secrets.KESTRA_HOSTNAME}}
          user: ${{secrets.KESTRA_USER}}
          password: ${{secrets.KESTRA_PASSWORD}}
          delete: false
Note that this example uses GitHub repository secrets to store the host name, user name and password to your Kestra instance. Make sure to add those secrets to your repository before using this workflow.
Here is a modified version of the same workflow but this time using an API token instead of a user name and password:
yaml
name: Kestra CI/CD
on:
  push:
    branches:
      - main
jobs:
  prod:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: validate-all flows
        uses: kestra-io/validate-action@master
        with:
          directory: ./flows/prod
          resource: flow
          server: ${{secrets.KESTRA_HOSTNAME}}
          apiToken: ${{secrets.KESTRA_API_TOKEN}}
      - name: deploy-prod
        uses: kestra-io/deploy-action@develop
        with:
          namespace: prod
          directory: ./flows/prod
          resource: flow
          server: ${{secrets.KESTRA_HOSTNAME}}
          apiToken: ${{secrets.KESTRA_API_TOKEN}}
          delete: false
      - name: deploy-prod-marketing
        uses: kestra-io/deploy-action@develop
        with:
          namespace: prod.marketing
          directory: ./flows/prod.marketing
          resource: flow
          server: ${{secrets.KESTRA_HOSTNAME}}
          apiToken: ${{secrets.KESTRA_API_TOKEN}}
          delete: false
Deploy flows from a GitLab CI/CD
GitLab CI/CD follows a similar pattern to the GitHub Actions example. See the GitLab section for more details.
Deploy flows from Terraform
While Terraform might be more challenging to understand at first, we highly recommend this option, as it provides the highest degree of flexibility. Using Kestra and Terraform together, your flows can be deployed along with other infrastructure resources in your stack, making it easier to adopt Infrastructure as Code.
The Terraform CI/CD page provides a more detailed explanation, but here is a simple Terraform configuration that you can use to automate the deployment of flows stored in a flows directory:
hcl
terraform {
  required_providers {
    kestra = {
      source  = ""kestra-io/kestra""
      version = ""~> 0.15.0""
    }
  }
}
provider ""kestra"" {
  url = ""http://localhost:8080"" # Kestra webserver/standalone server URL
  api_token = ""<your-api-token>"" # only available in the Enterprise Edition
}
resource ""kestra_flow"" ""flows"" {
  for_each  = fileset(path.module, ""flows/*.yml"")
  flow_id   = yamldecode(templatefile(each.value, {}))[""id""]
  namespace = yamldecode(templatefile(each.value, {}))[""namespace""]
  content   = templatefile(each.value, {})
  keep_original_source = true
}
You can save the code shown above in a file named main.tf. Then, run the following commands from the same directory where you stored that main.tf file:
bash
terraform init # downloads the terraform provider for Kestra
terraform validate # validates the configuration incl. the syntax of your flows
terraform apply -auto-approve # deploys your flows - can be used in a CI/CD process
Dive into each option
The following sections provide more details on each of the options listed above.
GitHub Actions
GitLab CI
Terraform
Helpers
Azure DevOps
BitBucket Pipes
Kubernetes Operator
Was this page helpful?
Yes
No
Version Control Cicd
Version Control with Git
Cicd
GitHub Actions""""""",2571,10972,kestra
https://kestra.io/docs/version-control-cicd/cicd/github-action,"""""""DocsVersion Control & CI/CDCI/CD PipelineGitHub Actions
GitHub Actions
Table of Contents
Kestra Actions
Input Reference
Validate Inputs
Deploy Inputs
Examples
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
How to use GitHub Actions to create a CI/CD pipeline for your Kestra flows.
We provide two official GitHub Actions to help you create a CI/CD pipeline for your Kestra flows.
In GitHub Actions, CI/CD pipelines are called a Workflow, and is built with Actions performing validation and deployment of your flows.
To use the GitHub Actions, your Kestra installation must be accessible from the GitHub Actions runner. This means that your Kestra server must be accessible from the internet, or that you must use a self-hosted runner.
Kestra Actions
Kestra offers two Actions to create a CI/CD pipeline within a GitHub repository.
Kestra Validate Action - Validate your flows and templates before deploying anything.
Kestra Deploy Action - Deploy your flows and templates to your Kestra server.
Input Reference
Validate Inputs
Inputs Required Default Description
directory ‚úîÔ∏è Folder containing your resources
resource ‚úîÔ∏è Resource you want to update in your namespace, can be flow or template
server ‚ùå URL of your Kestra server, if none is provided, validation is done locally
user ‚ùå User for the basic auth
password ‚ùå Password for the basic auth
apiToken ‚ùå API token for EE auth
tenant ‚ùå Tenant identifier (EE only, when multi-tenancy is enabled)
Deploy Inputs
Inputs Required Default Description
namespace ‚úîÔ∏è Namespace containing your flows and templates
directory ‚úîÔ∏è Folder containing your resources
resource ‚úîÔ∏è Resource you want to update in your namespace, can be either flow,template or namespace_files
server ‚úîÔ∏è URL of your Kestra server
user ‚ùå User name of your Kestra server
password ‚ùå Password of your Kestra server
delete ‚ùå true Flows found in Kestra server, but no longer existing in a specified directory, will be deleted by default. Set this to false if you want to avoid that behavior
tenant ‚ùå Tenant identifier (EE only, when multi-tenancy is enabled)
to ‚ùå Remote path indicating where to upload namespace files to
Examples
Here is an example of a Workflow using the Kestra actions to validate all Flows before deploying them.
yaml
name: Kestra CI/CD
on: [push]
jobs:
  validate:
    runs-on: ubuntu-latest
    name: Kestra validate
    steps:
      - name: Checkout repo content
        uses: actions/checkout@v4
      - name: Validate all flows on server-side
        uses: kestra-io/validate-action@develop
        with:
          directory: ./kestra/flows
          resource: flow
          server: server_url
  # If validation passed, deploy resources
  deploy:
    runs-on: ubuntu-latest
    name: Kestra deploy
    steps:
      # We can only deploy to one namespace at once,
      # so we have two different steps for our two namespaces product and engineering
      - name: Checkout repo content
        uses: actions/checkout@v4
      - name: Deploy product flows
        uses: kestra-io/deploy-action@master
        with:
          namespace: product
          directory: ./kestra/flows/product
          resource: flow
          server: server_url
      - name: Deploy engineering flows
        uses: kestra-io/deploy-action@master
        with:
          namespace: engineering
          directory: ./kestra/flows/engineering
          resource: flow
          server: server_url
Check out the How-to Guide for more examples.
Was this page helpful?
Yes
No
Version Control Cicd
CI/CD Pipeline
Cicd
GitLab CI""""""",821,3561,kestra
https://kestra.io/docs/version-control-cicd/cicd/gitlab,"""""""DocsVersion Control & CI/CDCI/CD PipelineGitLab CI
GitLab CI
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
How to use GitLab CI to create a CI/CD pipeline for your Kestra flows.
GitLab provides a solution called GitLab CI that allows you to define pipelines in YAML files to automate tests, compilation, and deployments of your applications.
Here is an example of a GitLab CI pipeline. We define the following stages:
validate, where we validate our flows
deploy, where we deploy our flows.
yaml
stages:
  - validate
  - deploy
default:
  image:
    name: kestra/kestra:latest
    entrypoint: [""""]
variables:
  KESTRA_HOST: https://kestra.io/
validate:
  stage: validate # Validate our flows server-side
  script:
    - /app/kestra flow validate ./kestra/flows --server ${KESTRA_HOST} --api-token $KESTRA_API_TOKEN
deploy:
  stage: deploy
  script:
    - /app/kestra flow namespace update my_namespace ./kestra/flows/prod --server ${KESTRA_HOST} --api-token $KESTRA_API_TOKEN
Was this page helpful?
Yes
No
Cicd
GitHub Actions
Cicd
Terraform""""""",290,1069,kestra
https://kestra.io/docs/version-control-cicd/cicd/terraform,"""""""DocsVersion Control & CI/CDCI/CD PipelineTerraform
Terraform
Table of Contents
Kestra Provider
Multitenancy
Example configuration
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
How to use Terraform to provision and manage changes to Kestra resources.
Kestra Provider
You can use the Official Kestra Provider to provision and manage changes to Kestra resources.
Multitenancy
The Kestra Terraform provider supports multitenancy, allowing you to manage resources across multiple tenants.
When configuring the provider, make sure to specify the tenant_id parameter with the tenant ID you want to interact with.
hcl
provider ""kestra"" {
  tenant_id = ""kestra-tech""
  url = ""https://us.kestra.cloud""
}
Example configuration
Flows should always be deployed before Templates, to avoid flows running before their templates are created.
First, you need to create a provider.tf or main.tf file with the following content to configure the provider:
provider.tf
hcl
provider ""kestra"" {
  # mandatory, the URL for kestra
  url = ""http://localhost:8080""
  # mandatory when using multitenancy, the ID of your tenant
  tenant_id = ""kestra-tech""
  # optional basic auth username
  username = ""john""
  # optional basic auth password
  password = ""my-password""
  # optional API token, can be used instead of basic auth in the Enterprise Edition
  api_token = ""my-api-token""
  # optional jwt token
  jwt = ""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6Iktlc3RyYS5pbyIsImlhdCI6MTUxNjIzOTAyMn0.hm2VKztDJP7CUsI69Th6Y5NLEQrXx7OErLXay55GD5U""
}
Then, you define the source and the version of the provider:
version.tf
hcl
kestra = {
  source  = ""kestra-io/kestra""
  version = ""~> 0.18.1""
}
Finally, you can create your resources:
flows.tf
hcl
resource ""kestra_flow"" ""flow-example"" {
  namespace = ""company.team""
  flow_id = ""myflow""
  content = file(""kestra/flows/my-flow.yml"")
}
templates.tf
hcl
resource ""kestra_template"" ""template-example"" {
  namespace = ""company.team""
  template_id = ""my-template""
  content = file(""kestra/templates/my-template.yml"")
  depends_on = [kestra_flow.flow-example] # Here we ensure that the flow is deployed before the template
}
More details can be found in the Terraform registry.
Was this page helpful?
Yes
No
Cicd
GitLab CI
Cicd
Helpers""""""",653,2301,kestra
https://kestra.io/docs/version-control-cicd/cicd/helpers,"""""""DocsVersion Control & CI/CDCI/CD PipelineHelpers
Helpers
Table of Contents
Expand the flow to be uploaded to the server
[[> file.txt]]: Include another file
Validate the flow to be uploaded to the server
Expand the flow to be uploaded to the server
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Kestra provides some helper functions that can help during flow development.
These helpers are only available during flow development to test on your local installation. Before sending it to your server, you must expand the flow definition; our CI/CD support will automatically expand it. These helpers cannot be used from Kestra's UI.
Expand the flow to be uploaded to the server
There is a convenient command on the Kestra executable that allows validation of the current flow and will output the expanded version of your flow without any helper:
bash
./kestra flow validate path-to-your-flow.yaml
[[> file.txt]]: Include another file
Working on a large flow can become complex when many tasks are defined, especially when you have some big text inside the flow definition (example, SQL statement, ...).
Let's take an example:
yaml
id: include
namespace: company.team
tasks:
- id: t1
  type: io.kestra.plugin.core.debug.Return
  format: |
    Lorem Ipsum is simply dummy text of the printing
    .....
    500 lines later
You can replace the flow definition with this one:
yaml
id: include
namespace: company.team
tasks:
- id: t1
  type: io.kestra.plugin.core.debug.Return
  format: ""[[> lorem.txt]]""
And have a local file lorem.txt with the large content in it.
The path can be:
[[> lorem.txt]]: a relative path from the flow (flow.yaml and lorem.txt are in the same directory),
[[> /path/to/lorem.txt]]: an absolute path,
[[> path/to/lorem.txt]]: a relative path from the flow (flow.yaml with a subdirectory path/to/).
When including a file, you must use the right YAML scalar type: literal (with or without quotes) for single-line scalars or folded for multiple-lines ones.
Includes are resolved recursively, so you can include a file from another include. This allows more complex things, but you need to take care that included files don't contain [[ .. ]]. If you need to have these characters in included files, escape them with \[[ ...]] !
Validate the flow to be uploaded to the server
There is a convenient command on the Kestra executable that allows validation of the current flow:
bash
./kestra flow validate --local path-to-your-flow.yaml
If your flow uses a helper function, flow validation must be done locally as the flow cannot be expanded on the webserver. Be careful that the local installation must have the same plugins as the remote installation.
Expand the flow to be uploaded to the server
There is a convenient command on the Kestra executable that allows expanding of the current flow. It will resolve includes if any:
bash
./kestra flow expand path-to-your-flow.yaml
Was this page helpful?
Yes
No
Cicd
Terraform
Cicd
Azure DevOps""""""",683,2983,kestra
https://kestra.io/docs/version-control-cicd/cicd/05-azure-devops,"""""""DocsVersion Control & CI/CDCI/CD PipelineAzure DevOps
Azure DevOps
Table of Contents
Setup an Azure DevOps Pipeline
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
How to use Azure DevOps to create a CI/CD pipeline for your Kestra flows.
Setup an Azure DevOps Pipeline
To create an Azure Devops Pipeline, first connect to your code repository. You can choose from several providers such as GitHub, Azure Repos Git or Bitbucket.
Then, choose the repository where your Kestra flows are located.
Start with a minimal pipeline template or use an existing one.
Consider the following pipeline:
yaml
trigger:
 branches:
   include:
     - main
pool:
  name: test-pool
stages:
  - stage: tfvalidate
    jobs:
      - job: deploy
        continueOnError: false
        steps:
          - task: TerraformInstaller@1
            inputs:
              terraformVersion: 'latest'
          - task: TerraformTaskV4@4
            inputs:
              provider: 'aws'
              command: 'init'
              backendServiceAWS: 'aws_s3'
              backendAWSBucketName: 'eu-north-1'
              backendAWSKey: 'kestra-tf'
          - task: TerraformTaskV4@4
            inputs:
              provider: 'aws'
              command: 'validate'
          - task: TerraformTaskV4@4
            inputs:
              provider: 'aws'
              command: 'apply'
              environmentServiceNameAWS: 'aws_s3'
The pipeline is triggered whenever the main branch is updated, so when you merge a PR into the main branch, the pipeline will run
Choose a pool created beforehand. Check the official Azure DevOps documentation to create and manage agent pools
Use the Terraform extension to install, validate, and apply Terraform resources. You can install the Terraform extension task by navigating to the Organization Settings > Extensions and then browse the marketplace to install the Terraform extension.
The first task is to use the TerraformInstaller@1 to install Terraform when the pipeline runs. Then, we use the `TerraformTaskV4@4`` three times:
run the `init`` command. Here, we use an AWS S3 bucket for the Terraform backend, but you can use either Azure RM backend, AWS, or GCP
run the `validate`` command, which will check whether the configuration is syntactically valid and internally consistent
run the `apply`` command to execute the actions proposed in the Terraform plan
You can find the specification of the Kestra Terraform provider in the corresponding documentation
Was this page helpful?
Yes
No
Cicd
Helpers
Cicd
BitBucket Pipes""""""",583,2566,kestra
https://kestra.io/docs/version-control-cicd/cicd/bitbucket-pipes,"""""""DocsVersion Control & CI/CDCI/CD PipelineBitBucket Pipes
BitBucket Pipes
Table of Contents
Setup a BitBucket Pipes
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
How to use BitBucket Pipes to create a CI/CD pipeline for your Kestra flows.
Setup a BitBucket Pipes
Using a basic Kestra image and corresponding Kestra CLI, you can validate and deploy flow from BitBucket repositories through BitBucket Pipes.
Here is a basic pipeline:
yaml
image: kestra/kestra
pipelines:
  default:
    - step:
        name: 'Validate Kestra flows'
        deployment: staging
        script:
          - /bin/sh /app/kestra flow validate flows/ --server $SERVER --tenant $TENANT --user $KESTRA_USER:$KESTRA_PASSWORD
    - step:
        name: 'Deploy Kestra flows'
        deployment: production
        script:
          - echo $SERVER
          - echo $KESTRA_USER
          - echo $KESTRA_PASSWORD
          - /bin/sh /app/kestra flow namespace update dev flows/ --server=$SERVER --tenant=$TENANT --user=$KESTRA_USER:$KESTRA_PASSWORD
Variables such as $SERVER, $KESTRA_USER, $KESTRA_PASSWORD (and optionally $TENANT if you're using a Kestra version supporting multi-tenancy) are set in the BitBucket Variable configuration:
Note that if you're using Kestra Enterprise Edition, instead of --user $KESTRA_USER:$KESTRA_PASSWORD, you can use the --api-token option to authenticate using an API token of a Service Account.
Here, we're using directly the Kestra CLI to:
Validate flows contained in the flows/ directory of the repository.
Deploy flows into the company.team namespace to your Kestra instance.
Was this page helpful?
Yes
No
Cicd
Azure DevOps
Cicd
Kubernetes Operator""""""",427,1686,kestra
https://kestra.io/docs/version-control-cicd/cicd/kubernetes-operator,"""""""DocsVersion Control & CI/CDCI/CD PipelineKubernetes Operator
Kubernetes Operator
Table of Contents
Installing the Kestra Kubernetes Operator
Managing Kestra resources via the operator
Managing Flow resources
Managing K/V entry resources
Managing Namespace File resources
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to use the Kestra Kubernetes Operator to provision and manage changes to Kestra resources including flows, namespace files, and k/v store entries.
This feature requires a commercial license.
A Kubernetes operator is an application-specific controller that extends the functionality of the Kubernetes API to create, configure, and manage instances of applications or their components on behalf of a Kubernetes user. It is a custom Kubernetes controller that uses custom resources (CR).
To define and manage these components, operators leverage Custom Resource Definitions (CRDs). CRDs allow you to extend the Kubernetes API with new resource types that are specific to your application or service.
The Kestra Kubernetes Operator will manage Kestra flows, namespace files and k/v store entries as Kuberntes resources.
Installing the Kestra Kubernetes Operator
We provide a Helm Chart to easily install Kestra in Kubernetes, see the Kubernetes installation guide.
This Helm Chart is capable of installing the Kestra Kubernetes Operator in your Kubernetes cluster.
The operator will automatically create and update the custom resource definitions for Kestra, so it needs Kubernetes RBAC that will be automatically created by the Helm Chart including a service account and cluster wide roles. Please reach out to us if you have any concern about this or struggle to make it work in your cluster.
The Kestra Kubernetes Operator will access the Kestra API, if you enabled authentication, you need to either create a service account or an API token for it.
To install the Kestra Kubernetes Operator inside your cluster, you need to configure the following properties in your Helm values:
yaml
operator:
  enabled: true
  apiKey: <your-kestra-api-token>
If you prefer to use a service account, please configure the following properties instead:
yaml
operator:
  enabled: true
  basicAuth: <username:password>
Then use helm install or helm update to release the changes into your Kubernetes cluster.
If everything goes well, you will have a kestra-operator Pod started.
text
kubectl get po
NAME                                 READY   STATUS    RESTARTS        AGE
kestra-operator-7d7bdbd846-pzpl2     1/1     Running   0               158m
kestra-postgresql-0                  1/1     Running   1 (2d23h ago)   3d
kestra-standalone-677474499f-4r5ft   1/1     Running   2 (5h10m ago)   2d23h
Managing Kestra resources via the operator
The Kestra Kubernetes operator will watch for three Kestra resources in all namespaces:
KestraFlow, shortname flow. To manage flows.
KestraKeyValue, shortnames keyvalue or kv. To manage K/V store entries.
KestraNamespaceFile, shortnames namespacefile or nsfile. To manage Namespace files.
Managing Flow resources
Here is an example Flow resource that you can create in a hello-world.yml file:
yaml
apiVersion: model.kestra.io/v1alpha1
kind: KestraFlow
metadata:
  name: hello-world
spec:
  id: hello-world
  namespace: company.team # This is a Kestra namespace, not a Kubernetes namespace
  source: |
   id: hello-world
   namespace: company.team
   tasks:
   - id: hello
     type: io.kestra.core.tasks.log.Log
Note: you need to both set the flow id and namespace in the resource spec and in the flow source to be able to update the flow.
You can then use the standard kubectl commands to create, update, list and delete your flows:
shell
# Create or update the flow
kubectl apply hello-world.yml
# List all flows
kubectl get flow
# Get the 'hello-world' flow
kubectl get flow hello-world
# Delete the 'hello-world' flow
kubectl delete flow hello-world
Managing K/V entry resources
Here is an example K/V entry resource that you can create in a kv-1.yml file:
yaml
apiVersion: model.kestra.io/v1alpha1
kind: KestraKeyValue
metadata:
  name: kv-1
spec:
  namespace: company.team # This is a Kestra namespace, not a Kubernetes namespace
  key: key1
  value: value1
You can then use the standard kubectl commands to create, update, list and delete your k/v entries:
shell
# Create or update the k/v entry
kubectl apply kv-1.yml
# List all flow
kubectl get kv
# Get the 'kv-1' k/v entries
kubectl get kv kv-1
# Delete the 'kv-1' k/v entry
kubectl delete kv kv-1
Managing Namespace File resources
Here is an example Namespace File resource that you can create in a nsfile-1 file:
yaml
apiVersion: model.kestra.io/v1alpha1
kind: KestraNamespaceFile
metadata:
  name: nsfile-1
spec:
  namespace: company.team # This is a Kestra namespace, not a Kubernetes namespace
  filename: nsfile-1.txt
  content: Hello World
You can then use the standard kubectl commands to create, update, list and delete your namespace files:
shell
# Create or update the namespace file
kubectl apply nsfile-1.yml
# List all namespace files
kubectl get nsfile
# Get the 'nsfile-1' namespace file
kubectl get nsfile nsfile-1
# Delete the 'nsfile-1' namespace file
kubectl delete nsfile nsfile-1
Was this page helpful?
Yes
No
Cicd
BitBucket Pipes
Docs
Plugin Developer Guide""""""",1274,5349,kestra
https://kestra.io/docs/plugin-developer-guide,"""""""DocsPlugin Developer Guide
Plugin Developer Guide
Table of Contents
The purpose of plugins
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Browse Kestra's integrations and learn how to create your own plugins.
The purpose of plugins
Plugins are the building blocks of Kestra's tasks and triggers. They encompass components interacting with external systems and performing the actual work in your flows.
Kestra comes prepackaged with hundreds of plugins, and you can also develop your own custom plugins.
To integrate with your internal systems and processes, you can build custom plugins. If you think it could be useful to others, consider contributing your plugin to our open-source community.
Setup for Plugin Development
Setup your environment for Plugin Development.
Gradle Configuration
We use Gradle as a build tool. This page will help you configure Gradle for your plugin.
Develop a Task
Here are the instructions to develop a new task.
Develop a Trigger
Here is how you can develop a Trigger.
Develop a Condition
Here is how you can develop a new Condition.
Add Unit Tests
To avoid regression, we recommend adding unit tests for all your tasks.
Document Your Plugin
Here is how you can document your plugin.
Build and Publish a Plugin
Use the included Gradle task to build the plugin. Then, you can publish it to Maven Central.
Was this page helpful?
Yes
No
Cicd
Kubernetes Operator
Plugin Developer Guide
Setup for Plugin Development""""""",307,1471,kestra
https://kestra.io/docs/plugin-developer-guide/setup,"""""""DocsPlugin Developer GuideSetup for Plugin Development
Setup for Plugin Development
Table of Contents
Plugin Template
Requirements
Create a new plugin
Plugin icons
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Setup your environment for Plugin Development.
Plugin Template
To get started with building a new plugin, make sure to use the plugin-template, as it comes prepackaged with the standardized repository structure and deployment workflows.
That template will create a project hosting a group of plugins ‚Äî we usually create multiple subplugins for a given service. For example, there's only one plugin for AWS, but it includes many subplugins for specific AWS services.
Note that the Kestra plugin library version must align with your Kestra instance. You may encounter validation issues during flow creation (e.g. Invalid bean response with status 422) when some plugins are on an older version of the Kestra plugin library. In that case, you may want to update the file plugin-yourplugin/gradle.properties and set the version property to the correct Kestra version e.g.:
version=0.17.0-SNAPSHOT
kestraVersion=[0.17,)
It's not mandatory that your plugin version matches the Kestra version, Kestra's official plugins version will always match the minor version of Kestra but it's only a best practice.
Then rebuild and publish the plugin.
Requirements
Kestra plugins development requirements are:
Java 21 or later.
IntelliJ IDEA (or any other Java IDE, we provide only help for IntelliJ IDEA).
Gradle (included most of the time with the IDE).
Create a new plugin
Here are the steps:
Go on the plugin-template repository.
Click on Use this template.
Choose the GitHub account you want to link and the repository name for the new plugin.
Clone the new repository: git clone git@github.com:{{user}}/{{name}}.git.
Open the cloned directory in IntelliJ IDEA.
Enable annotations processors.
If you are using an IntelliJ IDEA < 2020.03, install the lombok plugins (if not, it's included by default).
Once you completed the steps above, you should see a similar directory structure:
As you can see, there is one generated plugin: the Example class representing the Example plugin (a task).
A project typically hosts multiple plugins. We call a project a group of plugins, and you can have multiple sub-groups inside a project by splitting plugins into different packages. Each package that has a plugin class is a sub-group of plugins.
Plugin icons
Plugin icons need to be added in the SVG format ‚Äî see an example here in the JIRA plugin.
Where can you find icons?
for proprietary systems, Wikipedia is a good source of SVG icons
for AWS services, the AWS icons is a great resource
Google Fonts Icons
Feather Icons.
Was this page helpful?
Yes
No
Docs
Plugin Developer Guide
Plugin Developer Guide
Gradle Configuration""""""",609,2844,kestra
https://kestra.io/docs/plugin-developer-guide/gradle,"""""""DocsPlugin Developer GuideGradle Configuration
Gradle Configuration
Table of Contents
Mandatory configuration
Other configurations
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
We use Gradle as a build tool. This page will help you configure Gradle for your plugin.
Mandatory configuration
The first thing you need to configure is the plugin name and the class package.
Change in settings.gradle the rootProject.name = 'plugin-template' with your plugin name.
Change the class package: by default, the template provides a package io.kestra.plugin.templates, just rename the folder in src/main/java & src/test/java
Change the package name on build.gradle: replace group ""io.kestra.plugin.templates"" to the package name.
Now you can start developing your task or look at other optional gradle configuration.
Other configurations
Include some dependencies on plugins
You can add as many dependencies to your plugins, they will be isolated in the Kestra runtime. Thanks to this isolation, we ensure that two different versions of the same library will not clash and have runtime errors about missing methods.
The build.gradle handle most of Kestra use case by default using compileOnly group: ""io.kestra"", name: ""core"", version: kestraVersion for Kestra libs.
But if your plugin need some dependencies, you can add as many as you want that will be isolated, you just need to add api dependencies:
groovy
api group: 'com.google.code.gson', name: 'gson', version: '2.8.6'
Was this page helpful?
Yes
No
Plugin Developer Guide
Setup for Plugin Development
Plugin Developer Guide
Develop a Task""""""",348,1614,kestra
https://kestra.io/docs/plugin-developer-guide/task,"""""""DocsPlugin Developer GuideDevelop a Task
Develop a Task
Table of Contents
Runnable Task
Class annotations
Class declaration
Properties
Run
Outputs
Exception
Metrics
Documentation
Flowable Task
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Here are the instructions to develop a new task.
Runnable Task
Here is a simple Runnable Task that reverses a string
Lets look at this one more deeply:
Class annotations
java
@SuperBuilder
@ToString
@EqualsAndHashCode
@Getter
@NoArgsConstructor
These are required in order to make your plugin work with Kestra. These are Lombok annotations that allow Kestra and its internal serialization to work properly.
Class declaration
java
public class ReverseString extends Task implements RunnableTask<ReverseString.Output>
ReverseString is the name of your task, and it can be used on Kestra with type: io.kestra.plugin.templates.ReverseString (aka: {{package}}.{{className}}).
Class must extend Task to be usable.
implements RunnableTask<ReverseString.Output>: must implement RunnableTask to be discovered and must declare the output of the task ReverseString.Output.
Properties
java
    @PluginProperty(dynamic = true)
    private String format;
Declare all the properties that you can pass to the current task in a flow. For example, this will be a valid yaml for this task:
yaml
type: io.kestra.plugin.templates.ReverseString
format: ""{{ outputs.previousTask.name }}""
You can declare as many properties as you want. All of these will be filled by Kestra executors.
You can use any serializable by Jackson for your properties (ex: Double, boolean, ...). You can create any class as long as the class is Serializable.
Properties validation
Properties can be validated using javax.validation.constraints.* annotations. When the user creates a flow, your task properties will be validated before insertion and prevent wrong definition to be inserted.
The default available annotations are:
@Positive
@AssertFalse
@AssertTrue
@Max
@Min
@Negative
@NegativeOrZero
@Positive
@PositiveOrZero
@NotBlank
@NotNull
@Null
@NotEmpty
@Past
@PastOrPresent
@Future
@FutureOrPresent
You can also create your own custom validation. You must defined the annotation as follows:
java
@Retention(RetentionPolicy.RUNTIME)
@Constraint(validatedBy = { })
public @interface CronExpression {
    String message() default ""invalid cron expression ({validatedValue})"";
}
And you must also define a factory to inject the validation method:
java
@Factory
public class ValidationFactory {
private static final CronParser CRON_PARSER = new CronParser(CronDefinitionBuilder.instanceDefinitionFor(CronType.UNIX));
    @Singleton
    ConstraintValidator<CronExpression, CharSequence> cronExpressionValidator() {
        return (value, annotationMetadata, context) -> {
            if (value == null) {
                return true;
            }
            try {
                Cron parse = CRON_PARSER.parse(value.toString());
                parse.validate();
            } catch (IllegalArgumentException e) {
                return false;
            }
            return true;
        };
    }
}
Run
java
    @Override
    public ReverseString.Output run(RunContext runContext) throws Exception {
        Logger logger = runContext.logger();
        String render = runContext.render(format);
        logger.debug(render);
        return Output.builder()
            .reverse(StringUtils.reverse(render))
            .build();
    }
The run method is where the main logic of your task will do all the work needed. You can use any Java code here with any required libraries as long as you have declared them in the Gradle configuration.
Log
java
Logger logger = runContext.logger();
To have a logger, you need to use this instruction. This will provide a logger for the current execution and will log appropriately. Do not create your own custom logger in order to track logs on the UI.
Render variables
java
String render = runContext.render(format);
In order to use dynamic expressions, you need to render them i.e. transform the properties with Pebble. Do not forget to render variables if you need to pass an output from previous variables.
You also need to add the annotation @PluginProperty(dynamic = true) in order to explain in the documentation that you can pass some dynamic variables. Provide a @PluginProperty annotation even if you didn't set any of its attributes for all variables or the generated documentation will not be accurate.
Kestra storage
You can read any files from Kestra storage using the method runContext.uriToInputStream()
java
final URI from = new URI(runContext.render(this.from));
final InputStream inputStream = runContext.uriToInputStream(from);
You will get an InputStream in order to read the file from Kestra storage (coming from inputs or task outputs).
You can also write files to Kestra's internal storage using runContext.putTempFile(File file). The local file will be deleted, so you must use a temporary file.
java
File tempFile = File.createTempFile(""concat_"", """");
runContext.putTempFile(tempFile)
Do not forget to provide Outputs with the link generated by putTempFile in order for it to be usable by other tasks.
Outputs
java
public class ReverseString extends Task implements RunnableTask<ReverseString.Output> {
    @Override
    public ReverseString.Output run(RunContext runContext) throws Exception {
        return Output.builder()
            .reverse(StringUtils.reverse(render))
            .build();
    }
    @Builder
    @Getter
    public static class Output implements io.kestra.core.models.tasks.Output {
        @Schema(
            title = ""The reversed string""
        )
        private final String reverse;
    }
}
Each task must return a class instance with output values that can be used in the next tasks. You must return a class that implements io.kestra.core.models.tasks.Output. You can add as many properties as you want, just keep in mind that outputs need to be serializable. At execution time, outputs can be accessed by downstream tasks by leveraging outputs expressions e.g. {{ outputs.task_id.output_attribute }}.
If your task doesn't provide any outputs (mostly never), you use io.kestra.core.models.tasks.VoidOutput:
java
public class NoOutput extends Task implements FlowableTask<VoidOutput> {
    @Override
    public VoidOutput run(RunContext runContext) throws Exception {
        return null;
    }
}
Exception
In the run method, you can throw any Exception that will be caught by Kestra and will fail the execution. We advise you to throw any Exception that can break your task as soon as possible.
Metrics
You can expose metrics to add observability to your task. Metrics will be recorded with the execution and can be accessed via the UI or as Prometheus metrics.
There are two kinds of metrics available:
Counter: Counter.of(""your.counter"", count, tags); with args
String name: The name of the metric
Double|Long|Integer|Float count: the associated counter
String... tags: a list of tags associated with your metric
Timer: Timer.of(""your.duration"", duration, tags);
String name: The name of the metric
Duration duration: the recorded duration
String... tags: a list of tags associated with your metric
To save metrics with the execution, you need to use runContext.metric(metric).
Name
Must be lowercase separated by dots.
Tags
Must be pairs of tag key and value. An example of two valid tags (zone and location) is:
java
Counter.of(""your.counter"", count, ""zone"", ""EU"", ""location"", ""France"");
Documentation
Remember to document your tasks. For this, we provide a set of annotations explained in the Document each plugin section.
Flowable Task
Flowable tasks are the most complex tasks to develop, and will usually be available from the Kestra core. You will rarely need to create a flowable task by yourself.
When developing such tasks, you must make it fault-tolerant as an exception thrown by a flowable task can endanger the Kestra instance and lead to inconsistencies in the flow execution.
Keep in mind that a flowable task will be evaluated very frequently inside the Executor and must have low CPU usage; no I/O should be done by this kind of task.
In the future, complete documentation will be available here. In the meantime, you can find all the actual Flowable tasks here to have some inspiration for Sequential or Parallel tasks development.
Was this page helpful?
Yes
No
Plugin Developer Guide
Gradle Configuration
Plugin Developer Guide
Develop a Trigger""""""",1769,8493,kestra
https://kestra.io/docs/plugin-developer-guide/trigger,"""""""DocsPlugin Developer GuideDevelop a Trigger
Develop a Trigger
Table of Contents
Documentation
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Here is how you can develop a Trigger.
The Trigger example below will create an execution randomly
You need to extend PollingTriggerInterface and implement the Optional<Execution> evaluate(ConditionContext conditionContext, TriggerContext context) method.
You can have any properties you want, like for any task (validation, documentation, ...), and everything works the same way.
The evaluate method will receive these arguments:
ConditionContext conditionContext: a ConditionContext which includes various properties such as the RunContext in order to render your properties.
TriggerContext context: to have the context of this call (flow, execution, trigger, date, ...).
In this method, you add any logic you want: connect to a database, connect to remote file systems, ... You don't have to take care of resources, Kestra will run this method in its own thread.
This method must return an Optional<Execution> with:
Optional.empty(): if the condition is not validated.
Optional.of(execution): with the execution created if the condition is validated.
You have to provide a Output for any output needed (result of query, result of file system listing, ...) that will be available for the flow tasks within the {{ trigger.* }} variables.
Take care that the trigger must free the resource for the next evaluation. For each interval, this method will be called and if the conditions are met, an execution will be created.
To avoid this, move the file or remove the record from the database; take an action to avoid an infinite triggering.
Documentation
Remember to document your triggers. For this, we provide a set of annotations explained in the Document each plugin section.
Was this page helpful?
Yes
No
Plugin Developer Guide
Develop a Task
Plugin Developer Guide
Develop a Condition""""""",393,1956,kestra
https://kestra.io/docs/plugin-developer-guide/condition,"""""""DocsPlugin Developer GuideDevelop a Condition
Develop a Condition
Table of Contents
Documentation
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Here is how you can develop a new Condition.
Here is a simple condition example that validate the current flow:
You just need to extend Condition and implement the boolean test(ConditionContext conditionContext) method.
You can have any properties you want like for any task (validation, documentation, ...), everything works the same way.
The test will receive a ConditionContext that will expose:
conditionContext.getFlow(): the current flow.
conditionContext.getExecution(): the current execution that can be null for Triggers.
conditionContext.getRunContext(): a RunContext in order to render your properties.
This method must simply return a boolean in order to validate the condition.
Documentation
Remember to document your conditions. For this, we provide a set of annotations explained in the Document each plugin section.
Was this page helpful?
Yes
No
Plugin Developer Guide
Develop a Trigger
Plugin Developer Guide
Add Unit Tests""""""",218,1113,kestra
https://kestra.io/docs/plugin-developer-guide/unit-tests,"""""""DocsPlugin Developer GuideAdd Unit Tests
Add Unit Tests
Table of Contents
Unit test a RunnableTask
Unit test with a full flow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
To avoid regression, we recommend adding unit tests for all your tasks.
There are two main ways to unit-test your tasks. Both will be regular Micronaut tests, and hence must be annotated with @MicronautTest.
Unit test a RunnableTask
This is the most common way to test a RunnableTask. You create your RunnableTask, and test output or Exception. This will cover most of the cases.
Example
This is same as any Java unit tests, feel free to use any dependencies, test methods, start docker containers, ...
Unit test with a full flow
In case you want to add some unit test with a full flow (In some rare case, it can be necessary; for example, for FlowableTask), here is how you can write the unit test with the full flow.
Example
With this, you will:
Inject all dependencies with @Inject.
On init(), load all the flow on the src/resources/flow directory.
Run a full execution with Execution execution = runnerUtils.runOne(null, ""io.kestra.templates"", ""example"");. The first parameter is for the tenantId which can be null on tests.
With this execution, you can look at all the properties you want to control (status, taskRunList number, outputs, ...)
To make it work, you need to have an application.yml file with this minimum configuration:
yaml
kestra:
  repository:
    type: memory
  queue:
    type: memory
  storage:
    type: local
    local:
      basePath: /tmp/unittest
And these dependencies on your build.gradle:
groovy
    testImplementation group: ""io.kestra"", name: ""core"", version: kestraVersion
    testImplementation group: ""io.kestra"", name: ""repository-memory"", version: kestraVersion
    testImplementation group: ""io.kestra"", name: ""runner-memory"", version: kestraVersion
    testImplementation group: ""io.kestra"", name: ""storage-local"", version: kestraVersion
This will enable the in memory runner and will run your flow without any other dependencies (kafka, ...).
Was this page helpful?
Yes
No
Plugin Developer Guide
Develop a Condition
Plugin Developer Guide
Document Your Plugin""""""",509,2203,kestra
https://kestra.io/docs/plugin-developer-guide/document,"""""""DocsPlugin Developer GuideDocument Your Plugin
Document Your Plugin
Table of Contents
Document the plugin group
Manifest attributes
Additional markdown files
Group Icon
Document the plugin sub-groups
Sub-Group Icon
Document each plugin
Document the plugin class
Document the plugin properties
Document the plugin outputs
Document the plugin metrics
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Here is how you can document your plugin.
First, let us remember the organization of a plugin project:
The Gradle project can contain several plugins, we call it a group of plugins.
The package in which a plugin is written in is called a sub-group of plugins. Sometimes, there is only one sub-group, in which case the group and the sub-group are the same.
Each class is a plugin that provides one task, trigger, condition, etc.
The plugin documentation will be used on the Kestra website and the Kestra UI.
We provide a way to document each level of a plugin project.
Document the plugin group
Manifest attributes
Kestra uses custom manifest attributes to provide top-level group documentation.
The following manifest attributes are used to document the group of plugins:
X-Kestra-Title: by default, the Gradle project.name property is used.
X-Kestra-Group: by default, the Gradle group.id property with an additional group name is used.
X-Kestra-Description: by default, the Gradle project.description property is used.
X-Kestra-Version: by default, the Gradle project.version property is used.
If you follow the plugin structure of the template on GitHub, you should have something like this:
Example
As you can see, the most important documentation attribute is the description, which should be a short sentence describing the plugins.
Additional markdown files
You can add additional markdown files in the src/main/resources/doc directory.
If there is a file src/main/resources/doc/<plugin-group>, it will be inlined inside the main documentation page as the long description for the group of plugins.
For example, for the GCP group of plugins, the file is src/main/resources/doc/io.kestra.plugin.gcp, and it contains authentication information that applies to all tasks.
If there are files inside the src/main/resources/doc/guides directory, we will list them in a Guides section on the documentation for the group of plugins.
Group Icon
It is possible to provide an icon representing the whole plugin group. If there is a SVG file src/main/resources/icons/plugin-icon.svg, it will be used as the group icon.
Document the plugin sub-groups
Each sub-group can be documented via the io.kestra.core.models.annotations.PluginSubGroup annotation that must be defined at the package level in a package-info.java file.
The @PluginSubGroup annotation allows setting:
The sub-group title. If not set, the name of the sub-group will be used.
The sub-group description, which is a short sentence introducing the sub-group.
The sub-group categories, which is a list of PluginCategory. If not set, the category MISC will be used.
For example, for the GCP BigQuery sub-group:
java
@PluginSubGroup(
    title = ""BigQuery"",
    description = ""This sub-group of plugins contains tasks for accessing Google Cloud BigQuery.\n"" +
        ""BigQuery is a completely serverless and cost-effective enterprise data warehouse."",
    categories = { PluginSubGroup.PluginCategory.DATABASE, PluginSubGroup.PluginCategory.CLOUD }
)
package io.kestra.plugin.gcp.bigquery;
import io.kestra.core.models.annotations.PluginSubGroup;
Sub-Group Icon
Each plugin sub-group can define an icon representing plugins contained in the sub-group. If there is a SVG file src/main/resources/icons/<plugin-sub-group>.svg, it will be used as the icon for the corresponding plugins.
For example, for the GCP BigQuery sub-group, the src/main/resources/icons/io.kestra.plugin.gcp.bigquery.svg file is used.
Document each plugin
Plugin documentation will generate a JSON Schema that will be used to validate flows. It also generates documentation for both the UI and the website (see the kestra plugins doc command).
Document the plugin class
Each plugin class must be documented via the following:
The io.kestra.core.models.annotations.Plugin annotation allows providing examples.
The io.swagger.v3.oas.annotations.media.Schema annotation, which the title attribute will use as the plugin description.
For example, the Query task of the PostgreSQL group of plugins is documented as follows:
java
@Schema(
    title = ""Query a PostgresSQL server.""
)
@Plugin(
    examples = {
        @Example(
            full = true,
            title = ""Execute a query."",
            code = """"""
                id: query_postgres
                namespace: company.team
                tasks:
                  - id: query
                    type: io.kestra.plugin.jdbc.postgresql.Query
                    url: jdbc:postgresql://127.0.0.1:56982/
                    username: pg_user
                    password: pg_password
                    sql: |
                      select concert_id, available, a, b, c, d, play_time, library_record, floatn_test, double_test, real_test, numeric_test, date_type, time_type, timez_type, timestamp_type, timestampz_type, interval_type, pay_by_quarter, schedule, json_type, blob_type from pgsql_types
                    fetchType: FETCH
                """"""
        )
    }
)
For convenience, the code attribute of the @Example annotation is a list of strings. Each string will be a line of the example. That avoids concatenating multi-line strings in a single attribute.
You can add multiple examples if needed.
Document the plugin properties
In a plugin, all properties must be annotated by io.kestra.core.models.annotations.PluginProperty and should provide documentation via the io.swagger.v3.oas.annotations.media.Schema annotation and validation rules via javax.validation.constraints.*.
The @PluginProperty annotation contains two attributes:
dynamic: set it to true if the property will be rendered dynamically.
additionalProperties: you can use it to denote the sub-type of the property. For example, when using a Map<String, Message>, you can set it to Message.class.
The Swagger @Schema annotation contains a lot of attributes that can be used to document the plugin properties. The most useful are:
title: a short description of a property.
description: long description of a property.
anyOf: a list of allowed sub-types of a property. Use it when the property type is an interface, an abstract class, or a class inside a hierarchy of classes to denote possible sub-types. This should be set when the property type is Object.
The @Schema and @PluginProperty annotations can be used on fields, methods, or classes.
Many tasks can take input from multiple sources on the same property. They usually have a single from property, a string representing a file in the Kestra Storage, a single object, or a list of objects. To document such property, you can use anyOf this way:
java
@PluginProperty(dynamic = true)
@NotNull
@Schema(
    title = ""The source of the published data."",
    description = ""Can be an internal storage URI, a list of Pub/Sub messages, or a single Pub/Sub message."",
    anyOf = {String.class, Message[].class, Message.class}
)
private Object from;
Due to limitations on how JSON Schema works, you cannot add @Schema on a Java enum type and the plugin property that uses this type. We advise avoiding using @Schema on enumerations.
Document the plugin outputs
Outputs should be documented with the io.swagger.v3.oas.annotations.media.Schema annotation in the same way as plugin properties. Please read the section above for more information.
Only use the annotation mentioned above. Never use @PluginProperty on an output.
Document the plugin metrics
Tasks can expose metrics; to document those you must add a @Metric annotation instance for each metric in the @Plugin annotation instance of the task.
For example, to document two metrics: a length metric of type counter and a duration metric of type timer, you can use the following:
java
@Plugin(
    metrics = {
        @Metric(name = ""length"", type = Counter.TYPE),
        @Metric(name = ""duration"", type = Timer.TYPE)
    }
)
Was this page helpful?
Yes
No
Plugin Developer Guide
Add Unit Tests
Plugin Developer Guide
Build and Publish a Plugin""""""",1736,8337,kestra
https://kestra.io/docs/plugin-developer-guide/publish,"""""""DocsPlugin Developer GuideBuild and Publish a Plugin
Build and Publish a Plugin
Table of Contents
Build a plugin
Use a custom docker image with your plugin
Publish a plugin
GitHub Actions
Publish to Maven Central
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use the included Gradle task to build the plugin. Then, you can publish it to Maven Central.
Build a plugin
To build your plugin, execute the ./gradlew shadowJar command from the plugin directory.
The resulting JAR file will be generated in the build/libs directory.
To use this plugin in your Kestra instance, add this JAR to the Kestra plugins path.
Use a custom docker image with your plugin
Adding this Dockerfile to the root of your plugin project:
FROM kestra/kestra:develop

COPY build/libs/* /app/plugins/
You can build and run the image with the following command assuming you're in the root directory of your plugin: ./gradlew shadowJar && docker build -t kestra-custom . && docker run --rm -p 8080:8080 kestra-custom server local
You can now navigate to http://localhost:8080 and start using your custom plugin. Feel free to adapt the Dockerfile to your needs (eg. if you plan to use multiple custom plugins, include all builds directory in it).
Publish a plugin
Here is how you can publish your plugin to Maven Central.
GitHub Actions
The plugin template includes a GitHub Actions workflow to test and publish your plugin. You can extend it by adding any additional testing or deployment steps.
Publish to Maven Central
The template includes a Gradle task that will publish the plugin to Maven Central. You need a Maven Central account in order to publish your plugin.
You only need to configure the gradle.properties to have all required properties:
yaml
sonatypeUsername=
sonatypePassword=
signing.keyId=
signing.password=
signing.secretKeyRingFile=
There is a pre-configured GitHub Actions workflow in the .github/workflows/main.yml file that you can customize to your need:
Example
Was this page helpful?
Yes
No
Plugin Developer Guide
Document Your Plugin
Docs
How-to Guides""""""",457,2078,kestra
https://kestra.io/docs/how-to-guides,"""""""DocsHow-to Guides
How-to Guides
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Learn Kestra with our hands-on guides.
Adjust the filters based on your needs or search directly.
Filter by topic
Filter by stage
Getting Started
Access Local Files in Kestra
Access locally stored files on your machine.
Scripting
Integrations
Getting Started
Configure Alerts inside of Kestra
Configure alerts when workflow failures occurs.
DevOps
Kestra Concepts
Intermediate
Extend Kestra with the API
Extend Kestra by using the API.
Kestra Workflow Components
Advanced
Use Azure Managed Workload on Kestra
How to use Azure Workload identity to provide access to resources such as Azure Key Vault in Kestra
Kestra Concepts
DevOps
Integrations
Intermediate
Conditional Branching
How to use the Switch task to branch the flow based on a value.
Kestra Concepts
Advanced
Build a Custom Plugin for Kestra
Build your own Custom Plugin for Kestra.
Kestra Concepts
DevOps
Getting Started
Using Dataform in Kestra
Run transformations on BigQuery using Dataform in Kestra
Integrations
Getting Started
Manage dbt projects with Kestra's Code Editor
Edit dbt code from Kestra's Code Editor
Integrations
Intermediate
Debezium Tasks and Triggers
How to enable databases to leverage Debezium tasks and triggers.
Integrations
Intermediate
ETL Pipelines in Kestra
Build ETL pipelines in Kestra using DuckDB, Python and Task Runners.
Integrations
Intermediate
Validate and Deploy your Flows with GitHub Actions
How to use GitHub Actions to automatically validate and deploy your flows to Kestra.
Integrations
DevOps
Version Control
Getting Started
Run Go inside of your Flows
Run Go code directly inside of your Flows and generate outputs.
Scripting
Getting Started
Configure Google Service Account
Setup a Google Service Account inside of Kestra.
Integrations
Best Practices
Getting Started
Connect Google Sheets to Kestra
Learn step-by-step how to read data from a Google Sheet inside of a Kestra flow.
Integrations
Getting Started
Make HTTP Requests inside of your flows
Make HTTP Requests to fetch data and generate outputs.
Integrations
Getting Started
Pass Inputs via an API call
Passing Inputs via an API Call
Kestra Workflow Components
Getting Started
Validate Inputs with Enum Data Type
Input validation with the Enum data type
Kestra Workflow Components
Getting Started
Run JavaScript inside of your Flows
Run Node.js code directly inside of your Flows and generate outputs.
Scripting
Getting Started
Connect JavaScript Apps to Kestra
Integrate Kestra into your JavaScript App using Webhooks.
Scripting
Integrations
Getting Started
Run Julia inside of your Flows
Run Julia code directly inside of your Flows and generate outputs.
Scripting
Getting Started
Configure KeyCloak SSO in Kestra
Setup KeyCloak SSO to manage authentication for users.
Kestra Concepts
Getting Started
Set Up Secrets from a Helm Chart
How to add Kestra Secrets to your Helm Chart deployment.
Kestra Concepts
DevOps
Advanced
Long running and intensive processes on Kubernetes
Schedule long running and intensive processes with Kestra on Kubernetes.
DevOps
Kestra Workflow Components
Intermediate
Loop Over a List of Values
How to iterate over a list of values in your flow.
Kestra Workflow Components
Intermediate
Configure Monitoring with Grafana & Prometheus
Set up Prometheus and Grafana for monitoring Kestra.
DevOps
Best Practices
Intermediate
Multiple Condition Listener
How to set up a Flow to only trigger when multiple conditions are met.
Kestra Workflow Components
Getting Started
Handling null and undefined values
How to use the null coalescing operator to handle null and undefined values.
Best Practices
Getting Started
Parallel vs. Sequential Tasks
When to use parallel tasks and when to use sequential tasks in Kestra.
Kestra Concepts
Getting Started
Pause and Resume Flows in Kestra
How to Pause and Resume your flows.
Kestra Concepts
Getting Started
Run Perl inside of your Flows
Run Perl code directly inside of your Flows and generate outputs.
Scripting
Getting Started
Run Powershell inside of your Flows
Run PowerShell code inside of your flow.
Scripting
Getting Started
Push Flows to a Git Repository
Push your Flows to a Git Repository with the PushFlows Task.
Version Control
DevOps
Getting Started
Push Namespace Files to a Git Repository
Push files in your namespace to a Git Repository with the PushNamespaceFiles Task.
Version Control
DevOps
Getting Started
Run Python inside of your Flows
Run Python code directly inside of your Flows and generate outputs.
Scripting
Getting Started
Manage Python Dependencies
Manage your Python dependencies inside of Kestra.
Scripting
Getting Started
Run R inside of your Flows
Run R code directly inside of your Flows and generate outputs.
Scripting
Getting Started
Realtime Triggers
How to React to events as they happen with millisecond latency.
Kestra Workflow Components
Getting Started
Revision History & Rollback
Use revision history to rollback to an older version of a flow.
Kestra Concepts
Version Control
Getting Started
Run Ruby inside of your Flow
Run Ruby code directly inside of your Flows and generate outputs.
Scripting
Getting Started
Run Rust inside of your Flows
Run Rust code directly inside of your Flows and generate outputs.
Scripting
Getting Started
Configure Secrets
How you can use secrets in various Kestra use cases.
Kestra Concepts
Getting Started
Run Shell scripts inside of your Flows
Run Shell scripts directly inside of your Flows and generate outputs.
Scripting
Getting Started
Migrate from Shipyard
Migrate from Shipyard to Kestra.
Best Practices
Getting Started
Slack Events API
Trigger Kestra flows based on Slack events.
Integrations
Getting Started
Using SQLMesh to run dbt Projects
Using SQLMesh to run dbt project with Kestra.
Integrations
Getting Started
Configure SSL for Kestra
Configure secure access via https to the Kestra UI.
Kestra Concepts
Getting Started
Sync Flows from a Git Repository
Sync flows from a Git Repository to Kestra with the SyncFlows Task.
Version Control
DevOps
Intermediate
Synchronous Executions API
Manage the Executions API Synchronously.
Integrations
Getting Started
Sync Namespace Files from a Git Repository
Sync files from a Git Repository to Kestra with SyncNamespaceFiles Task.
Version Control
DevOps
Advanced
Modularize your triggers and schedules with Terraform
Scale your codebase using Terraform to template and make scheduling a breeze
DevOps
Integrations
Advanced
Leverage Terraform for flow modularity
Scale your codebase using Terraform to template and define flows
DevOps
Integrations
Beginner
Access Values Between Flows
How to access values across different flows.
Kestra Concepts
Getting Started
Setup Webhooks to trigger Flows
Execute flows using the Webhooks Trigger.
Integrations
Was this page helpful?
Yes
No
Plugin Developer Guide
Build and Publish a Plugin
How To Guides
Access Local Files in Kestra""""""",1583,6934,kestra
https://kestra.io/docs/enterprise,"""""""DocsEnterprise Edition
Enterprise Edition
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to configure Kestra Enterprise Edition.
The Enterprise Edition is a robust, enterprise-grade version of Kestra deployed to your private infrastructure. It offers security and governance features including multi-tenancy, authentication, SSO, RBAC, namespace-level management, distributed worker groups, worker isolation, secrets manager integrations, audit logs, and more.
This section describes those features in detail and explains how to configure them.
If you're interested to learn more, get in touch!
Enterprise Edition (EE)
Learn about the Enterprise Edition and how it can help you run Kestra securely and reliably at scale.
Setup
How to setup Kestra Enterprise Edition.
Tenants
How to enable multi-tenancy in your Kestra instance.
Authentication
How to configure the authentication for your Kestra instance.
Single Sign-On (SSO)
How to enable and setup SSO in your Kestra Enterprise instance.
Audit Logs
How to use Audit Logs to govern activities in your Kestra instance.
Namespace Management
How to govern secrets, variables and plugin defaults on a namespace level.
Centralized Task Configuration
How to centrally govern your task configuration in a modular way.
Allowed namespaces
How to manage cross-namespace permissions in the Enterprise Edition.
Kestra EE API
How to interact with Kestra Enterprise Edition using the API.
API Tokens
How to manage API tokens in Kestra.
Kestra EE CLI
How to interact with Kestra Enterprise Edition using the CLI.
Custom Blueprints
How to create and manage Custom Blueprints.
Enterprise Edition FAQ
Frequently asked questions about the Enterprise Edition of Kestra.
Kestra Identity
Common questions about the identity.
Role-Based Access Control (RBAC)
How to manage access and permissions to your instance.
Releases
Release cadence and support policy for Kestra Enterprise Edition (EE).
SCIM Directory Sync
Sync users and groups from your Identity Provider to Kestra using SCIM.
Secrets
How to create and manage Secrets in the Enterprise Edition.
Secrets Manager
How to configure the secrets manager.
Service Accounts
How to create and manage Service Accounts.
Task Runners
Task Runner capabilities and supported plugins.
Worker Group
How to configure Worker Groups in Kestra Enterprise Edition.
Worker Isolation
How to configure worker isolation in Kestra.
Was this page helpful?
Yes
No
How To Guides
Setup Webhooks to trigger Flows
Enterprise
Enterprise Edition (EE)""""""",540,2568,kestra
https://kestra.io/docs/enterprise/enterprise-edition,"""""""DocsCloud & Enterprise Edition APIEnterprise Edition (EE)
Enterprise Edition (EE)
Table of Contents
Key Features
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Learn about the Enterprise Edition and how it can help you run Kestra securely and reliably at scale.
Designed for production workloads with high security and compliance requirements, deployed in your private cloud.
Key Features
Kestra Enterprise is built on top of the Open Source Edition. However, it has a different architecture, with a few key differences listed below.
‚ö°Ô∏èHigh Availability: Kestra Enterprise is designed to be highly-available and fault-tolerant. It uses a Kafka cluster as a backend for event-driven orchestration, and Elasticsearch for storing logs and metrics. This does not only improve performance, but also ensures that there is no single point of failure, and that the system can scale to handle large workloads.
‚ö°Ô∏èMulti-Tenancy: the Enterprise Edition supports multi-tenancy, allowing you to create separate environments for different teams or projects. Each tenant is completely isolated from the others, and can be configured with its own access control policies.
‚ö°Ô∏èSecurity and Access Control: Kestra Enterprise supports Single Sign-On (SSO) and Role-Based Access Control (RBAC), allowing you to integrate with your existing identity provider and manage user access to workflows and resources.
‚ö°Ô∏èEnterprise Features: this Kestra edition comes with additional enterprise features, including Audit Logs, Worker Groups, Custom Blueprints, Namespace-level Secrets, Variables and Plugin Defaults.
‚ö°Ô∏èSecrets Management: Kestra Enterprise can securely store and manage secrets. You can also integrate your existing secret manager, such as AWS Secret Manager, Azure Key Vault, Elasticsearch, Google Secret Manager, and Hashicorp Vault.
‚ö°Ô∏èSupport: the Enterprise edition comes with guaranteed SLAs and priority support.
‚ö°Ô∏èOnboarding: we provide onboarding and training for your team to help you get started quickly.
If you're interested to learn more, get in touch!
Kestra Cloud (Alpha): if you don't have the capacity to host the Kestra Enterprise Edition yourself, you can try out Kestra Cloud, a fully managed SaaS product, hosted by the Kestra team. Kestra Cloud is currently in private Alpha. If you are interested in trying it out, sign up here.
Was this page helpful?
Yes
No
Docs
Enterprise Edition
Enterprise
Setup""""""",524,2466,kestra
https://kestra.io/docs/enterprise/setup,"""""""DocsCloud & Enterprise Edition APISetup
Setup
Table of Contents
Step 1: Validate Configuration
Step 2: Create Your First Tenant
Step 3: Create Your First User
Step 4: Start Kestra UI
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to setup Kestra Enterprise Edition.
The Setup Page will guide you through the initial configuration of your instance.
When you launch Kestra Enterprise Edition for the first time, you will be prompted to configure your instance. This includes setting up your first tenant, creating your first user, and starting the Kestra UI.
Step 1: Validate Configuration
The first screen shows the main configuration of your instance. It displays:
whether multitenancy is enabled
whether default tenant is enabled ‚Äî if yes, you can skip the Step 2 allowing you to create your first tenant
which database backend is configured (e.g, Postgres or Elasticsearch)
which queue backend is configured (e.g, Postgres or Kafka)
which internal storage backend is configured (e.g, S3, GCS, Azure Blob Storage, Minio, or local storage)
which secret backend is configured (e.g, Vault, AWS Secrets Manager, Elasticsearch, or not set up yet)
This step allows you to confirm whether your configuration is valid. If not, you can correct the configuration, restart the instance, and start the setup from scratch.
Step 2: Create Your First Tenant
If multitenancy is enabled, you will be prompted to create your first tenant.
If you choose to create a tenant, you will be asked to input the tenant id and tenant name, for example:
tenant id: stage
tenant name: Staging Environment.
If you enabled a default tenant, you can skip this step.
Step 3: Create Your First User
Now that you have your instance configured, you will be prompted to create your first user. This user will have a Super-Admin role for the instance, and will be able to manage tenants, users and roles.
Step 4: Start Kestra UI
Once your tenant and user are configured, you will be prompted to start Kestra UI. This will take you to the instance on the first tenant, logged in as the first user.
Was this page helpful?
Yes
No
Enterprise
Enterprise Edition (EE)
Enterprise
Tenants""""""",500,2208,kestra
https://kestra.io/docs/enterprise/tenants,"""""""DocsCloud & Enterprise Edition APITenants
Tenants
Table of Contents
What is Multi-Tenancy
Key Benefits of Multi-Tenancy
How to Enable Multi-Tenancy
Default Tenant
Creating and Managing Tenants
Creating a Tenant from the UI
Creating a Tenant from the CLI
Creating a Tenant from the API
Creating a Tenant from Terraform
Admin Role Assignment
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.13.0
How to enable multi-tenancy in your Kestra instance.
What is Multi-Tenancy
A tenant represents an isolated environment within a single Kestra instance.
Each tenant functions as a separate entity with its own resources, such as flows, triggers, or executions. Multi-tenancy enables different teams, projects, or customers to operate independently within the same Kestra instance, ensuring data privacy, security along with separation of resources between business units, teams, or customers. For example, you can have a dev tenant for development, a staging tenant for testing, and a prod tenant for production.
You can think of multi-tenancy as running multiple virtual instances in a single physical instance of Kestra Cloud or Kestra Enterprise Edition.
When multi-tenancy is enabled, all resources (such as flows, triggers, executions, RBAC, and more) are isolated by the tenant. This means that you can have a flow with the same identifier and the same namespace in multiple tenants at the same time.
Data stored inside the internal storage are also isolated by tenants.
Multi-tenancy functionality is not visible to end-users from the UI except for the tenant selection dropdown menu. That dropdown menu lists all tenants a user has access to, allowing them to switch between tenants easily. Each UI page also includes the tenant ID in the URL e.g. https://demo.kestra.io/ui/yourTenantId/executions/namespace/flow/executionId.
The API URLs also include the tenant identifier. For example, the URL of the API operation to list flows of the marketing namespace is /api/v1/flows/marketing when multi-tenancy is not enabled. Once you enable multi-tenancy and create a tenant prod, this URL becomes /api/v1/prod/flows/marketing. You can check the API Guide for more information.
Tenants must be created upfront, and a user needs to be granted access to use a specific tenant.
Key Benefits of Multi-Tenancy
Data Isolation: each tenant's data, configuration and code are isolated and inaccessible to other tenants.
Resource Isolation: each tenant's resources are isolated from other tenants ‚Äî incl. flows, triggers, executions, logs, audit logs, secrets, etc.
Simple Configuration: you can easily create new tenants instantly giving you a fresh, fully-isolated workspace accessible from your existing Kestra instance.
Intuitive UI Navigation: the UI provides a dropdown as well as tenant identifiers included in the URL to make switching between tenants seamless.
How to Enable Multi-Tenancy
By default, multi-tenancy is disabled. To enable it, add the following configuration:
yaml
kestra:
  ee:
    tenants:
      enabled: true
If you enable multi-tenancy in a Kestra instance with existing resources (flows, namespaces, executions), make sure to execute the kestra auths users sync-access command to synchronize the existing access permissions with the default tenant.
Default Tenant
When enabling multi-tenancy, you can also decide whether to enable the default tenant or not. Default tenant is a tenant without an identifier (aka the null tenant). It exists for backward compatibility when multi-tenancy is enabled in an existing Kestra instance. If you disable the default tenant in a Kestra instance that already has flows and executions, you will no longer be able to access them.
When multi-tenancy is enabled in a new Kestra instance, it's recommended to disable the default tenant so that all tenants will have an identifier. This way, all tenants are explicitly defined and can be referenced by their ID.
By default, multi-tenancy is disabled, and the default tenant is set to true. Once you enable multi-tenancy, you can set the default tenant to false to disable it so that your Kestra instance includes only the tenants you explicitly create. Here is how to enable multi-tenancy and disable the default tenant (best practice):
yaml
kestra:
  ee:
    tenants:
      enabled: true
      defaultTenant: false
Note that in Kestra Cloud, multi-tenancy is automatically enabled and the default tenant is disabled.
Once multi-tenancy is enabled, you can create one or more tenants e.g. from the UI, CLI, Terraform or API. Then, you can assign user roles and permissions within each tenant.
Creating and Managing Tenants
Tenants in Kestra can be managed in various ways: from the UI, CLI, API, or Terraform.
Creating a Tenant from the UI
Tenants can be created and managed directly through Kestra's user interface. Go to Administration -> Tenants. Then, click on the Create button:
Fill in the form and click Save:
The user who created the tenant will get an Admin Role for that tenant. You may need to refresh the UI to see updated Roles.
Creating a Tenant from the CLI
Kestra provides CLI commands for tenant creation. The following command will create a tenant with the identifier stage and the name Staging:
bash
kestra tenants create --tenant stage --name ""Staging""
Running kestra tenants create --help will show you all available properties:
bash
$ kestra tenants create --help
Usage: kestra tenants create [-hVv] [--internal-log]
                                [--admin-username=<adminUser>] [-c=<config>]
                                [-l=<logLevel>] [--name=<tenantName>]
                                [-p=<pluginsPath>] [--tenant=<tenantId>]
create a tenant and assign admin roles to an existing admin user
      --admin-username=<adminUser>
                            Username of an existing admin user that will be
                              admin of this tenant
  -c, --config=<config>     Path to a configuration file, default: /Users/anna/.
                              kestra/config.yml)
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log, default:
                              false)
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR; default: INFO)
      --name=<tenantName>   tenant description
  -p, --plugins=<pluginsPath>
                            Path to plugins directory , default:
                              /Users/anna/dev/plugins)
      --tenant=<tenantId>   tenant identifier
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
Creating a Tenant from the API
Tenants can be managed programmatically via Kestra's API. Here is an example of an API call for creating a tenant:
bash
curl -X POST ""https://demo.kestra.io/api/v1/tenants"" \
  -H ""accept: application/json"" \
  -H ""Content-Type: application/json"" \
  -d ""{ \""id\"": \""stage\"", \""name\"": \""staging\"", \""deleted\"": false}""
Creating a Tenant from Terraform
Tenants can be managed via Infrastructure as Code using Kestra's Terraform provider. Here is an example of a Terraform configuration for creating a tenant:
hcl
resource ""kestra_tenant"" ""stage"" {
  tenant_id = ""stage""
  name      = ""staging""
}
Admin Role Assignment
Regardless of which of the above methods you use to create a tenant, the User who creates the tenant will automatically get the Admin Role assigned. That role grants admin rights to that user on that tenant.
Note that there is an exception to this rule if tenant is created by a Super Admin. In that case, the Super Admin will have to explicitly assign the Admin Role for that tenant to themselves or any other User, Service Account or Group.
Was this page helpful?
Yes
No
Enterprise
Setup
Enterprise
Authentication""""""",1732,8004,kestra
https://kestra.io/docs/enterprise/authentication,"""""""DocsCloud & Enterprise Edition APIAuthentication
Authentication
Table of Contents
Basic Authentification
OpenID Connect (OIDC)
Single Sign-On (SSO) with Google, Microsoft, and others
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to configure the authentication for your Kestra instance.
Kestra provides two authentication methods:
Basic Auth: enabled by default
OpenID Connect (OIDC)
By default, the JWT token security is configured to use the default Kestra encryption key. If you haven't already configured it, generate a secret that is at least 256 bits and add it to your kestra configuration as follows:
yaml
kestra:
  encryption:
    secret-key: your-256-bits-secret
This secret must be the same on all your webserver instances and will be used to sign the JWT cookie and encode the refresh token.
If you want to use different keys, you can configure the key using the following configuration:
yaml
micronaut:
  security:
    token:
      jwt:
        generator:
          refresh-token:
            secret: refresh-token-256-bits-secret
        signatures:
          secret:
            generator:
              secret: signature-256-bits-secret
JWT configuration
It is possible to change the JWT cookie behavior using Micronaut Cookie Token Reader configuration. For example, you can define the cookie's maximum lifetime as micronaut.security.token.cookie.cookie-max-age: P2D.
Basic Authentification
The default installation comes with no users defined. To create an administrator account, use the following CLI command:
bash
./kestra auths users create --admin --username=<admin-username> --password=<admin-password> --tenant=<tenant-id>
If you don't have multi-tenancy enabled, you can omit the --tenant parameter.
OpenID Connect (OIDC)
To enable OIDC in the application, make sure to enable OIDC in Micronaut:
yaml
micronaut:
  security:
    oauth2:
      enabled: true
      clients:
        google:
          client-id: ""{{ clientId }}""
          client-secret: ""{{ clientSecret }}""
          openid:
            issuer: ""{{ issuerUrl }}""
More information can be found in the Micronaut OIDC configuration.
Single Sign-On (SSO) with Google, Microsoft, and others
Check the Single Sign-On documentation for more details on how to configure SSO with Google, Microsoft, and other providers.
Was this page helpful?
Yes
No
Enterprise
Tenants
Enterprise
Single Sign-On (SSO)""""""",537,2446,kestra
https://kestra.io/docs/enterprise/sso,"""""""DocsCloud & Enterprise Edition APISingle Sign-On (SSO)
Single Sign-On (SSO)
Table of Contents
Configuring Single Sign-On with OpenID Connect (OIDC)
Using Google as an OIDC SSO Provider
Using Microsoft as an OIDC SSO Provider
Using Microsoft Entra ID as an OIDC SSO Provider
Create an Enterprise Application
Generate Client Secret
Kestra Configuration
Using KeyCloak as an OICD SSO Provider
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to enable and setup SSO in your Kestra Enterprise instance.
Single Sign-On (SSO) is an authentication process that allows users to access multiple applications with one set of login credentials (e.g. Sign in with Google). Kestra supports SSO using the OpenID Connect (OIDC) protocol, which is a simple identity layer built on top of the OAuth 2.0 protocol.
Configuring Single Sign-On with OpenID Connect (OIDC)
To implement OIDC SSO, you'll need to configure the Micronaut framework that Kestra uses under the hood. Start by enabling OIDC in your yaml configuration file as follows:
yaml
micronaut:
  security:
    oauth2:
      enabled: true
      clients:
        oidc-provider:
          client-id: ""{{ clientId }}""
          client-secret: ""{{ clientSecret }}""
          openid:
            issuer: ""{{ issuerUrl }}""
Replace oidc-provider with your chosen provider's name, {{ clientId }} with your client ID, {{ clientSecret }} with your client secret, and {{ issuerUrl }} with your issuer URL.
For more configuration details, refer to the Micronaut OIDC configuration guide.
Using Google as an OIDC SSO Provider
For Google authentication, configure your yaml file in the following way:
yaml
micronaut:
  security:
    oauth2:
      enabled: true
      clients:
        google:
          client-id: ""{{ clientId }}""
          client-secret: ""{{ clientSecret }}""
          openid:
            issuer: 'https://accounts.google.com'
For getting your client-id and client-secret, check out the Google Documentation.
Using Microsoft as an OIDC SSO Provider
To use Microsoft authentication, follow these steps:
yaml
micronaut:
  security:
    oauth2:
      enabled: true
      clients:
        microsoft:
          client-id: ""{{ clientId }}""
          client-secret: ""{{ clientSecret }}""
          openid:
            issuer: 'https://login.microsoftonline.com/common/v2.0/'
For getting your client-id and client-secret, check out the Microsoft Documentation
Using Microsoft Entra ID as an OIDC SSO Provider
Create an Enterprise Application
Visit the Azure portal.
Select Microsoft Entra ID.
Navigate to App registrations.
Click on New registration and provide the necessary details:
Enter a name for your application.
Set ""Supported account types"" (e.g., ""Default Directory only - Single tenant"").
Under ""Redirect URI"", select ""Web"" and enter https://{{ url }}/oauth/callback/microsoft (make sure to use https and the actual URL of your webserver).
Generate Client Secret
Go to Certificates & secrets.
Under Client secrets, click on New client secret.
Copy the generated secret so you can use it in the {{ clientSecret }} field in your configuration.
Kestra Configuration
Copy the ""Application (client) ID"" from the Overview section into {{ clientId }} in your configuration.
In the Endpoints section, find the ""OpenID Connect metadata document"" URL, remove the .well-known/openid-configuration part, and use this as {{ issuerUrl }}.
The final URL should look like https://login.microsoftonline.com/{{ directory }}/v2.0/.
Here's an example Microsoft OIDC configuration:
yaml
micronaut:
  security:
    oauth2:
      enabled: true
      clients:
        microsoft:
          client-id: ""{{ clientId }}""
          client-secret: ""{{ clientSecret }}""
          openid:
            issuer: '{{ issuerUrl }}'
With these settings, Kestra is now configured to use OIDC for SSO with your chosen providers. Ensure that all placeholders are replaced with actual values obtained from the provider's configuration process.
Using KeyCloak as an OICD SSO Provider
In your KeyCloak realm be to sure to have a client with ""Client Authentication"" property set to ""On"" and ""Standard flow"" checked.
Set the ""Valid redirect URI"" property to https://{{ yourKestraServerURL }}/oauth/callback/keycloak.
Then, set the ""Valid post logout redirect URIs"" property to https://{{ yourKestraServerURL }}/logout.
Here's an example of KeyCloak OIDC configuration for Kestra:
yaml
micronaut:
  security:
    oauth2:
      enabled: true
      clients:
        keycloak:
          client-id: ""{{ clientId }}""
          client-secret: ""{{ clientSecret}}""
          openid:
            issuer: ""https://{{ keyCloakServer }}/auth/realms/{{yourRealm}}""
    endpoints:
      logout:
        get-allowed: true
For more configuration details, refer to the Keycloak OIDC configuration guide.
Was this page helpful?
Yes
No
Enterprise
Authentication
Enterprise
Audit Logs""""""",1090,4928,kestra
https://kestra.io/docs/enterprise/audit-logs,"""""""DocsCloud & Enterprise Edition APIAudit Logs
Audit Logs
Table of Contents
What are Audit Logs
Why are Audit Logs important
How to access Audit Logs
How to see a full diff of a specific event
How to use the Details filter to search for specific Audit Log events
How to filter for tenant-specific events
How to Purge Audit Logs
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to use Audit Logs to govern activities in your Kestra instance.
What are Audit Logs
Audit Logs record all activities performed in your Kestra instance by users and service accounts. By reviewing Audit Logs, system administrators can track user activity, and security teams can investigate incidents and ensure compliance with regulatory requirements.
Why are Audit Logs important
The audit log table in Kestra serves as a historical record that developers and system administrators can use to track changes, monitor system usage, and verify system activity. It's a transparency tool that helps in understanding the sequence of activities, ensuring accountability for actions taken, and providing data for troubleshooting and analysis. Given that Audit Logs are immutable, they can also be used to detect and investigate security incidents. If you leverage Kestra edition with Elasticsearch backend, you can also use Kibana to search and visualize your logs.
How to access Audit Logs
You can access Audit Logs from the Administration section in the UI. That UI page provides a detailed table of recorded events, capturing the actions taken within the system:
Each row in the table represents a distinct event with several columns providing specific details:
Resource Type column categorizes the resource that the event is associated with, such as editing a flow (FLOW) or executing it (EXECUTION).
Changes indicates whether a given resource has been created, updated, or deleted.
Actor identifies who performed the action. The user can be a human, system or a service account.
Details section offers an in-depth description of the event, including identifiers such as the id, namespace, flowId, executionId, revision, etc. ‚Äî those fields depend on the type of resource the event is associated with.
Date represents the timestamp of when the event occurred.
How to see a full diff of a specific event
To see a full diff of a specific event, click on the icon at the end of each row to expand the details. The expanded view will show the full diff of the event side-by-side, including the before and after states of a given resource:
Below is an example where we manually change the Execution state from FAILED to SUCCESS and the diff shows the exact change made to the Execution:
How to use the Details filter to search for specific Audit Log events
The Details filter allows you to flexibly search for any Audit Log event using the key:value format. It's a tag-based system which works the same way as Execution Labels.
For example, you can filter for all events related to a specific namespace by typing namespace:your_namespace:
To further filter for a specific event, you can simply click on the relevant tag in the Details column:
How to filter for tenant-specific events
Let's say you want to find out when a specific tenant was created. Simply type ""Tenant"" in the search bar to filter for events related to when the tenant was created, updated, or deleted.
Alternatively, you can explicitly type in the Details filter id:your_tenant_id to filter for events related to that tenant:
How to Purge Audit Logs
The Enterprise Edition of Kestra generates an audit log for every action taken on the platform. While these logs are essential for tracking changes and ensuring compliance, they can accumulate over time and take up significant amount of space in the database.
The PurgeAuditLogs task, available in Kestra v0.19.0 and higher, will remove old audit logs that are no longer needed. You can set a date range for the logs you want to delete, choose a specific namespace, and even filter by permissions or actions (CREATE, READ, UPDATE, DELETE).
Additional types of Purge tasks are described in the dedicated section.
Here is the recommended way to implement the Audit Logs retention policy that will purge audit logs older than one month:
yaml
id: audit_log_cleanup
namespace: system
tasks:
  - id: purge_audit_logs
    type: io.kestra.plugin.ee.core.log.PurgeAuditLogs
    description: Purge audit logs older than 1 month
    endDate: ""{{ now() | dateAdd(-1, 'MONTHS') }}""
Note how the above flow is added to the system namespace, which is the default namespace for System Flows. This ensures that this maintenance flow and its executions are hidden from the main UI, making them only visible within the system namespace that can be managed by platform administrators.
Combining the System Flows functionality with the PurgeAuditLogs task provides a simple way to manage your audit logs as code and from the UI, ensuring you keep them as long as you need to stay compliant while keeping your database clean and performant.
Was this page helpful?
Yes
No
Enterprise
Single Sign-On (SSO)
Enterprise
Namespace Management""""""",1051,5161,kestra
https://kestra.io/docs/enterprise/namespace-management,"""""""DocsCloud & Enterprise Edition APINamespace Management
Namespace Management
Table of Contents
The benefits of namespace management
Namespace-level features: secrets, variables and plugin defaults
Creating a namespace from the UI
Creating a namespace from Terraform
Adding Variables and Plugin Defaults to a Namespace Terraform resource
Adding Secrets to a Namespace using Terraform
Benefits of namespace-level secrets, variables and plugin defaults
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to govern secrets, variables and plugin defaults on a namespace level.
Kestra is a multi-tenant platform. Each tenant can have multiple namespaces, and each namespace provides additional isolation and security.
Namespaces provide:
a logical isolation of resources on top of the instance- or tenant-level isolation
fine-grained access-control to secrets, variables and task configuration.
Namespaces are particularly useful in environments with many users, teams, projects and applications.
The benefits of namespace management
Even though namespace is a required property of each flow, namespaces are not created by default. To illustrate this, let's look at the following flow:
yaml
id: hello_world
namespace: company.marketing
tasks:
  - id: log_task
    type: io.kestra.plugin.core.log.Log
    message: hi from {{ flow.namespace }}
This flow is assigned to the company.marketing namespace. However, if you navigate to the Namespaces page in the UI, you'll notice that the namespace itself doesn't exist yet. The company.marketing namespace is greyed out because it's just a placeholder:
You can only filter for existing namespaces. Once you are ready to turn a placeholder namespace into a fully-fledged namespace, you create it in one click:
Namespace-level features: secrets, variables and plugin defaults
Once you create a namespace, you can centrally govern the following:
namespace-level secrets
namespace-level variables which values can be accessed through {{ namespace.my_variable_name }}
namespace-level plugin defaults.
Since Kestra supports everything as code and from the UI, you can manage namespaces from the UI or programmatically (e.g. via our Terraform provider).
Creating a namespace from the UI
The video below shows how you can create a namespace from the Kestra UI. After creating a namespace, we're adding:
several new secrets
a nested namespace variable that references one of these secrets
a list of plugin defaults helping to use those pre-configured secrets and variables in all the tasks from the AWS and Git plugins.
For detailed instructions, refer to centralized task configuration.
Creating a namespace from Terraform
Let's reproduce everything from the above video using Kestra's Terraform provider so that you know how to perform the same steps both from the UI and programmatically.
To create a namespace from Terraform, use the kestra_namespace resource.
First, configure your Terraform backend and add Kestra as a required provider:
hcl
terraform {
  backend ""s3"" {
    bucket = ""kestraio""
    key    = ""terraform.tfstate""
    region = ""us-east-1""
  }
  required_providers {
    kestra = {
      source  = ""kestra-io/kestra""
      version = ""~>0.14""
    }
  }
}
provider ""kestra"" {
  url       = var.kestra_host
  username  = var.kestra_user
  password  = var.kestra_password
  tenant_id = var.kestra_tenant_id # only if you are using multi-tenancy
}
You can add a file main.tf to your Terraform project with the following content:
hcl
resource ""kestra_namespace"" ""marketing"" {
  namespace_id  = ""marketing""
  description   = ""Namespace for the marketing team""
}
The only required property is the namespace_id which is the name of the namespace. The description and all other properties are optional.
Adding Variables and Plugin Defaults to a Namespace Terraform resource
You can add variables and plugin defaults directly to the namespace resource by pointing to the YAML configuration files.
First, create the variables_marketing.yml file:
yaml
github:
  token: ""{{ secret('GITHUB_TOKEN') }}""
Then, create another file for task_defaults_marketing.yml:
yaml
- type: io.kestra.plugin.aws
  values:
    accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID') }}""
    region: us-east-1
    secretKeyId: ""{{ secret('AWS_SECRET_ACCESS_KEY') }}""
- type: io.kestra.plugin.git
  values:
    password: ""{{ render(namespace.github.token) }}""
    username: your-github-username
Finally, reference those files in your namespace resource definition:
hcl
resource ""kestra_namespace"" ""marketing"" {
  namespace_id  = ""marketing""
  description   = ""Namespace for the marketing team""
  variables     = file(""variables_marketing.yml"")
  task_defaults = file(""task_defaults_marketing.yml"")
}
Adding Secrets to a Namespace using Terraform
To programmatically add secrets to your namespace via Terraform, you can use the kestra_namespace_secret resource. Here is an example of adding multiple secrets to the marketing namespace:
hcl
resource ""kestra_namespace_secret"" ""github_token"" {
  namespace    = ""marketing""
  secret_key   = ""GITHUB_TOKEN""
  secret_value = var.github_token
}
resource ""kestra_namespace_secret"" ""aws_access_key_id"" {
  namespace    = ""marketing""
  secret_key   = ""AWS_ACCESS_KEY_ID""
  secret_value = var.aws_access_key_id
}
resource ""kestra_namespace_secret"" ""aws_secret_access_key"" {
  namespace    = ""marketing""
  secret_key   = ""AWS_SECRET_ACCESS_KEY""
  secret_value = var.aws_secret_access_key
}
Before referencing variables in your Terraform configuration, make sure to define them in your variables.tf file:
hcl
variable ""github_token"" {
  type = string
  sensitive = true
}
variable ""aws_access_key_id"" {
  type = string
  sensitive = true
}
variable ""aws_secret_access_key"" {
  type = string
  sensitive = true
}
variable ""kestra_user"" {
  type      = string
  sensitive = true
}
variable ""kestra_password"" {
  type      = string
  sensitive = true
}
variable ""kestra_host"" {
  type      = string
  sensitive = false
  default   = ""https://us.kestra.cloud""
}
variable ""kestra_tenant_id"" {
  type      = string
  sensitive = false
  default   = ""kestra-tech""
}
And add your secrets to the terraform.tfvars file:
hcl
github_token = ""your-github-token""
aws_access_key_id = ""your-aws-access-key-id""
aws_secret_access_key = ""your-aws-secret-access-key""
kestra_user = ""your-kestra-user""
kestra_password = ""your-kestra-password""
Benefits of namespace-level secrets, variables and plugin defaults
Namespace management functionality offers Enterprise-grade security and governance to your Kestra instance. It allows your organization to centrally manage your secrets, variables and task configuration while providing fine-grained access-control to those resources.
Was this page helpful?
Yes
No
Enterprise
Audit Logs
Enterprise
Centralized Task Configuration""""""",1510,6847,kestra
https://kestra.io/docs/enterprise/centralized-task-configuration,"""""""DocsCloud & Enterprise Edition APICentralized Task Configuration
Centralized Task Configuration
Table of Contents
Secrets
Plugin Defaults
Variables
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to centrally govern your task configuration in a modular way.
The Namespace page allows you to configure secrets, plugin defaults and variables that can be used within any flow in that namespace.
Secrets
On the Namespaces page, select the namespace where you want to define the secrets and go to the Secrets tab. Here, you will see all existing secrets associated with this namespace. Click on ""Add a secret"" button on the top right corner of the page.
You can now define the secret by providing the Key and the Secret value. Save the secret by clicking on the ""Save"" button at the bottom.
The secret key should now start appearing on the Secrets tab. You can edit the secret's value or delete the secret by clicking on the appropriate button towards the right of the secret row. You can reference the secret in the flow by using the key e.g. ""{{ secret('MYSQL_PASSWORD') }}"".
Here is how you can use it in a flow:
yaml
id: query-mysql
namespace: company.team
tasks:
  id: query
  type: ""io.kestra.plugin.jdbc.mysql.Query""
  url: jdbc:mysql://localhost:3306/test
  username: root
  password: ""{{ secret('MYSQL_PASSWORD') }}""
  sql: select * from employees
  fetchOne: true
Make sure to only use the secret in flows defined in the same namespace (or child namespace) as your secret.
Plugin Defaults
Plugin Defaults can also be defined at the namespace level. These plugin defaults are then applied for all tasks of the corresponding type defined in the flows under the same namespace.
On the Namespaces page, select the namespace where you want to define the plugin defaults and navigate to the Plugin defaults tab. You can add the plugin defaults here and save the changes by clicking on the ""Save"" button at the bottom of the page.
You can reference secrets and variables defined with the same namespace in the plugin defaults.
In the example below, you no longer need to add the password property for the MySQL query task as it's defined in your namespace-level pluginDefaults:
yaml
id: query-mysql
namespace: company.team
tasks:
  id: query
  type: ""io.kestra.plugin.jdbc.mysql.Query""
  url: jdbc:mysql://localhost:3306/test
  username: root
  sql: select * from employees
  fetchOne: true
Variables
Variables defined at the namespace level can be used in any flow defined under the same namespace using the syntax: {{ namespace.variable_name }}.
On the Namespaces page, select the namespace where you want to define the variables. Go to the Variables tab. You can now define the variables on this page. Save the changes by clicking the ""Save"" button at the bottom of the page.
Here is an example flow where the namespace variable is used:
yaml
id: query-mysql
namespace: company.team
tasks:
  id: query
  type: ""io.kestra.plugin.jdbc.mysql.Query""
  url: jdbc:mysql://localhost:3306/test
  username: ""{{ namespace.mysql_user }}""
  sql: select * from employees
  fetchOne: true
Was this page helpful?
Yes
No
Enterprise
Namespace Management
Enterprise
Allowed namespaces""""""",715,3231,kestra
https://kestra.io/docs/enterprise/allowed-namespaces,"""""""DocsCloud & Enterprise Edition APIAllowed namespaces
Allowed namespaces
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.17.0
How to manage cross-namespace permissions in the Enterprise Edition.
When you navigate to any Namespace and go to the Edit tab, you can explicitly configure which namespaces are allowed to access flows and other resources related to that namespace. By default, all namespaces are allowed:
However, you can restrict that access if you want only specific namespaces (or no namespace at all) to trigger its corresponding resources.
Was this page helpful?
Yes
No
Enterprise
Centralized Task Configuration
Enterprise
Kestra EE API""""""",147,715,kestra
https://kestra.io/docs/enterprise/api,"""""""DocsCloud & Enterprise Edition APIKestra EE API
Kestra EE API
Table of Contents
Authentication
Browse the API Reference
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to interact with Kestra Enterprise Edition using the API.
Authentication
To authenticate with the Kestra API, you will need to create an API token. You can create it directly from the Kestra UI.
Once you have your API token, you can use it to authenticate with the API. You can use the Authorization header with the Bearer token to authenticate with the API.
bash
curl -X POST http://localhost:8080/api/v1/executions/company.team/hello_world \
-H ""Authorization: Bearer YOUR_API_TOKEN""
Browse the API Reference
For a full list of available API endpoints, check the Enterprise Edition API Reference.
Was this page helpful?
Yes
No
Enterprise
Allowed namespaces
Enterprise
API Tokens""""""",206,912,kestra
https://kestra.io/docs/enterprise/api-tokens,"""""""DocsCloud & Enterprise Edition APIAPI Tokens
API Tokens
Table of Contents
What is an API token
Where you can use API tokens
How to create an API token
How to use an API token in an API request
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.15.0
How to manage API tokens in Kestra.
What is an API token
API tokens are used to authenticate API requests to the Kestra API. You can create an API token for a user or a service account.
Where you can use API tokens
API tokens are used anytime you want to grant programmatic access to the Kestra API. To authenticate your custom API calls, you can pass a bearer token to the request header. For example, you can use API tokens to authenticate with the Kestra API from a CI/CD pipeline, or from a custom application.
Currently, we support API tokens as authentication mechanism for the following services:
GitHub Actions
Terraform Provider
Kestra CLI
Kestra API
How to create an API token
To create an API token, navigate to the Administration section and click on the Service Accounts or Users page, depending on whether you want to create an API token for a service account (bot) or a regular user (human).
Then, go to the API Tokens tab and click on the Create button:
Fill in the form with the required information including the Name, Description and Max age, and click Generate:
Note: you can configure the token to expire after a certain period of time, or to never expire. Also, there is a toggle called Extended that will automatically prolong the token's expiration date by the specified number of days (Max Age) if the token is actively used. That toggle is disabled by default.
Once you confirm the API token creation via the Generate button, the token will be generated and displayed in the UI. Make sure to copy the token and store it in a secure location as it will not be displayed again.
How to use an API token in an API request
To authenticate your custom API calls, you can pass a Bearer token to the request's Authorization header. Here is an example that will trigger a flow execution using the Kestra API:
bash
curl -X POST http://localhost:8080/api/v1/executions/dev/hello-world \
-H ""Authorization: Bearer YOUR_API_TOKEN""
Was this page helpful?
Yes
No
Enterprise
Kestra EE API
Enterprise
Kestra EE CLI""""""",530,2334,kestra
https://kestra.io/docs/enterprise/cli,"""""""DocsCloud & Enterprise Edition APIKestra EE CLI
Kestra EE CLI
Table of Contents
Authentication
kestra
kestra auths
kestra flow
kestra tenants
kestra plugins
kestra server
kestra server executor
kestra server indexer
kestra server scheduler
kestra server standalone
kestra server webserver
kestra server worker
kestra server local
kestra sys
kestra sys reindex
kestra sys database
kestra sys submit-queued-execution
kestra configs
kestra sys-ee
kestra sys-ee restore-flow-listeners (relevant only for older versions of kestra before 0.12)
kestra sys-ee restore-queue
kestra sys-ee reset-concurrency-limit
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to interact with Kestra Enterprise Edition using the CLI.
Authentication
The Kestra CLI uses the same authentication as the Kestra API. You can use the --api-token option to authenticate with the API.
shell
kestra --api-token <your-api-token> --help
kestra
bash
Usage: kestra [-hV] [COMMAND]
Options:
  -h, --help      Show this help message and exit.
  -V, --version   Print version information and exit.
Commands:
  plugins    handle plugins
  server     handle servers
  flow       handle flows
  template   handle templates
  sys        handle systems maintenance
  configs    handle configs
  namespace  handle namespaces
  auths      handle auths
  sys-ee     handle kestra ee systems maintenance
  tenants    handle tenants
kestra auths
bash
Usage: kestra auths [-hVv] [--internal-log] [-c=<config>] [-l=<logLevel>]
                       [-p=<pluginsPath>] [COMMAND]
handle auths
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  users  handle users
Here is the list of available commands withing kestra auths:
kestra auths users
bash
Usage: kestra auths users [-hVv] [--internal-log] [-c=<config>]
                             [-l=<logLevel>] [-p=<pluginsPath>] [COMMAND]
handle users
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  create       Create a new users
  sync-access  Sync users access with the default Tenant.
               This command is designed to be used when enabling multi-tenancy
                 on an existing Kestra instance, in this case the existing user
                 will need to have their access synchronized if they need
                 access to the default tenants (groups and roles will be
                 synchronized)
  refresh      Refresh users to update their properties
  set-type     Set type of a user between STANDARD and SUPER_ADMIN.
kestra auths users sync-access
bash
Usage: kestra auths users sync-access [-hVv] [--internal-log] [-c=<config>]
       [-l=<logLevel>] [-p=<pluginsPath>]
Sync users access with the default Tenant.
This command is designed to be used when enabling multi-tenancy on an existing
Kestra instance, in this case the existing user will need to have their access
synchronized if they need access to the default tenants (groups and roles will
be synchronized)
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra auths users refresh
bash
Usage: kestra auths users refresh [-hVv] [--internal-log] [-c=<config>]
                                     [-l=<logLevel>] [-p=<pluginsPath>]
Refresh users to update their properties
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra auths users set-type
bash
Usage: kestra auths users set-type [-hVv] [--internal-log] [-c=<config>]
                                      [-l=<logLevel>] [-p=<pluginsPath>] <user>
                                      <type>
Set type of a user between STANDARD and SUPER_ADMIN.
      <user>              User username
      <type>              User type between STANDARD and SUPER_ADMIN
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra auths users create
bash
Usage: kestra auths users create [-hVv] [--admin] [--internal-log]
                          [--superadmin] [-c=<config>]
                          [-l=<logLevel>] [-p=<pluginsPath>]
                          [--tenant=<tenantId>] [--groups=<group>]...
                          <user> [<password>]
Create a new users
      <user>             User username
      [<password>]       User password
      --admin            Create the admin role if not exists and add it to
                         provided users; cannot be use at the same time as
                            --superadmin
-c, --config=<config>     Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
    --groups=<group>      User groups
-h, --help                Show this help message and exit.
    --internal-log        Change also log level for internal log
-l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
-p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
    --superadmin          Create the superadmin role if not exists and add it
                            to provided users, cannot be use at the same time
                            as --admin
    --tenant=<tenantId>   tenant identifier
-v, --verbose             Change log level. Multiple -v options increase the
                            verbosity.
-V, --version             Print version information and exit.
Example command to create a Super Admin user:
shell
kestra auths users create --superadmin \
  --tenant=default admin admin_password123
Example command to create an Admin user:
shell
kestra auths users create --admin \
  --tenant=default admin admin_password123
Example command to create a regular user:
shell
kestra auths users create --tenant=default user user_password123
kestra flow
bash
Usage: kestra flow [-hVv] [--internal-log] [-c=<config>] [-l=<logLevel>]
                      [-p=<pluginsPath>] [COMMAND]
handle flows
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  validate   validate a flow
  test       test a flow
  namespace  handle namespace flows
  dot        generate a dot graph from a file
  export     export flows to a zip file
kestra flow namespace
bash
Usage: kestra flow namespace [-hVv] [--internal-log] [-c=<config>]
                                [-l=<logLevel>] [-p=<pluginsPath>] [COMMAND]
handle namespace flows
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  update  handle namespace flows
kestra flow namespace update
bash
Usage: kestra flow namespace update [-hVv] [--[no-]delete] [--internal-log]
                                       [-c=<config>] [-l=<logLevel>]
                                       [-p=<pluginsPath>] [--server=<server>]
                                       [--tenant=<tenantId>] [--user=<user:
                                       password>] [--headers=<name=value>]...
                                       <namespace> <directory>
handle namespace flows
      <namespace>           the namespace to update
      <directory>           the directory containing files for current namespace
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
      --[no-]delete         if missing should be deleted
  -h, --help                Show this help message and exit.
      --headers=<name=value>
                            Headers to add to the request
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --server=<server>     Kestra server url
                              Default: http://localhost:8080
      --tenant=<tenantId>   Tenant identifier (EE only, when multi-tenancy is
                              enabled)
      --user=<user:password>
                            Server user and password
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra flow test
bash
Usage: kestra flow test [-hVv] [--internal-log] [-c=<config>]
                           [-l=<logLevel>] [-p=<pluginsPath>] <file>
                           [<inputs>...]
test a flow
      <file>              the flow file to test
      [<inputs>...]       the inputs to pass as key pair value separated by
                            space, for input type file, you need to pass an
                            absolute path.
                            Default: []
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra flow dot
bash
Usage: kestra flow dot [-hVv] [--internal-log] [-c=<config>] [-l=<logLevel>]
                          [-p=<pluginsPath>] <file>
generate a dot graph from a file
      <file>              the flow file to display
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra flow export
bash
Usage: kestra flow export [-hVv] [--internal-log] [-c=<config>]
                             [-l=<logLevel>] [--namespace=<namespace>]
                             [-p=<pluginsPath>] [--server=<server>]
                             [--tenant=<tenantId>] [--user=<user:password>]
                             [--headers=<name=value>]... <directory>
export flows to a zip file
      <directory>           the directory to export the file to
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -h, --help                Show this help message and exit.
      --headers=<name=value>
                            Headers to add to the request
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
      --namespace=<namespace>
                            the namespace of flows to export
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --server=<server>     Kestra server url
                              Default: http://localhost:8080
      --tenant=<tenantId>   Tenant identifier (EE only, when multi-tenancy is
                              enabled)
      --user=<user:password>
                            Server user and password
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra flow validate
bash
Usage: kestra flow validate [-hVv] [--internal-log] [--local] [-c=<config>]
                               [-l=<logLevel>] [-p=<pluginsPath>]
                               [--server=<server>] [--tenant=<tenantId>]
                               [--user=<user:password>]
                               [--headers=<name=value>]... <directory>
validate a flow
      <directory>           the directory containing files to check
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -h, --help                Show this help message and exit.
      --headers=<name=value>
                            Headers to add to the request
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
      --local               If validation should be done locally or using a
                              remote server
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --server=<server>     Kestra server url
                              Default: http://localhost:8080
      --tenant=<tenantId>   Tenant identifier (EE only, when multi-tenancy is
                              enabled)
      --user=<user:password>
                            Server user and password
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra tenants
bash
Usage: kestra tenants [-hVv] [--internal-log] [-c=<config>] [-l=<logLevel>]
                         [-p=<pluginsPath>] [COMMAND]
handle tenants
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  create  create a tenant and assign admin roles to an existing admin user
kestra tenants create
bash
Usage: kestra tenants create [-hVv] [--internal-log]
                                [--admin-username=<adminUser>] [-c=<config>]
                                [-l=<logLevel>] [-p=<pluginsPath>] <tenantId>
                                <tenantName>
create a tenant and assign admin roles to an existing admin user
      <tenantId>          tenant identifier
      <tenantName>        tenant description
      --admin-username=<adminUser>
                          Username of an existing admin user that will be admin
                            of this tenant
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra plugins
bash
Usage: kestra plugins [-hVv] [--internal-log] [-c=<config>] [-l=<logLevel>]
                         [-p=<pluginsPath>] [COMMAND]
handle plugins
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  install  install a plugin
  list     list all plugins already installed
  doc      write documentation for all plugins currently installed
kestra plugins install
bash
Usage: kestra plugins install [-hVv] [--internal-log] [-c=<config>]
                                 [-l=<logLevel>] [-p=<pluginsPath>]
                                 [--repositories=<repositories>]...
                                 [<dependencies>...]
install a plugin
      [<dependencies>...]   the plugins to install
                              Default: []
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --repositories=<repositories>
                            url to additional maven repositories
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra plugins list
bash
Usage: kestra plugins list [-hVv] [--core] [--internal-log] [-c=<config>]
                              [-l=<logLevel>] [-p=<pluginsPath>]
list all plugins already installed
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
      --core              Also write core tasks plugins
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra plugins doc
bash
Usage: kestra plugins doc [-hVv] [--core] [--icons] [--internal-log]
                             [-c=<config>] [-l=<logLevel>] [-p=<pluginsPath>]
                             <output>
write documentation for all plugins currently installed
      <output>            Path to write documentations files
                            Default: /tmp/6VA8fpHM6Jipu7caPPRpAY/docs
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
      --core              Also write core tasks docs files
  -h, --help              Show this help message and exit.
      --icons             Also write icon for each task
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra server
bash
Usage: kestra server [-hVv] [--internal-log] [-c=<config>] [-l=<logLevel>]
                        [-p=<pluginsPath>] [COMMAND]
handle servers
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  executor    start an executor
  indexer     start an indexer
  scheduler   start an scheduler
  standalone  start a standalone server
  webserver   start the webserver
  worker      start a worker
  local       start a local server
kestra server executor
bash
Usage: kestra server executor [-hVv] [--internal-log] [-c=<config>]
                                 [-l=<logLevel>] [-p=<pluginsPath>]
                                 [--port=<serverPort>]
                                 [--skip-executions=<skipExecutions>[,
                                 <skipExecutions>...]]...
start an executor
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --port=<serverPort>   the port to bind
      --skip-executions=<skipExecutions>[,<skipExecutions>...]
                            a list of execution identifiers to skip, separated
                              by a coma; for troubleshooting purpose only
                              Default: []
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra server indexer
bash
Usage: kestra server indexer [-hVv] [--internal-log] [-c=<config>]
                                [-l=<logLevel>] [-p=<pluginsPath>]
                                [--port=<serverPort>]
start an indexer
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --port=<serverPort>   the port to bind
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra server scheduler
bash
Usage: kestra server scheduler [-hVv] [--internal-log] [-c=<config>]
                                  [-l=<logLevel>] [-p=<pluginsPath>]
                                  [--port=<serverPort>]
start an scheduler
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --port=<serverPort>   the port to bind
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra server standalone
bash
Usage: kestra server standalone [-hVv] [--internal-log] [-c=<config>]
                                   [-f=<flowPath>] [-l=<logLevel>]
                                   [-p=<pluginsPath>] [--port=<serverPort>]
                                   [--worker-thread=<workerThread>]
                                   [--skip-executions=<skipExecutions>[,
                                   <skipExecutions>...]]...
start a standalone server
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -f, --flow-path=<flowPath>
                            the flow path containing flow to inject at startup
                              (when running with a memory flow repository)
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --port=<serverPort>   the port to bind
      --skip-executions=<skipExecutions>[,<skipExecutions>...]
                            a list of execution identifiers to skip, separated
                              by a coma; for troubleshooting purpose only
                              Default: []
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
      --worker-thread=<workerThread>
                            the number of worker thread
kestra server webserver
bash
Usage: kestra server webserver [-hVv] [--internal-log] [-c=<config>]
                                  [-l=<logLevel>] [-p=<pluginsPath>]
                                  [--port=<serverPort>]
start the webserver
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --port=<serverPort>   the port to bind
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra server worker
bash
Usage: kestra server worker [-hVv] [--internal-log] [-c=<config>]
                               [-g=<workerGroupKey>] [-l=<logLevel>]
                               [-p=<pluginsPath>] [--port=<serverPort>]
                               [-t=<thread>]
start a worker
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -g, --worker-group=<workerGroupKey>
                            the worker group key, must match the regex
                              [a-zA-Z0-9_-]+ (EE only)
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --port=<serverPort>   the port to bind
  -t, --thread=<thread>     the max number of concurrent threads to launch
                              Default: 4
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra server local
bash
Usage: kestra server local [-hVv] [--internal-log] [-c=<config>]
                              [-f=<flowPath>] [-l=<logLevel>]
                              [-p=<pluginsPath>] [--port=<serverPort>]
                              [--worker-thread=<workerThread>]
                              [--skip-executions=<skipExecutions>[,
                              <skipExecutions>...]]...
start a local server
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -f, --flow-path=<flowPath>
                            the flow path containing flow to inject at startup
                              (when running with a memory flow repository)
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --port=<serverPort>   the port to bind
      --skip-executions=<skipExecutions>[,<skipExecutions>...]
                            a list of execution identifiers to skip, separated
                              by a coma; for troubleshooting purpose only
                              Default: []
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
      --worker-thread=<workerThread>
                            the number of worker thread
kestra sys
bash
Usage: kestra sys [-hVv] [--internal-log] [-c=<config>] [-l=<logLevel>]
                     [-p=<pluginsPath>] [COMMAND]
handle systems maintenance
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  reindex                  reindex all records of a type: read them from the
                             database then update them
  database                 manage Kestra database
  submit-queued-execution  Submit all queued execution to the executor
kestra sys reindex
bash
Usage: kestra sys reindex [-hVv] [--internal-log] [-c=<config>]
                             [-l=<logLevel>] [-p=<pluginsPath>] [-t=<type>]
reindex all records of a type: read them from the database then update them
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -t, --type=<type>       The type of the records to reindex, only 'flow' is
                            supported for now.
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra sys database
bash
Usage: kestra sys database [-hVv] [--internal-log] [-c=<config>]
                              [-l=<logLevel>] [-p=<pluginsPath>] [COMMAND]
manage Kestra database
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  migrate  Force database schema migration.
           Kestra uses Flyway to manage database schema evolution, this command
             will run Flyway then exit.
kestra sys submit-queued-execution
bash
Usage: kestra sys submit-queued-execution [-hVv] [--internal-log]
       [-c=<config>] [-l=<logLevel>] [-p=<pluginsPath>]
Submit all queued execution to the executor
All queued execution will be submitted to the executor. Warning, if there is
still running executions and concurrency limit configured, the executions may
be queued again.
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra configs
bash
Usage: kestra configs [-hVv] [--internal-log] [-c=<config>] [-l=<logLevel>]
                         [-p=<pluginsPath>] [COMMAND]
handle configs
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  properties  Display actual configurations properties.
kestra configs properties:
bash
Usage: kestra configs properties [-hVv] [--internal-log] [-c=<config>]
                                    [-l=<logLevel>] [-p=<pluginsPath>]
Display actual configurations properties.
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra sys-ee
bash
Usage: kestra sys-ee [-hVv] [--internal-log] [-c=<config>] [-l=<logLevel>]
                        [-p=<pluginsPath>] [COMMAND]
handle kestra ee systems maintenance
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Commands:
  restore-flow-listeners   restore state-store for FlowListeners
  restore-queue            send all data from a repository to kafka.
  reset-concurrency-limit  Reset the concurrency limit stored on the Kafka
                             runner.
kestra sys-ee restore-flow-listeners (relevant only for older versions of kestra before 0.12)
Legacy command for Listeners.
bash
Usage: kestra sys-ee restore-flow-listeners [-hVv] [--internal-log]
       [-c=<config>] [-l=<logLevel>] [-p=<pluginsPath>] [--timeout=<timeout>]
restore state-store for FlowListeners
Mostly usefull in case of restore of flow queue, the state store need to be
init to avoid sending old revisions.
  -c, --config=<config>     Path to a configuration file
                              Default: /home/kestra/.kestra/config.yml
  -h, --help                Show this help message and exit.
      --internal-log        Change also log level for internal log
  -l, --log-level=<logLevel>
                            Change log level (values: TRACE, DEBUG, INFO, WARN,
                              ERROR)
                              Default: INFO
  -p, --plugins=<pluginsPath>
                            Path to plugins directory
                              Default: /app/plugins
      --timeout=<timeout>   Timeout before quit, considering we complete the
                              restore
                              Default: PT1M
  -v, --verbose             Change log level. Multiple -v options increase the
                              verbosity.
  -V, --version             Print version information and exit.
kestra sys-ee restore-queue
bash
Usage: kestra sys-ee restore-queue [-hVv] [--internal-log] [--no-flows]
                                      [--no-namespaces] [--no-recreate]
                                      [--no-templates] [--no-triggers]
                                      [--no-triggers-execution-id]
                                      [-c=<config>] [-l=<logLevel>]
                                      [-p=<pluginsPath>]
send all data from a repository to kafka.
Mostly useful to send all flows, templates, triggers & namespaces from
repository to kafka in case of restore.
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
      --no-flows          Don't send flows
      --no-namespaces     Don't send namespaces
      --no-recreate       Don't drop the topic and recreate it
      --no-templates      Don't send templates
      --no-triggers       Don't send triggers
      --no-triggers-execution-id
                          Remove executionId from trigger
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
kestra sys-ee reset-concurrency-limit
bash
Usage: kestra sys-ee reset-concurrency-limit [-hVv] [--internal-log]
       [-c=<config>] [-l=<logLevel>] [-p=<pluginsPath>]
Reset the concurrency limit stored on the Kafka runner.
Use it only if some flow that has a concurrency limit hasn't started due to
concurrency limit, even though there is no execution running.
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Was this page helpful?
Yes
No
Enterprise
API Tokens
Enterprise
Custom Blueprints""""""",9944,48196,kestra
https://kestra.io/docs/enterprise/custom-blueprints,"""""""DocsCloud & Enterprise Edition APICustom Blueprints
Custom Blueprints
Table of Contents
How to create a new Custom Blueprint
Benefits of Custom Blueprints
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to create and manage Custom Blueprints.
On top of the publicly available Community Blueprints, you can create custom Blueprints only available to your organization. You can use them to share, centralize, and document commonly used workflows in your team.
You can think of Custom Blueprints as your team's internal App Store, offering a wide range of integrations and validated workflow patterns tailored to your needs.
How to create a new Custom Blueprint
From the left navigation menu, go to Blueprints. Then, select the Custom Blueprints tab. Click on ""Create"".
Add a title, description, and the contents of the flow. You can add as many tags as you want. Then click on the ""Create"" button.
You can edit Blueprints at anytime, for example, to add new tasks or expand the documentation.
Benefits of Custom Blueprints
This feature significantly helps code reusability and facilitates collaboration within a team because sharing your code and documentation is now painless.
Once you reach a certain scale with many internal Blueprints, the search and filtering by tags will ensure that your Blueprints remain easy to find.
Was this page helpful?
Yes
No
Enterprise
Kestra EE CLI
Enterprise
Enterprise Edition FAQ""""""",307,1477,kestra
https://kestra.io/docs/enterprise/faq,"""""""DocsCloud & Enterprise Edition APIEnterprise Edition FAQ
Enterprise Edition FAQ
Table of Contents
My session expires too quickly. Is there a way to change the session expiration time?
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Frequently asked questions about the Enterprise Edition of Kestra.
My session expires too quickly. Is there a way to change the session expiration time?
Yes, there is! Add the following Micronaut setting to your Kestra configuration to change the session expiration time to 10 hours:
yaml
    environment:
      KESTRA_CONFIGURATION: |
        micronaut:
          security:
            token:
              generator:
                access-token:
                  expiration: 36000
              cookie:
                cookie-max-age: 10h
Was this page helpful?
Yes
No
Enterprise
Custom Blueprints
Enterprise
Kestra Identity""""""",189,920,kestra
https://kestra.io/docs/enterprise/kestra-identity,"""""""DocsCloud & Enterprise Edition APIKestra Identity
Kestra Identity
Table of Contents
Our Story
Logo
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Common questions about the identity.
Our Story
When we created Kestra, our ambition was to design a simple yet powerful and fast orchestration platform. We wanted to enable our clients to manage complex flows with the same agility as a conductor who leads a symphony. This is how our logo was born, which embodies Kestra‚Äôs ability to orchestrate multiple tasks simultaneously.
Logo
Dark version
Use this version when working on a dark background to ensure our name remains readable.
Light version
This is the preferred option when working with a light background.
Monogram
The wordmark colors adapt based on the background, while the icon remains without a background when placed on a dark background.
Click on the link below to download the logo pack in PNG & SVG:
Download Logo Pack
Was this page helpful?
Yes
No
Enterprise
Enterprise Edition FAQ
Enterprise
Role-Based Access Control (RBAC)""""""",228,1066,kestra
https://kestra.io/docs/enterprise/rbac,"""""""DocsCloud & Enterprise Edition APIRole-Based Access Control (RBAC)
Role-Based Access Control (RBAC)
Table of Contents
Overview
Roles and Bindings
Permissions
Actions
Currently Supported Roles
Super Admin and Admin
Super Admin
Admin
Users, Groups and Service Accounts
Users
Groups
RBAC FAQ
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to manage access and permissions to your instance.
Overview
Kestra Enterprise supports Role-Based Access Control (RBAC), allowing you to manage access to workflows and resources by assigning Roles to Users, Groups and Service Accounts.
The image below shows the relationship between Users, Groups, Service Accounts, Roles, and Bindings (visible on the Access page in the UI).
Roles and Bindings
A Role is a collection of permissions that can be assigned to Users, Service Accounts or Groups.
Theses permissions are defined by a combination of a Permission (e.g. FLOWS) and an Action ( e.g. CREATE).
More information
Permissions
A Permission is a resource that can be accessed by a User or Group. Supported Permissions:
FLOW
BLUEPRINT
TEMPLATE
NAMESPACE
EXECUTION
USER
GROUP
ROLE
BINDING
AUDITLOG
SECRET
IMPERSONATE
SETTING
INFRASTRUCTURE
Actions
An Action is a specific operation that can be performed on a Permission. Supported Actions:
CREATE
READ
UPDATE
DELETE
Currently Supported Roles
Currently, Kestra creates only an Admin role by default. That role grants full access to all resources.
Apart from that, you can create additional Roles with custom permissions.
Super Admin and Admin
Kestra provides two way for managing your instance: super admin and admin.
Super Admin is a user type with elevated privileges for global control
Admin is a customizable role that grants full access to all resources (scoped to a tenant if multi-tenancy is enabled).
Summary
Super Admin
Without any Role or Binding, Super Admin has access to manage tenants, users, roles, groups and access within a Kestra Enterprise instance.
More information
Creating a Super Admin
Grant/Revoke Super Admin permissions
Admin
In Kestra, the notion of Admin user does not exist; instead we create an Admin role with all permissions.
This role can be assigned to any User, Service Account or Group. This allows you to have different types of admin, to grant admin permissions to a whole group, and to revoke those admin permissions at any time without having to delete any group or user.
When using multi-tenancy, Kestra assigns by default the Admin Role to the user who created the tenant.
If you see an error when creating a new User or Service Account, it might be caused by a limit of your license. In that case, reach out to us to validate and optionally upgrade your license.
Creating a User with an Admin Role
Users, Groups and Service Accounts
In Kestra you will find three types of entities:
Users: represents a person
Groups: represents a collection of Users and Service Accounts
Service Accounts: represents an application
All theses entities can be assigned to a Role, which define what resources the User, Group or Service Account can access.
Note that these entities don‚Äôt belong to namespaces, but their permissions can be limited to specific namespaces via Bindings (Access page).
How to bind a role to a User, a Service Accounts or a Group?
How many Roles can a User, a Service Account or Group have?
Users
A User represents a person who can access Kestra, identified by an email address. Each user might have personal information attached to it, such as the first name or last name.
They can change their own password, and adjust other settings such as theme, editor preferences, timezone, and a default namespace.
Change password
If a user wants to change their password, they can do it on their profile. This page can be accessed through the top right corner of the UI.
Change password in the UI
Reset password (by a Super Admin)
Kestra does not provide any forgot password feature yet. Currently only a super admin can update a user password through its User Edit page.
Groups
Each Group is a collection of Users or Service Accounts.
Each User can be assigned to zero, one or more Groups.
Each Service Account can also be assigned to zero, one or more Groups.
Groups are a useful mechanism for providing the same roles to multiple Users or Service Accounts at once by binding a role to a Group.
What happens if you delete a Group?
All Users and Service Accounts assigned to that Group will lose permissions that were binds to the groups. However Users and Services Accounts will still exist.
RBAC FAQ
Why is Admin a Role rather than User type?
Why can't I edit an existing Binding?
Was this page helpful?
Yes
No
Enterprise
Kestra Identity
Enterprise
Releases""""""",1014,4751,kestra
https://kestra.io/docs/enterprise/releases,"""""""DocsCloud & Enterprise Edition APIReleases
Releases
Table of Contents
Release Cadence
Bugfix Releases
Backport Releases
Upgrade Support
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Release cadence and support policy for Kestra Enterprise Edition (EE).
Release Cadence
We release a new Kestra version every two months. The release date is easy to remember: it's always the first Tuesday of every second month.
For a detailed schedule of planned and recently shipped releases, see the table below:
Kestra Version Release Date
0.18.0 August 6, 2024
0.19.0 October 1, 2024
0.20.0 December 3, 2024
0.21.0 February 4, 2025
0.22.0 April 1, 2025
0.23.0 June 3, 2025
0.24.0 August 5, 2025
0.25.0 October 7, 2025
0.26.0 December 2, 2025
0.27.0 February 3, 2026
Bugfix Releases
Every Thursday, we release a new bugfix version for the latest release. This means that if you are using the latest version of Kestra, you can expect a new bugfix release every week. You can track which GitHub issues are planned for the next bugfix release in our public GitHub project board.
We recommend regularly updating to the latest version to benefit from the most recent bug fixes and security patches.
Backport Releases
Regardless of the Kestra version you are using, we provide backport releases to Enterprise customers upon request. If you submit a ticket to our support team, we will provide a backport release with the necessary bug fixes for your specific version.
The backport releases are provided on a best-effort basis to our Enterprise customers. We still recommend upgrading to the latest version to continuously benefit from the latest improvements and security updates.
Upgrade Support
If you have questions or need help upgrading to the latest version of Kestra EE, please contact our support team.
Was this page helpful?
Yes
No
Enterprise
Role-Based Access Control (RBAC)
Enterprise
SCIM Directory Sync""""""",487,1956,kestra
https://kestra.io/docs/enterprise/scim,"""""""DocsCloud & Enterprise Edition APISCIM Directory Sync
SCIM Directory Sync
Table of Contents
What is SCIM
Benefits of a Directory Sync with SCIM
Supported Identity Providers
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Sync users and groups from your Identity Provider to Kestra using SCIM.
What is SCIM
SCIM (System for Cross-domain Identity Management) is an open standard protocol designed to facilitate user identity management across multiple systems.
It simplifies user provisioning, de-provisioning, and group synchronization between identity providers (IdPs) such as Microsoft Entra ID or Okta, and service providers (SPs) such as Kestra. In Layman's terms, SCIM allows you to automatically keep your users and groups in sync between your IdP and Kestra.
Kestra relies explicitly on the SCIM 2.0 protocol for directory synchronization.
Benefits of a Directory Sync with SCIM
Automated provisioning and de-provisioning: SCIM allows you to automate provisioning and de-provisioning of users, creating a single source of truth (SSOT) of the user identity data. Instead of manually creating and managing users in Kestra, you can sync them from your IdP.
Consistency and compliance: with SCIM, you can ensure consistency of identity information across systems and stay compliant with security and regulatory requirements.
Governance at scale: managing users at scale across many applications can be difficult without a standardized method for identity synchronization. SCIM provides a scalable solution for managing user identities.
Supported Identity Providers
For a detailed guide on how to set up SCIM provisioning with a specific IdP, refer to the documentation for the respective provider.
authentik SCIM Provisioning
Sync Users and Groups from authentik to Kestra using SCIM.
Keycloak SCIM Provisioning
Sync Users and Groups from Keycloak to Kestra using SCIM.
Microsoft Entra ID SCIM Provisioning
Sync Users and Groups from Microsoft Entra ID to Kestra using SCIM.
Okta SCIM Provisioning
Sync Users and Groups from Okta to Kestra using SCIM.
Was this page helpful?
Yes
No
Enterprise
Releases
Scim
authentik SCIM Provisioning""""""",488,2206,kestra
https://kestra.io/docs/enterprise/scim/authentik,"""""""DocsCloud & Enterprise Edition APISCIM Directory Syncauthentik SCIM Provisioning
authentik SCIM Provisioning
Table of Contents
Prerequisites
Kestra SCIM Setup: Create a New Provisioning Integration
Enable or Disable SCIM Integration
IAM Role and Service Account
authentik SSO Setup
Install authentik
Create Application and SSO Provider in authentik
Configure Authentik SSO in Kestra Settings
Configure a Default Role for your SSO users in Kestra Settings
authentik SCIM 2.0 Setup
Test both SSO and SCIM by adding users and groups
Additional Resources
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Sync Users and Groups from authentik to Kestra using SCIM.
Prerequisites
authentik Account: an account with administrative privileges to configure SCIM provisioning.
Enable multi-tenancy in Kestra: tenants MUST be enabled in Kestra to support SCIM provisioning. You can enable tenants by setting the kestra.ee.tenants.enabled configuration property to true:
yaml
kestra:
  ee:
    tenants:
      enabled: true
Kestra SCIM Setup: Create a New Provisioning Integration
In the Kestra UI, navigate to the Administration ‚Üí IAM ‚Üí Provisioning page.
Click on the Create button in the top right corner of the page.
Fill in the following fields:
Name: Enter a name for the provisioning integration.
Description: Provide a brief description of the integration.
Provisioning Type: currently, we only support SCIM 2.0 ‚Äî leave the default selection and click Save.
The above steps will generate a SCIM endpoint URL and a Secret Token that you will use to authenticate authentik with the SCIM integration in Kestra. Save those details as we will need them in the next steps.
The endpoint should look as follows:
https://your_kestra_host/api/v1/your_tenant/integrations/integration_id/scim/v2
The Secret Token will be a long string (ca. 200 characters) that will authenticate requests from authentik to Kestra.
Enable or Disable SCIM Integration
Note that you can disable or completely remove the SCIM Integration at any time. When an integration is disabled, all incoming requests for that integration endpoint will be rejected.
At first, you can disable the integration to configure your authentik SCIM integration, and then enable it once the configuration is complete.
IAM Role and Service Account
When creating a new Provisioning Integration, Kestra will automatically create two additional objects:
Role SCIMProvisioner with the following permissions:
GROUPS: CREATE, READ UPDATE, DELETE
USERS: CREATE, READ, UPDATE
BINDINGS: CREATE, READ, UPDATE, DELETE
Service Account with an API Token which was previously displayed as a Secret Token for the integration:
Why the SCIMProvisioner role doesn't have the DELETE permission for USERS? This is because you cannot delete a user through our SCIM implementation. Users are global and SCIM provisioning is per tenant. When we receive a DELETE query for a user, we remove their tenant access but the user itself remains in the system.
authentik SSO Setup
Install authentik
Authentik provides a simple docker-compose installer for testing purposes. Follow the instructions and click on the initial setup URL http://docker.for.mac.localhost:9000/if/flow/initial-setup/ to create your first user.
Create Application and SSO Provider in authentik
On the left-hand side select Applications ‚Üí Applications. For simplicity we‚Äôll use the Create with Wizard button as this will create both an application and a provider.
On the Application Details screen, fill in the application name and slug. Set both here to kestra and click Next.
On the Provider Type screen, select OAuth2/OIDC and click Next.
On the Provider Configuration screen:
In the Authentication flow field, select ‚Äúdefault-authentication-flow (Welcome to authentik!)‚Äù
In the Authorization flow field, select ‚Äúdefault-provider-authorization-explicit-consent (Authorize Application)‚Äù
Keep the Client type as Confidential and under the Redirect URIs/Origins (RegEx), enter your Kestra host's /oauth/callback/authentik endpoint in the format http://<kestra_host>:<kestra_port>/oauth/callback/authentik e.g. http://localhost:8080/oauth/callback/authentik and then Submit the Application:
Note the Client ID and Client Secret as you will need these to configure Kestra in the next step.
Configure Authentik SSO in Kestra Settings
With the above Client ID and Secret, add the following in the micronaut configuration section:
yaml
        micronaut:
          security:
            oauth2:
              enabled: true
              clients:
                authentik:
                  client-id: ""CLIENT_ID""
                  client-secret: ""CLIENT_SECRET""
                  openid:
                    issuer: ""http://localhost:9000/application/o/kestra/""
You may need to adjust the above issuer URL if you named your application something other than kestra. Make sure to update that URL to match your application name http://localhost:9000/application/o/<application_name>/.
Configure a Default Role for your SSO users in Kestra Settings
To ensure that your SSO users have some initial permissions within Kestra UI, it's useful to set up a default role for them. You can do this by adding the following configuration under the kestra.security section:
yaml
kestra:
  security:
    defaultRole:
      name: default_admin_role
      description: ""Default Admin Role""
      permissions:
        NAMESPACE: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        ROLE: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        GROUP: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        EXECUTION: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        AUDITLOG: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        USER: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        BINDING: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        FLOW: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        SECRET: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        BLUEPRINT: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        INFRASTRUCTURE: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
        KVSTORE: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
  ee:
    tenants:
      enabled: true
      defaultTenant: false
‚ö†Ô∏è Make sure that your default-role is added under the kestra.security section, not under micronaut.security. Also, ensure that the default-role has the necessary permissions for your users to interact with Kestra. The above configuration is just an example and you might want to restrict the permissions boundaries for production use.
authentik SCIM 2.0 Setup
Configuring SCIM 2.0 requires a similar process to SSO ‚Äî you'll need to create a new Application. Then, in the second step, select SCIM as the Provider Type.
In the Protocol settings section, enter the URL and Secret Token obtained from Kestra.
If you are running authentik on a Mac machine with docker-compose installer, make sure to replace localhost in your Kestra's SCIM endpoint with docker.for.mac.localhost since otherwise the sync won't work. Your URL should look as follows: http://docker.for.mac.localhost:8080/api/v1/dev/integrations/zIRjRAMGvkammpeLVuyJl/scim/v2.
Test both SSO and SCIM by adding users and groups
Create first Users and Groups in the Directory settings.
Then, assign your user(s) to an existing group:
You can set password for each authentik user to allow them to log in directly to Kestra with their username/email and password.
Once groups and users are created, they should be visible in the Kestra UI under the IAM ‚Üí Users and Groups sections. It's best if you log in as the default admin user and attach a desired Role to each group to ensure that the users have the necessary permissions.
Then, to verify access, log in as one of those new authentik users in a separate browser or incognito mode and verify that the user has the permissions you expect.
Additional Resources
SCIM for authentik Documentation
Manage applications in authentik Documentation
Was this page helpful?
Yes
No
Enterprise
SCIM Directory Sync
Scim
Keycloak SCIM Provisioning""""""",1820,8020,kestra
https://kestra.io/docs/enterprise/scim/keycloak,"""""""DocsCloud & Enterprise Edition APISCIM Directory SyncKeycloak SCIM Provisioning
Keycloak SCIM Provisioning
Table of Contents
Prerequisites
Kestra SCIM Setup: Create a New Provisioning Integration
Enable or Disable SCIM Integration
IAM Role and Service Account
Keycloak SCIM Setup
Additional Resources
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Sync Users and Groups from Keycloak to Kestra using SCIM.
Prerequisites
Keycloak Account: an account with administrative privileges to configure SCIM provisioning.
Enable multi-tenancy in Kestra: tenants MUST be enabled in Kestra to support SCIM provisioning. You can enable tenants by setting the kestra.ee.tenants.enabled configuration property to true:
yaml
kestra:
  ee:
    tenants:
      enabled: true
Kestra SCIM Setup: Create a New Provisioning Integration
In the Kestra UI, navigate to the Administration ‚Üí IAM ‚Üí Provisioning page.
Click on the Create button in the top right corner of the page.
Fill in the following fields:
Name: Enter a name for the provisioning integration.
Description: Provide a brief description of the integration.
Provisioning Type: currently, we only support SCIM 2.0 ‚Äî leave the default selection and click Save.
The above steps will generate a SCIM endpoint URL and a Secret Token that you will use to authenticate Keycloak with the SCIM integration in Kestra. Save those details as we will need them in the next steps.
The endpoint should look as follows:
https://your_kestra_host/api/v1/your_tenant/integrations/integration_id/scim/v2
The Secret Token will be a long string (ca. 200 characters) that will authenticate requests from Keycloak to Kestra.
Enable or Disable SCIM Integration
Note that you can disable or completely remove the SCIM Integration at any time. When an integration is disabled, all incoming requests for that integration endpoint will be rejected.
At first, you can disable the integration to configure your Keycloak SCIM integration, and then enable it once the configuration is complete.
IAM Role and Service Account
When creating a new Provisioning Integration, Kestra will automatically create two additional objects:
Role SCIMProvisioner with the following permissions:
GROUPS: CREATE, READ UPDATE, DELETE
USERS: CREATE, READ, UPDATE
BINDINGS: CREATE, READ, UPDATE, DELETE
Service Account with an API Token which was previously displayed as a Secret Token for the integration:
Why the SCIMProvisioner role doesn't have the DELETE permission for USERS? This is because you cannot delete a user through our SCIM implementation. Users are global and SCIM provisioning is per tenant. When we receive a DELETE query for a user, we remove their tenant access but the user itself remains in the system.
Keycloak SCIM Setup
Keycloak doesn‚Äôt provide any built-in support for SCIM v2.0. Some open-source solutions support groups synchronization but not users and membership synchronization.
However, there are paid solutions such as SCIM for Keycloak that allow you to extend Keycloak with SCIM. The setup shown below was validated with Kestra 0.18.0 and Keyclock 25.0.2 ‚Äî best if you use the same or higher versions.
Obtain a License:
Create a new account on: https://scim-for-keycloak.de/
Purchase a free license (no VAT number or credit card is required for a free license).
Install the SCIM Provider Plugin:
Download the plugin JAR file from the Downloads section in your Account (e.g. scim-for-keycloak-kc-25-2.2.1-free.jar).
Place the JAR file in the ./providers directory of your Keycloak installation (or in the current folder if Keycloack is deployed with Docker).
More information: SCIM for Keycloak Installation
Deploy Keycloak:
Create a simple docker-compose.yaml file:
yaml
services:
  keyclock:
    container_name: keyclock
    image: quay.io/keycloak/keycloak:25.0.2
    ports:
      - 8085:8085
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
      KC_SPI_THEME_WELCOME_THEME: scim
      KC_SPI_REALM_RESTAPI_EXTENSION_SCIM_LICENSE_KEY: <LICENSES_KEY>
    command:
      [""start-dev"", ""--http-port=8085""]
    volumes:
      - ./providers:/opt/keycloak/providers
    network_mode: ""host"" # Optional: for accessing external Kestra
Run docker-compose up to start Keycloak.
Configure the SCIM for Keycloak:
To synchronize Users and Groups from Keycloak to Kestra, connect to the SCIM Administration Console for Keycloak with SCIM.
Enable SCIM for the Realm
Note that Bulk and Password synchronization operations are currently not supported by Kestra and must disabled in Keycloak.
Create a SCIM Client:
Navigate to the Remote SCIM Provider section
Fill the Base URL field with your Kestra SCIM Endpoint:
Fill the Authentication with your Kestra Secret Token:
Enable Provisioning:
Now that everything is configured, you can toggle the Enabled field on in the Kestra Provisioning Integration to start syncing users and groups from Keycloak to Kestra.
Additional Resources
SCIM for Keycloak Documentation
Was this page helpful?
Yes
No
Scim
authentik SCIM Provisioning
Scim
Microsoft Entra ID SCIM Provisioning""""""",1172,5129,kestra
https://kestra.io/docs/enterprise/scim/microsoft-entra-id,"""""""DocsCloud & Enterprise Edition APISCIM Directory SyncMicrosoft Entra ID SCIM Provisioning
Microsoft Entra ID SCIM Provisioning
Table of Contents
Prerequisites
Kestra SCIM Setup: Create a New Provisioning Integration
Enable or Disable SCIM Integration
IAM Role and Service Account
Microsoft Entra ID SCIM Setup
Additional Resources
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Sync Users and Groups from Microsoft Entra ID to Kestra using SCIM.
Prerequisites
Microsoft Entra ID Account: an account with administrative privileges to configure SCIM provisioning.
Enable multi-tenancy in Kestra: tenants MUST be enabled in Kestra to support SCIM provisioning. You can enable tenants by setting the kestra.ee.tenants.enabled configuration property to true:
yaml
kestra:
  ee:
    tenants:
      enabled: true
Kestra SCIM Setup: Create a New Provisioning Integration
In the Kestra UI, navigate to the Administration ‚Üí IAM ‚Üí Provisioning page.
Click on the Create button in the top right corner of the page.
Fill in the following fields:
Name: Enter a name for the provisioning integration.
Description: Provide a brief description of the integration.
Provisioning Type: currently, we only support SCIM 2.0 ‚Äî leave the default selection and click Save.
The above steps will generate a SCIM endpoint URL and a Secret Token that you will use to authenticate Microsoft Entra ID with the SCIM integration in Kestra. Save those details as we will need them in the next steps.
The endpoint should look as follows:
https://your_kestra_host/api/v1/your_tenant/integrations/integration_id/scim/v2
The Secret Token will be a long string (ca. 200 characters) that will authenticate requests from Microsoft Entra ID to Kestra.
Enable or Disable SCIM Integration
Note that you can disable or completely remove the SCIM Integration at any time. When an integration is disabled, all incoming requests for that integration endpoint will be rejected.
At first, you can disable the integration to configure your Microsoft Entra ID integration in the Azure portal, and then enable it once the configuration is complete.
IAM Role and Service Account
When creating a new Provisioning Integration, Kestra will automatically create two additional objects:
Role SCIMProvisioner with the following permissions:
GROUPS: CREATE, READ UPDATE, DELETE
USERS: CREATE, READ, UPDATE
BINDINGS: CREATE, READ, UPDATE, DELETE
Service Account with an API Token which was previously displayed as a Secret Token for the integration:
Why the SCIMProvisioner role doesn't have the DELETE permission for USERS? This is because you cannot delete a user through our SCIM implementation. Users are global and SCIM provisioning is per tenant. When we receive a DELETE query for a user, we remove their tenant access but the user itself remains in the system.
Microsoft Entra ID SCIM Setup
Register Kestra as an Enterprise Application:
Navigate to Microsoft Entra ID ‚Üí Enterprise Applications.
Click on the + New application button to create a new custom application. You can name the app ""KestraSCIM"" or any other relevant name.
Configure SCIM Provisioning:
Go to the newly created Kestra application.
Select ""Provisioning"" and set the Provisioning Mode to ""Automatic"".
Enter the SCIM endpoint URL and the Secret Token provided by Kestra. Paste kestra's SCIM endpoint URL into the Tenant URL field and the Secret Token into the Secret Token field.
Finally, click on Test Connection and on the Save button.
Map User and Group Attributes:
Configure attribute mappings for users and groups to match Kestra‚Äôs schema requirements.
Test the configuration and ensure that users and groups are synchronized correctly.
Enable Provisioning:
Now that everything is configured, you can enable the provisioning integration toggle in the Kestra UI to start syncing users and groups from Microsoft Entra ID to Kestra.
Additional Resources
Microsoft Entra ID SCIM Documentation
Was this page helpful?
Yes
No
Scim
Keycloak SCIM Provisioning
Scim
Okta SCIM Provisioning""""""",883,4070,kestra
https://kestra.io/docs/enterprise/scim/okta,"""""""DocsCloud & Enterprise Edition APISCIM Directory SyncOkta SCIM Provisioning
Okta SCIM Provisioning
Table of Contents
Prerequisites
Kestra SCIM Setup: Create a New Provisioning Integration
Enable or Disable SCIM Integration
IAM Role and Service Account
Okta SCIM Setup
Additional Resources
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Sync Users and Groups from Okta to Kestra using SCIM.
Prerequisites
Okta Account: an account with administrative privileges to configure SCIM provisioning.
Enable multi-tenancy in Kestra: tenants MUST be enabled in Kestra to support SCIM provisioning. You can enable tenants by setting the kestra.ee.tenants.enabled configuration property to true:
yaml
kestra:
  ee:
    tenants:
      enabled: true
Kestra SCIM Setup: Create a New Provisioning Integration
In the Kestra UI, navigate to the Administration ‚Üí IAM ‚Üí Provisioning page.
Click on the Create button in the top right corner of the page.
Fill in the following fields:
Name: Enter a name for the provisioning integration.
Description: Provide a brief description of the integration.
Provisioning Type: currently, we only support SCIM 2.0 ‚Äî leave the default selection and click Save.
The above steps will generate a SCIM endpoint URL and a Secret Token that you will use to authenticate Okta with the SCIM integration in Kestra. Save those details as we will need them in the next steps.
The endpoint should look as follows:
https://your_kestra_host/api/v1/your_tenant/integrations/integration_id/scim/v2
The Secret Token will be a long string (ca. 200 characters) that will authenticate requests from Okta to Kestra.
Enable or Disable SCIM Integration
Note that you can disable or completely remove the SCIM Integration at any time. When an integration is disabled, all incoming requests for that integration endpoint will be rejected.
At first, you can disable the integration to configure your Okta SCIM integration, and then enable it once the configuration is complete.
IAM Role and Service Account
When creating a new Provisioning Integration, Kestra will automatically create two additional objects:
Role SCIMProvisioner with the following permissions:
GROUPS: CREATE, READ UPDATE, DELETE
USERS: CREATE, READ, UPDATE
BINDINGS: CREATE, READ, UPDATE, DELETE
Service Account with an API Token which was previously displayed as a Secret Token for the integration:
Why the SCIMProvisioner role doesn't have the DELETE permission for USERS? This is because you cannot delete a user through our SCIM implementation. Users are global and SCIM provisioning is per tenant. When we receive a DELETE query for a user, we remove their tenant access but the user itself remains in the system.
Okta SCIM Setup
Create an App Integration:
Navigate to Okta Admin Console ‚Üí Applications ‚Üí Applications.
Click on ""Create App Integration"" and then select:
Sign-in Method: OIDC - OpenID Connect
Application Type: Web Application
Then on the next page:
Give your application a name, e.g. Kestra
Grant Type: Client Acting on behalf of itself ‚Üí Client Credentials ‚Üí True
Login
Sign-in redirect URIs ‚Üí http:///oauth/callback/okta
Sign-out redirect URIs ‚Üí http:///logout
Once application is created, select it in the Applications view and take note of the client ID and client secret.
Configure Okta in Kestra:
With the above client ID and secret, add the following in your Kestra Micronaut configuration:
yaml
        micronaut:
          security:
            oauth2:
              enabled: true
              clients:
                okta:
                  client-id: ""CLIENT_ID""
                  client-secret: ""CLIENT-SECRET""
                  openid:
                    issuer: ""https://{okta-account}.okta.com/""
Enter the SCIM endpoint URL and API token provided by Kestra.
Configure SCIM 2.0 in Okta:
In Okta, navigate to Applications ‚Üí Applications ‚Üí Browse App Catalog
Search for SCIM 2.0
Select SCIM 2.0 Test App (OAuth Bearer Token)
in Sign-in options select Secure Web Authentication ‚Üí user sets username/password
Click Done
Select the integration you have just created, then enter the Provisioning tab.
Fill in the Endpoint URL you obtained from Kestra into the SCIM 2.0 Base Url field. Enter the Secret Token generated in Kestra into the OAuth Bearer Token field.
Finally, click on the Test API Credentials to verify the connection.
Map Attributes:
Select ‚ÄúPush Groups‚Äù and choose the Groups you wish to push to Kestra.
Perform a test to ensure the mappings are correct and data is syncing properly.
Enable Provisioning:
Enable the provisioning integration toggle in the Kestra UI to begin automatic synchronization of users and groups from Okta to Kestra.
Additional Resources
Okta SCIM Documentation
Was this page helpful?
Yes
No
Scim
Microsoft Entra ID SCIM Provisioning
Enterprise
Secrets""""""",1080,4855,kestra
https://kestra.io/docs/enterprise/secrets,"""""""DocsCloud & Enterprise Edition APISecrets
Secrets
Table of Contents
What are Secrets
How to create a new Secret
How are Secrets different between the Open-Source and Enterprise Editions?
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to create and manage Secrets in the Enterprise Edition.
What are Secrets
Secrets are used to store confidential information such as passwords, API keys, and other sensitive data that should not be exposed in plain text. Secrets managed in Kestra are encrypted at rest and in transit to guarantee that your sensitive information is secure.
How to create a new Secret
From the left navigation menu, go to Namespaces. Select a namespace and click on the Secrets tab. Then, click on the ""Create"" button to add a new Secret.
How are Secrets different between the Open-Source and Enterprise Editions?
Currently, we don't provide Secrets Management in the Open-Source Edition. However, you can pass special base64-encoded environment variables to your Kestra instance to store sensitive information. Then, you can access these variables in your flows using the same secret() function as in the Enterprise Edition. Since there is no real notion of Secrets Management in the Open-Source Edition, you will need to manage the lifecycle of these environment variables manually. This means that you will need to restart your Kestra instance to update or delete a Secret. We encourage you to plan such operations carefully to avoid any downtime, or reach out to us to upgrade to the Enterprise Edition to benefit from the full Secrets Management backend including the possibility to integrate with your existing Secrets Manager.
Was this page helpful?
Yes
No
Scim
Okta SCIM Provisioning
Enterprise
Secrets Manager""""""",365,1798,kestra
https://kestra.io/docs/enterprise/secrets-manager,"""""""DocsCloud & Enterprise Edition APISecrets Manager
Secrets Manager
Table of Contents
AWS Secret Manager Configuration
Azure Key Vault Configuration
Elasticsearch Configuration
Google Secret Manager Configuration
Vault Configuration
KV Secrets Engine - Version 2
JDBC (Postgres, H2, MySQL) Secret Manager
Elastic Secret Manager
Default Tags
Enable Caching
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to configure the secrets manager.
Kestra integrates with various secret managers to provide secure storage and handling of sensitive data.
Kestra respects your privacy. Therefore, Secrets are persisted externally in a backend of your choice. They are accessed by workers at runtime and stored only in memory.
You can add, modify or delete secrets from the Secrets tab of any given namespace in the Kestra UI, or programmatically via Terraform.
AWS Secret Manager Configuration
In order to use AWS Secret Manager as a secrets backend, make sure that your AWS IAM user or role have the required permissions including CreateSecret, DeleteSecret, DescribeSecret, GetSecretValue, ListSecrets, PutSecretValue, RestoreSecret, TagResource, UpdateSecret.
You can configure the authentication to AWS Cloud in multiple ways:
Using accessKeyId, secretKeyId, and region properties.
Including a sessionToken alongside the above credentials.
If the above properties are not set, Kestra will use the default AWS authentication, in the same way as AWS CLI handles it (i.e. trying to use the AWS CLI profile or the default environment variables AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_DEFAULT_REGION).
yaml
kestra:
  secret:
    type: aws-secret-manager
    awsSecretManager:
      accessKeyId: mysuperaccesskey
      secretKeyId: mysupersecretkey
      sessionToken: mysupersessiontoken
      region: us-east-1
Additionally, you can configure the following properties:
Prefix: kestra.secret.aws-secret-manager.prefix is an optional property to store secrets separately for a different namespace, tenant, or instance. If configured, Kestra will prefix all Secret keys using that prefix. The main purpose of a prefix is to share the same secret manager between multiple Kestra instances.
Endpoint Override: kestra.secret.aws-secret-manager.endpointOverride is an optional property to replace AWS default endpoint by an AWS-compatible service such as MinIO.
Azure Key Vault Configuration
To configure Azure Key Vault as your secrets backend, make sure that kestra's user or service principal (clientId) has the necessary permissions, including ""Get"", ""List"", ""Set"", ""Delete"", ""Recover"", ""Backup"", ""Restore"", ""Purge"". Then, paste the clientSecret from the Azure portal to the clientSecret property in the configuration below.
yaml
kestra:
  secret:
    type: azure-key-vault
    azureKeyVault:
      clientSecret:
        tenantId: ""id""
        clientId: ""id""
        clientSecret: ""secret""
If no credentials are set in the above configuration, Kestra will use the default Azure authentication akin to the Azure CLI.
Additionally, you can configure the following properties:
Vault Name: kestra.secret.azure-key-vault.vaultName is the name of the Azure Key Vault.
Key Vault URI: kestra.secret.azure-key-vault.keyVaultUri is an optional property allowing you to replace the Azure Key Vault name with a full URL.
Prefix: kestra.secret.azure-key-vault.prefix is an optional property to store secrets separately for a different namespace, tenant, or instance. If configured, Kestra will prefix all Secret keys using that prefix. The main purpose of a prefix is to share the same secret manager between multiple Kestra instances.
Elasticsearch Configuration
Elasticsearch backend stores secrets with an additional layer of security using AES encryption. You will need to provide a cryptographic key (at least 32 characters-long string) in order to encrypt and decrypt secrets stored in Elasticsearch.
yaml
kestra:
  secret:
    type: elasticsearch
    elasticsearch:
      secret: ""a-secure-32-character-minimum-key""
Google Secret Manager Configuration
To leverage Google Secret Manager as your secrets backend, you will need to create a service account with the roles/secretmanager.admin permission. Paste the contents of the service account JSON key file to the serviceAccount property in the configuration below. Alternatively, set the GOOGLE_APPLICATION_CREDENTIALS environment variable to point to the credentials file.
yaml
kestra:
  secret:
    type: google-secret-manager
    googleSecretManager:
      project: gcp-project-id
      serviceAccount: |
        Paste here the contents of the service account JSON key file
If you opt for authentication using the GOOGLE_APPLICATION_CREDENTIALS environment variable, make sure that it's set on all worker nodes. Keep in mind that this authentication method is less secure than using the serviceAccount property.
If no credentials are set in the above configuration, Kestra will use the default Google authentication akin to the Google Cloud SDK.
Additionally, you can configure the kestra.secret.google-secret-manager.prefix property to store secrets separately for a different namespace, tenant, or instance. If configured, Kestra will prefix all Secret keys using that prefix. The main purpose of a prefix is to share the same secret manager between multiple Kestra instances.
Vault Configuration
Kestra currently supports the KV secrets engine - version 2 as a secrets backend. If you consider alternative Vault secrets engines, please note the following:
The Vault's database secrets engine, often referred to as ""dynamic secrets"", is not supported as we need long-term secret storage.
The Vault Secrets Operator on Kubernetes creates a Kubernetes secret which is compatible with Kestra with some additional steps. If you are interested about this option, reach out to us and we can advise how you can set this up.
Follow the steps below to configure the KV Secrets Engine - Version 2 as your secrets backend.
KV Secrets Engine - Version 2
To authenticate Kestra with HashiCorp Vault, you can use Userpass, Token or AppRole Auth Methods, all of which requires full read and write policies. You can optionally change root-engine or namespace (if you use Vault Enterprise).
Here is how you can set up Userpass Auth Method in your Kestra configuration:
yaml
kestra:
  secret:
    type: vault
    vault:
      address: ""http://localhostt:8200""
      password:
        user: john
        password: foo
Here is how you can set up Token Auth Method in your Kestra configuration:
yaml
kestra:
  secret:
    type: vault
    vault:
      address: ""http://localhostt:8200""
      token:
        token: your-secret-token
Finally, here is how you can set up AppRole Auth Method in your Kestra configuration:
yaml
kestra:
  secret:
    type: vault
    vault:
      address: ""http://localhostt:8200""
      appRole:
        path: approle
        roleId: your-role-id
        secretId: your-secret-id
Additionally, you can configure the following properties:
Address: kestra.secret.vault.address is a fully qualified address with scheme and port to your Vault instance.
Namespace: kestra.secret.vault.namespace is an optional configuration available on Vault Enterprise Pro allowing you to set a global namespace for the Vault server instance.
Engine Version: kestra.secret.vault.engine-version is an optional property allowing you to set the KV Secrets Engine version of the Vault server instance. Default is 2.
Root Engine: kestra.secret.vault.root-engine is an optional property allowing you to set the KV Secrets Engine of the Vault server instance. Default is secret.
JDBC (Postgres, H2, MySQL) Secret Manager
Kestra also supports internal secret backend. For the JDBC backend (H2, Postgres or MySQL), the following configuration allows you to set secret backend:
yaml
kestra:
  secret:
    type: jdbc
    jdbc:
      secret: ""your-secret-key""
Your secret key should be encrypted. You can find an example of encryption key here.
Elastic Secret Manager
For Kestra instance deployed using the Kafka/Elastic backend, the secret backend can be configured like this:
yaml
kestra:
  secret:
    type: elasticsearch
    elasticsearch:
      secret: ""your-secret-key""
Your secret key should be encrypted. You can find an example of encryption key here.
Default Tags
For each secret manager, you can configure the default tags that will be added to all newly created or updated secrets.
Configuration example:
yaml
kestra:
  secret:
    <secret-type>:
      # a map of default key/value tags
      tags:
        application: kestra-production
Enable Caching
If you use a secret manager provided by a cloud service provider, it may be worth enabling the secret cache to reduce the number of calls to the secret manager API.
Configuration example:
yaml
kestra:
  secret:
    cache:
      enabled: true
      maximumSize: 1000
      expireAfterWrite: 60s
kestra.secret.cache.enabled: Specifies whether to enable caching for secrets.
kestra.secret.cache.maximumSize: The maximum number of entries the cache may contain.
kestra.secret.cache.expireAfterWrite: Specifies that each entry should be automatically removed from the cache once this duration has elapsed after the entry's creation.
Was this page helpful?
Yes
No
Enterprise
Secrets
Enterprise
Service Accounts""""""",1970,9346,kestra
https://kestra.io/docs/enterprise/service-accounts,"""""""DocsCloud & Enterprise Edition APIService Accounts
Service Accounts
Table of Contents
Service Accounts vs. Users
Creating a Service Account
Users vs. Service Accounts vs. API Tokens
The Purpose of Service Accounts
Allocating Service Accounts to Groups
Service Account Name Convention
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.15.0
How to create and manage Service Accounts.
A Service Account represents an application that can access Kestra. It is not tied to a specific person, and does not have personal information (such as the first name, last name or email) attached to it. Instead, it only has a name, an optional description, an optional allocation to a group, and a list of Roles that grant it permissions to access specific resources.
Service Accounts vs. Users
In contrast to regular users, Service Accounts don't have a password and their access doesn't provide access to the Kestra UI ‚Äî they only have a programmatic API access to Kestra. You can think of Service Accounts as bots authenticating with Kestra using an API token.
Creating a Service Account
To create a new service account, go to the Service Accounts page under the Administration section and click on the Create button. Fill in the form with the required information including the name and description, and click Save:
Once you have created a service account, you can add a Role that will grant the service account permissions to specific resources. To do this, click on the Add button and select the role you want to assign to the service account.
Finally, you can generate an API token for the service account by clicking on the Create button. This will generate a token that you can use to authenticate the service account with Kestra from external applications such as CI/CD pipelines (e.g. in Terraform provider configuration or GitHub Actions secrets).
Note: You can configure the token to expire after a certain period of time, or to never expire. Also, there is a toggle called Extended that will automatically prolong the token's expiration date by the specified number of days (Max Age) if the token is actively used. That toggle is disabled by default.
Once you confirm the API token creation via the Generate button, the token will be generated and displayed in the UI. Make sure to copy the token and store it in a secure location as it will not be displayed again.
Users vs. Service Accounts vs. API Tokens
You can create an API token for a regular User as well. While Service Accounts are recommended for programmatic API access to Kestra from CI/CD or other external applications, it's often useful to create an API token for a regular user, so that programmatic actions performed by that user can be tracked and audited.
Therefore, the difference between a Service Account and a User is that a Service Account is designed for programmatic access, and doesn't have a password or personal information attached to it. Instead, it is authenticated exclusively using an API token. A User, on the other hand, can interact with both the Kestra UI and the API, and can be authenticated using a password or an API token.
The Purpose of Service Accounts
Service Accounts are intended for programmatic access to Kestra from any other application, such as CI/CD pipelines or your own custom APIs. For example, you can use the token to authenticate with Kestra Terraform provider or Kestra's GitHub Actions CI/CD pipeline.
Allocating Service Accounts to Groups
Each Service Account can be attached to one or more Groups e.g. a group ‚ÄúBots‚Äù that centrally governs programmatic access for CI/CD across multiple projects with just one Role. This is useful to manage programmatic access used by Terraform, GitHub Action, or other external applications, in one place by attaching a single Role to that Group.
Speaking of CI/CD, note that currently Kestra supports authenticating with both Basic Authentication User, as well as with an API token:
Use the --api-token=mytoken CLI property to allow authenticating with a service account token, e.g.:
./kestra namespace files update prod scripts . \
--server=https://demo.kestra.io --api-token yourtoken
Use the --user user_email:password flag to the CLI to allow authenticating with a Basic Authentication access, e.g.:
./kestra namespace files update prod scripts . \
--server=https://demo.kestra.io --user=rick.astely@kestra.io:password42
Service Account Name Convention
When creating a new service account, make sure to follow the DNS naming convention. Specifically, the name property needs to:
contain at most 63 characters
contain only lowercase alphanumeric characters or hyphens (i.e. the - character)
start with an alphanumeric character
end with an alphanumeric character.
Some examples to make that clear:
‚úÖ my-service-account is a valid name
‚úÖ my-service-account-1 is a valid name
‚ùå MY_SERVICE_ACCOUNT is not a valid name because it contains uppercase characters and underscores
‚ùå myServiceAccount is not a valid name because it contains uppercase characters and camel case
‚ùå my-service-account- is not a valid name because it ends with a hyphen.
Why do we follow such a restrictive convention? We follow the standard DNS-tyle pattern to be ready for potential future use cases where we could e.g. forward the service account name to a Kubernetes pod's labels. This way, we ensure that the service account name can be used in a variety of contexts without any issues.
Was this page helpful?
Yes
No
Enterprise
Secrets Manager
Enterprise
Task Runners""""""",1166,5554,kestra
https://kestra.io/docs/enterprise/task-runners,"""""""DocsCloud & Enterprise Edition APITask Runners
Task Runners
Table of Contents
Task Runner Types
Task Runners vs Worker Groups
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Task Runner capabilities and supported plugins.
Task Runners offer a powerful way to offload compute-intensive tasks to remote environments.
Task Runner Types
There are a number of task runner types. The Docker and Process task runners are included in the Open Source edition. All other types require an Enterprise Edition license or a Kestra Cloud account.
Enterprise Edition Task Runners:
Kubernetes
AWS Batch
Azure Batch
Google Batch
Google Cloud Run
Task Runners vs Worker Groups
Task Runners and Worker Groups both offload compute-intensive tasks to dedicated workers. However, worker groups have a broader scope, applying to all tasks in Kestra, whereas task runners are limited to scripting tasks (Python, R, JavaScript, Shell, dbt, etc. ‚Äî see the full list here). Worker groups can be used with any plugins.
For instance, if you need to query an on-premise SQL Server database running on a different server than Kestra, your SQL Server Query task can target a worker with access to that server. Additionally, worker groups can fulfill the same use case as task runners by distributing the load of scripting tasks to dedicated workers with the necessary resources and dependencies (incl. hardware, region, network, operating system).
You can read more about the differences on the dedicated page.
Was this page helpful?
Yes
No
Enterprise
Service Accounts
Enterprise
Worker Group""""""",343,1629,kestra
https://kestra.io/docs/enterprise/worker-group,"""""""DocsCloud & Enterprise Edition APIWorker Group
Worker Group
Table of Contents
Creating Worker Groups
Starting Workers for a Worker Group
Using Worker Groups
When to use Worker Groups
Load balancing
Central Queue to distribute task runs and polling triggers
What if multiple workers from the same worker group poll for jobs from the central queue?
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.10.0
How to configure Worker Groups in Kestra Enterprise Edition.
Worker Group is a set of workers that can be targeted specifically for a task execution or a polling trigger evaluation.
Creating Worker Groups
To create a new worker group, navigate to the Cluster page under the Administration section in the UI, go to the Worker Groups tab and click on the + Create button. Then, set a key (and optionally, also a description) for that worker group. You can accomplish the same via the API, CLI, or Terraform.
Starting Workers for a Worker Group
Once a worker group key is created, you can start a worker with the --worker-group workerGroupKey flag to assign it to that worker group. You can also assign a default worker group at the namespace and tenant level.
The Worker Groups UI tracks the health of worker groups, showing how many workers are polling for tasks within each worker group. This gives you visibility into which worker groups are active, and the number of active workers.
Using Worker Groups
To assign a worker group, add the workerGroup.key property to the task or the polling trigger. A default worker group can also be configured at the namespace or tenant level.
The flow editor validates worker group keys when creating flows from the UI. If the provided key doesn‚Äôt exist, the syntax validation will prevent the flow from being saved.
Example flow configuration with a worker group:
yaml
id: worker_group
namespace: dev
tasks:
  - id: wait
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - sleep 10
    workerGroup:
      key: gpu
If the workerGroup.key property is not provided, all tasks and polling triggers are executed on the default worker group. That default worker group doesn't have a dedicated key.
When to use Worker Groups
Here are common use cases in which Worker Groups can be beneficial:
Execute tasks and polling triggers on specific compute instances (e.g., a VM with a GPU and preconfigured CUDA drivers).
Execute tasks and polling triggers on a worker with a specific Operating System (e.g., a Windows server).
Restrict backend access to a set of workers (firewall rules, private networks, etc.).
Execute tasks and polling triggers close to a remote backend (region selection).
Even if you are using worker groups, we strongly recommend having at least one worker in the default worker group.
Load balancing
Whether you leverage worker groups or not, Kestra will balance the load across all available workers. The primary difference is that with worker groups, you can target specific workers for task execution or polling trigger evaluation.
A worker is part of a worker group if it is started with --worker-group workerGroupKey.
There's a slight difference between Kafka and JDBC architectures in terms of load balancing:
The Kafka architecture relies on Kafka consumer group protocol ‚Äî each worker group will use a different consumer group protocol, therefore each worker group will balance the load independently.
For JDBC, each worker within a group will poll the queues database table using the same poll query. All workers within the same worker group will poll for task runs and polling triggers in a FIFO manner.
Central Queue to distribute task runs and polling triggers
In both JDBC and Kafka architectures, we leverage a Central Queue to ensure that tasks and polling triggers are executed only once and in the right order.
Here's how it works:
Jobs (task runs and polling triggers) are submitted to a centralized queue. The queue acts as a holding area for all incoming jobs.
Workers periodically poll the central queue to check for available jobs. When a worker becomes free, it requests the next job from the queue.
Kestra backend keeps track of assignment of jobs to workers to ensure reliable execution and prevent duplicate processing.
What if multiple workers from the same worker group poll for jobs from the central queue?
Whether the jobs (task runs and polling triggers) are evenly distributed among workers depends on several factors:
The order in which workers poll the queue will affect distribution ‚Äî workers that poll the queue first will get jobs first (FIFO).
Variations in worker compute capabilities (and their processing speeds) can cause uneven job distribution. Faster workers will complete jobs and return to poll the queue more quickly than slower workers.
Was this page helpful?
Yes
No
Enterprise
Task Runners
Enterprise
Worker Isolation""""""",988,4965,kestra
https://kestra.io/docs/enterprise/worker-isolation,"""""""DocsCloud & Enterprise Edition APIWorker Isolation
Worker Isolation
Table of Contents
Java security
kestra.ee.java-security.forbidden-paths
kestra.ee.java-security.authorized-class-prefix
kestra.ee.java-security.forbidden-class-prefix
Scripting isolation
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
How to configure worker isolation in Kestra.
Java security
By default, Kestra uses a shared worker to handle workloads. This is fine for most use cases. However, when you are using a shared Kestra instance between multiple teams, this can allow people to access temporary files created by Kestra with powerful tasks like Groovy, Jython, etc... This is because the worker shares the same file system.
You can use the following to opt-in to real isolation of file systems using advanced Kestra EE Java security:
yaml
kestra:
  ee:
    javaSecurity:
      enabled: true
      forbiddenPaths:
        - /etc/
      authorizedClassPrefix:
        - io.kestra.plugin.core
        - io.kestra.plugin.gcp
kestra.ee.java-security.forbidden-paths
This is a list of paths on the file system that the Kestra Worker will be forbidden to read or write to. This can be useful to protect Kestra configuration files, for example.
kestra.ee.java-security.authorized-class-prefix
This is a list of classes that can create threads. Here you can set a list of prefixes (namespace) classes that will be allowed. All others will be refused.
For example, GCP plugins will need to create a thread in order to reach the GCP API. Since this whole plugin is deemed safe, you can whitelist it.
kestra.ee.java-security.forbidden-class-prefix
yaml
kestra:
  ee:
    javaSecurity:
      enabled: true
      forbiddenClassPrefix:
        - io.kestra.plugin.scripts
This is a list of classes that can't create any threads. Others plugins will be authorized.
Currently, all the official Kestra plugins are safe to be whitelisted except all scripts plugins since they allow custom code to be created that can be read and written on the file system. Do not add these to the forbidden-class-prefix.
Scripting isolation
For Bash tasks and other script tasks in the core, we advise you to force io.kestra.plugin.scripts.runner.docker.Docker isolation and to configure global cluster pluginDefaults:
yaml
kestra:
  tasks:
    defaults:
      - type: io.kestra.plugin.scripts.shell.Commands
        forced: true
        values:
          containerImage: ubuntu:latest
          taskRunner:
            type: io.kestra.plugin.scripts.runner.docker.Docker
You will need to add all script plugins tasks (like Python & Node) to be sure that no tasks can bypass the docker isolation.
Was this page helpful?
Yes
No
Enterprise
Worker Group
Docs
Task Runners""""""",626,2771,kestra
https://kestra.io/docs/task-runners,"""""""DocsTask Runners
Task Runners
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Open Source Edition
Enterprise Edition
>= 0.18.0
Task Runners is an extensible, pluggable system capable of executing your tasks in arbitrary remote environments.
Many data processing tasks are computationally intensive and require a lot of resources (such as CPU, GPU, and memory). Instead of provisioning always-on servers, Task Runners can execute your code on dynamically provisioned compute instances in the cloud, such as AWS ECS Fargate, Azure Batch, Google Batch, auto-scaled Kubernetes clusters, and more.
All you have to do to offload your task execution to a remote environment is to specify the taskRunner type in your task configuration. Each type of a task runner is a plugin with its own schema. The built-in code editor provides documentation, autocompletion, and syntax validation for all task runner plugin properties to ensure correctness, standardization, and consistency.
Note that some task runner plugins are available only in the Enterprise Edition. If you want to try them out, please reach out.
Task Runner Overview
Task Runner capabilities and supported plugins.
Task Runner Benefits
How Task Runners can help with resource allocation and environment management.
Task Runner vs. Worker Group
Find out when to use Task Runners or Worker Groups.
Task Runner Types
This section lists all task runners available in Kestra.
Was this page helpful?
Yes
No
Enterprise
Worker Isolation
Task Runners
Task Runner Overview""""""",323,1556,kestra
https://kestra.io/docs/task-runners/overview,"""""""DocsTask RunnersTask Runner Overview
Task Runner Overview
Table of Contents
Task Runners Capabilities
Plugins Supporting Task Runners
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Open Source Edition
Enterprise Edition
>= 0.18.0
Task Runner capabilities and supported plugins.
Task Runners Capabilities
Task Runners offer a powerful way to offload compute-intensive tasks to remote environments. The table below highlights their capabilities.
Capability Description
Fine-grained resource allocation Task Runners give you full control over the compute resources ‚Äî you can flexibly choose how much CPU, memory, or GPU you want to allocate to specific tasks.
Flexible deployment patterns Task Runners support various deployment models, including AWS ECS Fargate, Azure Batch, Google Batch, Kubernetes, and more. You can mix and match different runners even within a single workflow.
No vendor lock-in Task Runners are built on top of a plugin ecosystem, so you can run your code on any cloud provider or on-premises infrastructure without being locked to a specific vendor or deployment model.
Task isolation Your tasks run in fully isolated container environments without interfering with each other or competing for resources.
Made for development and production You can develop your code locally in Docker containers and run the same code in a production environment on a Kubernetes cluster. Thanks to task runners, setting this up is as simple as changing a single property.
Centralized configuration management Task Runners make it easy to centrally govern your configuration. For example, you can use pluginDefaults on a namespace level to manage your task runner configuration and credentials in a single place.
Documentation and autocompletion Each task runner is a plugin with its own schema. The built-in code editor provides documentation, autocompletion and syntax validation for all runner properties to ensure correctness, standardization and consistency.
No changes to your code You can run the same business logic in different environments without changing anything in your code.
Fully customizable If you need more customization, you can create your own Task Runner plugin to match your specific deployment patterns.
Plugins Supporting Task Runners
Task Runners are intended to be used in the tasks from the Script Plugin and its sub-plugins tasks, including:
Python
Node
Shell
PowerShell
R
Julia
Ruby
dbt
Singer
SQLMesh
Ansible
Terraform
Modal
AWS CLI
GCloud CLI
Azure CLI
Anytime you see a task that can execute a script or a series of commands, it's a script task that contains a taskRunner property.
Was this page helpful?
Yes
No
Docs
Task Runners
Task Runners
Task Runner Benefits""""""",547,2742,kestra
https://kestra.io/docs/task-runners/benefits,"""""""DocsTask RunnersTask Runner Benefits
Task Runner Benefits
Table of Contents
Docker in development, Kubernetes in production
Centralized configuration management
Documentation and autocompletion
Full customization: create your own Task Runner
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Open Source Edition
Enterprise Edition
>= 0.18.0
How Task Runners can help with resource allocation and environment management.
Docker in development, Kubernetes in production
Many Kestra users develop their scripts locally in Docker containers and then run the same code in a production environment as Kubernetes pods. Thanks to the taskRunner property, setting this up is a breeze. Below is an example showing how you can combine pluginDefaults with the taskRunner property to use Docker in the development environment and Kubernetes in production ‚Äî all without changing anything in your code.
Development namespace/tenant/instance:
yaml
pluginDefaults:
  - type: io.kestra.plugin.scripts
    values:
      taskRunner:
        type: io.kestra.plugin.scripts.runner.docker.Docker
        pullPolicy: IF_NOT_PRESENT # in dev, only pull the image when needed
        cpu:
          cpus: 1
        memory:
          memory: 512Mi
Production namespace/tenant/instance:
yaml
pluginDefaults:
  - type: io.kestra.plugin.scripts
    values:
      taskRunner:
        type: io.kestra.plugin.ee.kubernetes.runner.Kubernetes
        namespace: company.team
        pullPolicy: ALWAYS # Always pull the latest image in production
        config:
          username: ""{{ secret('K8S_USERNAME') }}""
          masterUrl: ""{{ secret('K8S_MASTER_URL') }}""
          caCert: ""{{ secret('K8S_CA_CERT') }}""
          clientCert: ""{{ secret('K8S_CLIENT_CERT') }}""
          clientKey: ""{{ secret('K8S_CLIENT_KEY') }}""
        resources: # can be overriden by a specific task if needed
          request: # The resources the container is guaranteed to get
            cpu: ""500m"" # Request 1/2 of a CPU (500 milliCPU)
            memory: ""256Mi"" # Request 256 MB of memory
Note how the containerImage property is not included in the taskRunner configuration but as a generic property available to any scripting task. This makes the configuration more flexible as usually the container image changes more often than the standard runner configuration. For instance, the dbt plugin may need a different image than the generic Python plugin, but the runner configuration can stay the same.
Centralized configuration management
The combination of pluginDefaults and taskRunner properties allows you to centrally manage your task runner configuration. For example, you can use pluginDefaults on a namespace level to centrally manage your AWS credentials for the Batch task runner plugin.
yaml
pluginDefaults:
  - type: io.kestra.plugin.ee.aws.runner.Batch
    values:
      accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID') }}""
      secretKeyId: ""{{ secret('AWS_SECRET_ACCESS_KEY') }}""
      region: ""us-east-1""
Documentation and autocompletion
Each task runner is a plugin with its own icon, documentation, and schema to validate its properties. The built-in code editor in the Kestra UI provides autocompletion and syntax validation for all runner properties, and when you click on the runner's name in the editor, you can see its documentation on the right side of the screen.
Full customization: create your own Task Runner
You can create a custom task runner plugin for your specific environment, build it as a JAR file, and add that file to the plugins directory. Once you restart Kestra, your custom runner plugin will be available on any script task in the system.
Was this page helpful?
Yes
No
Task Runners
Task Runner Overview
Task Runners
Task Runner vs. Worker Group""""""",806,3779,kestra
https://kestra.io/docs/task-runners/task-runners-vs-worker-groups,"""""""DocsTask RunnersTask Runner vs. Worker Group
Task Runner vs. Worker Group
Table of Contents
Overview
Key differences
Use cases
Usage
Worker Groups Usage
Task Runners Usage
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Find out when to use Task Runners or Worker Groups.
Overview
Task Runners and Worker Groups both offload compute-intensive tasks to dedicated workers. However, worker groups have a broader scope, applying to all tasks in Kestra, whereas task runners are limited to scripting tasks (Python, R, JavaScript, Shell, dbt, etc. ‚Äî see the full list here). Worker groups can be used with any plugins.
For instance, if you need to query an on-premise SQL Server database running on a different server than Kestra, your SQL Server Query task can target a worker with access to that server. Additionally, worker groups can fulfill the same use case as task runners by distributing the load of scripting tasks to dedicated workers with the necessary resources and dependencies (incl. hardware, region, network, operating system).
Key differences
Worker groups are always-on servers that can run any task in Kestra, while task runners are ephemeral containers that are spun up only when a task is executed. This has implications with respect to latency and cost:
Worker groups are running on dedicated servers, so they can start executing tasks immediately with millisecond latency. Task runners, on the other hand, need to be spun up before they can execute a task, which can introduce latency up to minutes. For example, the AWS Batch task runner can take up to 50 seconds to register a task definition and start a container on AWS ECS Fargate. With the Google Batch task runner, it can take up to 90 seconds if you don't use a compute reservation because GCP spins up a new compute instance for each task run.
Task runners can be more cost-effective for infrequent short-lived tasks, while worker groups are more cost-effective for frequent and long-running tasks.
Worker Groups work at the task level whereas Task Runner is only available for some task types such as Scripts, Commands, CLI.
The table below summarizes the differences between task runners and worker groups.
Task Runners Worker Groups
Scope Limited to scripting tasks Applicable to all tasks in Kestra
Use Cases Scripting tasks (Python, R, etc.) Any task, including database queries
Deployment Ephemeral containers Always-on servers
Resource Handling Spins up as needed Constantly available
Latency High latency (seconds, up to minutes) Low latency (milliseconds)
Cost Efficiency Suitable for infrequent tasks Suitable for frequent or long-running tasks
Use cases
Here are common use cases in which Worker Groups can be beneficial:
Execute tasks and polling triggers on specific servers (e.g., a VM with access to your on-premise database or a server with preconfigured CUDA drivers).
Execute tasks and polling triggers on a worker with a specific Operating System (e.g., a Windows server configured with specific software needed for a task).
Restrict backend access to a set of workers (firewall rules, private networks, etc.).
Here are common use cases in which Task Runners can be beneficial:
Offload compute-intensive tasks to compute resources provisioned on-demand.
Run tasks that temporarily require more resources than usual e.g., during a backfill or a nightly batch job.
Run tasks that require specific dependencies or hardware (e.g., GPU, memory, etc.).
Usage
Worker Groups Usage
First, make sure you start the worker with the --worker-group myWorkerGroupKey flag. It's important for the new worker to have a configuration similar to that of your principal Kestra server and to have access to the same backend database and internal storage. The configuration file will be passed via the --config flag, as shown in the example below.
shell
kestra server worker --worker-group=myWorkerGroupKey --config=/path/to/kestra-config.yaml
To assign a task to the desired worker group, simply add a workerGroup.key property. This will ensure that the task or polling trigger is executed on a worker in the specified worker group.
yaml
id: myflow
namespace: company.team
tasks:
  - id: gpu
    type: io.kestra.plugin.scripts.python.Commands
    namespaceFiles:
      enabled: true
    commands:
      - python ml_on_gpu.py
    workerGroup:
      key: myWorkerGroupKey
A default worker group can also be configured at the namespace level so that all tasks and polling triggers in that namespace are executed on workers in that worker group by default.
Task Runners Usage
To use a task runner, add a taskRunner property to your task configuration and choose the desired type of task runner. For example, to use the AWS Batch task runner, you would configure your task as follows:
yaml
id: aws_ecs_fargate_python
namespace: company.team
tasks:
  - id: run_python
    type: io.kestra.plugin.scripts.python.Script
    containerImage: ghcr.io/kestra-io/pydata:latest
    taskRunner:
      type: io.kestra.plugin.ee.aws.runner.Batch
      computeEnvironmentArn: ""arn:aws:batch:eu-west-1:707969873520:compute-environment/kestraFargateEnvironment""
      jobQueueArn: ""arn:aws:batch:eu-west-1:707969873520:job-queue/kestraJobQueue""
      executionRoleArn: ""arn:aws:iam::707969873520:role/kestraEcsTaskExecutionRole""
      taskRoleArn: ""arn:aws:iam::707969873520:role/ecsTaskRole""
      accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID') }}""
      secretKeyId: ""{{ secret('AWS_SECRET_ACCESS_KEY') }}""
      region: eu-west-1
      bucket: kestra-ie
    script: |
      import platform
      import socket
      import sys
      def print_environment_info():
          print(""Hello from AWS Batch and kestra!"")
          print(f""Host's network name: {platform.node()}"")
          print(f""Python version: {platform.python_version()}"")
          print(f""Platform information (instance type): {platform.platform()}"")
          print(f""OS/Arch: {sys.platform}/{platform.machine()}"")
          try:
              hostname = socket.gethostname()
              ip_address = socket.gethostbyname(hostname)
              print(f""Host IP Address: {ip_address}"")
          except socket.error as e:
              print(""Unable to obtain IP address."")
      if __name__ == '__main__':
          print_environment_info()
Was this page helpful?
Yes
No
Task Runners
Task Runner Benefits
Task Runners
Task Runner Types""""""",1414,6430,kestra
https://kestra.io/docs/task-runners/types,"""""""DocsTask RunnersTask Runner Types
Task Runner Types
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Open Source Edition
Enterprise Edition
>= 0.18.0
This section lists all task runners available in Kestra.
Each taskRunner is identified by its type. The Process and Docker task runners are fully open-source and located within the Kestra repository. By default, Kestra runs all script tasks using the Docker task runner.
All other plugins such as the AWS Batch, Google Batch, Google Cloud Run, Azure Batch, Kubernetes, and more planned for the future, are managed by Kestra and require an Enterprise Edition license. If you want to try them out, please reach out.
Process Task Runner
Run tasks as local processes.
Docker Task Runner
Run tasks as Docker containers.
Kubernetes Task Runner
Run tasks as Kubernetes pods.
AWS Batch Task Runner
Run tasks as AWS ECS Fargate or EC2 containers using AWS Batch.
Azure Batch Task Runner
Run tasks as containers on Azure Batch VMs.
Google Batch Task Runner
Run tasks as containers on Google Cloud VMs.
Google Cloud Run Task Runner
Run tasks as containers on Google Cloud Run.
Was this page helpful?
Yes
No
Task Runners
Task Runner vs. Worker Group
Types
Process Task Runner""""""",282,1253,kestra
https://kestra.io/docs/task-runners/types/process-task-runner,"""""""DocsTask RunnersTask Runner TypesProcess Task Runner
Process Task Runner
Table of Contents
How to use the Process task runner
Benefits
Combining task runners with Worker Groups
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Open Source Edition
Enterprise Edition
>= 0.18.0
Run tasks as local processes.
How to use the Process task runner
Here is an example of a Shell script configured with the Process task runner which runs a Shell command as a child process in the Kestra host:
yaml
id: process_script_runner
namespace: company.team
tasks:
  - id: shell
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - echo ""Hello World!""
The Process task runner doesn‚Äôt have any additional configuration beyond the type property.
Benefits
The Process task runner is useful if you want to access local files e.g. to take advantage of locally configured software libraries and virtual environments.
Combining task runners with Worker Groups
You can combine the Process task runner with Worker Groups to run tasks on dedicated servers that might have specific software libraries or configurations. This powerful combination allows you to leverage the compute resources of your Worker Groups while running tasks as local processes without the overhead of containerization.
The example below shows how to combine the Process task runner with Worker Groups to fully leverage the GPU resources of a dedicated server:
yaml
id: python_on_gpu
namespace: company.team
tasks:
  - id: gpu_intensive_ai_workload
    type: io.kestra.plugin.scripts.python.Commands
    namespaceFiles:
      enabled: true
    commands:
      - python main.py
    workerGroup:
      key: gpu
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
Note that Worker Group is an Enterprise Edition functionality. If you want to try it out, please reach out.
Was this page helpful?
Yes
No
Task Runners
Task Runner Types
Types
Docker Task Runner""""""",432,2034,kestra
https://kestra.io/docs/task-runners/types/docker-task-runner,"""""""DocsTask RunnersTask Runner TypesDocker Task Runner
Docker Task Runner
Table of Contents
How to use the Docker task runner
Docker task runner properties
Task runner behavior in a failure scenario
Kestra running in a Docker container, Task Runner running in DinD
Kestra running in Kubernetes, Task Runner running in DinD
Kestra deployed with Docker-Compose, Task Runner running in DinD
Insecure Registry
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Open Source Edition
Enterprise Edition
>= 0.18.0
Run tasks as Docker containers.
How to use the Docker task runner
Here is an example using the Docker task runner executing the commands in a Docker container:
yaml
id: docker_script_runner
namespace: company.team
tasks:
  - id: shell
    type: io.kestra.plugin.scripts.shell.Commands
    containerImage: centos
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      cpu:
        cpus: 1
    commands:
      - echo ""Hello World!""
Once you specify the taskRunner type, you get the autocompletion and validation for the runner-specific properties. In the example above, the task allocates 1 CPU to the container.
Docker task runner properties
The only property required by the taskRunner is the containerImage property that needs to be set on the script task. The image can be from a public or private registry.
Additionally, using the Docker task runner you can configure memory allocation, volumes, environment variables, and more. For a full list of properties available in the Docker task runner, check the Docker plugin documentation or explore the same in the built-in Code Editor in the Kestra UI.
The Docker task runner executes the script task as a container in a Docker-compatible engine. This means that you can use it to run scripts within a Kubernetes cluster with Docker-In-Docker (dind) or in a local Docker engine as well.
Task runner behavior in a failure scenario
Generally speaking, each task runner container initiated by Kestra will continue running until the task completes, even if the Kestra worker is terminated (e.g. due to a crash). However, there are some caveats to be aware of depending on how Kestra and the task runner are deployed.
Kestra running in a Docker container, Task Runner running in DinD
When Kestra runs in a Docker container and uses DinD for task runners, terminating the Kestra container will also terminate the DinD container and any running task containers inside DinD. No container is automatically restarted.
Kestra running in Kubernetes, Task Runner running in DinD
When Kestra and DinD are deployed in the same pod in a Kubernetes environment, the pod will be restarted if Kestra Worker fails. This ensures that the DinD container and any task runner containers are also restarted.
Kestra deployed with Docker-Compose, Task Runner running in DinD
When using Docker-Compose, Kestra and DinD containers can be managed independently. Restarting the Kestra container does NOT automatically restart the DinD container. Therefore, task runners running inside DinD may continue running even if Kestra is restarted.
Insecure Registry
The Docker task runner supports insecure registries. Prior to using this feature, ensure the insecure registry is configured on the host machine that your Kestra server is running on.
For example, if you have the insecure registry 10.10.1.5:5000, please add the following configuration to /etc/docker/daemon.json and then restart your Docker daemon.
json
{
  ""insecure-registries"" : [""10.10.1.5:5000""]
}
This can then be used in a flow with the following YAML
yaml
id: docker_example
namespace: demo
tasks:
  - id: my_command
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      config: |
        {
          ""insecure-registries"" : [""10.10.1.5:5000""]
        }
    containerImage: 10.10.1.5:5000/my-image
    commands:
      - echo ""Hello World!""
Was this page helpful?
Yes
No
Types
Process Task Runner
Types
Kubernetes Task Runner""""""",928,4052,kestra
https://kestra.io/docs/task-runners/types/kubernetes-task-runner,"""""""DocsTask RunnersTask Runner TypesKubernetes Task Runner
Kubernetes Task Runner
Table of Contents
How to use the Kubernetes task runner
File handling
Failure scenarios
Specifying resource requests for Python scripts
Using plugin defaults to avoid repetition
Guides
Google Kubernetes Engine (GKE)
Amazon Elastic Kubernetes Service (EKS)
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Run tasks as Kubernetes pods.
How to use the Kubernetes task runner
The Kubernetes task runner executes tasks in a specified Kubernetes cluster. It is useful to declare resource limits and resource requests.
Here is an example of a workflow with a task running Shell commands in a Kubernetes pod:
yaml
id: kubernetes_task_runner
namespace: company.team
description: |
  To get the kubeconfig file, run: `kubectl config view --minify --flatten`.
  Then, copy the values to the configuration below.
  Here is how Kubernetes task runner properties (on the left) map to the kubeconfig file's properties (on the right):
  - clientKeyData: client-key-data
  - clientCertData: client-certificate-data
  - caCertData: certificate-authority-data
  - masterUrl: server e.g. https://docker-for-desktop:6443
  - username: user e.g. docker-desktop
inputs:
  - id: file
    type: FILE
tasks:
  - id: shell
    type: io.kestra.plugin.scripts.shell.Commands
    inputFiles:
      data.txt: ""{{ inputs.file }}""
    outputFiles:
      - ""*.txt""
    containerImage: centos
    taskRunner:
      type: io.kestra.plugin.ee.kubernetes.runner.Kubernetes
      config:
        clientKeyData: client-key-data
        clientCertData: client-certificate-data
        caCertData: certificate-authority-data
        masterUrl: server e.g. https://docker-for-desktop:6443
        username: user e.g. docker-desktop
    commands:
      - echo ""Hello from a Kubernetes task runner!""
      - cp data.txt out.txt
To deploy Kubernetes with Docker Desktop, check out this guide.
To install kubectl, check out this guide.
File handling
If your script task has inputFiles or namespaceFiles configured, an init container will be added to upload files into the main container.
Similarly, if your script task has outputFiles configured, a sidecar container will be added to download files from the main container.
All containers will use an in-memory emptyDir volume for file exchange.
Failure scenarios
If a task is resubmitted (e.g. due to a retry or a Worker crash), the new Worker will reattach to the already running (or an already finished) pod instead of starting a new one.
Specifying resource requests for Python scripts
Some Python scripts may require more resources than others. You can specify the resources required by the Python script in the resources property of the task runner.
yaml
id: kubernetes_resources
namespace: company.team
tasks:
  - id: python_script
    type: io.kestra.plugin.scripts.python.Script
    containerImage: ghcr.io/kestra-io/pydata:latest
    taskRunner:
      type: io.kestra.plugin.ee.kubernetes.runner.Kubernetes
      namespace: default
      pullPolicy: Always
      config:
        username: docker-desktop
        masterUrl: https://docker-for-desktop:6443
        caCertData: xxx
        clientCertData: xxx
        clientKeyData: xxx
      resources:
        request: # The resources the container is guaranteed to get
          cpu: ""500m"" # Request 1/2 of a CPU (500 milliCPU)
          memory: ""128Mi"" # Request 128 MB of memory
    outputFiles:
      - ""*.json""
    script: |
      import platform
      import socket
      import sys
      import json
      from kestra import Kestra
      print(""Hello from a Kubernetes runner!"")
      host = platform.node()
      py_version = platform.python_version()
      platform = platform.platform()
      os_arch = f""{sys.platform}/{platform.machine()}""
      def print_environment_info():
          print(f""Host's network name: {host}"")
          print(f""Python version: {py_version}"")
          print(f""Platform info: {platform}"")
          print(f""OS/Arch: {os_arch}"")
          env_info = {
              ""host"": host,
              ""platform"": platform,
              ""os_arch"": os_arch,
              ""python_version"": py_version,
          }
          Kestra.outputs(env_info)
          filename = ""environment_info.json""
          with open(filename, ""w"") as json_file:
              json.dump(env_info, json_file, indent=4)
      if __name__ == '__main__':
          print_environment_info()
For a full list of properties available in the Kubernetes task runner, check the Kubernetes plugin documentation or explore the same in the built-in Code Editor in the Kestra UI.
Using plugin defaults to avoid repetition
You can use pluginDefaults to avoid repeating the same configuration across multiple tasks. For example, you can set the pullPolicy to Always for all tasks in a namespace:
yaml
id: k8s_taskrunner
namespace: company.team
tasks:
  - id: parallel
    type: io.kestra.plugin.core.flow.Parallel
    tasks:
      - id: run_command
        type: io.kestra.plugin.scripts.python.Commands
        containerImage: ghcr.io/kestra-io/kestrapy:latest
        commands:
          - pip show kestra
      - id: run_python
        type: io.kestra.plugin.scripts.python.Script
        containerImage: ghcr.io/kestra-io/pydata:latest
        script: |
          import socket
          ip_address = socket.gethostbyname(hostname)
          print(""Hello from AWS EKS and kestra!"")
          print(f""Host IP Address: {ip_address}"")
pluginDefaults:
  - type: io.kestra.plugin.scripts.python
    forced: true
    values:
      taskRunner:
        type: io.kestra.plugin.ee.kubernetes.runner.Kubernetes
        namespace: default
        pullPolicy: Always
        config:
          username: docker-desktop
          masterUrl: https://docker-for-desktop:6443
          caCertData: |-
            placeholder
          clientCertData: |-
            placeholder
          clientKeyData: |-
            placeholder
Guides
Below are a number of guides to help you set up the Kubernetes Task Runner on different platforms.
Google Kubernetes Engine (GKE)
Before you begin
Before you start, you need to have the following:
A Google Cloud account.
A Kestra instance in a version 0.16.0 or later with Google credentials stored as secrets or environment variables within the Kestra instance.
Set up Google Cloud
Inside Google Cloud, you'll need to do the following:
Create and select a project
Create a GKE Custer
Enable Kubernetes Engine API
Setup gcloud CLI with kubectl
Create a Service Account
Note: To authenticate with Google Cloud, you'll need to make a Service Account and add a JSON Key to Kestra. Read more about how to do that here For GKE, we'll need to make sure we have the Kubernetes Engine default node service account role assigned to our Service Account.
Creating our Flow
Here's an example flow for using the Kubernetes Task Runner with GKE. To authenticate, you need to use OAuth with a service account.
yaml
id: gke_task_runner
namespace: company.team
tasks:
  - id: auth
    type: io.kestra.plugin.gcp.auth.OauthAccessToken
    projectId: ""projectid"" # update
    serviceAccount: ""{{ secret('GOOGLE_SA') }}"" # update
  - id: shell
    type: io.kestra.plugin.scripts.shell.Commands
    containerImage: centos
    taskRunner:
      type: io.kestra.plugin.ee.kubernetes.runner.Kubernetes
      config:
        caCertData: ""{{ secret('certificate-authority-data') }}"" # update
        masterUrl: https://cluster-external-endpoint # update
        username: gke_projectid_region_clustername # update
        oauthToken: ""{{ outputs.auth.accessToken['tokenValue'] }}""
    commands:
      - echo ""Hello from a Kubernetes task runner!""
You'll need to use gcloud CLI tool to get the credentials such as username, masterUrl and caCertData. You can do this by running the following command:
bash
gcloud container clusters get-credentials clustername --region myregion --project projectid
You'll need to update the following arguments above with your own values:
clustername is the name of your cluster
myregion is the region your cluster is in, e.g. europe-west2
projectid is the id of your Google Cloud project.
Once you've run this command, you can now access your config with kubectl config view --minify --flatten so you can replace caCertData, masterUrl and username.
Amazon Elastic Kubernetes Service (EKS)
Here's an example flow for using Kubernetes Task Runner with AWS EKS. To authenticate, you need an OAuth token.
yaml
id: eks_task_runner
namespace: company.team
tasks:
  - id: shell
    type: io.kestra.plugin.scripts.shell.Commands
    containerImage: centos
    taskRunner:
      type: io.kestra.plugin.ee.kubernetes.runner.Kubernetes
      config:
        caCertData: ""{{ secret('certificate-authority-data') }}""
        masterUrl: https://xxx.xxx.region.eks.amazonaws.com
        username: arn:aws:eks:region:xxx:cluster/cluster_name
        oauthToken: xxx
    commands:
      - echo ""Hello from a Kubernetes task runner!""
Was this page helpful?
Yes
No
Types
Docker Task Runner
Types
AWS Batch Task Runner""""""",2091,9135,kestra
https://kestra.io/docs/task-runners/types/aws-batch-task-runner,"""""""DocsTask RunnersTask Runner TypesAWS Batch Task Runner
AWS Batch Task Runner
Table of Contents
How to use the AWS Batch task runner
How does the AWS Batch task runner work?
How to run tasks on AWS ECS Fargate
Full step-by-step guide: setting up AWS Batch from scratch
Before you begin
Terraform setup
AWS Management Console setup
Create an S3 Bucket
Run your Kestra task on AWS ECS Fargate
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Run tasks as AWS ECS Fargate or EC2 containers using AWS Batch.
How to use the AWS Batch task runner
To launch tasks on AWS Batch, there are three main concepts you need to be aware of:
Compute environment ‚Äî mandatory, it won't be created by the task. The compute environment is the infrastructure type for your tasks. It can be either an ECS Fargate or EC2 environment.
Job Queue ‚Äî optional, it will be created by the task if not specified. Creating a queue takes some time to set up, so be aware that this adds some latency to the script‚Äôs runtime.
Job ‚Äî created by the task runner; holds information about which image, commands, and resources to run on. In AWS ECS terminology, it‚Äôs the task definition for the ECS task.
To get started quickly, follow the instructions from this blueprint to provision all resources required to run containers on ECS Fargate.
How does the AWS Batch task runner work?
In order to support inputFiles, namespaceFiles, and outputFiles, the AWS Batch task runner currently relies on multi-containers ECS jobs and creates three containers for each job:
A before-container that uploads input files to S3.
The main container that fetches input files into the {{ workingDir }} directory and runs the task.
An after-container that fetches output files using outputFiles to make them available from the Kestra UI for download and preview.
Since we don't know the working directory of the container in advance, we always need to explicitly define the working directory and output directory when using the AWS Batch runner, e.g. use cat {{ workingDir }}/myFile.txt rather than cat myFile.txt.
How to run tasks on AWS ECS Fargate
The example below shows how to use the AWS Batch task runner to offload the execution of Python scripts to a serverless container running on AWS ECS Fargate:
yaml
id: aws_batch_runner
namespace: company.team
tasks:
  - id: scrape_environment_info
    type: io.kestra.plugin.scripts.python.Script
    containerImage: ghcr.io/kestra-io/pydata:latest
    taskRunner:
      type: io.kestra.plugin.ee.aws.runner.Batch
      region: eu-central-1
      accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID') }}""
      secretKeyId: ""{{ secret('AWS_SECRET_KEY_ID') }}""
      computeEnvironmentArn: ""arn:aws:batch:eu-central-1:707969873520:compute-environment/kestraFargateEnvironment""
      jobQueueArn: ""arn:aws:batch:eu-central-1:707969873520:job-queue/kestraJobQueue""
      executionRoleArn: ""arn:aws:iam::707969873520:role/kestraEcsTaskExecutionRole""
      taskRoleArn: arn:aws:iam::707969873520:role/ecsTaskRole
      bucket: kestra-product-de
    namespaceFiles:
      enabled: true
    outputFiles:
      - ""*.json""
    script: |
      import platform
      import socket
      import sys
      import json
      from kestra import Kestra
      print(""Hello from AWS Batch and kestra!"")
      def print_environment_info():
          print(f""Host's network name: {platform.node()}"")
          print(f""Python version: {platform.python_version()}"")
          print(f""Platform information (instance type): {platform.platform()}"")
          print(f""OS/Arch: {sys.platform}/{platform.machine()}"")
          env_info = {
              ""host"": platform.node(),
              ""platform"": platform.platform(),
              ""OS"": sys.platform,
              ""python_version"": platform.python_version(),
          }
          Kestra.outputs(env_info)
          filename = ""{{ workingDir }}/environment_info.json""
          with open(filename, ""w"") as json_file:
              json.dump(env_info, json_file, indent=4)
      if __name__ == ""__main__"":
          print_environment_info()
For a full list of properties available in the AWS Batch task runner, check the AWS plugin documentation or explore the same in the built-in Code Editor in the Kestra UI.
Full step-by-step guide: setting up AWS Batch from scratch
In order to use the AWS Batch task runner, you need to set up some resources in your AWS account. This guide will walk you through how you can configure the AWS Batch environment to run tasks on AWS ECS Fargate. We'll demonstrate two ways to set up the environment:
Using Terraform to provision all necessary resources using a simple terraform apply command.
Creating the resources step by step from the AWS Management Console.
Before you begin
Before you start, you need to have the following:
An AWS account.
Kestra Enterprise Edition instance in a version 0.18.0 or later with AWS credentials stored as secrets.
Terraform setup
Follow the instructions specified in the aws-batch/README within the terraform-deployments repository to provision all necessary resources using Terraform. You can also use the following blueprint that will create all necessary resources for you as part of a single Kestra workflow execution.
Here is a list of resources that will be created:
AWS Security Group: a security group for AWS Batch jobs with egress to the internet (required to be able to download public Docker images in your script tasks).
AWS IAM Roles and Policies: IAM roles and policies for AWS Batch and ECS Task Execution, including permissions for S3 access (S3 is used to store input and output files for container access).
AWS Batch Compute Environment: a managed ECS Fargate compute environment named kestraFargateEnvironment.
AWS Batch Job Queue: a job queue named kestraJobQueue for submitting batch jobs.
AWS Management Console setup
Create the ecsTaskExecutionRole IAM role
To use AWS Batch, we need an Execution Role that will allow AWS Batch to create and manage resources on our behalf.
Open the IAM console.
In the navigation menu, choose Roles.
Choose Create role.
In the Select trusted entity, choose Custom trust policy and paste the following `Trust policy JSON:
json
{
  ""Version"": ""2012-10-17"",
  ""Statement"": [
    {
      ""Sid"": """",
      ""Effect"": ""Allow"",
      ""Principal"": {
        ""Service"": ""ecs-tasks.amazonaws.com""
      },
      ""Action"": ""sts:AssumeRole""
    }
  ]
}
Click on Next and add the AmazonECSTaskExecutionRolePolicy.
Then, for Role Name, enter ecsTaskExecutionRole
Finally, click on Create role.
Make sure to copy the ARN of the role. You will need it later.
Create the ecsTaskRole IAM role
On top of the Execution Role, we will also need a Task Role that includes S3 access permissions to store files.
First, we'll need to create a policy the role can use for accessing S3.
Open the IAM console.
In the navigation menu, choose Policies.
Select JSON and paste the following into the Policy editor:
json
{
  ""Version"": ""2012-10-17"",
  ""Statement"": [
    {
      ""Action"": [
        ""s3:GetObject"",
        ""s3:PutObject"",
        ""s3:DeleteObject"",
        ""s3:ListBucket""
      ],
      ""Effect"": ""Allow"",
      ""Resource"": ""*""
    }
  ]
}
Select Next and type in a name for the policy, such as ecsTaskRoleS3Policy.
Once you're done, select Create policy.
Now we're ready to make our role. This is very similar to the previous role, but we need to add our new policy too:
Open the IAM console.
In the navigation menu, choose Roles.
Choose Create role.
In the Select trusted entity, choose Custom trust policy and paste the following `Trust policy JSON:
json
{
  ""Version"": ""2012-10-17"",
  ""Statement"": [
    {
      ""Sid"": """",
      ""Effect"": ""Allow"",
      ""Principal"": {
        ""Service"": ""ecs-tasks.amazonaws.com""
      },
      ""Action"": ""sts:AssumeRole""
    }
  ]
}
Click on Next
Search for the new policy and check the box on the left. Once you've done this, select Next.
Then, for Role Name, enter ecsTaskRole
Finally, click on Create role.
AWS Batch setup
Go to the AWS Batch console.
Then, click on ""Get Started"". If you don't see the ""Get Started"" button, add #firstRun to the URL:
This will launch a Wizard that will guide you through the process of creating a new compute environment.
You should see the following text recommending the use of Fargate:
""We recommend using Fargate in most scenarios. Fargate launches and scales the compute to closely match the resource requirements that you specify for the container. With Fargate, you don't need to over-provision or pay for additional servers. You also don't need to worry about the specifics of infrastructure-related parameters such as instance type. When the compute environment needs to be scaled up, jobs that run on Fargate resources can get started more quickly. Typically, it takes a few minutes to spin up a new Amazon EC2 instance. However, jobs that run on Fargate can be provisioned in about 30 seconds. The exact time required depends on several factors, including container image size and number of jobs. Learn more.""
We will follow that advice and use Fargate for this tutorial.
Step 1: Select Orchestration type
Select Fargate and click on Next.
Step 2: Create a compute environment
Add a name for your compute environment ‚Äî here, we chose ""kestra"". You can keep the default settings for everything. Select the VPC and subnets you want to use ‚Äî you can use the default VPC and subnets and the default VPC security group. Then, click on Next.
Step 3: Create a job queue
Now we can create a job queue. Here, we also name it ""kestra"". You can keep the default settings. Then, click on Next:
Step 4: Create a job definition
Finally, create a job definition. Here, we name it also ""kestra"". Under Execution role, select the role we created earlier (ecsTaskExecutionRole). Besides that, you can keep default settings for everything else (we adjusted the image to ghcr.io/kestra-io/pydata:latest but that's totally optional). Then, click on Next:
Step 5: Create a job
Finally, create a job. Here, we name it ""kestra"". Then, click on Next for a final review:
Step 6: Review and create
Review your settings and click on Create resources:
Once you see this message, you are all set:
Copy and apply the ARN to your Kestra configuration
Copy the ARN of the compute environment and job queue. You will need to add these to your Kestra configuration.
Create an S3 Bucket
Last thing we'll need is an S3 storage bucket. To do this, select S3 from Services then select Create bucket.
Next you'll need to add a name and leave everything else as a default value.
Scroll to the bottom and select Create bucket.
Now that we have a bucket, we'll need to add the name into Kestra.
Run your Kestra task on AWS ECS Fargate
Fill in the ARNs of the compute environment and job queue in your Kestra configuration. Here is an example of a flow that uses the aws.runner.Batch to run a Python script on AWS ECS Fargate to get environment information and print it to the logs:
yaml
id: aws_batch_runner
namespace: company.team
variables:
  compute_environment_arn: arn:aws:batch:us-east-1:123456789:compute-environment/kestra
  job_queue_arn: arn:aws:batch:us-east-1:123456789:job-queue/kestra
  execution_role_arn: arn:aws:iam::123456789:role/ecsTaskExecutionRole
  task_role_arn: arn:aws:iam::123456789:role/ecsTaskRole
tasks:
  - id: send_data
    type: io.kestra.plugin.scripts.python.Script
    containerImage: ghcr.io/kestra-io/pydata:latest
    taskRunner:
      type: io.kestra.plugin.ee.aws.runner.Batch
      region: us-east-1
      accessKeyId: ""{{ secret('AWS_ACCESS_KEY_ID') }}""
      secretKeyId: ""{{ secret('AWS_SECRET_KEY_ID') }}""
      computeEnvironmentArn: ""{{ vars.compute_environment_arn }}""
      jobQueueArn: ""{{ vars.job_queue_arn}}""
      executionRoleArn: ""{{ vars.execution_role_arn }}""
      taskRoleArn: ""{{ vars.task_role_arn }}""
      bucket: kestra-us
    script: |
      import platform
      import socket
      import sys
      print(""Hello from AWS Batch and kestra!"")
      def print_environment_info():
          print(f""Host's network name: {platform.node()}"")
          print(f""Python version: {platform.python_version()}"")
          print(f""Platform information (instance type): {platform.platform()}"")
          print(f""OS/Arch: {sys.platform}/{platform.machine()}"")
          try:
              hostname = socket.gethostname()
              ip_address = socket.gethostbyname(hostname)
              print(f""Host IP Address: {ip_address}"")
          except socket.error as e:
              print(""Unable to obtain IP address."")
      if __name__ == '__main__':
          print_environment_info()
When we execute this task, we can see the environment information inside of the logs generated by the Python script:
Was this page helpful?
Yes
No
Types
Kubernetes Task Runner
Types
Azure Batch Task Runner""""""",3009,12886,kestra
https://kestra.io/docs/task-runners/types/azure-batch-task-runner,"""""""DocsTask RunnersTask Runner TypesAzure Batch Task Runner
Azure Batch Task Runner
Table of Contents
How to use the Azure Batch task runner
How does Azure Batch task runner work
A full flow example
Full step-by-step guide: setting up Azure Batch from scratch
Before you begin
Azure Portal Setup
Creating our Flow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Run tasks as containers on Azure Batch VMs.
How to use the Azure Batch task runner
This task runner will deploy a container for the task in a specified Azure Batch pool.
To launch the task on Azure Batch, there is only two main concepts you need to be aware of:
Pool ‚Äî mandatory, not created by the task. This is a pool composed of nodes where your task can run on.
Job ‚Äî created by the task runner; holds information about which image, commands, and resources to run on.
How does Azure Batch task runner work
In order to support inputFiles, namespaceFiles, and outputFiles, the Azure Batch task runner currently relies on resource files and output files which transit through Azure Blob Storage.
Since we don't know the working directory of the container in advance, we always need to explicitly define the working directory and output directory when using the Azure Batch runner, e.g. use cat {{ workingDir }}/myFile.txt rather than cat myFile.txt.
A full flow example
yaml
id: azure_batch_runner
namespace: company.team
variables:
  poolId: ""poolId""
  containerName: ""containerName""
tasks:
  - id: scrape_environment_info
    type: io.kestra.plugin.scripts.python.Commands
    containerImage: ghcr.io/kestra-io/pydata:latest
    taskRunner:
      type: io.kestra.plugin.ee.azure.runner.Batch
      account: ""{{ secret('AZURE_ACCOUNT') }}""
      accessKey: ""{{ secret('AZURE_ACCESS_KEY') }}""
      endpoint: ""{{ secret('AZURE_ENDPOINT') }}""
      poolId: ""{{ vars.poolId }}""
      blobStorage:
        containerName: ""{{ vars.containerName }}""
        connectionString: ""{{ secret('AZURE_CONNECTION_STRING') }}""
    commands:
      - python {{ workingDir }}/main.py
    namespaceFiles:
      enabled: true
    outputFiles:
      - ""environment_info.json""
    inputFiles:
      main.py: |
        import platform
        import socket
        import sys
        import json
        from kestra import Kestra
        print(""Hello from Azure Batch and kestra!"")
        def print_environment_info():
            print(f""Host's network name: {platform.node()}"")
            print(f""Python version: {platform.python_version()}"")
            print(f""Platform information (instance type): {platform.platform()}"")
            print(f""OS/Arch: {sys.platform}/{platform.machine()}"")
            env_info = {
                ""host"": platform.node(),
                ""platform"": platform.platform(),
                ""OS"": sys.platform,
                ""python_version"": platform.python_version(),
            }
            Kestra.outputs(env_info)
            filename = 'environment_info.json'
            with open(filename, 'w') as json_file:
                json.dump(env_info, json_file, indent=4)
        if __name__ == '__main__':
          print_environment_info()
For a full list of properties available in the Azure Batch task runner, check the Azure plugin documentation or explore the same in the built-in Code Editor in the Kestra UI.
Full step-by-step guide: setting up Azure Batch from scratch
Before you begin
Before you start, you need to have the following:
An Microsoft Azure account.
A Kestra instance in a version 0.16.0 or later with Azure credentials stored as secrets or environment variables within the Kestra instance.
Azure Portal Setup
Create a Batch account and Azure Storage account
Once you're logged into your Azure account, search for ""Batch accounts"" and select the first option under Services.
Now on that page, select Create to make a new account.
Select the appropriate resource group as well as fill in the Account name and Location fields. Afterwards, click on Select a storage account.
If you do not have an existing storage account, press Create new and type a name in, e.g. ""mybatchstorage"". Leave the other settings as the default options and select OK.
Now we have all the correct details filled, we can now press Review + create and then Create on the next page to create our new Batch account.
Once the account has been created, you'll receive a Deployment succeeded message appear. Select **Go to resource to go to the account.
Create a pool
Now we have a Batch account, we can create a pool of compute notes in our Batch account that Kestra will use.
On the Batch account page, select Pools in the left navigation menu, then select Add at the top of the Pools page.
On the Add pool page, enter a Pool ID.
Under Operating System:
Select the Publisher as microsoft-azure-batch
Select the Offer as ubuntu-server-container
Select the Sku as 20-04-lts
Scroll down to Node size and select Standard_A1_v2 which is 1 vCPUs and 2 GB Memory. Also enter 2 for Target dedicated nodes.
Once you've done that, you can now select OK at the bottom to create the pool.
Create Access Key
Inside of our Batch account, go to Settings and then Keys. Generate a new set of keys. We'll need:
Batch account for account
Account endpoint for endpoint
Primary access key for accessKey
Blob storage
Search for Storage account and select our recently made account. Inside of here, go to the Data storage menu and select Containers. Now select + Container to make a new container.
Type in a name for the container and select Create.
Now that we've created our batch account, storage account, pool and container, we can now create our flow inside of Kestra.
Creating our Flow
Below is an example flow that will run a Python file called main.py on a Azure Batch Task Runner. At the top of the io.kestra.plugin.scripts.python.Commands task, there are the properties for defining our Task Runner:
yaml
containerImage: ghcr.io/kestra-io/pydata:latest
taskRunner:
  type: io.kestra.plugin.ee.azure.runner.Batch
  account: ""{{ secret('AZURE_ACCOUNT') }}""
  accessKey: ""{{ secret('AZURE_ACCESS_KEY') }}""
  endpoint: ""{{ secret('AZURE_ENDPOINT') }}""
  poolId: ""{{ vars.poolId }}""
  blobStorage:
    containerName: ""{{ vars.containerName }}""
    connectionString: ""{{ secret('AZURE_CONNECTION_STRING') }}""
This is where we can enter the details for Azure such as account, accessKey, endpoint, poolId, and blobStorage. We can add these as secrets and variables.
yaml
id: azure_batch_runner
namespace: company.team
variables:
  poolId: ""poolId""
  containerName: ""containerName""
tasks:
  - id: get_env_info
    type: io.kestra.plugin.scripts.python.Commands
    containerImage: ghcr.io/kestra-io/pydata:latest
    taskRunner:
      type: io.kestra.plugin.ee.azure.runner.Batch
      account: ""{{ secret('AZURE_ACCOUNT') }}""
      accessKey: ""{{ secret('AZURE_ACCESS_KEY') }}""
      endpoint: ""{{ secret('AZURE_ENDPOINT') }}""
      poolId: ""{{ vars.poolId }}""
      blobStorage:
        containerName: ""{{ vars.containerName }}""
        connectionString: ""{{ secret('AZURE_CONNECTION_STRING') }}""
    commands:
      - python {{ workingDir }}/main.py
    namespaceFiles:
      enabled: true
    outputFiles:
      - ""environment_info.json""
    inputFiles:
      main.py: |
        import platform
        import socket
        import sys
        import json
        from kestra import Kestra
        print(""Hello from Azure Batch and kestra!"")
        def print_environment_info():
            print(f""Host's network name: {platform.node()}"")
            print(f""Python version: {platform.python_version()}"")
            print(f""Platform information (instance type): {platform.platform()}"")
            print(f""OS/Arch: {sys.platform}/{platform.machine()}"")
            env_info = {
                ""host"": platform.node(),
                ""platform"": platform.platform(),
                ""OS"": sys.platform,
                ""python_version"": platform.python_version(),
            }
            Kestra.outputs(env_info)
            filename = 'environment_info.json'
            with open(filename, 'w') as json_file:
                json.dump(env_info, json_file, indent=4)
        if __name__ == '__main__':
          print_environment_info()
When we press execute, we can see that our task runner is created in the Logs.
We can also go to the Azure Portal to see our task runner has been created:
Once the task has completed, it will automatically close down the runner on Azure.
We can also view the outputs generated in the Outputs tab in Kestra, which contains information about the Azure Batch task runner generated from our Python script:
Was this page helpful?
Yes
No
Types
AWS Batch Task Runner
Types
Google Batch Task Runner""""""",1922,8759,kestra
https://kestra.io/docs/task-runners/types/google-batch-task-runner,"""""""DocsTask RunnersTask Runner TypesGoogle Batch Task Runner
Google Batch Task Runner
Table of Contents
How to use the Google Batch task runner
How does Google Batch task runner work
A full flow example
Full step-by-step guide: setting up Google Batch from scratch
Before you begin
Google Cloud Console Setup
Creating our Flow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Run tasks as containers on Google Cloud VMs.
How to use the Google Batch task runner
This task runner will deploy the container for the task to a specified Google Cloud Batch VM.
To launch the task on Google Cloud Batch, there are three main concepts you need to be aware of:
Machine Type ‚Äî a mandatory property indicating the compute machine type to which the task will be deployed. If no reservation is specified, a new compute instance will be created for each batch which can add around a minute of latency.
Reservation ‚Äî an optional property allowing you to set up a reservation for a given virtual machine and avoid the time needed to create a new compute instance for each task.
Network Interfaces ‚Äî an optional property; if not specified, it will use the default interface if not specified otherwise.
How does Google Batch task runner work
In order to support inputFiles, namespaceFiles, and outputFiles, the Google Batch task runner will do the following:
mount a volume from a GCS bucket
upload input files to the bucket before launching the container
download output files from the bucket after the container has finished running.
Since we don't know the working directory of the container in advance, you need to explicitly define the working directory and output directory when using the GCP Batch runner, e.g. use python {{ workingDir }}/main.py rather than python main.py.
A full flow example
yaml
id: gcp_batch_runner
namespace: company.team
variables:
  region: europe-west9
tasks:
  - id: scrape_environment_info
    type: io.kestra.plugin.scripts.python.Commands
    containerImage: ghcr.io/kestra-io/pydata:latest
    taskRunner:
      type: io.kestra.plugin.ee.gcp.runner.Batch
      projectId: ""{{ secret('GCP_PROJECT_ID') }}""
      region: ""{{ vars.region }}""
      bucket: ""{{ secret('GCS_BUCKET')}}""
      serviceAccount: ""{{ secret('GOOGLE_SA') }}""
    commands:
      - python {{ workingDir }}/main.py
    namespaceFiles:
      enabled: true
    outputFiles:
      - ""environment_info.json""
    inputFiles:
      main.py: |
        import platform
        import socket
        import sys
        import json
        from kestra import Kestra
        print(""Hello from GCP Batch and kestra!"")
        def print_environment_info():
            print(f""Host's network name: {platform.node()}"")
            print(f""Python version: {platform.python_version()}"")
            print(f""Platform information (instance type): {platform.platform()}"")
            print(f""OS/Arch: {sys.platform}/{platform.machine()}"")
            env_info = {
                ""host"": platform.node(),
                ""platform"": platform.platform(),
                ""OS"": sys.platform,
                ""python_version"": platform.python_version(),
            }
            Kestra.outputs(env_info)
            filename = '{{ workingDir }}/environment_info.json'
            with open(filename, 'w') as json_file:
                json.dump(env_info, json_file, indent=4)
        if __name__ == '__main__':
          print_environment_info()
For a full list of properties available in the Google Batch task runner, check the GCP plugin documentation or explore the same in the built-in Code Editor in the Kestra UI.
Full step-by-step guide: setting up Google Batch from scratch
Before you begin
Before you start, you need to have the following:
A Google Cloud account.
A Kestra instance in a version 0.16.0 or later with Google credentials stored as secrets or environment variables within the Kestra instance.
Google Cloud Console Setup
Create a project
If you don't already have a project, create one with a name of your choice.
Once you've done this, make sure your project is selected in the menu bar.
Enable Batch API
Inside of the Cloud Console, you'll need to go to APIs and search for Batch API. Once you've got to it, you'll need to enable it so that Kestra can create Batch Jobs.
After you've enabled it, you'll be prompted to make credentials for it so you can integrate it with your application.
Create the Service Account
Now that the Batch API is enabled, we can proceed with creating credentials so we can access GCP directly inside of Kestra. Following the prompt after enabling the Batch API, we will be asked to select the type of data we will be using. In this case, it's Application data which will create a Service Account for us to use.
After you've selected this, you'll need to give a name to your service account. Name it something memorable, as we'll need to type this into Kestra later.
Once you've given it a name, make sure to select the following roles:
Batch Job Editor
Logs Viewer
Storage Object Admin
Afterwards, we will need to make credentials for our service account so we can add these into Kestra. To do so, select our service account and select Keys then Add Key.
Make sure to select JSON as the Key type so we can either add it as a secret or directly into our flow.
Check out this guide on how to add your service account into Kestra as a secret.
We'll also need to make sure our service account can access the Compute Engine default service account so it can create jobs.
To do this, we can go to IAM & Admin, then Service Accounts. On this page, we can select the compute engine service account, select Permissions and then Grant Access. On this page, we want to add our original Service account as a Service Account User role. Once we've done this, we can select Save.
Create Bucket
Head to the search bar and type ""Bucket"" to find GCS Bucket. Now create a new bucket! You'll be prompted to set a name, region and various other permissions. For now, we can leave these all to default.
Creating our Flow
Below is an example flow that will run a Python file called main.py on a GCP Batch Task Runner. At the top of the io.kestra.plugin.scripts.python.Commands task, there are the properties for defining our Task Runner:
yaml
containerImage: ghcr.io/kestra-io/kestrapy:latest
taskRunner:
  type: io.kestra.plugin.ee.gcp.runner.Batch
  projectId: ""{{ secret('GCP_PROJECT_ID') }}""
  region: ""{{ vars.region }}""
  bucket: ""{{ secret('GCS_BUCKET') }}""
  serviceAccount: ""{{ secret('GOOGLE_SA') }}""
This is where we can enter the details for GCP such as the projectId, region, bucket, as well as serviceAccount. We can add these all as secrets.
yaml
id: gcp_batch_runner
namespace: company.team
variables:
  region: europe-west2
tasks:
  - id: scrape_environment_info
    type: io.kestra.plugin.scripts.python.Commands
    containerImage: ghcr.io/kestra-io/kestrapy:latest
    taskRunner:
      type: io.kestra.plugin.ee.gcp.runner.Batch
      projectId: ""{{ secret('GCP_PROJECT_ID') }}""
      region: ""{{ vars.region }}""
      bucket: ""{{ secret('GCS_BUCKET') }}""
      serviceAccount: ""{{ secret('GOOGLE_SA') }}""
    commands:
      - python {{ workingDir }}/main.py
    namespaceFiles:
      enabled: true
    outputFiles:
      - ""environment_info.json""
    inputFiles:
      main.py: |
        import platform
        import socket
        import sys
        import json
        from kestra import Kestra
        print(""Hello from GCP Batch and kestra!"")
        def print_environment_info():
            print(f""Host's network name: {platform.node()}"")
            print(f""Python version: {platform.python_version()}"")
            print(f""Platform information (instance type): {platform.platform()}"")
            print(f""OS/Arch: {sys.platform}/{platform.machine()}"")
            env_info = {
                ""host"": platform.node(),
                ""platform"": platform.platform(),
                ""OS"": sys.platform,
                ""python_version"": platform.python_version(),
            }
            Kestra.outputs(env_info)
            filename = '{{workingDir}}/environment_info.json'
            with open(filename, 'w') as json_file:
                json.dump(env_info, json_file, indent=4)
        print_environment_info()
When we press execute, we can see that our task runner is created in the Logs.
We can also go to the GCP Console and see our task runner has been created:
Once the task has completed, it will automatically close down the runner on Google Cloud.
We can also view the outputs generated in the Outputs tab in Kestra, which contains information about the Google Batch task runner generated from our Python script:
Was this page helpful?
Yes
No
Types
Azure Batch Task Runner
Types
Google Cloud Run Task Runner""""""",1937,8820,kestra
https://kestra.io/docs/task-runners/types/google-cloudrun-task-runner,"""""""DocsTask RunnersTask Runner TypesGoogle Cloud Run Task Runner
Google Cloud Run Task Runner
Table of Contents
How to use the Google Cloud Run task runner
How does Google Cloud Run task runner work
A full flow example
How to Run Tasks on Google Cloud Run
Before you begin
Google Cloud Console Setup
Creating our Flow
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
>= 0.18.0
Run tasks as containers on Google Cloud Run.
How to use the Google Cloud Run task runner
This runner will deploy the container for the task to a Google Compute Engine VM.
How does Google Cloud Run task runner work
To use inputFiles, outputFiles or namespaceFiles properties, make sure to set the bucket property. The bucket serves as an intermediary storage layer for the task runner. Input and namespace files will be uploaded to the cloud storage bucket before the task run.
Similarly, the task runner will store outputFiles in this bucket during the task run. In the end, the task runner will make those files available for download and preview from the UI by sending them to internal storage.
To make it easier to track where all files are stored, the task runner will generate a folder for each task run. You can access that folder using the {{ bucketPath }} Pebble expression or the BUCKET_PATH environment variable.
Due to the ephemeral nature of Cloud Run, the task runner will not run the task in the working directory but in the root directory. Therefore, you have to use the {{ workingDir }} Pebble expression or the WORKING_DIR environment variable to access the inputFiles and namespaceFiles from the task's working directory.
Note about termination of compute resources:
when the Kestra Worker running this task is terminated, the Cloud Run Job will still run until completion ‚Äî this is intended to avoid your tasks being interrupted due to Worker crashes.
when you manually kill the execution from the UI, the Cloud Run Job will be terminated ‚Äî this is intended to avoid unnecessary costs when you explicitly stop the execution (Note that this behavior is a work-in-progress, you can track the state here on GitHub).
A full flow example
The following example runs a simple Shell command in a Cloud Run container:
yaml
id: new-shell
namespace: company.team
variables:
  projectId: myProjectId
  region: europe-west2
tasks:
  - id: shell
    type: io.kestra.plugin.scripts.shell.Commands
    taskRunner:
      type: io.kestra.plugin.ee.gcp.runner.CloudRun
      projectId: ""{{ vars.projectId }}""
      region: ""{{ vars.region }}""
      serviceAccount: ""{{ secret('GOOGLE_SA') }}""
    commands:
      - echo ""Hello World""
The following example runs a Shell command in a Cloud Run container and passes input files to the task:
yaml
id: new-shell-with-file
namespace: company.team
variables:
  projectId: myProjectId
  region: europe-west2
inputs:
  - id: file
    type: FILE
tasks:
  - id: shell
    type: io.kestra.plugin.scripts.shell.Commands
    inputFiles:
      data.txt: ""{{ inputs.file }}""
    outputFiles:
      - out.txt
    containerImage: centos
    taskRunner:
      type: io.kestra.plugin.ee.gcp.runner.CloudRun
      projectId: ""{{ vars.projectId }}""
      region: ""{{ vars.region }}""
      bucket: ""{{ vars.bucket }}""
      serviceAccount: ""{{ secret('GOOGLE_SA') }}""
    commands:
      - cp {{ workingDir }}/data.txt {{ workingDir }}/out.txt
For a full list of properties available in the CloudRun task runner, check the GCP plugin documentation or explore the same in the built-in Code Editor in the Kestra UI.
How to Run Tasks on Google Cloud Run
Before you begin
Before you start, you need to have the following:
A Google Cloud account.
A Kestra instance in a version 0.16.0 or later with Google credentials stored as secrets or environment variables within the Kestra instance.
Google Cloud Console Setup
Create a project
If you don't already have a project, create one with a name of your choice.
Once you've done this, make sure your project is selected in the menu bar.
Enable Cloud Run Admin API
In the search bar, search and select APIs & Services. Then select Enable APIs and Services and search for Cloud Run Admin API. When you select this, select the Enable button.
Create the Service Account
Now that the Cloud Run Admin API is enabled, we can proceed with creating credentials so we can access GCP directly inside of Kestra.
In the search bar, search and select Service Accounts. Now select Create Service Account.
After you've selected this, you'll need to give a name to your service account. Name it something memorable, as we'll need to type this into Kestra later.
Once you've given it a name, make sure to select the following roles:
Cloud Run Developer
Logs Viewer
Storage Admin (to upload files to GCS and download files from GCS)
Check out this guide on how to add your service account into Kestra as a secret.
We'll also need to make sure our service account can access the Compute Engine default service account so it can create jobs.
To do this, we can go to IAM & Admin, then Service Accounts. On this page, we can select the compute engine service account, select Permissions and then Grant Access. On this page, we want to add our original Service account as a Service Account User role. Once we've done this, we can select Save.
Create Bucket
Head to the search bar and type ""Bucket"" to find GCS Bucket. Now create a new bucket! You'll be prompted to set a name, region and various other permissions. For now, we can leave these all to default.
Creating our Flow
Below is an example flow that will run a Shell script that will copy a file with a new file name using a GCP Cloud Run Task Runner. At the top of the io.kestra.plugin.scripts.shell.Commands task, there are the properties for defining our Task Runner:
yaml
containerImage: centos
taskRunner:
  type: io.kestra.plugin.ee.gcp.runner.CloudRun
  projectId: ""{{ secret('GCP_PROJECT_ID') }}""
  region: ""{{ vars.region }}""
  bucket: ""{{ secret('GCP_BUCKET') }}""
  serviceAccount: ""{{ secret('GOOGLE_SA') }}""
This is where we can enter the details for GCP such as the projectId, region, bucket, as well as serviceAccount. We can add these all as secrets.
The containerImage property is required because Cloud Run executes tasks as containers. You can use any image from a public or private registry. In this example, we are going to use centos.
yaml
id: new-shell-with-file
namespace: company.team
variables:
  projectId: myProjectId
  region: europe-west2
inputs:
  - id: file
    type: FILE
tasks:
  - id: shell
    type: io.kestra.plugin.scripts.shell.Commands
    inputFiles:
      data.txt: ""{{ inputs.file }}""
    outputFiles:
      - out.txt
    containerImage: centos
    taskRunner:
      type: io.kestra.plugin.ee.gcp.runner.CloudRun
      projectId: ""{{ secret('GCP_PROJECT_ID') }}""
      region: ""{{ vars.region }}""
      bucket: ""{{ secret('GCP_BUCKET') }}""
      serviceAccount: ""{{ secret('GOOGLE_SA') }}""
    commands:
      - cp {{ workingDir }}/data.txt {{ workingDir }}/out.txt
When we press execute, we can see that our task runner is created in the Logs.
We can also go to the GCP Console and see our task runner has been created:
Once the task has completed, it will automatically close down the VM on Google Cloud.
Was this page helpful?
Yes
No
Types
Google Batch Task Runner
Docs
Best Practices""""""",1663,7365,kestra
https://kestra.io/docs/best-practices,"""""""DocsBest Practices
Best Practices
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Best practices for building reliable workflows in Kestra.
Flow Best Practices
How to design your workflows for optimal performance.
Moving from Development to Production
Common patterns to deploy your flows from development to production environments.
Naming Conventions
Common naming conventions to keep your flows and tasks well-organized and consistent in Kestra.
Manage Environments
Kestra users can manage their ""environments"" through different levels of granularity. Kestra has three main concepts: instance, tenant, and namespace.
Managing pip Package Dependencies
Learn how to manage pip package dependencies in your flows.
Expressions with Namespace Files
How to pass expressions to Namespace Files.
Version Control with Git
Best practices for Version Control with Git in Kestra.
Was this page helpful?
Yes
No
Types
Google Cloud Run Task Runner
Best Practices
Flow Best Practices""""""",196,997,kestra
https://kestra.io/docs/best-practices/flows,"""""""DocsBest PracticesFlow Best Practices
Flow Best Practices
Table of Contents
Understanding what is an execution internally for Kestra
Task in the same execution
Volume of data from your outputs
Parallel Task
Duration of Tasks
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
How to design your workflows for optimal performance.
Understanding what is an execution internally for Kestra
The execution of a flow is an object that will contain:
All the TaskRuns for this flow, with each having:
Theirs attempts, with each having:
Theirs metrics
Their state histories
Theirs outputs
Their state histories
Internally:
Each TaskRun on a flow will be added on the same flow execution context that contains all tasks executed on this flow.
Each TaskRun status change is read by the Kestra Executor (at most 3 for a task: CREATED, RUNNING then SUCCESS).
For each state on the Executor, we need:
to fetch the serialized flow execution context over the network,
to deserialize the flow execution context, find the next task or tasks and serialize the flow execution context,
to send the serialized flow execution context over the network.
The bigger the flow execution context, the longer it will take to handle this serialization phase.
Depending on the Kestra internal queue and repository implementation, there can be a hard limit on the size of the flow execution context as it is stored as a single row/message. Usually, this limit is around 1MB, so this is important to avoid storing large amounts of data inside the flow execution context.
Task in the same execution
While it is possible to code a flow with any number of tasks, it is not recommended to have a lot of tasks on the same flow.
A flow can be comprised of manually generated or dynamic tasks. While EachSequential and EachParallel are really powerful tasks to loop over the result of a previous task, there are some drawbacks. If the task you are looping over is too large, you can easily end up with hundreds of tasks created. If, for example, you were using a pattern with Each inside Each (nested looping), it would take only a flow with 20 TaskRuns X 20 TaskRuns to reach 400 TaskRuns.
Based on our observations, we have seen that in cases where there are more than 100 tasks on a flow, we see a decrease in performance and longer executions.
To avoid reaching these limits, you can easily create a subflow with the Subflow task, passing arguments from parent to child. In this case, since the Subflow task creates a new execution, the subflow tasks will be isolated and won't hurt performance.
Volume of data from your outputs
Some tasks allow you to fetch results on outputs to be reused on the next tasks. While this is powerful, this is not intended to be used to transport a lot of data! For example, with the Query task from BigQuery, there is a fetch property that allows fetching a result-set as an output attribute.
Imagine a big table with many megabytes or even gigabytes of data. If you use fetch, the output will be stored in the execution context and will need to be serialized on each task state change! This is not the idea behind fetch, it serves mostly to query a few rows to use it on a Switch task for example, or an EachParallel task to loop over.
In most cases, there is a stores property that can handle a large volume of data. When an output is stored, it uses Kestra's internal storage, and only the URL of the stored file is stored in the execution context.
Parallel Task
Using the Parallel task is a convenient way to optimize flow duration, but keep in mind that, by default, all parallel tasks are launched at the same time (unless you specify the concurrent property). The only limit will be the number of worker threads you have configured.
Keep this in mind, because you cannot allow parallel tasks to reach the limit of external systems, such as connection limits or quotas.
Duration of Tasks
By default, Kestra never limits the duration (unless specified explicitly on the task's documentation) of the tasks. If you have a long-running process or an infinite loop, the tasks will never end. We can control the timeout on Runnable Tasks with the property timeout that takes a ISO 8601 duration like PT5M for a duration of 5 minutes.
Was this page helpful?
Yes
No
Docs
Best Practices
Best Practices
Moving from Development to Production""""""",919,4356,kestra
https://kestra.io/docs/best-practices/from-dev-to-prod,"""""""DocsBest PracticesMoving from Development to Production
Moving from Development to Production
Table of Contents
Development Environment
Production Environment
User Access
Flows Deployment
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Common patterns to deploy your flows from development to production environments.
Development Environment
One best practice with Kestra is to have one development instance where users can write their flow directly in UI. This instance can be seen as a ""sandbox"" where flows can be tested and executed without the fear to break critical business operations.
We usually encourage two types of development environment:
installing Kestra on your local machine (usually with Docker Compose installation)
installing Kestra on a Kubernetes cluster accessible by users and separated from production matters.
Production Environment
The production instance should be safeguarded. Especially as this environment supports critical operations and engages your responsibilities for end users.
One common best practice here is to limit the access of the production environment. In this case, there two elements to consider:
User access
Flow deployments
User Access
For Kestra Enterprise users, this is streamlined with RBAC and SSO features. With role policies such as ""Admin"" or ""Viewer"", one administrator can manage all user access with fine-grain control over all Kestra resources. You can learn more in the dedicated documentation.
For open-source users it's usually a good idea to have a restricted instance, meaning an instance only accessible by CI/CD and administrators.
Flows Deployment
Kestra offers many strategies to deploy flows to an instance:
Through the UI
Sync with Git
CI/CD
Terraform
API.
Choosing one way or the other depends of your preferences and your current deployment patterns.
One recurring pattern is moving flows from the development to the production instance through version control system and CI/CD.
When users have developed flows, they will usually commit changes to a version control system (Git). Then, upon validated pull request, the CI/CD engine will deploy the corresponding flows to the production instance.
The way users can commit flow changes to Git can be addressed with the following patterns:
Export or copy-paste flows from the user interface
Using the git.PushFlows task
The way CI/CD deploy flows to production instance can be addressed with the following patterns:
GitHub Action, GitLab CI/CD, Jenkins, Azure DevOps, etc.
Terraform deployment
Kestra CLI
You can find more about CI/CD pattern with Kestra here.
Git Example
We can use the git.SyncFlows task combined with a Trigger to automatically pull Flows from the main branch of the Git repository.
This means Kestra will manage the process, reducing the number of systems needed to automate the dev to prod process.
You can use either a Schedule Trigger to pull on a regular routine, e.g. nightly, or the Webhook Trigger to pull when the main branch receives new commits. Check out this dedicated guide on setting them up.
If we combine this with the git.PushFlows task, we can push our Flows to our repository from our local development environment, ensuring they are validated as Kestra will not let you save an invalid flow.
On top of that, we can automatically open a Pull Request with the create.Pulls task to main to speed up the process of getting the Flows to production.
While we can be sure that our flows are valid, this will not check for logical errors. We'd recommend testing flows separately to check this before deploying to production.
CI/CD Example
We can use CI/CD to automatically deploy our flows from our Git repository to our production instance of Kestra when they are merged to the main branch.
With GitHub, we can use the official Deploy Action, which uses the Kestra Server CLI under the hood, to deploy when a Pull Request is merged to main.
We can combine the Deploy Action with the Validate Action, which runs a validate check on Flows using the Kestra Server CLI.
This means we can configure the Git Repository to require status checks to pass before a Pull Request can be merged - preventing any invalid flows from being deployed to production.
Note: If a flow is in an invalid format, the Deploy Action will fail.
Was this page helpful?
Yes
No
Best Practices
Flow Best Practices
Best Practices
Naming Conventions""""""",893,4399,kestra
https://kestra.io/docs/best-practices/naming-conventions,"""""""DocsBest PracticesNaming Conventions
Naming Conventions
Table of Contents
Namespace Naming Convention
Why we recommend a company.team namespace structure
Example Namespace Structure
Should you use environment-specific namespaces?
Summary
ID Naming Convention
Subscript notation and valid characters in IDs
Snake case
Camel case
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Common naming conventions to keep your flows and tasks well-organized and consistent in Kestra.
Namespace Naming Convention
We recommend using the company.team naming convention for namespaces to maintain a well-organized and consistent structure across your workflows. This pattern helps in the following ways:
Centralized governance for credentials
Sharing configurations across namespaces
Simplified Git sync
Why we recommend a company.team namespace structure
By having a root namespace named after your company, you can centrally govern plugin defaults, variables and secrets and share that configuration across all other namespaces under the company root.
Adhering to this naming convention also simplifies Git operations. You can maintain a single flow that synchronizes all workflows with Git across all namespaces under the parent namespace named after your company.
The next level of namespaces should be named after your team (e.g., company.team). This structure allows for centralized governance and visibility at the team level before further dividing into projects, systems, or other logical hierarchies. When syncing your code with Git, that nested structure will be reflected as nested directories in your Git repository.
Example Namespace Structure
Here is an example of how you might structure your namespaces:
mycompany
mycompany.marketing
mycompany.marketing.projectA
mycompany.marketing.projectB
mycompany.sales
mycompany.sales.projectC
mycompany.sales.projectD
Should you use environment-specific namespaces?
We generally recommend against using environment-specific namespaces (e.g., dev, prod, staging) because it can lead to several issues such as:
Dev and prod not fully separated: a development workflow running out of memory could impact the production instance.
Duplication of configurations: you may end up duplicating configurations across environments, which can lead to inconsistencies.
It's recommended to use separate Kestra instances to separate dev and prod environments.
Summary
The company.team namespace structure will help you to facilitate a logical, easy to maintain hierarchy, and will make it easy to sync your workflows with Git. To reliably separate dev and prod environments, use separate Kestra instances or tenants.
ID Naming Convention
We recommend using the same convention across all IDs:
Flows
Tasks
Inputs
Outputs
Triggers
Subscript notation and valid characters in IDs
Kestra doesn't enforce any naming convention. For example, if you want to use the URL-style naming including hyphens, Kestra supports that. However, keep in mind that IDs for flows, tasks, inputs, outputs and triggers must match the ""^[a-zA-Z0-9][a-zA-Z0-9_-]*"" regex pattern. This means that:
you can't use any special characters except for hyphens - and underscores _
when using hyphens, you need to follow the format ""{{ outputs.task_id[your-custom-value].attribute }}"" when referencing that ID in output expressions; the square brackets [] in [your-custom-value] is called the subscript notation and it enables using special characters such as spaces or hyphens (as in the kebab-case notation) in task identifiers or output attributes.
We recommend using the snake_case or camelCase conventions over the kebab-case, as they allow you to avoid the subscript notation and make your flows easier to read.
Snake case
Snake case is a common naming convention in programming. It's popular among Python developers in the data science, AI and data engineering domain.
Here is an example of a flow using the snake case convention to name IDs for flows, inputs, outputs, tasks, and triggers:
yaml
id: api_python_sql
namespace: prod.marketing.attribution
inputs:
  - id: api_endpoint
    type: URL
    defaults: https://dummyjson.com/products
tasks:
  - id: fetch_products
    type: io.kestra.plugin.core.http.Request
    uri: ""{{ inputs.api_endpoint }}""
  - id: transform_in_python
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:slim
    beforeCommands:
      - pip install polars
    warningOnStdErr: false
    outputFiles:
      - ""products.csv""
    script: |
      import polars as pl
      data = {{ outputs.fetch_products.body | jq('.products') | first }}
      df = pl.from_dicts(data)
      df.glimpse()
      df.select([""brand"", ""price""]).write_csv(""products.csv"")
  - id: sql_query
    type: io.kestra.plugin.jdbc.duckdb.Query
    inputFiles:
      in.csv: ""{{ outputs.transform_in_python.outputFiles['products.csv'] }}""
    sql: |
      SELECT brand, round(avg(price), 2) as avg_price
      FROM read_csv_auto('{{ workingDir }}/in.csv', header=True)
      GROUP BY brand
      ORDER BY avg_price DESC;
    fetchType: STORE
outputs:
  - id: final_result
    value: ""{{ outputs.sql_query.uri }}""
triggers:
  - id: daily_at_9am
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 9 * * *""
Camel case
Camel case is another common naming convention in programming. It's popular among Java and JavaScript developers. Let's look at the same flow as above, but using the camel case convention:
yaml
id: apiPythonSql
namespace: prod.marketing.attribution
inputs:
  - id: apiEndpoint
    type: URL
    defaults: https://dummyjson.com/products
tasks:
  - id: fetchProducts
    type: io.kestra.plugin.core.http.Request
    uri: ""{{ inputs.apiEndpoint }}""
  - id: transformInPython
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:slim
    beforeCommands:
      - pip install polars
    warningOnStdErr: false
    outputFiles:
      - ""products.csv""
    script: |
      import polars as pl
      data = {{outputs.fetchProducts.body | jq('.products') | first}}
      df = pl.from_dicts(data)
      df.glimpse()
      df.select([""brand"", ""price""]).write_csv(""products.csv"")
  - id: sqlQuery
    type: io.kestra.plugin.jdbc.duckdb.Query
    inputFiles:
      in.csv: ""{{ outputs.transformInPython.outputFiles['products.csv'] }}""
    sql: |
      SELECT brand, round(avg(price), 2) as avgPrice
      FROM read_csv_auto('{{workingDir}}/in.csv', header=True)
      GROUP BY brand
      ORDER BY avgPrice DESC;
    store: true
outputs:
  - id: finalResult
    value: ""{{ outputs.sqlQuery.uri }}""
triggers:
  - id: dailyAt9am
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 9 * * *""
Both conventions are valid and it's up to you to choose the one you prefer.
Was this page helpful?
Yes
No
Best Practices
Moving from Development to Production
Best Practices
Manage Environments""""""",1524,6867,kestra
https://kestra.io/docs/best-practices/manage-environments,"""""""DocsBest PracticesManage Environments
Manage Environments
Table of Contents
When to use multiple instances?
When to use multiple tenants?
When to use multiple namespaces?
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Kestra users can manage their ""environments"" through different levels of granularity. Kestra has three main concepts: instance, tenant, and namespace.
When to use multiple instances?
An instance is a full deployment of Kestra. One best practice in Kestra is to have at least two separated instances: one for development and one for production.
The development serves as a ""sandbox"", only for development matters, while the production instance serves critical operations and is only accessible by administrators.
Large organizations sometimes have 3 or 4 environments: it's best to have Kestra Enterprise Edition to properly manage all these instances (thanks to improved governance, security and scalability provided by the Enterprise Edition of Kestra).
When to use multiple tenants?
Tenant are logic separations of an instance. You can think of them as isolated Kestra projects using instance resources. One instance can have many tenants.
This is useful when the operation managed by Kestra serves different customers or teams. For example, a company with 10 customers would use tenants to separate each of them in Kestra. We can imagine the same in an international company, using Kestra tenants country-wise.
One can also use tenants to separate engineer environments within the same development instance.
Be aware that each tenant is using the same underlying instance resources. Therefore, it's not a best practice to use tenants to separate a development and a production environment. If the underlying instance is out of service for any reason, every tenant will be down too.
When to use multiple namespaces?
Namespaces are great for managing your flows organizations. One can use namespaces to arrange projects by domain or team.
They can be used as ""environments"" for getting started and for open-source users who don't want to manage two or more instances. Again, it's not a best practice for critical operations as one development can crash the flow supporting ""production"".
Was this page helpful?
Yes
No
Best Practices
Naming Conventions
Best Practices
Managing pip Package Dependencies""""""",459,2346,kestra
https://kestra.io/docs/best-practices/managing-pip-dependencies,"""""""DocsBest PracticesManaging pip Package Dependencies
Managing pip Package Dependencies
Table of Contents
Motivation
Using a custom Docker image
Install pip package dependencies at server startup
Using cache files
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Learn how to manage pip package dependencies in your flows.
Motivation
Your Python code may require some pip package dependencies. The way you manage these dependencies can have an impact on the execution time of your flows.
If you install pip packages within beforeCommands, these packages will be downloaded and installed each time you run your task. This can lead to increased duration of your workflow executions. The following sections describe several ways to manage pip package dependencies in your flows.
Using a custom Docker image
Instead of using the Python Docker image, and installing pip package dependencies using beforeCommands, you can create a customer Docker image with Python and the required pip package dependencies. As all the pip packages would be part of this custom Docker image, you need not download and install the pip package dependencies during each execution. This would prevent the load on the execution, and the execution time will be dedicated to only the processing of the Python code.
For example, the Python example has pandas as a dependency. We can specify a Python container image that has this pre-installed, such as ghcr.io/kestra-io/pydata:latest meaning we don't need to use beforeCommands:
yaml
id: docker_dependencies
namespace: company.team
tasks:
  - id: code
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: ghcr.io/kestra-io/pydata:latest
    script: |
      import pandas as pd
      df = pd.read_csv('https://huggingface.co/datasets/kestra/datasets/raw/main/csv/orders.csv')
      total_revenue = df['total'].sum()
Install pip package dependencies at server startup
This is another way of preventing the overload of downloading and installing pip package dependencies in each execution. You can install all the pip package dependencies, and then start the Kestra server. For Kestra standalone server, you can achieve this by running the command below:
bash
pip install requests pandas polars && ./kestra server standalone --worker-thread=16
If you run Kestra using Docker, create a Dockerfile if you haven't already and install your dependencies using RUN inside of your Dockerfile. You will also need to set the USER to root for this to work.
dockerfile
FROM kestra/kestra:latest
USER root
RUN pip install requests pandas polars
CMD [""server"", ""standalone""]
Inside of your Docker Compose, you'll need to replace the image property with build: . to use our Dockerfile instead of the kestra image directly from DockerHub. Also, remove the command property as this is now handled in our Dockerfile with CMD:
yaml
services:
  ...
  kestra:
    build: .
    ...
When you run Kestra using Docker Compose, you will now see the Python dependencies added to the Dockerfile.
In either of these Kestra server installations, you will need to run the Python tasks using the Process Task Runner so that the Python code has access to the pip package dependencies installed in the Kestra server process.
We can check our dependencies are installed with the example below:
yaml
id: list_dependencies
namespace: company.team
tasks:
  - id: check
    type: io.kestra.plugin.scripts.python.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - pip list
Using cache files
In a WorkingDirectory task, you can have the virtual environment setup with the Process Task Runner, install all the pip package dependencies, and cache the venv folder. The pip package dependencies will then be cached as part of the virtual environment folder, and you need not install it on every execution of the flow. This is explained in detail in the caching page.
Here is a sample flow demonstrating how the venv folder can be cached:
yaml
id: python_cached_dependencies
namespace: company.team
tasks:
  - id: working_dir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: python_script
        type: io.kestra.plugin.scripts.python.Script
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
        warningOnStdErr: false
        beforeCommands:
          - python -m venv venv
          - . venv/bin/activate
          - pip install pandas
        script: |
          import pandas as pd
          print(pd.__version__)
    cache:
      patterns:
        - venv/**
      ttl: PT24H
Thus, using one of the above techniques, you can prevent the installation of the pip package dependencies with every execution, and reduce your execution time.
Was this page helpful?
Yes
No
Best Practices
Manage Environments
Best Practices
Expressions with Namespace Files""""""",1051,4938,kestra
https://kestra.io/docs/best-practices/expressions-with-namespace-files,"""""""DocsBest PracticesExpressions with Namespace Files
Expressions with Namespace Files
Table of Contents
Using Namespace Files with Environment Variables
Using Namespace Files with CLI arguments
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
How to pass expressions to Namespace Files.
You can write the script inline in your flow, and use expressions as part of this inline script. Here is an example flow whih has an expression within the inline script:
yaml
id: expressions_inline
namespace: company.team
inputs:
  - id: uri
    type: URI
    defaults: https://www.google.com/
tasks:
  - id: inline_script
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: ghcr.io/kestra-io/pydata:latest
    script: |
      import requests
      url = ""{{ inputs.uri }}""
      response = requests.get(url)
      if response.status_code == 200:
          print(response.text)
      else:
          print(f""Failed to retrieve the webpage. Status code: {response.status_code}"")
This approach is very convenient for scripts that are specific to the flow, and does not allow us to have a separate file for our code. Having a separate file has multiple benefits:
There's multiple files of code being used - common with larger projects
The code is long and will be hard to maintain directly inside of the workflow - this makes the workflow harder to maintain too
The files are written and tested locally and synced to Kestra through Git
The files are used across multiple flows - this avoids repeating the code in each workflow
You cannot directly use Expressions inside of Namespace Files as they will not be rendered, or allow you to run your code outside of Kestra. There are 2 ways to allow you to pass expressions to your code:
Using Namespace Files with environment variables
Using Namespace Files with CLI arguments
In either case, we need to add our code as a Namespace File. To do this, you can use the Editor or import it directly.
Using Namespace Files with Environment Variables
You can pass inputs as environment variables using an expression.
This example uses the input uri and passes it to the task code as an environment variable so the Python code can access it
yaml
id: expressions_env_vars
namespace: company.team
inputs:
  - id: uri
    type: URI
    defaults: https://www.google.com/
tasks:
  - id: code
    type: io.kestra.plugin.scripts.python.Commands
    namespaceFiles:
      enabled: true
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: ghcr.io/kestra-io/pydata:latest
    commands:
      - python main.py
    env:
      URI: ""{{ inputs.uri }}""
Inside of the Python code, we use os.environ to fetch the environment variable:
python
import requests
import os
# Perform the GET request
response = requests.get(os.environ['URI'])
# Check if the request was successful
if response.status_code == 200:
    # Print the content of the page
    print(response.text)
else:
    print(f""Failed to retrieve the webpage. Status code: {response.status_code}"")
Using this method, it allows us to keep our code in a separate file, while also preventing our code from getting much longer than the inline example.
Using Namespace Files with CLI arguments
We can pass arguments directly to our code at execution. In Python, we can use argparse to achieve this.
Before we can execute our code, we will need to modify it to receive our argument correctly using the following:
python
import argparse
import requests
# Setup command line argument parsing
parser = argparse.ArgumentParser(description=""Fetch the content of a given URL"")
parser.add_argument(""url"", type=str, help=""The URL to fetch"")
args = parser.parse_args()
# Perform the GET request
response = requests.get(args.url)
# Check if the request was successful
if response.status_code == 200:
    # Print the content of the page
    print(response.text)
else:
    print(f""Failed to retrieve the webpage. Status code: {response.status_code}"")
You can pass the arguments to your code using an expression. The expression will be rendered, and the evaluated values will be passed to the script via argparse:
yaml
id: expressions_argparse
namespace: company.team
inputs:
  - id: uri
    type: URI
    defaults: https://www.google.com/
tasks:
  - id: hello
    type: io.kestra.plugin.scripts.python.Commands
    namespaceFiles:
      enabled: true
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: ghcr.io/kestra-io/pydata:latest
    commands:
      - python main.py ""{{ inputs.uri }}""
Using this method, the code has grows longer due to handling of arguments using argparse. This can be clearly seen by comparing the script in the Editor to the inline script used in the first approach. However, this method is very helpful from reusability perspective where the same script can be used in multiple flows without any code duplication of the script.
Was this page helpful?
Yes
No
Best Practices
Managing pip Package Dependencies
Best Practices
Version Control with Git""""""",1114,5117,kestra
https://kestra.io/docs/best-practices/git,"""""""DocsBest PracticesVersion Control with Git
Version Control with Git
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
>= 0.17.0
Best practices for Version Control with Git in Kestra.
By default, all Kestra flows are automatically versioned with Revisions. You don't need to use any additional version control system to track changes to your flows. Kestra automatically creates a new revision of a flow whenever you save it, and you can view the history of changes to a flow, compare changes between revisions, and restore a previous version at any time.
However, if you want to use Git to track changes to your Flows and Namespace Files, you can do so using the built-in Git support in Kestra.
There are multiple ways to use Git with Kestra:
The git.SyncFlows pattern allows you to implement GitOps and use Git as a single source of truth for your flows.
The git.SyncNamespaceFiles pattern allows you to implement GitOps and use Git as a single source of truth for your namespace files.
The git.PushFlows pattern allows you to edit your flows from the UI and regularly commit and push changes to Git; this pattern is useful if you want to use the built-in Editor in the UI and still have your code in Git.
The git.PushNamespaceFiles pattern allows you to edit your namespace files from the UI and regularly commit and push changes to Git; this pattern is useful if you want to use the built-in Editor in the UI and still have your files in Git.
The CI/CD pattern is useful if you want to manage the CI/CD process yourself e.g. via GitHub Actions or Terraform, and keep Git as a single source of truth for your code.
The image below shows how to choose the right pattern based on your needs:
For a detailed comparison of the three patterns, check the Version Control with Git page.
Was this page helpful?
Yes
No
Best Practices
Expressions with Namespace Files
Docs
Administrator Guide""""""",420,1922,kestra
https://kestra.io/docs/administrator-guide,"""""""DocsAdministrator Guide
Administrator Guide
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
The Administrator Guide covers everything you need to know about managing your Kestra cluster.
Check the Installation Guide for details on how to install Kestra to your preferred environment.
Check the Configuration Reference for details on how to configure Kestra based your specific needs.
Software and Hardware Requirements
This page describes the software and hardware requirements for Kestra.
Alerting & Monitoring
Here are some best practices for alerting and monitoring your Kestra instance.
Troubleshooting
Something doesn't work as expected? Check out our advice to help you troubleshoot.
Backup & Restore
Backup Kestra.
High Availability
Kestra is designed to be highly available and fault-tolerant. This section describes how to configure Kestra for high availability.
Purge
Purge old executions and logs to save disk space.
Managing Upgrades
Kestra is a fast-evolving project. This section will guide you through the process of upgrading your Kestra installation.
Usage
Here are the configuration options for the usage report.
Webserver URL
How to configure the URL of your Kestra webserver.
Was this page helpful?
Yes
No
Best Practices
Version Control with Git
Administrator Guide
Software and Hardware Requirements""""""",277,1347,kestra
https://kestra.io/docs/administrator-guide/requirements,"""""""DocsAdministrator GuideSoftware and Hardware Requirements
Software and Hardware Requirements
Table of Contents
Software requirements
Java
Queue and Repository
Internal Storage
Hardware requirements
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
This page describes the software and hardware requirements for Kestra.
Software requirements
The table below lists the software requirements for Kestra.
Java
Kestra Edition Required version Note
OSS/Enterprise >= 21 && < 22 Default 21 using Eclipse Temurin
Queue and Repository
Kestra Open-Source edition supports either Postgres or MySQL for use with the queue and repository components.
With Kestra Enterprise Edition (EE) you have the choice:
The same JDBC configuration as Open-Source for smaller scale deployments with an additional option to use SQL Server JDBC backend
Kafka plus Elasticsearch/Opensearch for large scale deployments
Kestra Edition Database Required version Note
OSS/Enterprise PostgreSQL >=14 && <= 16.3 Default latest
OSS/Enterprise MySQL >=8 with exception 8.0.31 Default 8.3.2
Enterprise SQL Server (Preview) >= SQL Server 2019 Default 2022
Enterprise Apache Kafka >=3
Enterprise Elasticsearch >=7
Enterprise Opensearch >=2
Internal Storage
Kestra Edition Storage Provider Required version Note
OSS/Enterprise MinIO >=8
OSS/Enterprise Google Cloud GCS N/A
OSS/Enterprise AWS S3 N/A
OSS/Enterprise Azure Blob Storage N/A
Hardware requirements
Kestra standalone server needs at least 4GiB of memory and 2vCPU to run correctly. In order to use script tasks, the server also needs to be able to run Docker-in-Docker (this is why e.g. AWS ECR Fargate is currently not supported).
If you need more guidance on how much memory and CPU to allocate to each architecture component, reach out to us and we'll help you with the sizing based on your expected workload.
Was this page helpful?
Yes
No
Docs
Administrator Guide
Administrator Guide
Alerting & Monitoring""""""",443,1952,kestra
https://kestra.io/docs/administrator-guide/monitoring,"""""""DocsAdministrator GuideAlerting & Monitoring
Alerting & Monitoring
Table of Contents
Alerting
Monitoring
Prometheus
Kestra's metrics
Others metrics
Grafana and Kibana
Kestra endpoints
Other Micronaut default endpoints
Debugging techniques
Enable verbose log
Take a thread dump
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Here are some best practices for alerting and monitoring your Kestra instance.
Alerting
Failure alerts are non-negotiable. When a production workflow fails, you should get notified about it as soon as possible. To implement failure alerting, you can leverage Kestra's built in notification tasks, including:
Slack
Microsoft Teams
Email
Technically, you can add custom failure alerts to each flow separately using the errors tasks:
yaml
id: onFailureAlert
namespace: company.team
tasks:
  - id: fail
    type: io.kestra.plugin.core.execution.Fail
errors:
  - id: slack
    type: io.kestra.plugin.notifications.slack.SlackIncomingWebhook
    url: ""{{ secret('SLACK_WEBHOOK') }}""
    payload: |
      {
        ""channel"": ""#alerts"",
        ""text"": ""Failure alert for flow {{ flow.namespace }}.{{ flow.id }} with ID {{ execution.id }}""
      }
However, this can lead to some boilerplate code if you start copy-pasting this errors configuration to multiple flows.
To implement a centralized namespace-level alerting, we instead recommend a dedicated monitoring workflow with a notification task and a Flow trigger. Below is an example workflow that automatically sends a Slack alert as soon as any flow in a namespace company.analytics fails or finishes with warnings.
yaml
id: failureAlertToSlack
namespace: company.monitoring
tasks:
  - id: send
    type: io.kestra.plugin.notifications.slack.SlackExecution
    url: ""{{ secret('SLACK_WEBHOOK') }}""
    channel: ""#general""
    executionId: ""{{trigger.executionId}}""
triggers:
  - id: listen
    type: io.kestra.plugin.core.trigger.Flow
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - FAILED
          - WARNING
      - type: io.kestra.plugin.core.condition.ExecutionNamespaceCondition
        namespace: company.analytics
        prefix: true
Adding this single flow will ensure that you receive a Slack alert on any flow failure in the company.analytics namespace. Here is an example alert notification:
Note that if you want this alert to be sent on failure across multiple namespaces, you will need to add an OrCondition to the conditions list. See the example below:
yaml
id: alert
namespace: company.system
tasks:
  - id: send
    type: io.kestra.plugin.notifications.slack.SlackExecution
    url: ""{{ secret('SLACK_WEBHOOK') }}""
    channel: ""#general""
    executionId: ""{{trigger.executionId}}""
triggers:
  - id: listen
    type: io.kestra.plugin.core.trigger.Flow
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - FAILED
          - WARNING
      - type: io.kestra.plugin.core.condition.OrCondition
        conditions:
          - type: io.kestra.plugin.core.condition.ExecutionNamespaceCondition
            namespace: company.product
            prefix: true
          - type: io.kestra.plugin.core.condition.ExecutionFlowCondition
            flowId: cleanup
            namespace: company.system
The example above is correct. However, if you instead list the conditions without the OrCondition, no alerts would be sent as kestra would try to match all criteria and there would be no overlap between the two conditions (they would cancel each other out). See the example below:
yaml
id: bad_example
namespace: company.monitoring
description: This example will not work
tasks:
  - id: send
    type: io.kestra.plugin.notifications.slack.SlackExecution
    url: ""{{ secret('SLACK_WEBHOOK') }}""
    channel: ""#general""
    executionId: ""{{trigger.executionId}}""
triggers:
  - id: listen
    type: io.kestra.plugin.core.trigger.Flow
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - FAILED
          - WARNING
      - type: io.kestra.plugin.core.condition.ExecutionNamespaceCondition
        namespace: company.product
        prefix: true
      - type: io.kestra.plugin.core.condition.ExecutionFlowCondition
        flowId: cleanup
        namespace: company.system
Here, there's no overlap between the two conditions. The first condition will only match executions in the company.product namespace, while the second condition will only match executions from the cleanup flow in the company.system namespace. If you want to match executions from the cleanup flow in the company.system namespace or any execution in the product namespace, make sure to add the OrCondition.
Monitoring
By default, Kestra exposes a monitoring endpoint on port 8081. You can change this port using the endpoints.all.port property in the configuration options.
This monitoring endpoint provides invaluable information for troubleshooting and monitoring, including Prometheus metrics and several Kestra's internal routes. For instance, the /health endpoint exposed by default on port 8081 (e.g. http://localhost:8081/health) generates a similar response as shown below as long as your Kestra instance is healthy:
json
{
  ""name"": ""kestra"",
  ""status"": ""UP"",
  ""details"": {
    ""jdbc"": {
      ""name"": ""kestra"",
      ""status"": ""UP"",
      ""details"": {
        ""jdbc:postgresql://postgres:5432/kestra"": {
          ""name"": ""kestra"",
          ""status"": ""UP"",
          ""details"": {
            ""database"": ""PostgreSQL"",
            ""version"": ""15.3 (Debian 15.3-1.pgdg110+1)""
          }
        }
      }
    },
    ""compositeDiscoveryClient()"": {
      ""name"": ""kestra"",
      ""status"": ""UP"",
      ""details"": {
        ""services"": {
        }
      }
    },
    ""service"": {
      ""name"": ""kestra"",
      ""status"": ""UP""
    },
    ""diskSpace"": {
      ""name"": ""kestra"",
      ""status"": ""UP"",
      ""details"": {
        ""total"": 204403494912,
        ""free"": 13187035136,
        ""threshold"": 10485760
      }
    }
  }
}
Prometheus
Kestra exposes Prometheus metrics on the endpoint /prometheus. This endpoint can be used by any compatible monitoring system.
For more details about Prometheus setup, refer to the Monitoring with Grafana & Prometheus article.
Kestra's metrics
You can leverage Kestra's internal metrics to configure custom alerts. Each metric provides multiple time series with tags allowing to track at least namespace & flow but also other tags depending on available tasks.
Kestra metrics use the prefix kestra. This prefix can be changed using the kestra.metrics.prefix property in the configuration options.
Each task type can expose custom metrics that will be also exposed on Prometheus.
Worker
Metrics Type Description
worker.running.count GAUGE Count of tasks actually running
worker.started.count COUNTER Count of tasks started
worker.retried.count COUNTER Count of tasks retried
worker.ended.count COUNTER Count of tasks ended
worker.ended.duration TIMER Duration of tasks ended
worker.job.running GAUGE Count of currently running worker jobs
worker.job.pending GAUGE Count of currently pending worker jobs
worker.job.thread GAUGE Total worker job thread count
The worker.job.pending, worker.job.running, and worker.job.thread metrics are intended for autoscaling worker servers.
Executor
Metrics Type Description
executor.taskrun.next.count COUNTER Count of tasks found
executor.taskrun.ended.count COUNTER Count of tasks ended
executor.taskrun.ended.duration TIMER Duration of tasks ended
executor.workertaskresult.count COUNTER Count of task results sent by a worker
executor.execution.started.count COUNTER Count of executions started
executor.execution.end.count COUNTER Count of executions ended
executor.execution.duration TIMER Duration of executions ended
Indexer
Metrics Type Description
indexer.count COUNTER Count of index requests sent to a repository
indexer.duration DURATION Duration of index requests sent to a repository
Scheduler
Metrics Type Description
scheduler.trigger.count COUNTER Count of triggers
scheduler.evaluate.running.count COUNTER Evaluation of triggers actually running
scheduler.evaluate.duration TIMER Duration of trigger evaluation
Others metrics
Kestra also exposes all internal metrics from the following sources:
Micronaut
Kafka
Thread pools of the application
JVM
Check out the Micronaut documentation for more information.
Grafana and Kibana
Kestra uses Elasticsearch to store all executions and metrics. Therefore, you can easily create a dashboard with Grafana or Kibana to monitor the health of your Kestra instance.
We'd love to see what dashboards you will build. Feel free to share a screenshot or a template of your dashboard with the community.
Kestra endpoints
Kestra exposes internal endpoints on the management port (8081 by default) to provide status corresponding to the server type:
/worker: will expose all currently running tasks on this worker.
/scheduler: will expose all currently scheduled flows on this scheduler with the next date.
/kafkastreams: will expose all Kafka Streams states and aggregated store lag.
/kafkastreams/{clientId}/lag: will expose details lag for a clientId.
/kafkastreams/{clientId}/metrics: will expose details metrics for a clientId.
Other Micronaut default endpoints
Since Kestra is based on Micronaut, the default Micronaut endpoints are enabled by default on port 8081:
/info Info Endpoint with git status information.
/health Health Endpoint usable as an external heathcheck for the application.
/loggers Loggers Endpoint allows changing logger level at runtime.
/metrics Metrics Endpoint metrics in JSON format.
/env Environment Endpoint to debug configuration files.
You can disable some endpoints following the above Micronaut configuration.
Debugging techniques
Without any order, here are debugging techniques that administrators can use to understand their issues:
Enable verbose log
Kestra had some management endpoints including one that allows changing logging verbosity at run time.
Inside the container (or in local if standalone jar is used), send this command to enable very verbose logging:
shell
curl -i -X POST -H ""Content-Type: application/json"" \
  -d '{ ""configuredLevel"": ""TRACE"" }' \
  http://localhost:8081/loggers/io.kestra
Alternatively, you can change logging levels on configuration files:
yaml
logger:
  levels:
    io.kestra.core.runners: TRACE
Take a thread dump
You can request a thread dump via the /threaddump endpoint available on the management port (8081 if not configured otherwise).
Was this page helpful?
Yes
No
Administrator Guide
Software and Hardware Requirements
Administrator Guide
Troubleshooting""""""",2321,10731,kestra
https://kestra.io/docs/administrator-guide/troubleshooting,"""""""DocsAdministrator GuideTroubleshooting
Troubleshooting
Table of Contents
CrashLoopBackoff when restarting all pods
Unprocessable execution
Docker in Docker (DinD)
Docker in Docker using Helm charts
Docker in Docker (DinD) on a Mac with ARM-based Apple silicon chip
tmp directory ""No such file or directory""
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Something doesn't work as expected? Check out our advice to help you troubleshoot.
CrashLoopBackoff when restarting all pods
Question from a user: ""When I restart all Kubernetes pods at once, they get stuck in a CrashLoopBackoff for a number of minutes before eventually resolving - Why does it happen?""
You are likely hitting the startup issue of a Java application causing failure of liveness probes. The startup can consume a lot of resources, since Java will load many classes at startup. Setting the CPU limit to 0.5 can improve the startup time of the server and should resolve the failing healthchecks.
Unprocessable execution
Sometimes, things can go wrong in an unattended manner; in such situations, you can skip an execution that Kestra is not able to process.
To do so, you can start the executor server (or the standalone server if not using a deployment with separate components) with a list of execution identifiers to skip.
sh
kestra server executor --skip-executions 6FSPERUe1JwbYmMmdwRlgV,5iLGjTLOHAVGUGlsesFaMb
For skipping all executions of a:
Flows
You can skip all executions of one or more flows by using the --skip-flows flag:
sh
kestra server executor --skip-flows flowA,flowB
Example: Suppose you're dealing with a flow called daily-data-sync. If it's causing issues and you want to skip its execution, you can run:
sh
kestra server executor --skip-flows daily-data-sync
Namespace
To skip all executions within specific namespaces, use the --skip-namespaces flag:
sh
kestra server executor --skip-namespaces myNamespaceA,myNamespaceB
Example: If you have a namespace called production-data, and you want to skip all executions under it, use:
sh
kestra server executor --skip-namespaces production-data
Tenant
To skip all executions associated with specific tenants, you can use the --skip-tenants flag:
sh
kestra server executor --skip-tenants tenantA,tenantB
Example: Let's say you have a tenant named companyA, and you want to skip all executions for that tenant:
sh
kestra server executor --skip-tenants companyA
Docker in Docker (DinD)
If you face some issues using Docker in Docker e.g. with Script tasks using DOCKER runner, start troubleshooting by attaching the terminal: docker run -it --privileged docker:dind sh. Then, use docker logs container_ID to get the container logs.
Also, try docker inspect container_ID to get more information about your Docker container. The output from this command displays details about the container, its environments, network settings, etc. This information can help you identify what might be wrong.
Docker in Docker using Helm charts
On some Kubernetes deployments, using DinD with our default Helm charts can lead to:
bash
Device ""ip_tables"" does not exist.
ip_tables              24576  4 iptable_raw,iptable_mangle,iptable_nat,iptable_filter
modprobe: can't change directory to '/lib/modules': No such file or directory
error: attempting to run rootless dockerd but need 'kernel.unprivileged_userns_clone' (/proc/sys/kernel/unprivileged_userns_clone) set to 1
To fix this, use root to launch the DinD container by setting the following values:
yaml
dind:
  image:
    tag: dind
  args:
    - --log-level=fatal
  securityContext:
    runAsUser: 0
    runAsGroup: 0
securityContext:
  runAsUser: 0
  runAsGroup: 0
Docker in Docker (DinD) on a Mac with ARM-based Apple silicon chip
If you are getting an error similar to: java.io.IOException: com.sun.jna.LastErrorException: [111] Connection refused, it might be related to a Docker in Docker (DinD) issue.
Try using an embedded Docker server as shown below:
Example docker-compose.yml
tmp directory ""No such file or directory""
If you're encountering errors associated to the tmp directory such as ""No such file or directory"", there's a good chance your tmp directory isn't mounted correctly in your Kestra configuration.
When configuring your docker-compose.yml, it's important to make sure that the tmpDir has the same path as the volume otherwise Kestra won't know what directory to mount for the tmp directory.
yaml
kestra:
  tasks:
    tmpDir:
      path: /home/kestra/tmp
In this example, /home/kestra:/home/kestra matches the tasks tmpDir field.
yaml
volumes:
  - kestra-data:/app/storage
  - /var/run/docker.sock:/var/run/docker.sock
  - /home/kestra:/home/kestra
Was this page helpful?
Yes
No
Administrator Guide
Alerting & Monitoring
Administrator Guide
Backup & Restore""""""",1141,4784,kestra
https://kestra.io/docs/administrator-guide/backup-and-restore,"""""""DocsAdministrator GuideBackup & Restore
Backup & Restore
Table of Contents
Metadata only Backup & Restore in the Enterprise Edition
Metadata backup
Metadata restore
Full Backup & Restore
Backup & Restore with the JDBC Backend
Backup & Restore with the Elasticsearch and Kafka Backend
Backup & Restore of Internal Storage
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Backup Kestra.
Kestra offers a backup functionality for Kestra metadata i.e. all data not related to workflow executions. Executions are not included in the backup as capturing them can be costly and the resulting backup file could be excessively large. However, Kestra uses a database and internal storage that can be backed up and restored if a metadata backup is not sufficient.
Metadata only Backup & Restore in the Enterprise Edition
Since version 0.19, Kestra Enterprise Edition provides metadata backup & restore functionality. This backup feature can be used to back up metadata in a Kestra instance, and restore it in another instance that can be in a different Kestra version or using a different backend.
We recommend to backup and restore metadata when Kestra is stopped, otherwise the backup may not be in a consistent state.
Currently, the metadata backup will back up all data not related to Executions, including custom blueprints, flows, namespaces, roles, secrets (for JDBC and Elasticsearch secrets manager backend), security integrations, settings, templates, tenants, triggers, users and access bindings.
Metadata backup
To back up Kestra instance metadata, you can use the following command:
shell
kestra backups create FULL
FULL indicates that we want to back up the full instance. If you want to back up only a single tenant (in case multi-tenancy is enabled), you can use TENANT instead. In this case, users and tenants will not be included in the backup (only the selected tenant will be included).
By default, backups are encrypted using the Kestra embedded encryption key. You can adjust this behavior using command line parameters.
You can use the following command line parameters:
--tenant: only when backup type is TENANT, use it to specify the name of the tenant to backup. If not set, the default tenant will be used.
--encryption-key: use it to specify a custom encryption key instead of the Kestra embedded one.
--no-encryption: use it to bypass backup encryption. Metadata backup may contain sensitive information so make sure you are aware of the risk when bypassing the encryption.
When you start the backup process from the command line, you will see the following logs which include a backup summary and the URI to the Kestra internal storage file where the backup will be stored.
2024-09-17 16:33:12,706 INFO  create       io.kestra.ee.backup.BackupService Backup summary: [BINDING: 3, BLUEPRINT: 1, FLOW: 13, GROUP: 1, NAMESPACE: 1, ROLE: 6, SECRET: 1, SECURITY_INTEGRATION: 0, SETTING: 1, TENANT: 1, TENANT_ACCESS: 2, TRIGGER: 2, USER: 1]
2024-09-17 16:33:12,706 INFO  create       io.kestra.ee.backup.BackupService Backup instance created in 508 ms
Backup created: kestra:///backups/full/backup-20240917163312.kestra
Metadata restore
To restore Kestra instance using a metadata backup, you can use the following command with the internal storage URI provided by the backup command:
shell
kestra backups restore kestra:///backups/full/backup-20240917163312.kestra
You can use the following command line parameters:
--encryption-key: use it to specify a custom encryption key instead of the Kestra embedded one.
Starting the restore process from the command line will display the following logs which include backup information and a restore summary.
2024-09-17 16:41:06,065 INFO  restore      io.kestra.ee.backup.BackupService Restoring kestra:///backups/full/backup-20240917163312.kestra
2024-09-17 16:41:06,149 INFO  restore      io.kestra.ee.backup.BackupService Restoring FULL backup from Kestra version 0.19.0-SNAPSHOT created at 2024-09-17T16:33:12.700099909
2024-09-17 16:41:06,150 INFO  restore      io.kestra.ee.backup.BackupService Backup summary: [BINDING: 3, BLUEPRINT: 1, FLOW: 13, GROUP: 1, NAMESPACE: 1, ROLE: 6, SECRET: 1, SECURITY_INTEGRATION: 0, SETTING: 1, TENANT: 1, TENANT_ACCESS: 2, TRIGGER: 2, USER: 1]
2024-09-17 16:41:07,182 INFO  restore      io.kestra.ee.backup.BackupService Restore summary: [BINDING: 3, BLUEPRINT: 1, FLOW: 13, GROUP: 1, NAMESPACE: 1, ROLE: 6, SECRET: 1, SECURITY_INTEGRATION: 0, SETTING: 1, TENANT: 1, TENANT_ACCESS: 2, USER: 1, TRIGGER: 2]
Backup restored from URI: kestra:///backups/full/backup-20240917163312.kestra
Full Backup & Restore
Backup & Restore with the JDBC Backend
With the JDBC backend, Kestra can be backed up and restored using the database's native backup tools.
Backup & Restore for PostgreSQL
First, stop Kestra to ensure the database is in a stable state. Although pg_dump allows you to back up a running PostgreSQL database, it's always better to perform backups offline when possible.
Next, run the following command:
shell
pg_dump -h localhost -p 5432 -U <username> -d <database> -F tar -f kestra.tar
To restore the backup to a new database, use pg_restore:
shell
pg_restore -h localhost -p 5432 -U <username> -d <database> kestra.tar
Finally, restart Kestra.
Backup & Restore for MySQL
First, stop Kestra to ensure the database is in a stable state. Although MySQL's mysqldump allows you to back up a running MySQL database, it's always better to perform backups offline when possible.
Next, run the following command to back up the database:
shell
mysqldump -h localhost -P 3306 -u <username> -p<password> <database> > kestra.sql
To restore the backup to a new database, use the following command:
shell
mysql -h localhost -P 3306 -u <username> -p <password> <database> < kestra.sql
The < kestra.sql part tells MySQL to read and execute the SQL statements contained in the kestra.sql backup file as input.
Finally, restart Kestra.
Backup & Restore with the Elasticsearch and Kafka Backend
With the Elasticsearch and Kafka backend, Kestra can be backed up and restored using Elasticsearch snapshots. Kafka will be reinitialized with the information from Elasticsearch.
This guide assumes you have already configured a snapshot repository in Elasticsearch named my_snapshot_repository. Elasticsearch provides several backup options. We will leverage basic snapshot and restore operations using the Elasticsearch API.
First, create an Elasticsearch snapshot named kestra:
PUT _snapshot/my_snapshot_repository/kestra?wait_for_completion=true
Next, delete all Kestra indices and recreate them using the snapshot:
POST _snapshot/my_snapshot_repository/kestra/_restore
{
  ""indices"": ""kestra_*""
}
If you need to start from a fresh Kafka instance, you can reindex Kafka from the data in Elasticsearch using the following Kestra command:
shell
kestra sys-ee restore-queue
Since some execution information is stored only in Kafka, not all pending executions may be restarted.
Finally, restart Kestra.
Backup & Restore of Internal Storage
Kestra's internal storage can be implemented using either a local filesystem or an object storage service.
If you're using the local filesystem implementation, you can back up and restore the directory with standard filesystem backup tools.
If you're using an object storage service provided by a cloud provider, you can replicate a bucket across multiple locations. Usually, this option is sufficient for disaster recovery. Alternatively, refer to your cloud provider's documentation for instructions on external bucket backup or replication to a different region.
If you're running your own object storage (e.g., using MinIO from our Helm Chart), you can leverage Restic or set up a replication strategy that fits your needs.
Was this page helpful?
Yes
No
Administrator Guide
Troubleshooting
Administrator Guide
High Availability""""""",1877,7873,kestra
https://kestra.io/docs/administrator-guide/high-availability,"""""""DocsAdministrator GuideHigh Availability
High Availability
Table of Contents
Overview
Scaling the components
Load balancing
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Kestra is designed to be highly available and fault-tolerant. This section describes how to configure Kestra for high availability.
Overview
First, let's define what we mean by high availability.
Highly available systems are designed to guarantee continuous operation, even in the event of a failure. This is achieved by eliminating single points of failure and ensuring that there are redundant systems and components.
In Kestra, high availability is achieved by running multiple instances of all components, such as the webserver hosting the API, the scheduler, the executor, the indexer and the workers. This ensures that if one instance fails, the system can continue to operate without interruption.
Note that you need to deploy Kestra using the Kafka and Elasticsearch architecture. This architecture is designed to be highly available and fault-tolerant.
Scaling the components
The following components can be scaled horizontally (e.g. by allocating more replicas in your Helm chart values):
Webserver
Scheduler
Executor
Worker
Indexer
Additionally, the Elasticsearch and Kafka clusters can be scaled out as needed to handle large volumes of data.
Finally, the internal storage (such as e.g. S3) is highly available and fault-tolerant by design.
Ensure that the host system is configured for high availability and fault-tolerance. For instance, you can adjust the Linux kernel net.ipv4.tcp_retries2 parameter to reduce TCP retransmission times.
Load balancing
To ensure high availability, you should use a load balancer to distribute incoming requests across multiple instances of the webserver. This ensures that if one instance fails, the system can continue to operate without interruption.
Was this page helpful?
Yes
No
Administrator Guide
Backup & Restore
Administrator Guide
Purge""""""",400,2025,kestra
https://kestra.io/docs/administrator-guide/purge,"""""""DocsAdministrator GuidePurge
Purge
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
>= 0.18.0
Purge old executions and logs to save disk space.
As your workflows grow, you may need to clean up old executions and logs to save disk space.
The recommended way to clean execution and logs is using a combination of io.kestra.plugin.core.execution.PurgeExecutions and the newly added io.kestra.plugin.core.log.PurgeLogs task as shown below. The PurgeLogs task removes all logs (both Execution logs and Trigger logs) in a performant batch operation. Combining those two together will give you the same functionality as the previous io.kestra.plugin.core.storage.Purge task but in a more performant and reliable way (roughly 10x faster).
Additionally, the Enterprise Edition includes the PurgeAuditLogs task.
yaml
id: purge
namespace: company.myteam
description: |
  This flow will remove all executions and logs older than 1 month.
  We recommend running this flow daily to avoid running out of disk space.
tasks:
  - id: purge_executions
    type: io.kestra.plugin.core.execution.PurgeExecutions
    endDate: ""{{ now() | dateAdd(-1, 'MONTHS') }}""
    purgeLog: false
  - id: purge_logs
    type: io.kestra.plugin.core.log.PurgeLogs
    endDate: ""{{ now() | dateAdd(-1, 'MONTHS') }}""
triggers:
  - id: daily
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""@daily""
Note that the Purge tasks do not affect Kestra's internal queues. Queue retention is configured separately. The database type uses a dedicated JDBC Cleaner and the Kafka type relies on topic retention.
Renamed Purge Tasks in 0.18.0
Was this page helpful?
Yes
No
Administrator Guide
High Availability
Administrator Guide
Managing Upgrades""""""",416,1747,kestra
https://kestra.io/docs/administrator-guide/upgrades,"""""""DocsAdministrator GuideManaging Upgrades
Managing Upgrades
Table of Contents
Where you can find the release changelog
How to identify breaking changes in a release
How to minimise downtime when updating Kestra
How to stick to a specific Kestra version
Migrating a Standalone Installation
Migrating an installation with Docker
Docker Compose
Migration in Kubernetes using Helm
Rolling upgrades in Kubernetes
Where can I find migration guides
How to stay informed about new releases
Database Migrations
Automatic database migration
Manual database migration
Getting help
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Kestra is a fast-evolving project. This section will guide you through the process of upgrading your Kestra installation.
Where you can find the release changelog
You can find the release changelog on the main repository's Releases page. The changelog includes a full list of changes, new features, and bug fixes for each release, as well as any breaking changes that may require your attention. For a high-level eplanation of the changes, you can also check release blog posts.
How to identify breaking changes in a release
Next to all bug fixes and enhancements, you can find a dedicated section called Breaking Changes in the release notes. This section lists changes that may require some adjustments in your code or Kestra configuration, along with links to the documentation showing how to migrate.
‚ö†Ô∏è Note that Breaking Changes are always included as the last section of the release notes. Make sure to inspect that part of the release notes before upgrading to a new version.
How to minimise downtime when updating Kestra
If running Kestra in separate components you should:
Stop the executors and the scheduler
Stop the workers - there is a graceful shutdown (which can be configured but I'm not sure we already document how to configure this) and automatic task resubmission.
Stop the webserver (and the indexer using EE and Kafka)
Normally, there is a graceful shutdown on all components so you will not lose anything. Once this is done, you can update and restart everything in the opposite order (or any order as all components are independent).
The webserver host the API so it's the one that must be stopped then started immediately to avoid potential downtime. Once this has been done, you can restart the other components so flow executions can start again.
How to stick to a specific Kestra version
If you want to stick to a specific Kestra version, you can pin the Docker image tag to a specific release. Here are some examples:
kestra/kestra:v0.14.4 includes the 0.14.4 release with the fourth patch version
kestra/kestra:v0.14.4-full includes the 0.14.4 release with all plugins
kestra/kestra:v0.15.0 includes the 0.15 release without any plugins
kestra/kestra:v0.15.0-full includes the 0.15 release with all plugins.
Note that you can always create a custom image with your own plugins and package dependencies, as explained in the Docker installation.
Migrating a Standalone Installation
If you use a manual standalone installation with Java, you can download the Kestra binary for a specific version from the Assets menu of a specific Release page. The image below shows how you can download the binary for the 0.14.1 release.
Once you downloaded the binary, you can start kestra from that binary using the following command:
bash
./kestra-VERSION server standalone
Migrating an installation with Docker
If you use Docker, you can change the Docker image tag to the desired version and restart the container(s) or Kubernetes pod(s).
Docker Compose
If you use Docker compose, adjust your Docker Compose file to use the desired Docker image tag and run docker-compose up -d to restart the container(s).
Migration in Kubernetes using Helm
If you use Helm, adjust the Helm chart tag value to point the installation to the desired version. For example, you can run the following command to upgrade the installation to the desired version:
bash
helm upgrade kestra kestra/kestra --set image.tag=v0.15.0-full
For more complex configurations that include multiple changes, consider using a custom values file:
First, create a values.yaml file that contains the settings you want to adjust.
Then, use the helm upgrade command with the -f flag to specify your custom values file:
sh
helm upgrade kestra kestra/kestra -f values.yaml
Rolling upgrades in Kubernetes
Upgrading Kestra on a Kubernetes cluster depends on a deployment rollout strategy.
Every service can be rolled out without any downtime except for a worker that needs a special attention.
Each standard component during the rollout will create a pod with a new version (keeping the old one running). When the new pod is up and running (passing all health checks), Kubernetes will shutdown the previous one leading to a zero-downtime migration.
Upgrading workers is more involved since workers handle data processing tasks which can range from a few seconds to many hours. You need to define the behavior for these tasks.
By default, Kestra worker process will wait until the completion of all task runs before shutting down during a migration. However, you can overwrite that default behavior if you wish. Kestra Helm charts provide a configuration of a terminationGracePeriodSeconds (set to 60 seconds by default) that allows you to define the amount of time you want to wait before force-killing the worker.
If the worker has no workers or is able to terminate all tasks before the grace period, it will be shutdown directly. If the pod is not able to finish the tasks affected before terminationGracePeriodSeconds, Kubernetes will kill the pod, leading to some tasks being resubmitted and handled by another worker.
In Kestra, every worker that died unexpectedly will be detected by the executor, and all unfinished task runs will be resubmitted and will be picked up by a new worker. In case of rollout with terminationGracePeriodSeconds, we are in the case of unexpected failure and the task will also be resubmitted.
Where can I find migration guides
The Migrations section includes detailed information about deprecated features and provides guidance on how to migrate from the deprecated to a new behavior.
For all breaking changes, the migration guides are linked in the release notes.
How to stay informed about new releases
You can get notified about new releases in the following ways:
Subscribe to notifications in the #announcements channel in the Slack community.
Follow us on Twitter
Follow us on LinkedIn
Subscribe to the Kestra newsletter
Subscribe to Release notifications on the main GitHub repository, as shown in the image below:
Database Migrations
There are two types of database migrations: automatic and manual.
Automatic database migration
Kestra uses Flyway to automatically perform database migrations when Kestra server is started. Flyway is a tool that allows version controlling changes to a database (such as Kestra's database) so that you can migrate it to a new version easily. Kestra stores the current version of the database in a table called flyway_schema_history. When Flyway runs, it compares the current version of the database with the version that it should be at. If the versions do not match, Flyway will run the necessary migrations to bring the database up to date. This process is automatic when Kestra server starts, therefore no manual intervention is required.
Manual database migration
Sometimes a manual database migration is useful, especially when you have a large database and you want to perform the migration before upgrading Kestra to avoid a long downtime.
For example, when migrating from Kestra v0.12.0 to v0.13.0, all indexes will be rebuilt due to addition of the multi-tenancy feature (the tenant_id column is added on almost every table). When using the JDBC runner with a large database, database migration can take multiple hours. In such use cases, we recommend performing the migration manually before starting Kestra by using the kestra sys database migrate command.
This command should use the same configuration as configured on your Kestra instance. Depending on whether you deploy Kestra using Docker or Kubernetes, this command can be launched via a docker exec or a kubectl exec command.
There are two ways to initiate the manual database migration:
Keep Kestra running in an old version. Then, stop Kestra and launch the command on the new version.
Start Kestra on the new version with automatic schema migration disabled via flyway.datasources.postgres.enabled=false (in case you're database is not postgres replace postgres with the type of your database) and launch the command: kestra sys database migrate.
Here is an example of how to launch the command via a docker exec command:
bash
docker exec your_container_id bash ./kestra sys database migrate --help
Here is the output of that --help command:
bash
Usage: kestra sys database migrate [-hVv] [--internal-log] [-c=<config>]
                                   [-l=<logLevel>] [-p=<pluginsPath>]
Force database schema migration.
Kestra uses Flyway to manage database schema evolution, this command will run
Flyway then exit.
  -c, --config=<config>   Path to a configuration file, default: /root/.
                            kestra/config.yml)
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log, default:
                            false)
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR; default: INFO)
  -p, --plugins=<pluginsPath>
                          Path to plugins directory , default: ./plugins)
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Getting help
If you have any questions about the upgrade process:
if you are a Kestra Enterprise customer, please submit a Support Ticket
reach out to us via Slack.
We understand that upgrades can be difficult. If you need more help, reach out to us and we'll help you with the migration based on your specific environment and use case.
Was this page helpful?
Yes
No
Administrator Guide
Purge
Administrator Guide
Usage""""""",2157,10328,kestra
https://kestra.io/docs/administrator-guide/usage,"""""""DocsAdministrator GuideUsage
Usage
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Here are the configuration options for the usage report.
Understanding how you use Kestra is very important to us: it helps us improve the solution in many ways. For this reason, the kestra.anonymous-usage-report.enabled option is mandatory: we want you to consider whether you wish to share anonymous data with us so that we can benefit from your experience and use cases.
kestra.anonymous-usage-report.enabled: (default true)
kestra.anonymous-usage-report.initial-delay: (default 5m)
kestra.anonymous-usage-report.fixed-delay: (default 1h)
The collected data can be found here. We collect only anonymous data that allows us to understand how you use Kestra. The data collected includes:
host data: cpu, ram, os, jvm and a fingerprint of the machine.
plugins data: the list of plugins installed and their current versions.
flow data: the namespace count, flow count, the task type and the trigger type used.
execution data: the execution and taskruns count for last 2 days with count and duration grouped by status.
common data: the server type, version, timezone, env, start time and url.
Was this page helpful?
Yes
No
Administrator Guide
Managing Upgrades
Administrator Guide
Webserver URL""""""",290,1302,kestra
https://kestra.io/docs/administrator-guide/webserver-url,"""""""DocsAdministrator GuideWebserver URL
Webserver URL
Table of Contents
URL Configuration
Proxy Configuration
Forward Proxy Configuration
Reverse Proxy Configuration
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
How to configure the URL of your Kestra webserver.
URL Configuration
Some notification services require a URL configuration defined in order to add links from the alert message. Use a full URI here with a trailing / (without ui or api).
yaml
kestra:
  url: https://www.my-host.com/kestra/
Proxy Configuration
In networking, a forward proxy acts on behalf of clients controlling outbound traffic, while a reverse proxy acts on behalf of servers controlling inbound traffic and often providing additional features such as load balancing and SSL encryption.
A (forward) proxy serves as an intermediary for requests from clients seeking resources from other servers (like Kestra API in order to retrieve blueprints and plugin documentation), while a reverse proxy sits in front of one or more web servers, intercepting requests from clients before they are sent to the server.
Forward Proxy Configuration
In a forward proxy, the client connects to the proxy server, requesting some service (such as Kestra API) available from a different server.
In order to set up proxy in your Kestra installation, you may need to adjust the micronaut.http.services.api configuration to include a proxy address, username, and password. This will allow you to make requests to the Kestra API through the proxy in order to fetch data for the Kestra UI, such as e.g. Blueprints. Here is how you can adjust your config.yml file to include the necessary configuration:
yaml
micronaut:
  http:
    services:
      api:
        url: https://api.kestra.io
        proxy-type: http
        proxy-address: my.company.proxy.address:port
        proxy-username: ""username""
        proxy-password: ""password""
        follow-redirects: true
Make sure to check the Micronaut HttpClient Configuration for more information on how to configure the DefaultHttpClientConfiguration in your config.yml file.
Another way to authenticate is to provide the micronaut.http.client.proxy-authorization: Basic <base64-encoded username:password> and micronaut.http.services.*.proxy-authorization: Basic <base64-encoded username:password> so that the password is not displayed in plain text in the config file.
Reverse Proxy Configuration
Reverse proxies are used to hide the identity of the server from the clients and may perform tasks such as load balancing, authentication, decryption, and caching. A reverse proxy acts on behalf of the server, taking requests from the external network, and directing them to the internal server(s) that can fulfill those requests.
If you want to host Kestra behind a reverse proxy, make sure to use the Server Send Event (SSE) to display executions in real-time.
On some reverse proxies, such as Nginx, you need to disable buffering to enable real-time updates.
Here is a working configuration:
bash
location / {
    proxy_pass  http://localhost:<kestra_port>;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection ""upgrade"";
    proxy_read_timeout 600s;
    proxy_redirect    off;
    proxy_set_header  Host             $http_host;
    proxy_set_header  X-Real-IP        $remote_addr;
    proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;
    proxy_set_header  X-Forwarded-Protocol $scheme;
    # Needed for SSE
    proxy_buffering off;
    proxy_cache off;
}
Should you wish to access Kestra via a separate context path via the reverse proxy, a change will be required in the Micronaut settings of Kestra.
For instance, say I wish to access the Kestra UI through mycompany.com/kestra, add the following configuration to your Kestra startup configuration:
yaml
micronaut:
  server:
    context-path: ""/kestra""
Then, modify your above nginx configuration to the following
bash
server {
    listen 80;
    server_name mycompany.com;
    location /kestra {
        proxy_pass  http://<kestra-hostname>:<kestra-port>/kestra;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection ""upgrade"";
        proxy_read_timeout 600s;
        proxy_redirect    off;
        proxy_set_header  Host             $http_host;
        proxy_set_header  X-Real-IP        $remote_addr;
        proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;
        proxy_set_header  X-Forwarded-Protocol $scheme;
        # Needed for SSE
        proxy_buffering off;
        proxy_cache off;
    }
}
Was this page helpful?
Yes
No
Administrator Guide
Usage
Docs
Migration Guide""""""",1030,4705,kestra
https://kestra.io/docs/migration-guide,"""""""DocsMigration Guide
Migration Guide
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Migrate Kestra smoothly with in-depth guides.
Upgrades and migrations are sometimes necessary. This section covers what's being phased out and what you can use instead.
0.11.0
Deprecated features and migration guides for 0.11.0 and onwards.
0.12.0
Deprecated features and migration guides for 0.12.0 and onwards.
0.13.0
Deprecated features and migration guides for 0.13.0 and onwards.
0.14.0
Deprecated features and migration guides for 0.14.0 and onwards.
0.15.0
Deprecated features and migration guides for 0.15.0 and onwards.
0.17.0
Deprecated features and migration guides for 0.17.0 and onwards.
0.18.0
Deprecated features and migration guides for 0.18.0 and onwards.
0.19.0
Deprecated features and migration guides for 0.19.0 and onwards.
Was this page helpful?
Yes
No
Administrator Guide
Webserver URL
Migration Guide
0.11.0""""""",253,942,kestra
https://kestra.io/docs/migration-guide/0.11.0,"""""""DocsMigration Guide0.11.0
0.11.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.11.0
Deprecated features and migration guides for 0.11.0 and onwards.
Script tasks moved to dedicated plugins
Script tasks included in the core plugin have been deprecated in 0.11.0 and moved to dedicated plugins.
Deprecation of Templates
Since 0.11.0, Templates are deprecated and disabled by default. Please use subflows instead.
Was this page helpful?
Yes
No
Docs
Migration Guide
0.11.0
Script tasks moved to dedicated plugins""""""",142,548,kestra
https://kestra.io/docs/migration-guide/0.11.0/core-script-tasks,"""""""DocsMigration Guide0.11.0Script tasks moved to dedicated plugins
Script tasks moved to dedicated plugins
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.11.0
Script tasks included in the core plugin have been deprecated in 0.11.0 and moved to dedicated plugins.
Previously, there was scripting tasks inside the core plugin (the plugin that offers core task and is always included inside any Kestra distribution). Since the introduction of the new Script tasks in dedicated plugins, the old core scripting tasks have been deprecated and moved out of the core plugin.
If you use one of these tasks, you should migrate to the new one that offers improved scripting capabilities and runs by default in a separate Docker container.
If you still want to use one of the old tasks and you don't use one of our *-full Docker images and manually install plugins, you must include the new plugin that now includes the old deprecated tasks.
Here is the list of the old tasks with their new location and the replacement tasks:
The Bash task is now located inside the plugin-script-shell plugin and replaced by the Shell Commands and Script tasks.
The Node task is now located inside the plugin-script-node plugin and replaced by the Node Commands and Script tasks.
The Python task is now located inside the plugin-script-python plugin and replaced by the Python Commands and Script tasks.
Was this page helpful?
Yes
No
Migration Guide
0.11.0
0.11.0
Deprecation of Templates""""""",314,1498,kestra
https://kestra.io/docs/migration-guide/0.11.0/templates,"""""""DocsMigration Guide0.11.0Deprecation of Templates
Deprecation of Templates
Table of Contents
Why templates are deprecated
Templates ‚ö†Ô∏è
Subflows ‚úÖ
Side-by-side comparison
Documentation of the deprecated feature
Example
Templates UI
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.11.0
Since 0.11.0, Templates are deprecated and disabled by default. Please use subflows instead.
If you still rely on templates, you can re-enable them in your configuration.
Why templates are deprecated
Subflows are more powerful ‚Äî subflows provide the same functionality as templates while simultaneously being more flexible than templates. For instance, inputs are not allowed in a template because a template is only a list of tasks that get copied to another flow that references it. In contrast, when invoking a subflow, you can parametrize it with custom parameters. This way, subflows allow you to define workflow logic once and invoke it in other flows with custom parameters.
Subflows are more transparently reflected in the topology view and don't require copying tasks.
If you are using templates and you are not ready to migrate to subflows yet, add the following Kestra configuration option to still be able to use them:
yaml
kestra:
  templates:
    enabled: true
Templates ‚ö†Ô∏è
A typical template has an ID, a namespace, and a list of tasks. Here is an example template:
yaml
id: mytemplate
namespace: company.team
tasks:
  - id: workingDir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: bash
        type: io.kestra.plugin.scripts.shell.Commands
        commands:
          - mkdir -p out
          - echo ""Hello from 1"" >> out/output1.txt
          - echo ""Hello from 2"" >> out/output2.txt
          - echo ""Hello from 3"" >> out/output3.txt
          - echo ""Hello from 4"" >> out/output4.txt
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
      - id: out
        type: io.kestra.plugin.core.storage.LocalFiles
        outputs:
          - out/**
  - id: each
    type: io.kestra.plugin.core.flow.EachParallel
    value: ""{{outputs.out.uris | jq('.[]')}}""
    tasks:
      - id: path
        type: io.kestra.plugin.core.debug.Return
        format: ""{{taskrun.value}}""
      - id: contents
        type: io.kestra.plugin.scripts.shell.Commands
        commands:
          - cat ""{{taskrun.value}}""
        taskRunner:
          type: io.kestra.plugin.core.runner.Process
You can trigger it in a flow using the io.kestra.plugin.core.flow.Template task:
yaml
id: templatedFlow
namespace: company.team
tasks:
  - id: first
    type: io.kestra.plugin.core.log.Log
    message: first task
  - id: template
    type: io.kestra.plugin.core.flow.Template
    namespace: company.team
    templateId: mytemplate
  - id: last
    type: io.kestra.plugin.core.log.Log
    message: last task
This example shows that templates are quite restrictive ‚Äî you can only invoke them as-is. You cannot set custom input values, and there is no link from this flow to the template. In contrast, subflows can be parametrized, and you can navigate to the subflow in the topology view. From the 0.11.0 release, you can also expand and collapse a subflow (child flow) to inspect the available tasks directly from the parent flow.
Subflows ‚úÖ
To migrate from a template to a subflow, you can create a flow that is a 1:1 copy of your template. This flow can then be invoked as a subflow the same way you used to invoke a template (only using a different task).
In our example, we can create a new flow called mytemplate in a namespace dev. This flow will be invoked from a parent flow as a subflow.
Then, to create a child flow (a subflow), you only need to change the following values in the templatedFlow:
Change the io.kestra.plugin.core.flow.Template task type to io.kestra.plugin.core.flow.Subflow
Change the templateId to flowId.
See the example below showing how you can invoke a subflow from a parent flow:
yaml
id: parentFlow
namespace: company.team
tasks:
  - id: subflow
    type: io.kestra.plugin.core.flow.Subflow
    namespace: company.team
    flowId: mytemplate
And here is a complete example showing how a template task can be migrated to a subflow task:
yaml
id: parentFlow
namespace: company.team
tasks:
  - id: first
    type: io.kestra.plugin.core.log.Log
    message: first task
  - id: subflow
    type: io.kestra.plugin.core.flow.Subflow
    namespace: company.team
    flowId: mytemplate
  - id: last
    type: io.kestra.plugin.core.log.Log
    message: last task
If your subflow has input parameters and you want to override them when calling the subflow, you can configure them as follows:
yaml
id: parentFlow
namespace: company.team
tasks:
  - id: first
    type: io.kestra.plugin.core.log.Log
    message: first task
  - id: subflow
    type: io.kestra.plugin.core.flow.Subflow
    namespace: company.team
    flowId: mytemplate
    inputs:
      myIntegerParameter: 42
      myStringParameter: hello world!
  - id: last
    type: io.kestra.plugin.core.log.Log
    message: last task
Side-by-side comparison
You can look at both a flow with a template task and a flow with a subflow task side by side to see the difference in syntax:
If you still have questions about migrating from templates to subflows, reach out via our Community Slack.
Documentation of the deprecated feature
Templates are lists of tasks that can be shared between flows. You can define a template and call it from other flows, allowing them to share a list of tasks and keep these tasks updated without changing your flow.
All tasks in a template will be executed sequentially; you can provide the same tasks that are found in a standard flow, including an errors branch.
Templates can have arguments passed via the args property ‚Äî see the Template Task documentation.
Example
Below is a flow sample that will include a template:
yaml
id: with-template
namespace: company.team
inputs:
  - id: store
    type: STRING
    required: true
tasks:
  - id: render-template
    type: io.kestra.plugin.core.flow.Template
    namespace: company.team
    templateId: template-example
    args:
      renamedStore: ""{{ inputs.store }}""
If the template is defined like so:
yaml
id: template-example
namespace: company.team
tasks:
  - id: task-defined-by-template
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ parent.outputs.args.renamedStore }}""
It will result in a flow similar to the following:
yaml
id: with-template
namespace: company.team
tasks:
  - id: render-template
    type: io.kestra.plugin.core.flow.Sequential
    tasks:
      - id: task-defined-by-template
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ inputs.store }}""
All tasks from the template will be copied at runtime.
From the template, you can access all execution context variables. However, this is discouraged. The best is to use the args property to rename variables from the global context to the template's local one.
Templates UI
If enabled, you can inspect Templates on the Templates page.
A Template page allows to edit the template via a YAML editor.
Was this page helpful?
Yes
No
0.11.0
Script tasks moved to dedicated plugins
Migration Guide
0.12.0""""""",1709,7216,kestra
https://kestra.io/docs/migration-guide/0.12.0,"""""""DocsMigration Guide0.12.0
0.12.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.12.0
Deprecated features and migration guides for 0.12.0 and onwards.
Deprecation of Listeners
Listeners are deprecated and disabled by default starting from the 0.12.0 release. Please use Flow triggers instead.
Was this page helpful?
Yes
No
0.11.0
Deprecation of Templates
0.12.0
Deprecation of Listeners""""""",122,424,kestra
https://kestra.io/docs/migration-guide/0.12.0/listeners,"""""""DocsMigration Guide0.12.0Deprecation of Listeners
Deprecation of Listeners
Table of Contents
Why listeners are deprecated
Listeners ‚ö†Ô∏è
Flow trigger ‚úÖ
Side-by-side comparison
Documentation of the deprecated feature
Example listener
Properties
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.12.0
Listeners are deprecated and disabled by default starting from the 0.12.0 release. Please use Flow triggers instead.
Why listeners are deprecated
The listener is a redundant concept. Flow triggers allow you to do all that listeners can accomplish and more. The only difference between listeners and triggers is that listeners are defined inline within the same flow code and are, therefore, more tightly coupled with the flow. In contrast, a Flow trigger is defined in a separate independent flow that can simultaneously listen to the condition of multiple flows that satisfy specific conditions. This gives you more flexibility.
It is an extra concept that you, as a user, would need to learn even though you may not have to if you already know Flow triggers.
It's a hard-to-grasp concept ‚Äî listeners can launch tasks outside of the flow, i.e., tasks that will not be considered part of the flow but are defined within it. Additionally, the results of listeners will not change the execution status of the flow, so having them defined within the flow has caused some confusion in the past.
Currently, listeners are mainly used to send failure (or success) notifications, and Kestra already has two concepts allowing you to do that: triggers and errors. Having three choices for such a standard use case has led to confusion about when to use which of them.
If you are using listeners and you are not ready to migrate to Flow triggers yet, add the following Kestra configuration option to still be able to use listeners:
yaml
kestra:
  listeners:
    enabled: true
Then, make sure to also add the following plugin defaults to your configuration to ensure that your conditions are working properly after the upgrade to any version after 0.12.0:
yaml
kestra:
  tasks:
    defaults:
    - type: io.kestra.plugin.core.condition.DateTimeBetweenCondition
      values:
        date: ""{{ now() }}""
    - type: io.kestra.plugin.core.condition.DayWeekCondition
      values:
        date: ""{{ now(format=""iso_local_date"") }}""
    - type: io.kestra.plugin.core.condition.DayWeekInMonthCondition
      values:
        date: ""{{ now(format=""iso_local_date"") }}""
    - type: io.kestra.plugin.core.condition.TimeBetweenCondition
      values:
        date: ""{{ now(format='iso_offset_time') }}""
    - type: io.kestra.plugin.core.condition.WeekendCondition
      values:
        date: ""{{ now(format='iso_local_date') }}""
Due to listeners' deprecation, we changed the default behavior of various io.kestra.core.models.conditions-type conditions to use the {{trigger.date}} as default value for the date property instead of using ""{{ now(format='iso_local_date') }}"". To ensure that your conditions are working properly after the upgrade to any version after 0.12.0, you need to add the above plugin defaults to your Kestra configuration.
Listeners ‚ö†Ô∏è
Here is an example of a fairly typical listener used to implement error notifications:
yaml
id: alert_to_slack
namespace: prod.monitoring
tasks:
  - id: fail
    type: io.kestra.plugin.core.execution.Fail
listeners:
  - tasks:
      - id: slack
        type: io.kestra.plugin.notifications.slack.SlackExecution
        url: ""{{ secret('SLACK_WEBHOOK') }}""
        channel: ""#general""
        executionId: ""{{ execution.id }}""
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - FAILED
          - WARNING
This flow will fail and the listener tasks will be triggered anytime the flow reaches the specified execution status condition ‚Äî here, the FAILED status.
The next section shows how you can accomplish the same using Flow triggers.
Flow trigger ‚úÖ
To migrate from a listener to a Flow trigger, create a new flow. Add a trigger of type io.kestra.plugin.core.trigger.Flow and move the condition e.g. ExecutionStatusCondition to the trigger conditions. Finally, move the list of tasks from listeners to tasks in the flow.
The example below will explain it better than words:
yaml
id: alert_to_slack
namespace: prod.monitoring
tasks:
  - id: slack
    type: io.kestra.plugin.notifications.slack.SlackExecution
    url: ""{{ secret('SLACK_WEBHOOK') }}""
    channel: ""#general""
    executionId: ""{{trigger.executionId}}""
triggers:
  - id: execution_status_events
    type: io.kestra.plugin.core.trigger.Flow
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - FAILED
          - WARNING
      - type: io.kestra.plugin.core.condition.ExecutionFlowCondition
        namespace: prod
        flowId: demo
That flow trigger listens to the execution status of the following flow:
yaml
id: demo
namespace: prod
tasks:
  - id: fail
    type: io.kestra.plugin.core.execution.Fail
Anytime you execute that demo flow, the Slack notification will be sent, thanks to the Flow trigger. Additionally, the Dependencies tab of both flows will make it clear that they depend on each other.
Side-by-side comparison
You can look at both a flow with a listener and a flow with a Flow trigger side by side to see the syntax difference:
If you still have questions about migrating from listeners to flow triggers, reach out via our Community Slack.
Documentation of the deprecated feature
Listeners are special branches of a flow that can listen to the current flow and launch tasks outside the flow. The result of a listener's tasks will not change the execution status of a flow. The listener's tasks are run at the end of the flow.
Listeners are usually used to send notifications or handle special end-task behavior that should not be considered part of the main flow.
Example listener
A listener that sends a Slack notification for a failed task (this would require the Slack plugin).
yaml
listeners:
  - tasks:
      - id: sendSlackAlert
        type: io.kestra.plugin.notifications.slack.SlackExecution
        url: https://hooks.slack.com/services/XXX/YYY/ZZZ
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - FAILED
Properties
conditions
Type: array
SubType: Condition
Required: ‚ùå
A list of Conditions that must be validated in order to execute the listener tasks. If you don't provide any conditions, the listeners will always be executed.
tasks
Type: array
SubType: Task
Required: ‚ùå
A list of tasks that will be executed at the end of the flow. The status of these tasks will not impact the main execution and will not change the execution status even if they fail.
You can use every tasks you need here, even Flowable. All task id must be unique for the whole flow even for main tasks and errors.
description
Type: string
Required: ‚ùå
Description for documentation.
Was this page helpful?
Yes
No
Migration Guide
0.12.0
Migration Guide
0.13.0""""""",1547,7072,kestra
https://kestra.io/docs/migration-guide/0.13.0,"""""""DocsMigration Guide0.13.0
0.13.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.13.0
Deprecated features and migration guides for 0.13.0 and onwards.
Sync Users Access to a Default Tenant
Adjusting users' access to the default tenant.
Was this page helpful?
Yes
No
0.12.0
Deprecation of Listeners
0.13.0
Sync Users Access to a Default Tenant""""""",111,380,kestra
https://kestra.io/docs/migration-guide/0.13.0/default-tenant,"""""""DocsMigration Guide0.13.0Sync Users Access to a Default Tenant
Sync Users Access to a Default Tenant
Table of Contents
Overview
Migration
Summary
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Release:
0.13.0
Adjusting users' access to the default tenant.
Overview
In the v0.13.0 release, we introduced multitenancy. As a result, user's access is now managed at the tenant level.
Migration
After upgrading to v0.13.0, you will need to adjust your users' access to make it consistent with the new multitenancy model. To make this process easier, there is a new kestra-ee auths users sync-access command available in the Kestra CLI that allows you to automatically sync users' access to a default tenant.
Run the following command:
bash
kestra-ee auths users sync-access
Here is a detailed command usage for reference:
bash
Usage: kestra-ee auths users sync-access [-hVv] [--internal-log] [-c=<config>]
       [-l=<logLevel>] [-p=<pluginsPath>]
Sync users access with the default Tenant.
This command is designed to be used when enabling multi-tenancy on an existing
Kestra instance, in this case the existing user will need to have their access
synchronized if they need access to the default tenants (groups and roles will
be synchronized)
  -c, --config=<config>   Path to a configuration file
                            Default: /home/kestra/.kestra/config.yml
  -h, --help              Show this help message and exit.
      --internal-log      Change also log level for internal log
  -l, --log-level=<logLevel>
                          Change log level (values: TRACE, DEBUG, INFO, WARN,
                            ERROR)
                            Default: INFO
  -p, --plugins=<pluginsPath>
                          Path to plugins directory
                            Default: /app/plugins
  -v, --verbose           Change log level. Multiple -v options increase the
                            verbosity.
  -V, --version           Print version information and exit.
Summary
Running the kestra-ee auths users sync-access command will perform the necessary migration to make your users' access consistent with the new multitenancy model.
Was this page helpful?
Yes
No
Migration Guide
0.13.0
Migration Guide
0.14.0""""""",523,2288,kestra
https://kestra.io/docs/migration-guide/0.14.0,"""""""DocsMigration Guide0.14.0
0.14.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.14.0
Deprecated features and migration guides for 0.14.0 and onwards.
Change in managing Groups via the API
This change affects the way you manage groups via the API.
Recursive rendering of Pebble expressions
Since 0.14.0, kestra's templating engine has changed the default rendering behavior to not recursive.
Was this page helpful?
Yes
No
0.13.0
Sync Users Access to a Default Tenant
0.14.0
Change in managing Groups via the API""""""",145,549,kestra
https://kestra.io/docs/migration-guide/0.14.0/group-list,"""""""DocsMigration Guide0.14.0Change in managing Groups via the API
Change in managing Groups via the API
Table of Contents
Overview
Migration
Summary
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
Release:
0.14.0
This change affects the way you manage groups via the API.
Overview
In the v0.14.0 release, we've changed the structure of the Groups API to prevent duplicate groups from being created.
Before Kestra v0.14.0, you could create multiple groups with the same name. Since this can lead to confusion especially in a multitenant environment, we've decided to prevent this behavior.
Migration
The groups property has been renamed to groupList and the groupId now needs to be unique.
yaml
groupList:
  - groupId: yourGroupId
    membership: MEMBER
Note that if you use Kestra UI or manage users and groups via Terraform, you won't be affected by this change at all. This change only affects customers who manage groups programmatically via the API directly.
Summary
The main change is that you no longer can create multiple groups with the same name. If you try to edit a group of which name exists more than once, you will be prompted to rename the group to a unique name.
Was this page helpful?
Yes
No
Migration Guide
0.14.0
0.14.0
Recursive rendering of Pebble expressions""""""",310,1337,kestra
https://kestra.io/docs/migration-guide/0.14.0/recursive-rendering,"""""""DocsMigration Guide0.14.0Recursive rendering of Pebble expressions
Recursive rendering of Pebble expressions
Table of Contents
Why the change?
The new render() function
Migrating a 0.13.0 flow to the new rendering behavior in 0.14.0
How to keep the previous behavior
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.14.0
Since 0.14.0, kestra's templating engine has changed the default rendering behavior to not recursive.
Why the change?
Before the release 0.14, kestra's templating engine has been rendering all expressions recursively. While recursive rendering enabled many flexible usage patterns, it also opened up the door to some unintended behavior. For example, if you wanted to parse JSON elements of a webhook payload that contained a templated string from other applications (such as GitHub Actions or dbt core), the recursive rendering would attempt to parse those expressions, resulting in an error.
The release 0.14.0 has changed the default rendering behavior to not recursive and introduced a new render() function that gives you more control over which expressions should be rendered and how.
The new render() function
The syntax for the render() function is as follows:
yaml
{{ render(expression_string, recursive=true) }} # if false, render only once
Here is a simple usage example:
yaml
id: render_variables_recursively
namespace: company.team
variables:
  trigger_var: ""{{ trigger.date ?? execution.startDate | date('yyyy-MM-dd') }}""
tasks:
  - id: parse_date
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ render(vars.trigger_var) }}"" # this will print the recursively-rendered variable
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/1 * * * *""
Migrating a 0.13.0 flow to the new rendering behavior in 0.14.0
As you can see in the above example, simply wrapping the Pebble expression in the render() function will allow you to easily migrate your existing flows to the kestra version 0.14.0. However, if you have many flows that use the previous recursive rendering behavior, you may perform that migration later. We've added a boolean configuration variable called recursive-rendering that allows you to keep the previous recursive rendering behavior and gives you more time to migrate your flows.
How to keep the previous behavior
To keep the previous (recursive) behavior, add the following configuration:
yaml
kestra:
  variables:
    recursiveRendering: true # default: false
This is an instance-level configuration, so you don't need any changes in your code. We recommend that you migrate your flows to the new rendering behavior as soon as you can, as we believe this more explicit rendering behavior will be more intuitive and less error-prone in the long run.
Was this page helpful?
Yes
No
0.14.0
Change in managing Groups via the API
Migration Guide
0.15.0""""""",644,2884,kestra
https://kestra.io/docs/migration-guide/0.15.0,"""""""DocsMigration Guide0.15.0
0.15.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.15.0
Deprecated features and migration guides for 0.15.0 and onwards.
Inputs Name
The name property of inputs are deprecated in favor of id for consistency with the rest of the flow configuration.
Migration to Micronaut 4.3
Kestra 0.15.0 has been migrated to Micronaut 4.3 for improved security. This page explains how to make your custom plugins compatible with this new version.
Schedule Conditions
The scheduleConditions property of Schedule trigger is deprecated. Instead, use conditions to define custom scheduling conditions.
Subflow outputs behavior
The outputs property of a parent flow's Subflow task is deprecated. Instead, use flow outputs to pass data between flows.
Was this page helpful?
Yes
No
0.14.0
Recursive rendering of Pebble expressions
0.15.0
Inputs Name""""""",214,895,kestra
https://kestra.io/docs/migration-guide/0.15.0/inputs-name,"""""""DocsMigration Guide0.15.0Inputs Name
Inputs Name
Table of Contents
Before Kestra 0.15.0
After Kestra 0.15.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.15.0
The name property of inputs are deprecated in favor of id for consistency with the rest of the flow configuration.
Note that the change has been implemented in a non-breaking way, so you don't need to immediately change your existing flows in order to successfully migrate to 0.15.0. However, we recommend using the id property at least for new flows. The name property will be removed in the future.
All you need to do is to rename the name to id in your flow configuration ‚Äî no other changes are required.
Before Kestra 0.15.0
To make the change clear, here is how inputs were defined before Kestra 0.15.0:
yaml
id: myflow
namespace: company.team
inputs:
  - name: beverage
    type: STRING
    defaults: coffee
  - name: quantity
    type: INTEGER
    defaults: 1
After Kestra 0.15.0
Here is how inputs are defined after Kestra 0.15.0:
yaml
id: myflow
namespace: company.team
inputs:
  - id: beverage
    type: STRING
    defaults: coffee
  - id: quantity
    type: INTEGER
    defaults: 1
Was this page helpful?
Yes
No
Migration Guide
0.15.0
0.15.0
Migration to Micronaut 4.3""""""",362,1278,kestra
https://kestra.io/docs/migration-guide/0.15.0/micronaut4,"""""""DocsMigration Guide0.15.0Migration to Micronaut 4.3
Migration to Micronaut 4.3
Table of Contents
Micronaut 4 and Project Reactor
Jakarta migration
Project Reactor migration
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.15.0
Kestra 0.15.0 has been migrated to Micronaut 4.3 for improved security. This page explains how to make your custom plugins compatible with this new version.
Micronaut 4 and Project Reactor
Custom plugins need to be migrated to Micronaut 4.3 in order to be compatible with Kestra 0.15.0 and later.
Make sure to upgrade your gradle.properties to the following library versions:
properties
version=0.15.0-SNAPSHOT
kestraVersion=[0.15,)
micronautVersion=4.3.0
lombokVersion=1.18.30
In gradle.build, update the dependencies as follows:
groovy
dependencies {
    // lombok
    annotationProcessor ""org.projectlombok:lombok:$lombokVersion""
    compileOnly ""org.projectlombok:lombok:$lombokVersion""
    // micronaut
    annotationProcessor platform(""io.micronaut.platform:micronaut-platform:$micronautVersion"")
    annotationProcessor ""io.micronaut:micronaut-inject-java""
    annotationProcessor ""io.micronaut.validation:micronaut-validation-processor""
    compileOnly platform(""io.micronaut.platform:micronaut-platform:$micronautVersion"")
    compileOnly ""io.micronaut:micronaut-inject""
    compileOnly ""io.micronaut.validation:micronaut-validation""
    // kestra
    compileOnly group: ""io.kestra"", name: ""core"", version: kestraVersion
    // other libs go here
}
Note that some libraries are no longer included by default in Micronaut 4.3. For instance:
if you use Jackson in your custom plugin, you need to add compileOnly ""io.micronaut:micronaut-jackson-databind""
if you use the HTTP client, you need to add compileOnly ""io.micronaut:micronaut-http-client"".
Make sure to remove the following Gradle configuration, as Kestra now uses SLF4J 2:
groovy
configurations.all {
    resolutionStrategy {
        force(""org.slf4j:slf4j-api:1.7.36"")
    }
}
Test dependencies require an adjustment as well:
groovy
dependencies {
    // lombok
    testAnnotationProcessor ""org.projectlombok:lombok:"" + lombokVersion
    testCompileOnly 'org.projectlombok:lombok:' + lombokVersion
    // micronaut
    testAnnotationProcessor platform(""io.micronaut.platform:micronaut-platform:$micronautVersion"")
    testAnnotationProcessor ""io.micronaut:micronaut-inject-java""
    testAnnotationProcessor ""io.micronaut.validation:micronaut-validation-processor""
    testImplementation platform(""io.micronaut.platform:micronaut-platform:$micronautVersion"")
    testImplementation ""io.micronaut.test:micronaut-test-junit5""
    // test deps needed only for to have a runner
    testImplementation group: ""io.kestra"", name: ""core"", version: kestraVersion
    testImplementation group: ""io.kestra"", name: ""repository-memory"", version: kestraVersion
    testImplementation group: ""io.kestra"", name: ""runner-memory"", version: kestraVersion
    testImplementation group: ""io.kestra"", name: ""storage-local"", version: kestraVersion
    // test
    testImplementation ""org.junit.jupiter:junit-jupiter-engine""
    testImplementation ""org.hamcrest:hamcrest:2.2""
    testImplementation ""org.hamcrest:hamcrest-library:2.2""
}
Jakarta migration
Make sure to adjust the imports from javax.* to jakarta.* ‚Äî this is due to the migration from Java EE to Jakarta EE.
Some IDEs do this automatically. For example, IntelliJ has a command Refactor -> Migrate Packages and Classes -> Java EE to Jakarta EE). Alternatively, you can use the OpenRewrite project.
Project Reactor migration
Our reactive stack has been migrated from the deprecated RxJava 2 to the Project Reactor.
If your plugin uses RxJava, make sure to migrate it to the Project Reactor.
Replace the library io.micronaut.rxjava2:micronaut-rxjava2 by io.micronaut.reactor:micronaut-reactor.
Then, update your code to use the Project Reactor types:
Flux (instead of Flowable)
Mono (instead of Single).
Lastly, if you were using the reactive HTTP client, make sure to replace the io.micronaut.rxjava2:micronaut-rxjava2-http-client by io.micronaut.reactor:micronaut-reactor-http-client.
Was this page helpful?
Yes
No
0.15.0
Inputs Name
0.15.0
Schedule Conditions""""""",1104,4229,kestra
https://kestra.io/docs/migration-guide/0.15.0/schedule-conditions,"""""""DocsMigration Guide0.15.0Schedule Conditions
Schedule Conditions
Table of Contents
Behavior before Kestra 0.15.0
Behavior after Kestra 0.15.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.15.0
The scheduleConditions property of Schedule trigger is deprecated. Instead, use conditions to define custom scheduling conditions.
This change is implemented in a non-breaking way, so you don't need to immediately change your existing flows in order to successfully migrate to 0.15.0. However, we recommend using the conditions property at least for new flows. The scheduleConditions property will be removed in the future.
All you need to do is to rename scheduleConditions to conditions in your flow configuration ‚Äî no other changes are required.
Behavior before Kestra 0.15.0
To make the change clear, here is how scheduling conditions were defined before Kestra 0.15.0:
yaml
id: beverage_order
namespace: company.team
inputs:
  - name: beverage
    type: STRING
    defaults: coffee
tasks:
  - id: order_beverage
    type: io.kestra.plugin.core.http.Request
    uri: https://reqres.in/api/products
    method: POST
    contentType: application/json
    formData:
      beverage: ""{{inputs.beverage}}""
  - id: set_labels
    type: io.kestra.plugin.core.execution.Labels
    labels:
      date: ""{{trigger.date ?? execution.startDate | date('yyyy-MM-dd')}}""
      beverage: ""{{inputs.beverage}}""
triggers:
  - id: workday
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 9 * * *""
    scheduleConditions:
      - type: io.kestra.plugin.core.condition.NotCondition
        conditions:
          - type: io.kestra.plugin.core.condition.WeekendCondition
  - id: weekend
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 20 * * *""
    scheduleConditions:
      - type: io.kestra.plugin.core.condition.WeekendCondition
    inputs:
      beverage: beer
The above flow has two triggers, workday and weekend.
The workday trigger is scheduled to run on workdays to order a coffee at 9 am.
The weekend trigger is scheduled to run on weekends to order a beer at 8 pm.
Behavior after Kestra 0.15.0
Here is the same flow with the scheduleConditions property replaced by conditions:
yaml
id: beverage_order
namespace: company.team
inputs:
  - id: beverage
    type: STRING
    defaults: coffee
tasks:
  - id: order_beverage
    type: io.kestra.plugin.core.http.Request
    uri: https://reqres.in/api/products
    method: POST
    contentType: application/json
    formData:
      beverage: ""{{inputs.beverage}}""
  - id: set_labels
    type: io.kestra.plugin.core.execution.Labels
    labels:
      date: ""{{trigger.date ?? execution.startDate | date('yyyy-MM-dd')}}""
      beverage: ""{{inputs.beverage}}""
triggers:
  - id: workday
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 9 * * *""
    conditions:
      - type: io.kestra.plugin.core.condition.NotCondition
        conditions:
          - type: io.kestra.plugin.core.condition.WeekendCondition
  - id: weekend
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""0 20 * * *""
    conditions:
      - type: io.kestra.plugin.core.condition.WeekendCondition
    inputs:
      beverage: beer
Was this page helpful?
Yes
No
0.15.0
Migration to Micronaut 4.3
0.15.0
Subflow outputs behavior""""""",829,3304,kestra
https://kestra.io/docs/migration-guide/0.15.0/subflow-outputs,"""""""DocsMigration Guide0.15.0Subflow outputs behavior
Subflow outputs behavior
Table of Contents
Subflow outputs behavior before Kestra 0.15.0
Example
How to keep the old subflow outputs behavior
Improved subflow outputs in Kestra 0.15.0
Why the change?
Benefits of the new subflow outputs
How to use the new subflow outputs
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.15.0
The outputs property of a parent flow's Subflow task is deprecated. Instead, use flow outputs to pass data between flows.
Subflow outputs behavior before Kestra 0.15.0
If you are on Kestra 0.14.4 or earlier, passing data between subflows required using the outputs property within the parent flow's Subflow task.
Example
Let's say you have a following subflow (aka child flow) with a task mytask generating an output called value:
yaml
id: flow_outputs
namespace: company.team
tasks:
  - id: mytask
    type: io.kestra.plugin.core.debug.Return
    format: this is a task output used as a final flow output
To access this output in a different task within the same flow, you would use the syntax {{outputs.mytask.value}}. However, if you want to access this output in a parent flow, you would need to define the output in the outputs property within the parent flow's Subflow task as follows:
yaml
id: parent_flow
namespace: company.team
tasks:
  - id: subflow
    type: io.kestra.plugin.core.flow.Subflow
    flowId: flow_outputs
    namespace: company.team
    wait: true
    outputs: # üö® this property is deprecated in Kestra 0.15.0
      final: ""{{ outputs.mytask.value }}""
  - id: log
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.subflow.outputs.final }}""
You can see that the outputs property is used to define the output of the subflow and stored in the variable named final (the name of the keys are arbitrary). This approach is not ideal, as you need to know the internals of the subflow to access its outputs. Also, it's not clear to the consumer what type of data is being passed. This is why this property is deprecated in Kestra 0.15.0.
How to keep the old subflow outputs behavior
Before looking at how the same is achieved in Kestra 0.15.0, let's look at how you can keep this behavior if you are not ready to migrate to the new subflow outputs behavior.
To keep the old behavior with the outputs property, you can set the following configuration in your application.yml:
yaml
kestra:
  plugins:
    configurations:
      - type: io.kestra.plugin.core.flow.Subflow
        values:
          outputs:
            enabled: true # for backward-compatibility -- false by default
      - type: io.kestra.plugin.core.flow.Flow
        values:
          outputs:
            enabled: true # for backward-compatibility -- false by default
Once the outputs configuration is set to enabled: true, you can use the old behavior of defining outputs within the Subflow or Flow task in the parent flow.
Improved subflow outputs in Kestra 0.15.0
Why the change?
Kestra 0.15.0 introduced a concept of flow-level outputs to make it easier to pass data between flows. Until now, the parent flow had to know the internals of the subflow to access its outputs. This introduced a tight coupling as the parent flow was dependent on the subflow's internal logic, which can change over time, potentially breaking the parent flow. Also, it was exposing all outputs from child flows (producers) to all parent flows (consumers), which is not always desirable. Often you don't want to expose all outputs of a subflow to the parent flow.
Benefits of the new subflow outputs
Now, you have more control over what subflow outputs do you want to expose to other flows. The parent flow does not need to know the internals of the child flow ‚Äî it can simply access the subflow outputs by key. This more decoupled approach means that the parent flow is less dependent on the subflow, and the subflow can change its implementation without breaking the parent flow.
You can think of flow outputs as data contracts between flows. The subflow defines what data it produces, and the parent flow defines what data it consumes. This makes it easier to understand the dataflow between workflows and improves maintainability of both flows over time.
How to use the new subflow outputs
Since 0.15.0, the flow can produce outputs simply by defining them in the flow file. Here is an example of a flow that produces an output:
yaml
id: flow_outputs
namespace: company.team
tasks:
  - id: mytask
    type: io.kestra.plugin.core.debug.Return
    format: this is a task output used as a final flow output
outputs:
  - id: final
    type: STRING
    value: ""{{ outputs.mytask.value }}""
You can see that outputs are defined as a list of key-value pairs. The id is the name of the output attribute (which must be unique within a flow), and the value is the value of the output. The type lets you define the expected type of the output. You can also add a description to the output.
You will see the output of the flow on the Executions page in the Overview tab.
Here is how you can access the flow output in the parent flow:
yaml
id: parent_flow
namespace: company.team
tasks:
  - id: subflow
    type: io.kestra.plugin.core.flow.Subflow
    flowId: flow_outputs
    namespace: company.team
    wait: true
  - id: log_subflow_output
    type: io.kestra.plugin.core.log.Log
    message: ""{{ outputs.subflow.outputs.final }}""
In the example above, the subflow task produces an output attribute final. This output attribute is then used in the log_subflow_output task.
Note how the outputs are set twice within the ""{{outputs.subflow.outputs.final}}"":
once to access outputs of the subflow task
once to access the outputs of the subflow itself ‚Äî specifically, the final output.
Here is what you will see in the Outputs tab of the Executions page in the parent flow:
Was this page helpful?
Yes
No
0.15.0
Schedule Conditions
Migration Guide
0.17.0""""""",1395,5932,kestra
https://kestra.io/docs/migration-guide/0.17.0,"""""""DocsMigration Guide0.17.0
0.17.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.17.0
Deprecated features and migration guides for 0.17.0 and onwards.
Deprecation of LocalFiles and outputDir
Migrate from LocalFiles and outputDir to inputFiles and outputFiles.
Plugin Discovery Mechanism
Kestra 0.17.0 uses a new mechanism to discover and load plugins. If you use custom plugins, follow this guide to make the necessary adjustments.
Renamed Plugins
Many core plugins have been renamed in Kestra 0.17.0, and taskDefaults are now pluginDefaults. While these are non-breaking changes, we recommend updating your flows to use the new names.
Volume Mount
How to migrate volume-enabled to the plugin configuration.
Was this page helpful?
Yes
No
0.15.0
Subflow outputs behavior
0.17.0
Deprecation of LocalFiles and outputDir""""""",217,854,kestra
https://kestra.io/docs/migration-guide/0.17.0/local-files,"""""""DocsMigration Guide0.17.0Deprecation of LocalFiles and outputDir
Deprecation of LocalFiles and outputDir
Table of Contents
Overview
Examples
outputDir
LocalFiles
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.17.0
Migrate from LocalFiles and outputDir to inputFiles and outputFiles.
Overview
The LocalFiles and outputDir are deprecated due to overlapping functionality that already exists using inputFiles and outputFiles on the WorkingDirectory and script tasks.
outputDir: the {{ outputDir }} expression has been deprecated due to overlapping functionality available through the outputFiles property which is more flexible.
LocalFiles: the LocalFiles feature was initially introduced to allow injecting additional files into the script task's WorkingDirectory. However, this feature was confusing as there is nothing local about these files, and with the introduction of inputFiles to the WorkingDirectory, it became redundant. We recommend using the inputFiles property instead of LocalFiles to inject files into the script task's WorkingDirectory. The example below demonstrates how to do that:
yaml
id: apiJSONtoMongoDB
namespace: company.team
tasks:
  - id: inlineScript
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: python:3.11-slim
    beforeCommands:
      - pip install requests kestra > /dev/null
    warningOnStdErr: false
    outputFiles:
      - output.json
    inputFiles:
      query.sql: |
        SELECT sum(total) as total, avg(quantity) as avg_quantity
        FROM sales;
    script: |
      import requests
      import json
      from kestra import Kestra
      with open('query.sql', 'r') as input_file:
          sql = input_file.read()
      response = requests.get('https://api.github.com')
      data = response.json()
      with open('output.json', 'w') as output_file:
          json.dump(data, output_file)
      Kestra.outputs({'receivedSQL': sql, 'status': response.status_code})
  - id: loadToMongoDB
    type: io.kestra.plugin.mongodb.Load
    connection:
      uri: mongodb://host.docker.internal:27017/
    database: local
    collection: github
    from: ""{{ outputs.inlineScript.outputFiles['output.json'] }}""
Examples
To help you migrate your flows, here's a few examples of how you might update your flow to use the new format in 0.17.0.
outputDir
Before
Previously, you would specify {{ outputDir }} as you save the file.
yaml
id: getting_started_output
namespace: company.team
inputs:
  - id: api_url
    type: STRING
    defaults: https://dummyjson.com/products
tasks:
  - id: api
    type: io.kestra.plugin.fs.http.Request
    uri: ""{{ inputs.api_url }}""
  - id: python
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:slim
    beforeCommands:
      - pip install polars
    warningOnStdErr: false
    script: |
      import polars as pl
      data = {{outputs.api.body | jq('.products') | first}}
      df = pl.from_dicts(data)
      df.glimpse()
      df.select([""brand"", ""price""]).write_csv(""{{outputDir}}/products.csv"")
After
Now you can remove this, and just specify the file name in the outputFiles properties.
yaml
id: getting_started_output
namespace: company.team
inputs:
  - id: api_url
    type: STRING
    defaults: https://dummyjson.com/products
tasks:
  - id: api
    type: io.kestra.plugin.fs.http.Request
    uri: ""{{ inputs.api_url }}""
  - id: python
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:slim
    beforeCommands:
      - pip install polars
    warningOnStdErr: false
    outputFiles:
      - ""products.csv""
    script: |
      import polars as pl
      data = {{outputs.api.body | jq('.products') | first}}
      df = pl.from_dicts(data)
      df.glimpse()
      df.select([""brand"", ""price""]).write_csv(""products.csv"")
LocalFiles
Before
Previously, you would add a separate LocalFiles task inside of the WorkingDirectory task to specify your inputs for later tasks.
yaml
id: pip
namespace: company.team
tasks:
  - id: wdir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
    - id: pip
      type: io.kestra.plugin.core.storage.LocalFiles
      inputs:
        requirements.txt: |
          kestra>=0.6.0
          pandas>=1.3.5
          requests>=2.31.0
    - id: pythonScript
      type: io.kestra.plugin.scripts.python.Script
      docker:
        image: python:3.11-slim
      beforeCommands:
        - pip install -r requirements.txt > /dev/null
      warningOnStdErr: false
      script: |
        import requests
        import kestra
        import pandas as pd
        print(f""requests version: {requests.__version__}"")
        print(f""pandas version: {pd.__version__}"")
        methods = [i for i in dir(kestra.Kestra) if not i.startswith(""_"")]
        print(f""Kestra methods: {methods}"")
After
In 0.17.0, you can specify your input files by using the inputFiles property from the WorkingDirectory task, removing the need for the LocalFiles task all together.
yaml
id: pip
namespace: company.team
tasks:
  - id: wdir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    inputFiles:
      requirements.txt: |
          kestra>=0.6.0
          pandas>=1.3.5
          requests>=2.31.0
    tasks:
    - id: pythonScript
      type: io.kestra.plugin.scripts.python.Script
      containerImage: python:3.11-slim
      beforeCommands:
        - pip install -r requirements.txt > /dev/null
      warningOnStdErr: false
      script: |
        import requests
        import kestra
        import pandas as pd
        print(f""requests version: {requests.__version__}"")
        print(f""pandas version: {pd.__version__}"")
        methods = [i for i in dir(kestra.Kestra) if not i.startswith(""_"")]
        print(f""Kestra methods: {methods}"")
Was this page helpful?
Yes
No
Migration Guide
0.17.0
0.17.0
Plugin Discovery Mechanism""""""",1469,5918,kestra
https://kestra.io/docs/migration-guide/0.17.0/plugin-discovery-mechanism,"""""""DocsMigration Guide0.17.0Plugin Discovery Mechanism
Plugin Discovery Mechanism
Table of Contents
Why the Change?
Micronaut Dependencies
Kestra's Annotation Processor
Custom Validators
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.17.0
Kestra 0.17.0 uses a new mechanism to discover and load plugins. If you use custom plugins, follow this guide to make the necessary adjustments.
Plugins are now discovered and loaded using the standard Java Service Loader.
Why the Change?
So far, Kestra heavily relied on the Bean Introspection mechanism provided by the Micronaut Framework for loading plugins (Micronaut is the JVM-based API framework used by Kestra).
However, we have repeatedly encountered some limitations in maintaining the backward compatibility of plugins during major version upgrades of Micronaut. In addition, this implementation was limiting our ability to introduce future enhancements around the plugin mechanism.
Thanks to this new implementation, we reduced the number of dependencies required for developing custom plugins, and these plugins now load twice as fast as before.
Finally, this change is part of a wider effort to improve the developer experience around plugins, and to reduce Micronaut's exposure outside the Kestra core.
Unfortunately, we've had to introduce some minor breaking-changes to the way custom plugins should be built.
Below are the changes required to migrate to Kestra 0.17.0.
Micronaut Dependencies
For most plugin implementations, all Micronaut libs can be removed from the compileOnly dependencies in the build.gradle file.
However, Micronaut is still required to use the utility classes provided by Kestra for running unit-tests.
Kestra's Annotation Processor
Kestra requires a new annotation processor to be configured in the build.gradle file of your project (or pom.xml for Maven).
annotationProcessor group: ""io.kestra"", name: ""processor"", version: kestraVersion
The role of this processor is to automatically manage the META-INF/services file needed by Java to discover your plugins.
Custom Validators
Kestra allows you to develop a custom constraint validator using the standard Java API for bean validation (i.e., JSR-380), which is used to validate the properties of custom tasks.
The custom validator must now implement the standard jakarta.validation.ConstraintValidator instead of the interface provided by Micronaut: io.micronaut.validation.validator.constraints.ConstraintValidator.
In addition, custom validation annotation should now strictly adhere to the Java bean specification ‚Äî see the example below.
Kestra 0.16.6 and before:
java
// file: io.kestra.plugins.custom.CustomNotEmpty.java
@Retention(RetentionPolicy.RUNTIME)
@Constraint(validatedBy = CustomNotEmptyValidator.class)
public @interface CustomNotEmpty {
    String message() default ""invalid"";
}
java
// file: io.kestra.plugins.custom.CustomNotEmptyValidator.java
import io.micronaut.validation.validator.constraints.ConstraintValidator;
import io.micronaut.validation.validator.constraints.ConstraintValidatorContext;
// ...
@Singleton
@Introspected
public class CustomNotEmptyValidator implements ConstraintValidator<CustomNotEmpty, String> {
    @Override
    public boolean isValid(
        @Nullable String value,
        @NonNull AnnotationValue<CustomNotEmpty> annotationMetadata,
        @NonNull ConstraintValidatorContext context) {
        if (value == null) {
            return true; // nulls are allowed according to spec
        } else if (value.size() < 2) {
            context.messageTemplate(""string must have at-least two characters"");
            return false;
        } else {
            return true;
        }
    }
}
Kestra 0.17.0 and later:
java
// file: io.kestra.plugins.custom.CustomNotEmpty.java
@Retention(RetentionPolicy.RUNTIME)
@Constraint(validatedBy = CustomNotEmptyValidator.class)
public @interface CustomNotEmpty {
    String message() default ""invalid"";
    Class<?>[] groups() default {};
    Class<? extends Payload>[] payload() default {};
}
java
// file: io.kestra.plugins.custom.CustomNotEmptyValidator.java
import jakarta.validation.ConstraintValidator;
import jakarta.validation.ConstraintValidatorContext;
// ...
@Singleton
@Introspected
public class CustomNotEmptyValidator implements ConstraintValidator<CustomNotEmpty, String> {
    @Override
    public boolean isValid(String value, ConstraintValidatorContext context) {
        if (value == null) {
            return true; // nulls are allowed according to spec
        } else if (value.size() < 2) {
            context.disableDefaultConstraintViolation();
            context
                .buildConstraintViolationWithTemplate(""string must have at-least two characters"")
                .addConstraintViolation();
            context.messageTemplate();
            return false;
        } else {
            return true;
        }
    }
}
Was this page helpful?
Yes
No
0.17.0
Deprecation of LocalFiles and outputDir
0.17.0
Renamed Plugins""""""",1027,5016,kestra
https://kestra.io/docs/migration-guide/0.17.0/renamed-plugins,"""""""DocsMigration Guide0.17.0Renamed Plugins
Renamed Plugins
Table of Contents
Why the Change?
Renamed Core Plugins
Renamed Serdes Plugins
Renamed Task Runners
Renamed Redis Triggers and Tasks
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.17.0
Many core plugins have been renamed in Kestra 0.17.0, and taskDefaults are now pluginDefaults. While these are non-breaking changes, we recommend updating your flows to use the new names.
Why the Change?
Multiple plugin types have been moved to a new package structure under io.kestra.plugin.core to make the plugin system more consistent and intuitive.
We've also renamed taskDefaults to pluginDefaults to highlight that you can set default values for all plugins (including triggers, task runners and more), not just tasks.
All of these are non-breaking changes as we leverage aliases for backward compatibility. You will see a friendly warning in the UI code editor if you use the old names.
It's worth taking a couple of minutes to rename those in your flows to future-proof your code.
Renamed Core Plugins
Here is the schema showing how the core abstractions have been renamed:
io.kestra.core.models.conditions.types.* ‚Üí io.kestra.plugin.core.condition.*
io.kestra.core.models.triggers.types.* ‚Üí io.kestra.plugin.core.trigger.*
io.kestra.core.models.tasks.runners.types.* ‚Üí io.kestra.plugin.core.runner.*
io.kestra.core.tasks.storages.* ‚Üí io.kestra.plugin.core.storage.*
io.kestra.core.tasks.*.* ‚Üí io.kestra.plugin.core.*.*
io.kestra.plugin.fs.http.* ‚Üí io.kestra.plugin.core.http.*
Below you can see the full list of renamed plugins:
Old Name Before Kestra 0.17.0 New Name After Kestra 0.17.0
io.kestra.core.models.conditions.types.DateTimeBetweenCondition io.kestra.plugin.core.condition.DateTimeBetweenCondition
io.kestra.core.models.conditions.types.DayWeekCondition io.kestra.plugin.core.condition.DayWeekCondition
io.kestra.core.models.conditions.types.DayWeekInMonthCondition io.kestra.plugin.core.condition.DayWeekInMonthCondition
io.kestra.core.models.conditions.types.ExecutionFlowCondition io.kestra.plugin.core.condition.ExecutionFlowCondition
io.kestra.core.models.conditions.types.ExecutionLabelsCondition io.kestra.plugin.core.condition.ExecutionLabelsCondition
io.kestra.core.models.conditions.types.ExecutionNamespaceCondition io.kestra.plugin.core.condition.ExecutionNamespaceCondition
io.kestra.core.models.conditions.types.ExecutionStatusCondition io.kestra.plugin.core.condition.ExecutionStatusCondition
io.kestra.core.models.conditions.types.FlowCondition io.kestra.plugin.core.condition.FlowCondition
io.kestra.core.models.conditions.types.FlowNamespaceCondition io.kestra.plugin.core.condition.FlowNamespaceCondition
io.kestra.core.models.conditions.types.HasRetryAttemptCondition io.kestra.plugin.core.condition.HasRetryAttemptCondition
io.kestra.core.models.conditions.types.MultipleCondition io.kestra.plugin.core.condition.MultipleCondition
io.kestra.core.models.conditions.types.NotCondition io.kestra.plugin.core.condition.NotCondition
io.kestra.core.models.conditions.types.OrCondition io.kestra.plugin.core.condition.OrCondition
io.kestra.core.models.conditions.types.PublicHolidayCondition io.kestra.plugin.core.condition.PublicHolidayCondition
io.kestra.core.models.conditions.types.TimeBetweenCondition io.kestra.plugin.core.condition.TimeBetweenCondition
io.kestra.core.models.conditions.types.VariableCondition io.kestra.plugin.core.condition.ExpressionCondition
io.kestra.core.models.conditions.types.WeekendCondition io.kestra.plugin.core.condition.WeekendCondition
io.kestra.core.models.tasks.runners.types.ProcessTaskRunner io.kestra.plugin.core.runner.Process
io.kestra.core.models.triggers.types.Flow io.kestra.plugin.core.trigger.Flow
io.kestra.core.models.triggers.types.Schedule io.kestra.plugin.core.trigger.Schedule
io.kestra.core.models.triggers.types.Webhook io.kestra.plugin.core.trigger.Webhook
io.kestra.core.tasks.debugs.Echo io.kestra.plugin.core.debug.Echo
io.kestra.core.tasks.debugs.Return io.kestra.plugin.core.debug.Return
io.kestra.core.tasks.executions.Counts io.kestra.plugin.core.execution.Count
io.kestra.core.tasks.executions.Fail io.kestra.plugin.core.execution.Fail
io.kestra.core.tasks.executions.Labels io.kestra.plugin.core.execution.Labels
io.kestra.core.tasks.flows.AllowFailure io.kestra.plugin.core.flow.AllowFailure
io.kestra.core.tasks.flows.Dag io.kestra.plugin.core.flow.Dag
io.kestra.core.tasks.flows.EachParallel io.kestra.plugin.core.flow.EachParallel
io.kestra.core.tasks.flows.EachSequential io.kestra.plugin.core.flow.EachSequential
io.kestra.core.tasks.flows.Flow io.kestra.plugin.core.flow.Flow
io.kestra.core.tasks.flows.ForEachItem io.kestra.plugin.core.flow.ForEachItem
io.kestra.core.tasks.flows.If io.kestra.plugin.core.flow.If
io.kestra.core.tasks.flows.Parallel io.kestra.plugin.core.flow.Parallel
io.kestra.core.tasks.flows.Pause io.kestra.plugin.core.flow.Pause
io.kestra.core.tasks.flows.Sequential io.kestra.plugin.core.flow.Sequential
io.kestra.core.tasks.flows.Subflow io.kestra.plugin.core.flow.Subflow
io.kestra.core.tasks.flows.Switch io.kestra.plugin.core.flow.Switch
io.kestra.core.tasks.flows.Template io.kestra.plugin.core.flow.Template
io.kestra.core.tasks.flows.WorkingDirectory io.kestra.plugin.core.flow.WorkingDirectory
io.kestra.core.tasks.log.Fetch io.kestra.plugin.core.log.Fetch
io.kestra.core.tasks.log.Log io.kestra.plugin.core.log.Log
io.kestra.core.tasks.states.Delete io.kestra.plugin.core.state.Delete
io.kestra.core.tasks.states.Get io.kestra.plugin.core.state.Get
io.kestra.core.tasks.states.Set io.kestra.plugin.core.state.Set
io.kestra.core.tasks.storages.Concat io.kestra.plugin.core.storage.Concat
io.kestra.core.tasks.storages.DeduplicateItems io.kestra.plugin.core.storage.DeduplicateItems
io.kestra.core.tasks.storages.Delete io.kestra.plugin.core.storage.Delete
io.kestra.core.tasks.storages.FilterItems io.kestra.plugin.core.storage.FilterItems
io.kestra.core.tasks.storages.LocalFiles io.kestra.plugin.core.storage.LocalFiles
io.kestra.core.tasks.storages.Purge io.kestra.plugin.core.storage.Purge
io.kestra.core.tasks.storages.PurgeExecution io.kestra.plugin.core.storage.PurgeExecution
io.kestra.core.tasks.storages.Reverse io.kestra.plugin.core.storage.Reverse
io.kestra.core.tasks.storages.Size io.kestra.plugin.core.storage.Size
io.kestra.core.tasks.storages.Split io.kestra.plugin.core.storage.Split
io.kestra.core.tasks.templating.TemplatedTask io.kestra.plugin.core.templating.TemplatedTask
io.kestra.core.tasks.trigger.Toggle io.kestra.plugin.core.trigger.Toggle
io.kestra.plugin.fs.http.Download io.kestra.plugin.core.http.Download
io.kestra.plugin.fs.http.Request io.kestra.plugin.core.http.Request
io.kestra.plugin.fs.http.Trigger io.kestra.plugin.core.http.Trigger
Renamed Serdes Plugins
We've also renamed serialization tasks from Readers and Writers to explicit conversion tasks to make it more explicit that these tasks are intended to either convert from or to Ion ‚Äî the primary data format used in Kestra to serialize data between tasks and storage systems. For example, CsvReader is now CsvToIon and the CsvWriter is now IonToCsv.
A full list of the renamed serialization tasks:
CsvReader ‚Üí CsvToIon
CsvWriter ‚Üí IonToCsv
JsonReader ‚Üí JsonToIon
JsonWriter ‚Üí IonToJson
AvroReader ‚Üí AvroToIon
AvroWriter ‚Üí IonToAvro
XmlReader ‚Üí XmlToIon
XmlWriter ‚Üí IonToXml
ParquetReader ‚Üí ParquetToIon
ParquetWriter ‚Üí IonToParquet
The table shows full paths of the renamed serialization tasks:
Old Path Before Kestra 0.17.0 New Path After Kestra 0.17.0
io.kestra.plugin.serdes.csv.CsvReader io.kestra.plugin.serdes.csv.CsvToIon
io.kestra.plugin.serdes.csv.CsvWriter io.kestra.plugin.serdes.csv.IonToCsv
io.kestra.plugin.serdes.json.JsonReader io.kestra.plugin.serdes.json.JsonToIon
io.kestra.plugin.serdes.json.JsonWriter io.kestra.plugin.serdes.json.IonToJson
io.kestra.plugin.serdes.avro.AvroReader io.kestra.plugin.serdes.avro.AvroToIon
io.kestra.plugin.serdes.avro.AvroWriter io.kestra.plugin.serdes.avro.IonToAvro
io.kestra.plugin.serdes.xml.XmlReader io.kestra.plugin.serdes.xml.XmlToIon
io.kestra.plugin.serdes.xml.XmlWriter io.kestra.plugin.serdes.xml.IonToXml
io.kestra.plugin.serdes.parquet.ParquetReader io.kestra.plugin.serdes.parquet.ParquetToIon
io.kestra.plugin.serdes.parquet.ParquetWriter io.kestra.plugin.serdes.parquet.IonToParquet
Renamed Task Runners
We've also renamed the task runners to make them more readable and easier to use. For example, io.kestra.plugin.aws.runner.AwsBatchTaskRunner is now io.kestra.plugin.ee.aws.runner.Batch. The updated names are as follows:
Old Path Before Kestra 0.17.0 New Path After Kestra 0.17.0
io.kestra.core.models.tasks.runners.types.ProcessTaskRunner io.kestra.plugin.core.runner.Process
io.kestra.plugin.scripts.runner.docker.DockerTaskRunner io.kestra.plugin.scripts.runner.docker.Docker
io.kestra.plugin.ee.kubernetes.runner.KubernetesTaskRunner io.kestra.plugin.ee.kubernetes.runner.Kubernetes
io.kestra.plugin.ee.aws.runner.AwsBatchTaskRunner io.kestra.plugin.ee.aws.runner.Batch
io.kestra.plugin.ee.azure.runner.AzureBatchTaskRunner io.kestra.plugin.ee.azure.runner.Batch
io.kestra.plugin.ee.gcp.runner.GcpBatchTaskRunner io.kestra.plugin.ee.gcp.runner.Batch
io.kestra.plugin.ee.gcp.runner.GcpCloudRunTaskRunner io.kestra.plugin.ee.gcp.runner.CloudRun
Renamed Redis Triggers and Tasks
The Redis plugin has been updated to make it easier to extend and maintain. The following classes have been renamed:
Old Path Before Kestra 0.17.0 New Path After Kestra 0.17.0
io.kestra.plugin.redis.ListPop io.kestra.plugin.redis.list.ListPop
io.kestra.plugin.redis.ListPush io.kestra.plugin.redis.list.ListPush
io.kestra.plugin.redis.TriggerList io.kestra.plugin.redis.list.Trigger
- io.kestra.plugin.redis.list.RealtimeTrigger
io.kestra.plugin.redis.Publish io.kestra.plugin.redis.pubsub.Publish
io.kestra.plugin.redis.Get io.kestra.plugin.redis.string.Get
io.kestra.plugin.redis.Set io.kestra.plugin.redis.string.Set
io.kestra.plugin.redis.Delete io.kestra.plugin.redis.string.Delete
Was this page helpful?
Yes
No
0.17.0
Plugin Discovery Mechanism
0.17.0
Volume Mount""""""",2350,10141,kestra
https://kestra.io/docs/migration-guide/0.17.0/volume-mount,"""""""DocsMigration Guide0.17.0Volume Mount
Volume Mount
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.17.0
How to migrate volume-enabled to the plugin configuration.
The docker volume mount, by setting the property kestra.tasks.scripts.docker.volume-enabled to true, has been deprecated since 0.17.0. It is now recommended to use the plugin configuration volume-enabled for the Docker runner plugin.
This change is implemented in a non-breaking way, so you don't need to immediately change the way you use the docker volume mount. In case you use this older method for mounting the volume, you will receive the following deprecation warning:
The kestra.tasks.scripts.docker.volume-enabled is deprecated, please use the plugin configuration volume-enabled instead.
It is recommended to make the following change in the Docker Compose file for mounting the volume:
yaml
 kestra:
    image: kestra/kestra:latest
    pull_policy: always
    user: ""root""
    env_file:
      - .env
    command: server standalone --worker-thread=128
    volumes:
      - kestra-data:/app/storage
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/kestra-wd:/tmp/kestra-wd:rw
    environment:
      KESTRA_CONFIGURATION: |
        datasources:
          postgres:
            url: jdbc:postgresql://postgres:5432/kestra
            driverClassName: org.postgresql.Driver
            username: kestra
            password: k3str4
        kestra:
          server:
            basicAuth:
              enabled: false
              username: ""admin@kestra.io"" # it must be a valid email address
              password: kestra
          repository:
            type: postgres
          storage:
            type: local
            local:
              basePath: ""/app/storage""
          queue:
            type: postgres
          tasks:
            tmpDir:
              path: /tmp/kestra-wd/tmp
          plugins:
            configurations:
              - type: io.kestra.plugin.scripts.runner.docker.Docker
                values:
                  volumeEnabled: true # üëà this is the relevant setting
For more information, you can refer the Bind mount page.
Was this page helpful?
Yes
No
0.17.0
Renamed Plugins
Migration Guide
0.18.0""""""",506,2259,kestra
https://kestra.io/docs/migration-guide/0.18.0,"""""""DocsMigration Guide0.18.0
0.18.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.18.0
Deprecated features and migration guides for 0.18.0 and onwards.
Deprecation of runner property in favor of taskRunner
How to migrate from runner to taskRunner.
Deprecation of Terraform task_defaults in favor of plugin_defaults
How to migrate task_defaults to plugin_defaults for the Kestra Terraform Provider.
Was this page helpful?
Yes
No
0.17.0
Volume Mount
0.18.0
Deprecation of runner property in favor of taskRunner""""""",145,545,kestra
https://kestra.io/docs/migration-guide/0.18.0/runners,"""""""DocsMigration Guide0.18.0Deprecation of runner property in favor of taskRunner
Deprecation of runner property in favor of taskRunner
Table of Contents
Why the change?
Migration
From PROCESS runner to taskRunner
From DOCKER runner to taskRunner
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.18.0
How to migrate from runner to taskRunner.
Why the change?
Task Runners is a pluggable system that allows you to offload the execution of your tasks to different environments.
With the general availability of taskRunner in Kestra 0.18.0, the runner property is deprecated. Task Runners provide more flexibility and control over how your tasks are executed, allowing you to run your code in various remote environments by:
Leveraging task runner plugins managed by Kestra
Building your own task runner plugins customized to your needs.
Migration
To migrate from the runner property to taskRunner, update your flow code as follows:
Replace the runner property with taskRunner.
If you were using the DOCKER runner with a custom Docker image, replace the docker.image property with the containerImage property.
Update any other properties in the taskRunner configuration as needed, e.g. to configure Docker image pull policies, CPU and memory limits, or to provide credentials to private Docker registries.
Note that all other script task's properties, such as the beforeCommands, commands, inputFiles, outputFiles, interpreter, env, warningOnStdErr, workerGroup, and more, remain the same. You only need to replace the runner property with taskRunner and adjust the Docker image configuration if needed.
Let's look at some examples to make this clearer.
From PROCESS runner to taskRunner
If you were using the PROCESS runner to execute your tasks in local processes, add the taskRunner property with the type set to io.kestra.plugin.core.runner.Process.
Before (the old way):
yaml
id: example_with_runner
namespace: company.team
tasks:
  - id: script
    type: io.kestra.plugin.scripts.python.Script
    runner: PROCESS
    script: |
      from kestra import Kestra
      data = dict(message=""Hello from Kestra!"", release=""0.17.0"")
      print(data.get(""message""))
      Kestra.outputs(data)
After (the current way):
yaml
id: example_with_taskRunner
namespace: company.team
tasks:
  - id: script
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    script: |
      from kestra import Kestra
      data = dict(message=""Hello from Kestra!"", release=""0.18.0"")
      print(data.get(""message""))
      Kestra.outputs(data)
From DOCKER runner to taskRunner
If you were using the DOCKER runner to run your scripts in a Docker container, add the taskRunner property with the type set to io.kestra.plugin.scripts.runner.docker.Docker.
Before (the old way):
yaml
id: example_with_runner
namespace: company.team
tasks:
  - id: script
    type: io.kestra.plugin.scripts.python.Script
    runner: DOCKER
    docker:
      image: ghcr.io/kestra-io/kestrapy:latest
      pullPolicy: IF_NOT_PRESENT
      cpu:
        cpus: 1
      memory:
        memory: ""512MB""
    script: |
      from kestra import Kestra
      data = dict(message=""Hello from Kestra!"", release=""0.17.0"")
      print(data.get(""message""))
      Kestra.outputs(data)
After (the current way):
yaml
id: example_with_taskRunner
namespace: company.team
tasks:
  - id: script
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      pullPolicy: IF_NOT_PRESENT
      cpu:
        cpus: 1
      memory:
        memory: ""512MB""
    containerImage: ghcr.io/kestra-io/kestrapy:latest
    script: |
      from kestra import Kestra
      data = dict(message=""Hello from Kestra!"", release=""0.18.0"")
      print(data.get(""message""))
      Kestra.outputs(data)
Note how the containerImage is now a top-level property of each script task. This makes the configuration more flexible, as the image changes more often than the standard runner configuration.
Was this page helpful?
Yes
No
Migration Guide
0.18.0
0.18.0
Deprecation of Terraform task_defaults in favor of plugin_defaults""""""",1000,4185,kestra
https://kestra.io/docs/migration-guide/0.18.0/tf-task-defaults,"""""""DocsMigration Guide0.18.0Deprecation of Terraform task_defaults in favor of plugin_defaults
Deprecation of Terraform task_defaults in favor of plugin_defaults
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.18.0
How to migrate task_defaults to plugin_defaults for the Kestra Terraform Provider.
In the v0.17.0 release, we renamed Task Defaults to Plugin Defaults as this better reflects their purpose. As a result, the 0.18.0 version of the Terraform Provider now uses the property plugin_defaults instead of task_defaults in the kestra_namespace resource.
In order to migrate to the new version, simply replace task_defaults with plugin_defaults in your Terraform configuration before you upgrade your Kestra Terraform provider.
Was this page helpful?
Yes
No
0.18.0
Deprecation of runner property in favor of taskRunner
Migration Guide
0.19.0""""""",206,881,kestra
https://kestra.io/docs/migration-guide/0.19.0,"""""""DocsMigration Guide0.19.0
0.19.0
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.19.0
Deprecated features and migration guides for 0.19.0 and onwards.
Deprecation of State Store in favor of KV Store
How to migrate from State Store to KV Store.
Was this page helpful?
Yes
No
0.18.0
Deprecation of Terraform task_defaults in favor of plugin_defaults
0.19.0
Deprecation of State Store in favor of KV Store""""""",126,440,kestra
https://kestra.io/docs/migration-guide/0.19.0/state-store,"""""""DocsMigration Guide0.19.0Deprecation of State Store in favor of KV Store
Deprecation of State Store in favor of KV Store
Table of Contents
Overview
Why the change?
State Store tasks
How to migrate
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Release:
0.19.0
How to migrate from State Store to KV Store.
Overview
The State Store is a mechanism used under the hood by kestra to store the state of a task execution as a file in internal storage.
With the general availability of the KV Store in Kestra 0.18.0, the State Store is deprecated starting with Kestra 0.19.0.
Why the change?
State Store was difficult to troubleshoot and manage. There was no way to view what data is actually stored in the State Store from the UI/API, and the data stored there was tied to a given flow execution, making it chalenging to manage the lifecycle of the data.
The KV Store provides more flexibility and control over the data persisted during your task execution, allowing you to:
set a type for each key (e.g. string, number, boolean, datetime, date, duration, JSON),
view the data from the UI,
query the persisted values via key from your flows or via API,
manage the lifecycle for each key via TTL.
State Store tasks
The State Store tasks are deprecated in favor of equivalent KV Store tasks. The table below shows a mapping of the deprecated State Store tasks to the KV Store tasks.
State Store task KV Store task
io.kestra.plugin.core.state.Get io.kestra.plugin.core.kv.Get
io.kestra.plugin.core.state.Set io.kestra.plugin.core.kv.Set
io.kestra.plugin.core.state.Delete io.kestra.plugin.core.kv.Delete
How to migrate
All plugins that were using State Store now leverage KV Store under the hood. This includes:
all Singer plugins
all Debezium plugins
CloudQuery plugin
If you were using one of those plugins, make sure to run this command after upgrading to Kestra 0.19.0:
bash
/app/kestra sys state-store migrate
Additionally, if you were using the State Store tasks directly in your flows, make sure to update your flows to use the equivalent KV Store tasks.
Was this page helpful?
Yes
No
Migration Guide
0.19.0
Docs
Configuration""""""",506,2151,kestra
https://kestra.io/docs/configuration,"""""""DocsConfiguration
Configuration
Table of Contents
Setup
Internal storage configuration
Queue configuration
Repository configuration
Database
Queue and Repository
Datasources
Connection pool size
Datasources
JDBC Queues
JDBC Cleaner
Protecting against too big messages
Telemetry
Elasticsearch
Trust all SSL certificates
Indices Prefix
Indices Split
Index Rotation
EE Java Security
Forbidden Paths
Authorized Class Prefix
Forbidden Class Prefix
EE License
Multi-tenancy
Default Tenant
Encryption
Endpoints
Environment
JVM
Timezone
Indexer
Kafka
Client Properties
Topics
Consumer, Producer and Stream properties
Topic names and properties
Consumer Prefix
Topic Prefix
Client Loggers
Kafka Stream State Directory
Topic retention
Protecting against too big messages
Listeners
Logger
Access Log configuration
Log Format
Metrics
Micronaut
Configure port
Configure SSL
Timeout and max uploaded file size
Changing base path
Changing host resolution
Configuring CORS
Plugins
Enable or disable features
Set default values
Allowed plugins
Plugin defaults
Retries
Secret Managers
AWS Secret Manager
Azure Key Vault
Elasticsearch
Google Secret Manager
HashiCorp Vault
JDBC
Secret Tags
Secret Cache
Security
Super-Admin
Default Role
Server
HTTP Basic Authentication
Delete configuration files
Server Liveness & Heartbeats
Heartbeat Frequency
Heartbeat Missed
Worker Task Restart Strategy
Termination Grace Period
Internal Storage
S3
Minio
Azure
GCS
System Flows
Tasks
Plugin Default Configuration
Volume Enabled for Docker Task Runner
Temporary storage configuration
Tutorial Flows
Enabling Templates
Kestra URL
Variables
Environment Variables Prefix
Global Variables
Recursive Rendering
Cache Size
Webserver
Google Analytics ID
Append HTML tags to the webserver application
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Configuration Reference for Kestra.
Almost everything is configurable in Kestra. This section describes the different configuration options available to Administrators.
Kestra configuration is a YAML file that can be passed as an environment variable, a file, or added directly in the Docker Compose file depending on your chosen installation option. The configuration is intended to hold deployment-specific options and it's divided into different sections, each corresponding to a different part of the system:
yaml
datasources:
  postgres:
    url: jdbc:postgresql://postgres:5432/kestra
    driverClassName: org.postgresql.Driver
    username: kestra
    password: k3str4
kestra:
  server:
    basicAuth:
      enabled: false
      username: ""admin@kestra.io"" # it must be a valid email address
      password: kestra
  repository:
    type: postgres
  storage:
    type: local
    local:
      basePath: ""/app/storage""
  queue:
    type: postgres
  tasks:
    tmpDir:
      path: ""/tmp/kestra-wd/tmp""
  url: ""http://localhost:8080/""
Setup
Kestra offers many configuration options and customization.
There are three main components that need to be configured during the initial setup:
Internal Storage
Queue
Repository
Internal storage configuration
Kestra supports multiple internal storage types, the default being the local storage that will store data in a local folder on the host filesystem. It's recommended only for local testing as it doesn't provide resiliency or redundancy.
To choose another storage type, you will need to configure the kestra.storage.type option. Make sure to download the corresponding storage plugins first. The following example configures Google Cloud Storage as internal storage.
yaml
kestra:
  storage:
    type: gcs
Queue configuration
Kestra supports multiple queue types, which must be compatible with the repository type. The default queue depends on your chosen architecture and installation option.
The following queue types are available:
In-memory queue used with the in-memory repository ‚Äî intended for local testing.
Database queue used with the database repository. It currently supports H2, MySQL, and PostgreSQL as a database.
Kafka queue used with the Elasticsearch repository. Those are only available in the Enterprise Edition.
To enable the PostgreSQL database queue, you need to add the kestra.queue configuration:
yaml
kestra:
  queue:
    type: postgres
Repository configuration
Kestra supports multiple repository types, which must be compatible with the queue type. Also here, the default depends on your installation option.
The following repository types are available:
In-memory that must be used with the in-memory queue. It is only suitable for local testing as it doesn't provide any resiliency or scalability and didn't implement all functionalities.
Database that must be used with the database queue. It currently supports H2, MySQL or PostgreSQL as a database.
Elasticsearch that must be used with the Kafka queue. Those are only available inside the Enterprise Edition.
To enable the PostgreSQL database repository, you need to add the kestra.repository configuration:
yaml
kestra:
  repository:
    type: postgres
For more details, check the database configuration and the Elasticsearch configuration.
Database
Queue and Repository
In order to configure a database backend, you need to set the kestra.queue.type and kestra.repository.type to your chosen database type. Here is an example for PostgreSQL:
yaml
kestra:
  queue:
    type: postgres
  repository:
    type: postgres
Currently, Kestra supports Postgres, H2, MySQL, and SQL Server (available in a preview in the Enterprise Edition since Kestra 0.18.0).
H2 can be convenient for local development.
For production, we recommend PostgreSQL. If PostgreSQL is not an option for you, MySQL and SQL Server can be used as well.
Check the Software Requirements section for the minimum version of each database.
If you experience performance issues when using PostgreSQL, you can tune the cost optimizer parameter random_page_cost=1.1, which should make PostgreSQL use the right index for the queues table. You can also configure kestra.queue.postgres.disableSeqScan=true so that Kestra turns off sequential scans on the queue polling query forcing PostgreSQL to use the index.
Datasources
Once you added the kestra.queue.type and kestra.repository.type, you need to configure the datasources section.
Kestra uses The HikariCP connection pool under the hood, and if needed, you can configure multiple options from the HikariCP documentation directly in your datasources configuration.
PostgreSQL
MySQL
SQL Server
H2
Connection pool size
The total number of connections opened to the database will depend on your chosen architecture. Each Kestra instance will open a pool of up to the maximumPoolSize (10 by default), with a minimum size of the minimumIdle (also set to 10 by default).
If you deploy Kestra as a standalone server, it will open 10 connections to the database.
If you deploy each Kestra component separately, it will open 40 connections to the database (10 per component).
If you deploy each Kestra component separately with 3 replicas, it will open 120 connections to the database.
Usually, the default connection pool sizing is enough, as HikariCP is optimized to use a low number of connections.
Datasources
The table below shows the datasource configuration properties. For more details, check the HikariCP configuration documentation.
Properties Type Description
url String The JDBC connection string.
catalog String The default catalog name to be set on connections.
schema String The default schema name to be set on connections.
username String The default username used.
password String The default password to use.
transactionIsolation String The default transaction isolation level.
poolName String The name of the connection pool.
connectionInitSql String The SQL string that will be executed on all new connections when they are created, before they are added to the pool.
connectionTestQuery String The SQL query to be executed to test the validity of connections.
connectionTimeout Long The maximum number of milliseconds that a client will wait for a connection from the pool.
idleTimeout Long The maximum amount of time (in milliseconds) that a connection is allowed to sit idle in the pool.
minimumIdle Long The minimum number of idle connections that HikariCP tries to maintain in the pool, including both idle and in-use connections. Defaults to the value of maximumPoolSize
initializationFailTimeout Long The pool initialization failure timeout.
leakDetectionThreshold Long The amount of time that a connection can be out of the pool before a message is logged indicating a possible connection leak.
maximumPoolSize Int The maximum size that the pool is allowed to reach, including both idle and in-use connections. Defaults to 10.
maxLifetime Long The maximum lifetime of a connection in the pool.
validationTimeout Long The maximum number of milliseconds that the pool will wait for a connection to be validated as alive.
Here's the default HikariCP configuration:
yaml
transactionIsolation: default # driver default
poolName: HikariPool-<Generated>
connectionInitSql: null
connectionTestQuery: null
connectionTimeout: 30000 # 30 seconds
idleTimeout: 600000 # 10 minutes
minimumIdle: 10 # same as maximum-pool-size
initializationFailTimeout: 1
leakDetectionThreshold: 0
maximumPoolSize: 10
maxLifetime: 1800000 # 30 minutes
validationTimeout: 5000
JDBC Queues
Kestra database queues simulate queuing doing long polling. They query a queues table to detect new messages.
You can change these parameters to reduce the polling latency, but be aware it will increase the load on the database:
kestra.jdbc.queues.pollSize: the maximum number of queues items fetched by each poll.
kestra.jdbc.queues.minPollInterval: the minimum duration between 2 polls.
kestra.jdbc.queues.maxPollInterval: the maximum duration between 2 polls.
kestra.jdbc.queues.pollSwitchInterval: the delay for switching from min-poll-interval to max-poll-interval when no message is received. (ex: when one message is received, the minPollInterval is used, if no new message arrived within pollSwitchInterval, we switch to maxPollInterval).
Here is the default configuration:
yaml
kestra:
  jdbc:
    queues:
      pollSize: 100
      minPollInterval: 25ms
      maxPollInterval: 1000ms
      pollSwitchInterval: 5s
JDBC Cleaner
Kestra cleans the queues table periodically to optimize storage and performance. You can control how often you want this cleaning to happen, and how long messages should be kept in the queues table using the kestra.jdbc.cleaner configuration.
Here is the default configuration:
yaml
kestra:
  jdbc:
    cleaner:
      initialDelay: 1h
      fixedDelay: 1h
      retention: 7d
Protecting against too big messages
Note: this is an experimental feature available starting with Kestra 0.19.
The database backend has no limit on the size of messages it can handle. However, as messages are loaded into memory, this can endanger Kestra itself and push pressure on memory usage.
To prevent that, you can configure a functionality that will refuse to store too big messages in the execution context (for example data stored in outputs property) and fail the execution instead.
The following configuration will refuse messages that exceed 1MiB by failing the execution.
yaml
kestra:
  jdbc:
    queues:
      messageProtection:
        enabled: true
        limit: 1048576
Telemetry
By default, the kestra.anonymousUsageReport is enabled to send anonymous usage data to Kestra to help us improve the product. If you want to disable it, you can set it to false:
yaml
kestra:
  anonymousUsageReport:
    enabled: false
You can change the initial delay (default 5m):
yaml
kestra:
  anonymousUsageReport:
    initialDelay: 5m
You can change the fixed delay (default 1h):
yaml
kestra:
  anonymousUsageReport:
    fixedDelay: 1h
Elasticsearch
Elasticsearch is an Enterprise Edition functionality.
The kestra.elasticsearch setting allows you to configure the way Kestra connects to the Elasticsearch cluster.
Here is a minimal configuration example:
yaml
kestra:
  elasticsearch:
    client:
      httpHosts: ""http://localhost:9200""
  repository:
    type: elasticsearch
Here is another example with a secured Elasticsearch cluster with basic authentication:
yaml
kestra:
  elasticsearch:
    client:
      httpHosts:
        - ""http://node-1:9200""
        - ""http://node-2:9200""
        - ""http://node-3:9200""
      basicAuth:
        username: ""<your-user>""
        password: ""<your-password>""
  repository:
    type: elasticsearch
Trust all SSL certificates
Using the kestra.elasticsearch.client.trustAllSsl configuration, you can trust all SSL certificates during the connection. This is useful for development servers with self-signed certificates.
yaml
kestra:
  elasticsearch:
    client:
      httpHosts: ""https://localhost:9200""
      trustAllSsl: true
Indices Prefix
The kestra.elasticsearch.defaults.indicePrefix configuration allows to change the prefix of the indices. By default, the prefix will be kestra_.
For example, if you want to share a common Elasticsearch cluster for multiple instances of Kestra, add a different prefix for each instance as follows:
yaml
kestra:
  elasticsearch:
    defaults:
      indicePrefix: ""uat_kestra""
Indices Split
By default, a unique indices are used for all different data.
Using the kestra.elasticsearch.indices configuration, you can split the indices by type. This is useful for large instances where you may want to split the index by day, week or month to avoid having large indices in ElasticSearch.
Currently, the executions, logs and metrics can be split, and we support all these split types:
DAILY
WEEKLY
MONTHLY
YEARLY
yaml
kestra:
  elasticsearch:
    indices:
      executions:
        alias: daily
      logs:
        alias: daily
      metrics:
        alias: daily
Index Rotation
When you enable index rotation, it creates an alias and one index per periodicity (day, week, etc.).
It's safe to enable it on an existing instance however the alias will clash with the existing index so you should move the existing index, for example change kestra_logs to kestra_logs-1 before switching to the alias.
As indexes will be created with name-periodicity using the -1 suffix, make sure you will still include the old data (until you make the decision to purge it).
Be careful that not all indexes can be safely purged. You should only enable alias for historical data that keeps growing (like logs, metrics and executions).
It's safe to disable aliases but in the case existing data would not be recovered anymore.
It is totally safe to switch from one periodicity to another as the alias is for name-* so the periodicity is not important.
EE Java Security
You can use the kestra.ee.javaSecurity configuration to opt-in to isolation of file systems using advanced Kestra EE Java security:
yaml
kestra:
  ee:
    javaSecurity:
      enabled: true
      forbiddenPaths:
        - /etc/
      authorizedClassPrefix:
        - io.kestra.plugin.core
        - io.kestra.plugin.gcp
Forbidden Paths
The kestra.ee.javaSecurity.forbiddenPaths configuration is a list of paths on the file system that the Kestra Worker will be forbidden to read or write to. This can be useful to protect Kestra configuration files.
Authorized Class Prefix
The kestra.ee.javaSecurity.authorizedClassPrefix configuration is a list of classes that can create threads. Here you can set a list of prefixes (namespace) classes that will be allowed. All others will be refused.
Forbidden Class Prefix
The kestra.ee.javaSecurity.forbiddenClassPrefix configuration is a list of classes that can't create any threads. Others plugins will be authorized.
yaml
kestra:
  ee:
    javaSecurity:
      enabled: true
      forbiddenClassPrefix:
        - io.kestra.plugin.scripts
EE License
To use Kestra Enterprise Edition, you will need a valid license configured under the kestra.ee.license configuration. The license is unique to your organization. If you need a license, please reach out to our Sales team at sales@kestra.io.
The license is set up using two configuration properties: id and key.
kestra.ee.license.id: license identifier.
kestra.ee.license.key: license key.
When you launch Kestra Enterprise Edition, it will check the license and display the validation step in the log.
Multi-tenancy
By default, multi-tenancy is disabled. To enable it, add the kestra.ee.tenants configuration:
yaml
kestra:
  ee:
    tenants:
      enabled: true
Default Tenant
By default, multi-tenancy is disabled, and the default tenant is set to true. Once you enable multi-tenancy, you can set the default tenant to false using the kestra.ee.tenants.defaultTenant configuration:
yaml
kestra:
  ee:
    tenants:
      enabled: true
      defaultTenant: false
This will enable multi-tenancy and disable the default tenant (best practice). It is recommended to disable it so that your Kestra instance includes only the tenants you explicitly create.
Encryption
Kestra 0.15.0 and later supports encryption of sensitive data. This allows inputs and outputs to be automatically encrypted and decrypted when they are stored in the database.
To enable encryption, you need to provide a base64-encoded secret key in the kestra.encryption configuration:
yaml
kestra:
  encryption:
    secretKey: BASE64_ENCODED_STRING_OF_32_CHARCTERS
To generate a 32-character string and then base64 encode it, you can use the defacto standard for cryptography, OpenSSL:
bash
openssl rand -base64 32
If you don't have OpenSSL installed, you can use the following Bash commands to generate a base64-encoded 32-character encryption key:
bash
random_string=$(LC_ALL=C tr -dc 'A-Za-z0-9' < /dev/urandom | head -c 32)
echo ""$random_string"" | base64
If you run Kestra with Docker-Compose, here is how you can add that key in the KESTRA_CONFIGURATION environment variable in your docker-compose.yml file:
yaml
  kestra:
    image: kestra/kestra:latest
    environment:
      KESTRA_CONFIGURATION: |
        kestra:
          encryption:
            secretKey: NWRhUDc5TERWY2QyMDhSSHhfeWYzbjJpNE5vb3M5NnY=
Once the secret key is set, you can use an input and output of type SECRET:
yaml
id: my_secret_flow
namespace: company.team
inputs:
  - id: secret
    type: SECRET
tasks:
  - id: mytask
    type: io.kestra.plugin.core.log.Log
    message: task that needs the secret to connect to an external system
outputs:
  - id: secret_output
    type: SECRET
    value: ""{{ inputs.secret }}""
When executing this flow, you will see a masked field:
In the Execution Overview tab, you will see a masked value of the secret.
If the secretKey is not set in the kestra.encryption configuration, you will get an error: Illegal argument: Unable to use a SECRET input as encryption is not configured when trying to use a SECRET input or output type.
Endpoints
Management endpoints can be set up from the Micronaut endpoint configuration. You can also secure all endpoints with basic authentication using the endpoints configuration:
yaml
endpoints:
  all:
    basicAuth:
      username: your-user
      password: your-password
Environment
Here are the configuration options for the environment UI display.
You can add a label and a color to identify your environment in the UI by adding the kestra.environment configuration:
yaml
kestra:
  environment:
    name: Production
    color: ""#FCB37C""
You can also set that environment name and color directly from the UI. Just go to the settings page and type the desired Environment name and select the color.
JVM
All JVM options can be passed in an environment variable named JAVA_OPTS. You can use it to change all JVM options available, such as memory, encoding, etc.
Example:
shell
export JAVA_OPTS=""-Duser.timezone=Europe/Paris""
Timezone
By default, Kestra will handle all dates using your system's timezone. You can change the timezone using the user.timezone JVM option.
Changing the timezone will mostly affect:
scheduler: by default, all schedule dates are UTC; changing the Java timezone will allow scheduling the flow in your timezone.
logs display: in your configured timezone.
Indexer
Indexer send data from Kafka to Elasticsearch using Bulk Request. You can control the batch size and frequency to reduce the load on ElasticSearch using the kestra.indexer configuration. This will delay some information on the UI raising that values, example:
yaml
kestra:
  indexer:
    batchSize: 500 # (default value, any integer > 0)
    batchDuration: PT1S # (default value, any duration)
Kafka
Kafka is part of the Enterprise Edition.
You can set up your Kafka connection using the kestra.kafka configuration.
Client Properties
The most important configuration step is defining how Kestra should connect to the Kafka cluster. You can set this up using the kestra.kafka.client.properties configuration.
Here is a minimal configuration example:
yaml
kestra:
  kafka:
    client:
      properties:
        bootstrap.servers: ""localhost:9092""
  queue:
    type: kafka
Here is another example with SSL configuration:
yaml
kestra:
  kafka:
    client:
      properties:
        bootstrap.servers: ""host:port""
        security.protocol: ""SSL""
        ssl.endpoint.identification.algorithm: """"
        ssl.key.password: ""<your-password>""
        ssl.keystore.location: ""/etc/ssl/private/keystore.p12""
        ssl.keystore.password: ""<your-password>""
        ssl.keystore.type: ""PKCS12""
        ssl.truststore.location: ""/etc/ssl/private/truststore.jks""
        ssl.truststore.password: ""<your-password>""
  queue:
    type: kafka
kestra.kafka.client.properties allows passing any standard Kafka properties. More details can be found on the Kafka Documentation.
Topics
By default, Kestra automatically creates all the needed topics. You can change the partition count and replication factor of these topics using the kestra.kafka.defaults.topic configuration.
kestra.kafka.defaults.topic.partitions: (default 16)
kestra.kafka.defaults.topic.replicationFactor: (default 1)
The number of topic's partitions limits the number of concurrently processing server instances consuming that particular topic. For example, using 16 partitions for every topic limits the effective number of instances to 16 executor servers, 16 worker servers, etc.
For the optimal value of the replication factor, validate the actual configuration of the target Kafka cluster. Generally, for high availability, the value should match the number of Kafka brokers in the cluster. For example, a cluster consisting of 3 nodes should use the replication factor of 3.
Consumer, Producer and Stream properties
You can change the default properties of the Kafka client used by Kestra using the kestra.kafka.defaults.[consumer|producer|stream].properties configuration. These allow you to change any available properties.
Here is the default configuration:
yaml
kestra:
  kafka:
    defaults:
      consumer:
        properties:
          isolation.level: ""read_committed""
          auto.offset.reset: ""earliest""
          enable.auto.commit: ""false""
      producer:
        properties:
          acks: ""all""
          compression.type: ""lz4""
          max.request.size: ""10485760""
      stream:
        properties:
          processing.guarantee: ""exactly_once""
          replication.factor: ""${kestra.kafka.defaults.topic.replicationFactor}""
          acks: ""all""
          compression.type: ""lz4""
          max.request.size: ""10485760""
          state.dir: ""/tmp/kafka-streams""
Topic names and properties
All the topics used by Kestra are declared with the default name and properties. You can change the default values using the kestra.kafka.defaults.topics configuration:
kestra.kafka.defaults.topics.{{topic}}.name: Change the name of the topic.
kestra.kafka.defaults.topics.{{topic}}.properties: Change the default properties used during topic automatic creation.
You can see default configuration on this file.
Consumer Prefix
The kestra.kafka.defaults.consumerPrefix configuration allows changing the consumer-group prefix. By default, the prefix will be kestra.
For example, if you want to share a common Kafka cluster for multiple instances of Kestra, you must configure a different prefix for each instance like this:
yaml
kestra:
  kafka:
    defaults:
      consumerPrefix: ""uat_kestra""
Topic Prefix
The kestra.kafka.defaults.topicPrefix configuration allows changing the topic name prefix. By default, the prefix will be kestra_.
For example, if you want to share a common Kafka cluster for multiple instances of Kestra, add a different prefix for each instance like this:
yaml
kestra:
  kafka:
    defaults:
      topicPrefix: ""uat_kestra""
Client Loggers
The kestra.kafka.client.loggers configuration allows enabling logging for all messages processed by the Kafka cluster. Use it to debug all the messages consumed or produced on the Kafka cluster.
This configuration has a huge performance impact, using regexp and serialization for most of the messages.
yaml
kestra:
  kafka:
    client:
      loggers:
        - level: INFO # mandatory: ERROR, WARN, INFO, DEBUG, TRACE, the logger must be configured at least at this level for class io.kestra.runner.kafka.AbstractInterceptor
          type: PRODUCER # optional: CONSUMER or PRODUCER
          topicRegexp: ""kestra_(executions|workertaskresult)"" # optional: a regexp validating the topic
          keyRegexp: .*parallel.* # optional: a regexp validating the key
          valueRegexp: .*parallel.* # optional: a regexp validating the json full body
Kafka Stream State Directory
Kestra uses the Kafka Stream framework, this framework uses a local directory for state persistence. By default, the state directory is /tmp/kafka-streams and can be configured using the kestra.kafka.stream.properties.state.dir configuration property.
This directory should not be purged while the application runs but can be purged between restarts. If persisted between restarts, the startup time could be improved as the state of the Kafka Stream will be recovered from the directory.
It is advised to purge this directory before a Kestra update, if not, an error message may be displayed in the log that can be safely ignored.
Topic retention
Each Kafka topic used by Kestra is configurable using the following configuration property:
yaml
kestra:
  kafka:
    topics:
      execution:
        properties:
          kafka.property: value
By default, except for topics where we need unlimited retention as they store referential data like flow or trigger definition, all topics are configured with a default retention of 7 days.
For example, for the topic storing executions, you can configure the retention via this configuration property:
yaml
  kafka:
    topics:
      execution:
        properties:
          retention.ms: ""86400000""
Protecting against too big messages
Note: this is an experimental feature.
Kafka topic has a limit of the size of messages it can handle. By default, we set this limit to 10MiB. If a message exceeds this limit, it may crash the executor and Kestra will stop.
To prevent that, you can configure a functionality that will automatically store too big messages to the internal storage.
yaml
kestra:
  kafka:
    messageProtection:
      enabled: true
The hard-limit is not mandatory, in this case messages of any size will be accepted.
Listeners
Listeners are deprecated and disabled by default since the 0.11.0 release. You can re-enable them using the kestra.listeners configuration:
yaml
kestra:
  listeners:
    enabled: true
Logger
You can change the log behavior in Kestra by adjusting the logger configuration parameters:
yaml
logger:
  levels:
    io.kestra.runner: TRACE
    org.elasticsearch.client: TRACE
    org.elasticsearch.client.sniffer: TRACE
    org.apache.kafka: DEBUG
    io.netty.handler.logging: TRACE
Access Log configuration
You can configure the access log from the webserver using the micronaut.server.netty.accessLogger configuration:
micronaut.server.netty.accessLogger.enabled: enable access log from webserver (default true).
micronaut.server.netty.accessLogger.name: logger name (default io.kestra.webserver.access).
micronaut.server.netty.accessLogger.format: access log format (default ""%{yyyy-MM-dd'T'HH:mm:ss.SSS'Z'}t | %r | status: %s | ip: %a | length: %b | duration: %D"").
micronaut.server.netty.accessLogger.exclusions: list of regexp to define which log to exclude.
Here are the default values:
yaml
micronaut:
  server:
    netty:
      accessLogger:
        enabled: true
        name: io.kestra.webserver.access
        format: ""[Date: {}] [Duration: {} ms] [Method: {}] [Url: {}] [Status: {}] [Length: {}] [Ip: {}] [Port: {}]""
        exclusions:
          - /ui/.+
          - /health
          - /prometheus
Log Format
We are using Logback to handle log. You change the format of the log format, and we provide some default and common one configuring a logback configuration files.
If you want to customize the log format, you can create a logback.xml file and add it to the classpath. Then, add a new JAVA_OPTS environment variable: ""-Dlogback.configurationFile=file:/path/to/your/configuration/logback.xml""
We provide some predefined configuration, and some example of the logback.xml files:
GCP
xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<configuration debug=""false"">
    <include resource=""logback/base.xml"" />
    <include resource=""logback/gcp.xml"" />
    <root level=""WARN"">
        <appender-ref ref=""CONSOLE_JSON_OUT"" />
        <appender-ref ref=""CONSOLE_JSON_ERR"" />
    </root>
</configuration>
Elastic Common Schema (ECS) format
xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<configuration debug=""true"">
  <include resource=""logback/base.xml"" />
  <include resource=""logback/ecs.xml"" />
  <root level=""WARN"">
    <appender-ref ref=""CONSOLE_ECS_OUT"" />
    <appender-ref ref=""CONSOLE_ECS_ERR"" />
  </root>
</configuration>
Metrics
You can set the prefix for all Kestra metrics using the kestra.metrics configuration:
yaml
kestra:
  metrics:
    prefix: kestra
Micronaut
Given that Kestra is a Java-based application built on top of Micronaut, there are multiple Micronaut settings that you can configure based on your needs using the micronaut configuration.
To see all the possible configuration options, check the official Micronaut guide.
Below are some tips on the Micronaut configuration options which are most relevant to Kestra.
Configure port
yaml
micronaut:
  server:
    port: 8086
Configure SSL
This guide will help you configure SSL with Micronaut. A final working configuration would look as follows (considering you would use environment variables injection for passwords):
yaml
micronaut:
  security:
    x509:
      enabled: true
  ssl:
    enabled: true
  server:
    ssl:
      clientAuthentication: need
      keyStore:
        path: classpath:ssl/keystore.p12
        password: ${KEYSTORE_PASSWORD}
        type: PKCS12
      trustStore:
        path: classpath:ssl/truststore.jks
        password: ${TRUSTSTORE_PASSWORD}
        type: JKS
Timeout and max uploaded file size
Below is the default configuration for the timeout and max uploaded file size. You can change these values as needed:
yaml
micronaut:
  server:
    maxRequestSize: 10GB
    multipart:
      maxFileSize: 10GB
      disk: true
    readIdleTimeout: 60m
    writeIdleTimeout: 60m
    idleTimeout: 60m
    netty:
      maxChunkSize: 10MB
Changing base path
If behind a reverse proxy, you can change the base path of the application with the following configuration:
yaml
micronaut:
  server:
    contextPath: ""kestra-prd""
Changing host resolution
If behind a reverse proxy, you can change host resolution (http/https/domain name) providing the header sent by your reverse proxy:
yaml
micronaut:
  server:
    hostResolution:
      hostHeader: Host
      protocolHeader: X-Forwarded-Proto
Configuring CORS
In case you run into issues related to CORS policy, say while calling the webhook API from a JS application, you can enable the processing of CORS requests with the following configuration:
yaml
micronaut:
  server:
    cors:
      enabled: true
For more detailed changes like allowing only specific origins or specific methods, you can refer this guide.
Plugins
Maven repositories used by the command kestra plugins install can be configured using the kestra.plugins configuration.
Maven Central is mandatory for Kestra and its plugins. However, you can add your own (Maven) repository in order to download your custom plugins using the following configuration:
yaml
kestra:
  plugins:
    repositories:
      central:
        url: https://repo.maven.apache.org/maven2/
      jcenter:
        url: https://jcenter.bintray.com/
      kestra:
        url: https://dl.bintray.com/kestra/maven
Enable or disable features
The configuration of plugins section can be also used to enable or disable some features of specific Kestra plugins, or to set some default values for them.
Here is an example of how to enable outputs for Subflow and Flow tasks:
yaml
kestra:
  plugins:
    configurations:
      - type: io.kestra.plugin.core.flow.Subflow
        values:
          outputs:
            enabled: true # for backward-compatibility -- false by default
      - type: io.kestra.plugin.core.flow.Flow
        values:
          outputs:
            enabled: true # for backward-compatibility -- false by default
By default, the outputs property of a parent flow's Subflow task is deprecated in favor of flow outputs in Kestra 0.15.0 and higher. However, setting such configuration will keep the old behavior with the outputs property.
Set default values
You can also set default values for a plugin. For example, starting from Kestra 0.15.0, you can set the default value for the recoverMissedSchedules property of the Schedule trigger to NONE to avoid recovering missed scheduled executions after a server restart:
yaml
kestra:
  plugins:
    configurations:
      - type: io.kestra.plugin.core.trigger.Schedule
        values:
          # Available options: LAST | NONE | ALL. The default is ALL
          recoverMissedSchedules: NONE
Before 0.15, Kestra was always recovering missed schedules. This means that if your server was down for a few hours, Kestra would recover all missed schedules when it was back up. This behavior was not always desirable, as often the recovery of missed schedules is not necessary e.g. during a planned maintenance window. This is why, starting from Kestra 0.15 release, you can customize the recoverMissedSchedules property and choose whether you want to recover missed schedules or not.
The recoverMissedSchedules configuration can be set to ALL, NONE or LAST:
ALL: Kestra will recover all missed schedules. This is the default value.
NONE: Kestra will not recover any missed schedules.
LAST: Kestra will recover only the last missed schedule for each flow.
Note that this is a global configuration that will apply to all flows, unless explicitly overwritten within the flow definition:
yaml
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: ""*/15 * * * *""
    recoverMissedSchedules: NONE
In this example, the recoverMissedSchedules is set to NONE, which means that Kestra will not recover any missed schedules for this specific flow regardless of the global configuration.
Allowed plugins
This is an Enterprise Edition feature available starting with Kestra 0.19.
You can restrict which plugins can be used in a Kestra instance by configuring an allowlist / exclude list using regexes.
The following configuration only allow plugin from the io.kestra package and disallow the io.kestra.plugin.core.debug.Echo plugin.
yaml
kestra:
  plugins:
    security:
      includes:
        - io.kestra.*
      excludes:
        - io.kestra.plugin.core.debug.Echo
Plugin defaults
You can provide global plugin defaults using the kestra.plugins.defaults configuration. Those will be applied to each task on your cluster if a property is not defined on flows or tasks. Plugin defaults allow ensuring a property is defined at a default value for these tasks.
yaml
kestra:
  plugins:
    defaults:
    - type: io.kestra.plugin.core.log.Log
      values:
        level: ERROR
Forced plugin defaults:
ensure a property is set globally for a task, and no task can override it
are critical for security and governance, e.g. to enforce Shell tasks to run as Docker containers.
yaml
kestra:
  plugins:
    defaults:
      - type: io.kestra.plugin.scripts.shell.Script
        forced: true
        values:
          taskRunner:
            type: io.kestra.plugin.scripts.runner.docker.Docker
Retries
Kestra uses external storage and secrets so that your private data and secrets are stored in a secure way in your private infrastructure. These external systems communicate with Kestra through APIs. Those API calls, however, might eperience transient failures. To handle these transient failures, Kestra allows you to set up automatic retries using the kestra.retries configuration.
Here are the available retry configuration options:
kestra.retries.attempts: the max number of retries (default 5)
kestra.retries.delay: the initial delay between retries (default 1s)
kestra.retries.maxDelay: the max amount of time to retry (default undefined)
kestra.retries.multiplier: the multiplier of delay between each attempt (default 2.0)
Note that those retries are only applied to API calls made to internal storage (like S3 or GCS) and to secrets managers (like Vault or AWS Secrets Manager). They are not applied to tasks.
In order to globally configure retries for tasks, you can use the plugin defaults with a global scope tied to the main io.kestra plugin path as follows:
yaml
- type: io.kestra
  retry:
    type: constant # type: string
    interval: PT5M # type: Duration
    maxDuration: PT1H # type: Duration
    maxAttempt: 3 # type: int
    warningOnRetry: true # type: boolean, default is false
Secret Managers
You can configure the secret manager backend using the kestra.secret configuration.
AWS Secret Manager
In order to use AWS Secret Manager as a secrets backend, make sure that your AWS IAM user or role have the required permissions including CreateSecret, DeleteSecret, DescribeSecret, GetSecretValue, ListSecrets, PutSecretValue, RestoreSecret, TagResource, UpdateSecret.
yaml
kestra:
  secret:
    type: aws-secret-manager
    awsSecretManager:
      accessKeyId: mysuperaccesskey
      secretKeyId: mysupersecretkey
      sessionToken: mysupersessiontoken
      region: us-east-1
Azure Key Vault
To configure Azure Key Vault as your secrets backend, make sure that kestra's user or service principal (clientId) has the necessary permissions, including ""Get"", ""List"", ""Set"", ""Delete"", ""Recover"", ""Backup"", ""Restore"", ""Purge"". Then, paste the clientSecret from the Azure portal to the clientSecret property in the configuration below.
yaml
kestra:
  secret:
    type: azure-key-vault
    azureKeyVault:
      clientSecret:
        tenantId: ""id""
        clientId: ""id""
        clientSecret: ""secret""
Elasticsearch
Elasticsearch backend stores secrets with an additional layer of security using AES encryption. You will need to provide a cryptographic key (at least 32 characters-long string) in order to encrypt and decrypt secrets stored in Elasticsearch.
yaml
kestra:
  secret:
    type: elasticsearch
    elasticsearch:
      secret: ""a-secure-32-character-minimum-key""
Google Secret Manager
To leverage Google Secret Manager as your secrets backend, you will need to create a service account with the roles/secretmanager.admin permission. Paste the contents of the service account JSON key file to the serviceAccount property in the configuration below. Alternatively, set the GOOGLE_APPLICATION_CREDENTIALS environment variable to point to the credentials file.
yaml
kestra:
  secret:
    type: google-secret-manager
    googleSecretManager:
      project: gcp-project-id
      serviceAccount: |
        Paste here the contents of the service account JSON key file
HashiCorp Vault
Kestra currently supports the KV secrets engine - version 2 as a secrets backend.
To authenticate Kestra with HashiCorp Vault, you can use Userpass, Token or AppRole Auth Methods, all of which requires full read and write policies. You can optionally change root-engine or namespace (if you use Vault Enterprise).
Userpass Auth Method:
yaml
kestra:
  secret:
    type: vault
    vault:
      address: ""http://localhostt:8200""
      password:
        user: john
        password: foo
    cache:
      enabled: true
      maximumSize: 1000
      expireAfterWrite: 60s
Token Auth Method:
yaml
kestra:
  secret:
    type: vault
    vault:
      address: ""http://localhostt:8200""
      token:
        token: your-secret-token
AppRole Auth Method:
yaml
kestra:
  secret:
    type: vault
    vault:
      address: ""http://localhostt:8200""
      appRole:
        path: approle
        roleId: your-role-id
        secretId: your-secret-id
JDBC
yaml
kestra:
  secret:
    type: jdbc
    jdbc:
      secret: ""your-secret-key""
Secret Tags
yaml
kestra:
  secret:
    <secret-type>:
      # a map of default key/value tags
      tags:
        application: kestra-production
Secret Cache
yaml
kestra:
  secret:
    cache:
      enabled: true
      maximumSize: 1000
      expireAfterWrite: 60s
Security
Using the kestra.security configuration, you can set up multiple security features of Kestra.
Super-Admin
The most powerful user in Kestra is the SuperAdmin
You can create a SuperAdmin user from the kestra.security.superAdmin configuration.
The super-admin requires three properties:
kestra.security.superAdmin.username: the username of the super-admin
kestra.security.superAdmin.password: the password of the super-admin
kestra.security.superAdmin.tenantAdminAccess: a list of tenants that the super-admin can access
This property can be omitted if you do not use multi-tenancy
If a Tenant does not exists, it will be created
At each startup, this user is checked and if the list of access permissions has been modified, new access permissions can be created, but none will be removed
The password should never be stored in clear text in the configuration file. Make sure to use an environment variable in the format ${KESTRA_SUPERADMIN_PASSWORD}.
yaml
kestra:
  security:
    superAdmin:
      username: your_username
      password: ${KESTRA_SUPERADMIN_PASSWORD}
      tenantAdminAccess:
        - <optional>
Default Role
The default role is the role that will be assigned to a new user when it is created.
You can define the default role using the kestra.security.defaultRole configuration. Whenever you start Kestra, the default role will be checked and created if it doesn't exist.
The default role requires three properties:
kestra.security.defaultRole.name: the name of the default role
kestra.security.defaultRole.description: the description of the default role
kestra.security.defaultRole.permissions: the permissions of the default role
This has to be a map with a Permission as a key and a list of Action as a value
yaml
kestra:
  security:
    defaultRole:
      name: default
      description: ""Default role""
      permissions:
        FLOW: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
When using multitenancy, the default role will be added to every tenant and will grant specified access permissions to new users across all tenants. If you prefer to restrict the default role to only allow access to a given tenant e.g. staging, you can add the tenantId property as follows:
yaml
kestra:
  security:
    defaultRole:
      name: default
      description: ""Default role""
      permissions:
        FLOW: [""CREATE"", ""READ"", ""UPDATE"", ""DELETE""]
      tenantId: staging
Make sure that you attach the defaultRole configuration under kestra.securityrather than under micronaut.security ‚Äî it's easy to confuse the two so make sure you enter that configuration in the right place.
Server
Using the kestra.server configuration, you can set up multiple server-specific functionalities.
HTTP Basic Authentication
You can protect your Kestra installation with HTTP Basic Authentication.
yaml
kestra:
  server:
    basicAuth:
      enabled: true
      username: admin
      password: kestra
HTTP Basic Authentication is disabled by default - you can enable it in your Kestra configuration, as shown above. If you need more fine-grained control over user and access management, the Enterprise Edition provides additional authentication mechanisms, including features such as SSO and RBAC. For more details, see the Authentication page.
Delete configuration files
kestra.configurations.deleteFilesOnStart:
This setting allows to delete all configuration files after the server startup. It prevents the ability to read configuration files (that may contain your secrets) from a Bash task for example. The server will keep these values in memory, and they won't be accessible from tasks.
Type Boolean
Default false
Server Liveness & Heartbeats
Kestra's servers use a heartbeat mechanism to periodically send their current state to the Kestra backend, indicating their liveness. That mechanism is crucial for the timely detection of server failures and for ensuring seamless continuity in workflow executions.
Here are the configuration parameters for all server types starting from Kestra 0.16.0.
Note that although it's recommended to deploy the same configuration for all Kestra servers, it's perfectly safe to set different values for those parameters depending on the server type.
kestra.server.liveness.enabled
Enable the liveness probe for the server. This property controls whether a server can be detected as DISCONNECTED or not. Must always be true for production environment.
Type Boolean
Default true
kestra.server.liveness.interval
Frequency at which an Executor will check the liveness of connected servers.
Type Duration
Default 5s
kestra.server.liveness.timeout
The time an Executor will wait for a state update from a server before considering it as DISCONNECTED.
Type Duration
Default 45s
Note that this parameter MUST be configured with the same value for all Executor server.
kestra.server.liveness.initialDelay
The initial delay after which an Executor will start monitoring the liveliness of a server joining the cluster.
Type Duration
Default 45s
Note that this parameter MUST be configured with the same value for all Executor server.
kestra.server.liveness.heartbeatInterval
The interval at which a server will send a heartbeat indicating its current state. Must be strictly inferior to kestra.server.liveness.timeout.
Type Duration
Default 3s
Recommended configuration for production
Here is the default and recommended configuration for production ():
For JDBC deployment-mode (OSS):
yaml
kestra:
  server:
    liveness:
      enabled: true
      interval: 5s
      timeout: 45s
      initialDelay: 45s
      heartbeatInterval: 3s
For Kafka deployment-mode (Enterprise Edition):
yaml
kestra:
  server:
    liveness:
      timeout: 1m
      initialDelay: 1m
Note that Worker liveness is directly managed by the Apache Kafka protocol which natively provides durability and reliability of task executions.
For Kestra versions prior to 0.16.0
Heartbeat Frequency
The interval at which a Worker will send a heartbeat indicating its current state can be configured using the kestra.heartbeat.frequency configuration.
Type Duration
Default 10s
Heartbeat Missed
The number of missed heartbeats before Executors will consider a Worker as DEAD can be configured using the kestra.heartbeat.heartbeatMissed configuration.
Type Integer
Default 3
Worker Task Restart Strategy
Starting with Kestra 0.16.0, you can configure the strategy to be used by Executors when a Worker is detected as unhealthy regarding uncompleted tasks (JDBC deployment mode).
kestra.server.workerTaskRestartStrategy
The strategy to be used for restarting uncompleted tasks in the event of a worker failure.
Supported strategies are:
NEVER:
Tasks will never be restarted in the event of a worker failure (i.e., tasks are run at most once).
IMMEDIATELY:
Tasks will be restarted immediately in the event of a worker failure, (i.e., as soon as a worker is detected as DISCONNECTED). This strategy can be used to reduce task recovery times at the risk of introducing duplicate executions (i.e., tasks are run at least once).
AFTER_TERMINATION_GRACE_PERIOD:
Tasks will be restarted on worker failure after the kestra.server.terminationGracePeriod. This strategy should prefer to reduce the risk of task duplication (i.e., tasks are run exactly once in the best effort).
Type String
Default AFTER_TERMINATION_GRACE_PERIOD
Valid values: [ NEVER, IMMEDIATELY, AFTER_TERMINATION_GRACE_PERIOD ]
Termination Grace Period
When a Kestra Server receives a SIGTERM signal it will immediately try to stop gracefully.
Starting with Kestra 0.16.0, you can configure the termination grace period for each Kestra Server. The termination grace period defines the allowed period for a server to stop gracefully.
kestra.server.terminationGracePeriod
The expected time for the server to complete all its tasks before shutting down.
Type Duration
Default 5m
Internal Storage
Using the kestra.storage configuration, you can set up the desired internal storage type for Kestra.
The default internal storage implementation is the local storage which is not suitable for production as it will store data in a local folder on the host filesystem.
This local storage can be configured as follows:
yaml
kestra:
  storage:
    type: local
    local:
      basePath: /tmp/kestra/storage/ # your custom path
Other internal storage types include:
Storage S3 for AWS S3
Storage GCS for Google Cloud Storage
Storage Minio compatible with others S3 like storage services
Storage Azure for Azure Blob Storage
S3
First, make sure that the S3 storage plugin is installed in your environment. You can install it with the following Kestra command: ./kestra plugins install io.kestra.storage:storage-s3:LATEST. This command will download the plugin's jar file into the plugin's directory.
Then, enable the storage using the following configuration:
yaml
kestra:
  storage:
    type: s3
    s3:
      endpoint: ""<your-s3-endpoint>"" # Only needed if you host your own S3 storage
      accessKey: ""<your-aws-access-key-id>""
      secretKey: ""<your-aws-secret-access-key>""
      region: ""<your-aws-region>""
      bucket: ""<your-s3-bucket-name>""
      forcePathStyle: ""<true|false>"" # optional, defaults to false, useful if you mandate domain resolution to be path-based due to DNS for eg.
If you are using an AWS EC2 or EKS instance, you can use the default credentials provider chain. In this case, you can omit the accessKey and secretKey options:
yaml
kestra:
  storage:
    type: s3
    s3:
      region: ""<your-aws-region>""
      bucket: ""<your-s3-bucket-name>""
Additional configurations can be found here.
Assume IAM Role - AWS Security Token Service (STS)
Minio
If you use Minio or similar S3-compatible storage options, you can follow the same process as shown above to install the Minio storage plugin. Then, make sure to include the Minio's endpoint and port in the storage configuration:
yaml
kestra:
  storage:
    type: minio
    minio:
      endpoint: ""<your-endpoint>""
      port: ""<your-port>""
      accessKey: ""<your-accessKey>""
      secretKey: ""<your-secretKey>""
      region: ""<your-region>""
      secure: ""<your-secure>""
      bucket: ""<your-bucket>""
      partSize: ""<your-part-size>"" # syntax: <number><unit> (KB, MB, GB), defaults to 5MB
Optionally and if the Minio configured is configured to do so (MINIO_DOMAIN=my.domain.com environment variable on Minio server), you can also use the kestra.storage.minio.vhost: true property to make Minio client to use the virtual host syntax.
Please note that the endpoint should always be your base domain (even if you use the virtual host syntax). In the above example, endpoint: my.domain.com, bucket: my-bucket. Setting endpoint: my-bucket.my.domain.com will lead to failure.
Azure
First, install the Azure storage plugin. To do that, you can leverage the following Kestra command: ./kestra plugins install io.kestra.storage:storage-azure:LATEST. This command will download the plugin's jar file into the plugins directory.
Adjust the storage configuration shown below depending on your chosen authentication method:
yaml
kestra:
  storage:
    type: azure
    azure:
      endpoint: ""https://unittestkt.blob.core.windows.net""
      container: storage
      connectionString: ""<connection-string>""
      sharedKeyAccountName: ""<shared-key-account-name>""
      sharedKeyAccountAccessKey: ""<shared-key-account-access-key>""
      sasToken: ""<sas-token>""
Note that your Azure Blob Storage should disable Hierarchical namespace as this feature is not supported in Kestra.
GCS
You can install the GCS storage plugin using the following Kestra command: ./kestra plugins install io.kestra.storage:storage-gcs:LATEST. This command will download the plugin's jar file into the plugins directory.
Then, you can enable the storage using the following configuration:
yaml
kestra:
  storage:
    type: gcs
    gcs:
      bucket: ""<your-bucket-name>""
      projectId: ""<project-id or use default projectId>""
      serviceAccount: ""<serviceAccount key as JSON or use default credentials>""
If you haven't configured the kestra.storage.gcs.serviceAccount option, Kestra will use the default service account, which is:
the service account defined on the cluster (for GKE deployments)
the service account defined on the compute instance (for GCE deployments).
You can also provide the environment variable GOOGLE_APPLICATION_CREDENTIALS with a path to a JSON file containing GCP service account key.
You can find more details in the GCP documentation.
System Flows
By default, the system namespace is reserved for System Flows. These background workflows are intended to perform routine tasks such as sending alerts and purging old logs. If you want to overwrite the name used for System Flows, use the kestra.system-flows configuration:
yaml
kestra:
  systemFlows:
    namespace: system
Tasks
Using the kestra.tasks configuration, you can set up multiple task-specific features.
Plugin Default Configuration
You can set defaults for specific tasks using the kestra.plugins.defaults configuration. These defaults will be applied to all tasks on your cluster if a property is not defined on flows or tasks.
You can use this to isolate tasks in containers, such as scripting tasks. For Bash tasks and other script tasks in the core, we advise you to force io.kestra.plugin.scripts.runner.docker.Docker isolation and to configure global cluster pluginDefaults:
yaml
kestra:
  plugins:
    defaults:
      - type: io.kestra.plugin.scripts.shell.Commands
        forced: true
        values:
          containerImage: ubuntu:latest
          taskRunner:
            type: io.kestra.plugin.scripts.runner.docker.Docker
Volume Enabled for Docker Task Runner
Volumes mount are disabled by default for security reasons, you can enabled it with this configurations:
yaml
kestra:
  plugins:
    configurations:
      - type: io.kestra.plugin.scripts.runner.docker.Docker
        values:
          volumeEnabled: true
Temporary storage configuration
Kestra writes temporary files during task processing. By default, files will be created on /tmp, but you can change the location with this configuration:
yaml
kestra:
  tasks:
    tmpDir:
      path: /home/kestra/tmp
Note: The tmpDir path must be aligned to the volume path otherwise Kestra will not know what directory to mount for the tmp directory.
yaml
volumes:
  - kestraData:/app/storage
  - /var/run/docker.sock:/var/run/docker.sock
  - /home/kestra:/home/kestra
In this example, /home/kestra:/home/kestra matches the tasks tmpDir field.
Tutorial Flows
Tutorial flows are used to help users understand how Kestra works. They are used in the Guided Tour that allows you to select your use case and see how Kestra can help you solve it. You can disable the tutorial flows in production using the kestra.tutorialFlows configuration:
yaml
kestra:
  tutorialFlows:
    enabled: false
Disable Tutorial Flows
To disable the tutorial flows, set the tutorialFlows property to false in your configuration file.
yaml
kestra:
  tutorialFlows:
    enabled: false # true by default
The tutorial flows are included in the open-source edition of Kestra by default. It's recommended to set that property to false in production environments to avoid unnecessary flows from being loaded into the production system.
Enabling Templates
Templates are marked as deprecated and disabled by default starting from the 0.11.0 release. You can re-enable them with the kestra.templates configuration:
yaml
kestra:
  templates:
    enabled: true
Kestra URL
Some notification services require a URL configuration defined in kestra.url in order to add links from the alert message. Use a full URI here with a trailing / (without ui or api).
yaml
kestra:
  url: https://www.my-host.com/kestra/
Variables
Using the kestra.variables configuration, you can determine how variables are handled in Kestra.
Environment Variables Prefix
Kestra provides a way to use environment variables in your flow. By default, Kestra will only look at environment variables that start with KESTRA_. You can change this prefix by setting the kestra.variables.envVarsPrefix configuration option:
yaml
kestra:
  variables:
    envVarsPrefix: KESTRA_
These variables will be accessible in a flow with {{ envs.your_env }} in lowercase without the prefix.
For example, an environment variable with the name KESTRA_MY_ENV can be accessed using {{ envs.my_env }}.
Global Variables
You can also set global variables directly in the kestra.variables.globals configuration. These variables will be accessible in all flows across the instance.
For example, the following variable will be accessible in a flow using {{ globals.host }}:
yaml
kestra:
  variables:
    globals:
      host: pg.db.prod
Keep in mind that if a variable is in camel case, it will be transformed into hyphenated case. For example, the global variable shown below will be accessible in flows with {{ globals['myVar'] }} or {{ globals['environment-name'] }}:
yaml
kestra:
  variables:
    globals:
      environment_name: dev
      myVar: my variable
Recursive Rendering
The kestra.variables.recursiveRendering configuration allows you to enable the pre-0.14.0 recursive rendering behavior and give administrators more time to migrate deployed flows. It defaults to false:
yaml
kestra:
  variables:
    recursiveRendering: true
The rendering of template variables can be CPU intensive, and by default we enable a cache of ""templates"". You can disable it using the kestra.variables.cacheEnabled configuration:
yaml
kestra:
  variables:
    cacheEnabled: false
We recommend keeping the cache enabled, as it can improve the performance.
Cache Size
The rendering of template variables cache is an LRU cache (keeps most commonly used variables) and will be cached in memory (default 1000). You can change the size of the template cache (in number of templates) using the kestra.variables.cacheSize configuration.
yaml
kestra:
  variables:
    cacheSize: 1000
Keep in mind that the higher this number will be, the more memory the server will use.
Webserver
Using the kestra.webserver configuration, you can adjust the settings of the Kestra webserver.
Google Analytics ID
Using the kestra.webserver.googleAnalytics configuration, you can add a Google Analytics tracking ID to report all page tracking. Here is an example of how you can add your Google Analytics tracking ID:
yaml
kestra:
  webserver:
    googleAnalytics: UA-12345678-1
Append HTML tags to the webserver application
With the help of the kestra.webserver.htmlHead configuration, you can append HTML tags to the webserver application. This can bw used to inject CSS or JavaScript to customize the web application.
For example, here is how you can add a red banner in production environments:
yaml
kestra:
  webserver:
    htmlHead: |
      <style type=""text/css"">
        .v-sidebar-menu .logo:after {
          background: var(--danger);
          display: block;
          content: ""Local"";
          position: relative;
          textTransform: uppercase;
          bottom: -65px;
          textAlign: center;
          color: var(--white-always);
        }
      </style>
Was this page helpful?
Yes
No
0.19.0
Deprecation of State Store in favor of KV Store
Docs
Expressions""""""",13352,60386,kestra
https://kestra.io/docs/expressions,"""""""DocsExpressions
Expressions
Table of Contents
Overview
Using Expressions
Flow and Execution Expressions
Default Execution Context Variables
Environment Variables
Global Variables
Flow Variables
Inputs
Secrets
Namespace Variables (EE)
Outputs
Pebble Templating
Parsing Complex Variables
Render Function and Null-Coalescing
Expression Usage
Syntax Reference
Filters
Functions
Control Structures
Macros
Named Arguments
Comments
Literals
Collections
Math
Logical Operators
Comparisons
Tests
Conditional (Ternary) Operator
Null-Coalescing Operator
Operator Precedence
Basic Filters
JSON Filters
toJson
jq
Manipulating JSON Payloads
Numeric Filters
abs
number
numberFormat
Object Filters
chunk
className
first
join
keys
values
last
length
merge
reverse
rsort
slice
sort
split
String Filters
abbreviate
base64decode
base64encode
capitalize
title
default
escapeChar
lower
replace
sha256
startsWith
slugify
substringAfter
substringAfterLast
substringBefore
substringBeforeLast
trim
upper
urldecode
urlencode
Temporal Filters
date
dateAdd
timestamp
timestampMicro
timestampNano
Example with Temporal Filters
YAML Filters
yaml
indent
nindent
Example with indent and nindent
Functions
block
currentEachOutput
fromJson
yaml
max
min
now
parent
range
printContext
read
render
renderOnce
secret
Example with Functions
Operators
Comparison Operators
concat
contains
is
logic
math
not
null-coalescing
ternary operator
Tag
block
filter
for
if
macro
raw
set
Test
defined
empty
even
iterable
json
map
null
odd
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Expressions & Context Variables
Overview
Kestra's expressions combine the Pebble templating engine with the execution context to dynamically render flow properties. This page lists available expressions and explains how to use them in your flows.
Using Expressions
To dynamically set values in your flows, wrap an expression in curly braces, e.g. {{ your_expression }}.
Flows, tasks, executions, triggers, and schedules come with built-in expressions. For example:
{{ flow.id }} gives the flow's identifier within an execution
{{ inputs.myinput }} retrieves an input value passed to the execution
{{ outputs.mytask.myoutput }} fetches a task's output.
To debug expressions, use the Debug Outputs console as demonstrated in the video below:
Flow and Execution Expressions
Flow and execution expressions let you use the execution context to set task properties. For example, you can reference {{ execution.startDate }} to include the execution's start date in a file name.
Some expressions, such as flow.id or flow.namespace, access metadata stored in the execution context. Others, such as FILE-type inputs and outputs, pull data from Kestra's internal storage or environment variables.
The execution context includes these variables:
flow
execution
inputs
outputs
labels
tasks
trigger ‚Äî available if at least one trigger is defined in the flow
vars ‚Äî available if variables are defined in the flow configuration
namespace ‚Äî available in EE when Variables are set in the Namespace configuration
envs ‚Äî environment variables
globals ‚Äî global variables.
To see all metadata available in the execution context, use {{ printContext() }} in the Debug Outputs console.
Default Execution Context Variables
The following table lists the default execution context variables available in Kestra:
Parameter Description
{{ flow.id }} Identifier of the flow.
{{ flow.namespace }} Namespace of the flow.
{{ flow.tenantId }} Identifier of the tenant (Enterprise Edition only).
{{ flow.revision }} Revision number of the flow.
{{ execution.id }} Unique ID of the execution.
{{ execution.startDate }} Start date of the execution, which can be formatted using {{ execution.startDate | date(""yyyy-MM-dd HH:mm:ss.SSSSSS"") }}.
{{ execution.originalId }} Original execution ID, remains the same even during replay, retaining the first execution ID.
{{ task.id }} ID of the current task.
{{ task.type }} Type of the current task (Java fully qualified class name).
{{ taskrun.id }} ID of the current task run.
{{ taskrun.startDate }} Start date of the current task run.
{{ taskrun.attemptsCount }} Number of attempts for the current task (includes retries or restarts).
{{ taskrun.parentId }} Parent ID of the current task run. Available only for tasks nested under a Flowable task.
{{ taskrun.value }} Value of the current task run. Available only for tasks wrapped in Flowable tasks.
{{ parent.taskrun.value }} Value of the nearest parent task run. Available only for tasks nested under a Flowable task.
{{ parent.outputs }} Outputs of the nearest parent task run. Available only for tasks nested under a Flowable task.
{{ parents }} List of parent tasks. Available only for tasks nested under a Flowable task.
{{ labels }} Execution labels accessible by keys, e.g. {{ labels.myKey }}.
Additional Variables for Schedule Trigger
When the execution is triggered by a Schedule, the following variables are also available:
Parameter Description
{{ trigger.date }} Date of the current schedule.
{{ trigger.next }} Date of the next schedule.
{{ trigger.previous }} Date of the previous schedule.
Additional Variables for Flow Trigger
When the execution is triggered by a Flow, the following variables are also available:
Parameter Description
{{ trigger.executionId }} ID of the execution triggering the current flow.
{{ trigger.namespace }} Namespace of the flow triggering the current flow.
{{ trigger.flowId }} ID of the flow triggering the current flow.
{{ trigger.flowRevision }} Revision of the flow triggering the current flow.
All expressions can be used with the Pebble template syntax {{ expression }}. For example:
yaml
id: expressions
namespace: company.team
tasks:
  - id: debug_expressions
    type: io.kestra.plugin.core.debug.Return
    format: |
      taskId: {{ task.id }}
      date: {{ execution.startDate | date(""yyyy-MM-dd HH:mm:ss.SSSSSS"") }}
Use the date filter to format the execution.startDate variable as yyyy-MM-dd HH:mm:ss.SSSSSS, e.g., {{ execution.startDate | date(""yyyy-MM-dd HH:mm:ss.SSSSSS"") }}.
Environment Variables
Kestra provides access to environment variables prefixed with KESTRA_ by default, unless configured otherwise in the variables configuration.
To use an environment variable, such as KESTRA_FOO, reference it as {{ envs.foo }}. The variable name is derived by removing the KESTRA_ prefix and converting the remainder to lowercase.
Global Variables
You can define global variables in Kestra's configuration and access them using {{ globals.foo }}.
Flow Variables
To avoid hardcoding values in tasks, you can declare variables at the flow level using the variables property. These variables can be accessed anywhere in the flow with the vars.my_variable syntax. For example:
yaml
id: flow_variables
namespace: company.team
variables:
  my_variable: ""my_value""
tasks:
  - id: print_variable
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ vars.my_variable }}""
Inputs
Flow inputs can be referenced using the inputs.inputName syntax. For example:
yaml
id: render_inputs
namespace: company.team
inputs:
  - id: myInput
    type: STRING
tasks:
  - id: myTask
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ inputs.myInput }}""
Secrets
You can retrieve secrets in your flow using the secret() function. Secrets are stored in a secure way and can be accessed as follows:
yaml
id: use_secret_in_flow
namespace: company.team
tasks:
  - id: myTask
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ secret('MY_SECRET') }}""
Secrets are supported in both the open-source version and Enterprise Edition. For additional details, refer to the Secrets documentation.
Namespace Variables (EE)
Namespace variables are key-value pairs defined in YAML configuration. They can be nested and referenced in flows using dot notation, e.g., {{ namespace.myproject.myvariable }}. To define namespace variables:
Navigate to Namespaces in the Kestra UI.
Select the namespace.
Add variables in the Variables tab.
Namespace variables are scoped to the specific namespace and inherited by child namespaces. Reference these variables in your flow using the namespace.your_variable syntax. Example:
yaml
id: namespace_variables
namespace: company.team
tasks:
  - id: myTask
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ namespace.your_variable }}""
If a namespace variable contains Pebble expressions, such as {{ secret('GITHUB_TOKEN') }}, you need to use the render function to evaluate it. For example, assume the following variable is defined in the Variables tab:
yaml
github:
  token: ""{{ secret('GITHUB_TOKEN') }}""
To reference github.token in your flow, use ""{{ render(namespace.github.token) }}"":
yaml
id: recursive_namespace_variables_rendering
namespace: company.team
tasks:
  - id: myTask
    type: io.kestra.plugin.core.debug.Return
    format: ""{{ render(namespace.github.token) }}""
The render() function is required to parse namespace or flow variables containing Pebble expressions. Without it, the variable is treated as a string, and its expressions are not evaluated.
Outputs
Task outputs can be accessed using {{ outputs.taskId.outputAttribute }}, where:
taskId is the ID of the task
outputAttribute is the attribute of the task's output. Each task emits specific output attributes ‚Äî refer to task documentation for details.
Example of passing data between tasks using outputs:
yaml
id: pass_data_between_tasks
namespace: company.team
tasks:
  - id: first
    type: io.kestra.plugin.core.debug.Return
    format: First output value
  - id: second-task
    type: io.kestra.plugin.core.debug.Return
    format: Second output value
  - id: print_both_outputs
    type: io.kestra.plugin.core.log.Log
    message: |
      First: {{ outputs.first.value }}
      Second: {{ outputs['second-task'].value }}
The Return-type task emits an output attribute called value. The print_both_outputs task demonstrates two ways to access outputs:
Dot notation: {{ outputs.first.value }}
Subscript notation: {{ outputs['second-task'].value }} ‚Äî required for task IDs with special characters (e.g., hyphens). We recommend using camelCase or snake_case for task IDs to avoid this issue.
Pebble Templating
Pebble templating provides many ways to dynamically evaluate expressions.
The example below demonstrates parsing Pebble expressions within variables, based on inputs and trigger values. The Null-Coalescing Operator ?? is used to select the first non-null value.
Parsing Complex Variables
The workflow shown below defines two variables:
trigger_or_yesterday:
Evaluates to trigger.date if the flow runs on a schedule.
If no schedule is available, it defaults to yesterday‚Äôs date by subtracting one day from execution.startDate.
input_or_yesterday:
Evaluates to the mydate input if provided.
If the input is absent, it defaults to yesterday‚Äôs date, calculated using execution.startDate minus one day with the dateAdd function.
yaml
id: render_complex_expressions
namespace: company.team
inputs:
  - id: mydate
    type: DATETIME
    required: false
variables:
  trigger_or_yesterday: ""{{ trigger.date ?? (execution.startDate | dateAdd(-1, 'DAYS')) }}""
  input_or_yesterday: ""{{ inputs.mydate ?? (execution.startDate | dateAdd(-1, 'DAYS')) }}""
tasks:
  - id: yesterday
    type: io.kestra.plugin.core.log.Log
    message: ""{{ render(vars.trigger_or_yesterday) }}""
  - id: input_or_yesterday
    type: io.kestra.plugin.core.log.Log
    message: ""{{ render(vars.input_or_yesterday) }}""
Render Function and Null-Coalescing
render Function: the render function is required to evaluate variables containing Pebble expressions. Without it, variables will be treated as strings, and expressions inside them will not be evaluated.
Null-Coalescing Operator (??): this operator ensures that the first non-null value is selected, providing a fallback mechanism.
Combining the render() function with the Null-Coalescing operator enables dynamic and flexible parsing of complex expressions.
Expression Usage
This section summarizes the main syntax of filters, functions, and control structures available in Pebble templating.
Syntax Reference
Pebble templates use two primary delimiters:
{{ ... }}: outputs the result of an expression. Expressions can be simple variables or complex calculations.
{% ... %}: controls the template‚Äôs flow, such as with if statements or for loops.
To escape expressions or control structures, use the raw tag. This prevents Pebble from interpreting content within {{ ... }} or {% ... %}.
Dot notation (.) is used to access nested attributes. For attributes with special characters, use square brackets:
twig
{{ foo.bar }} # Accesses 'bar' in 'foo'
{{ foo['foo-bar'] }} # Accesses 'foo-bar' in 'foo'
For names with hyphens (-), use subscript notation: {{ outputs.mytask.myoutput['foo-bar'] }}. To avoid this, use camelCase or snake_case for names.
For lists, access elements by index with square brackets ([]):
twig
{{ foo[0] }} # Accesses the first element in the list 'foo'
Filters
Filters transform values and are applied using the pipe (|) symbol. Filters can be chained:
twig
{{ ""Lemons to lemonade."" | upper | abbreviate(10) }}
# Output: LEMONS TO ...
Functions
Functions generate new values. They are called with a name followed by parentheses:
twig
{{ max(user.score, highscore) }}
# Outputs the maximum of 'user.score' and 'highscore'
Control Structures
Pebble supports loops and conditionals to control the flow of templates.
For Loop:
twig
{% for article in articles %}
  {{ article.title }}
{% else %}
  ""No articles available.""
{% endfor %}
If Statement:
twig
{% if category == ""news"" %}
  {{ news }}
{% elseif category == ""sports"" %}
  {{ sports }}
{% else %}
  ""Select a category""
{% endif %}
Macros
Macros are reusable template snippets, similar to functions:
twig
{% macro input(type, name) %}
  {{ name }} is of type {{ type }}
{% endmacro %}
Usage:
twig
{{ input(""text"", ""example"") }}
# Output: example is of type text
Macros only access their local arguments.
Named Arguments
Filters, functions, and macros support named arguments for clarity:
twig
{{ stringDate | date(existingFormat=""yyyy-MMMM-d"", format=""yyyy/MMMM/d"") }}
Named arguments can define defaults in macros:
twig
{% macro input(type=""text"", name, value="""") %}
  type: ""{{ type }}"", name: ""{{ name }}"", value: ""{{ value }}""
{% endmacro %}
{{ input(name=""country"") }}
# Output: type: ""text"", name: ""country"", value: """"
Comments
Add comments using {# ... #}. They do not appear in output:
twig
{# This is a comment #}
{{ ""Visible content"" }}
In YAML, use # for comments.
Literals
Pebble supports literals for strings, numbers, booleans, and null values:
""Hello World"": Strings use single or double quotes.
100 + 10l * 2.5: Numbers include integers, longs, and floats.
true, false: Boolean values.
null: Represents no value.
Collections
Create lists and maps directly:
[""apple"", ""banana""]: a list of strings.
{""apple"":""red"", ""banana"":""yellow""}: a map of key-value pairs.
Math
Basic mathematical operators are supported:
+: Addition
-: Subtraction
*: Multiplication
/: Division
%: Modulus
Logical Operators
Combine expressions using:
and: True if both are true.
or: True if either is true.
not: Negates an expression.
Comparisons
Pebble supports common comparison operators: ==, !=, <, >, <=, >=.
Tests
Use the is operator to test expressions:
twig
{% if 3 is odd %}
  ""Odd number""
{% endif %}
Negate tests with is not:
twig
{% if name is not null %}
  ""Name exists""
{% endif %}
Conditional (Ternary) Operator
The conditional operator (?) works like Java's ternary operator:
twig
{{ foo ? ""yes"" : ""no"" }}
Null-Coalescing Operator
The ?? operator provides a fallback if a variable is null:
twig
{{ foo ?? bar ?? ""default"" }}
Raises an exception if no variable is defined:
twig
{{ foo ?? bar ?? raise }}
Operator Precedence
Operators are evaluated in the following order:
.
|
%, /, *
-, +
==, !=, >, <, >=, <=
is, is not
and
or
Basic Filters
Filters transform variables in expressions, allowing for operations like formatting, string manipulation, and list processing. Filters are applied using the pipe symbol (|) and can be chained together.
To apply a filter, use this syntax:
twig
{{ name | title }}
This example converts name to title case.
Filters that accept arguments use parentheses. For example, to join a list of strings with commas:
twig
{{ list | join(', ') }}
To apply a filter to a block of text, wrap it with the filter tag:
twig
{% filter lower | title %}
  hello world
{% endfilter %}
JSON Filters
JSON filters are specifically designed to manipulate JSON objects, such as API responses.
toJson
The toJson filter converts any object into a JSON string. Examples:
twig
{{ [1, 2, 3] | toJson }} # Outputs: '[1, 2, 3]'
{{ true | toJson }} # Outputs: 'true'
{{ ""foo"" | toJson }} # Outputs: '""foo""'
In versions prior to v0.18.0, this filter was named json. Using json will still work but raises a warning in the UI.
jq
The jq filter applies a JQ expression to a variable. The result is always an array formatted as JSON. Use the first filter to extract the first (or only) result.
Examples:
twig
{{ [1, 2, 3] | jq('.') }}
# Outputs: '[1, 2, 3]'
{{ [1, 2, 3] | jq('.[0]') | first }}
# Outputs: '1'
Given the context:
json
{
  ""outputs"": {
    ""task1"": {
      ""value"": 1,
      ""text"": ""awesome1""
    },
    ""task2"": {
      ""value"": 2,
      ""text"": ""awesome2""
    }
  }
}
The following expression extracts the value of task1:
twig
{{ outputs | jq('.task1.value') | first }}
# Outputs: '1'
Arguments
expression: The JQ expression to apply.
Manipulating JSON Payloads
Here is a comprehensive example of JSON manipulation. This flow takes a JSON payload as input and performs multiple transformations:
yaml
id: myflow
namespace: company.myteam
inputs:
  - id: payload
    type: JSON
    defaults: |-
      {
        ""name"": ""John Doe"",
        ""score"": {
          ""English"": 72,
          ""Maths"": 88,
          ""French"": 95,
          ""Spanish"": 85,
          ""Science"": 91
        },
        ""address"": {
          ""city"": ""Paris"",
          ""country"": ""France""
        },
        ""graduation_years"": [2020, 2021, 2022, 2023]
      }
tasks:
  - id: print_status
    type: io.kestra.plugin.core.log.Log
    message:
      - ""Student name: {{ inputs.payload.name }}"" # Extracting a value
      - ""Score in languages: {{ inputs.payload.score.English + inputs.payload.score.French + inputs.payload.score.Spanish }}"" # Summing numbers
      - ""Total subjects: {{ inputs.payload.score | length }}"" # Counting keys in a map
      - ""Total score: {{ inputs.payload.score | values | jq('reduce .[] as $num (0; .+$num)') | first }}"" # Summing all values
      - ""Complete address: {{ inputs.payload.address.city }}, {{ inputs.payload.address.country | upper }}"" # Concatenation and transformation
      - ""Total years for graduation: {{ inputs.payload.graduation_years | length }}"" # Counting array elements
      - ""Started college in: {{ inputs.payload.graduation_years | first }}"" # First element in an array
      - ""Completed college in: {{ inputs.payload.graduation_years | last }}"" # Last element in an array
Running this flow will log:
Student name: John Doe
Score in languages: 252
Total subjects: 5
Total score: 431
Complete address: Paris, FRANCE
Total years for graduation: 4
Started college in: 2020
Completed college in: 2023
Numeric Filters
Numeric filters are used to format numbers or convert strings to numbers.
abs
The abs filter returns the absolute value of a number.
twig
{{ -7 | abs }}
# output: 7
number
The number filter parses a string into a number. If no type is specified, the type is inferred.
twig
{{ ""12.3"" | number | className }}
# output: java.lang.Float
{{ ""9223372036854775807"" | number('BIGDECIMAL') | className }}
# output: java.math.BigDecimal
type:
INT
FLOAT
LONG
DOUBLE
BIGDECIMAL
BIGINTEGER
numberFormat
The numberFormat filter formats a number using java.text.DecimalFormat.
twig
{{ 3.141592653 | numberFormat(""#.##"") }}
# output: 3.14
Object Filters
Object filters manipulate collections such as maps, arrays, or strings.
chunk
The chunk filter partitions a list into chunks of the specified size.
twig
{{ [1, 2, 3, 4, 5] | chunk(2) }}
# results in: [[1, 2], [3, 4], [5]]
className
The className filter returns the class name of an object.
twig
{{ ""12.3"" | number | className }}
# output: java.lang.Float
first
The first filter retrieves the first item of a collection or the first character of a string.
twig
{{ ['apple', 'banana'] | first }}
# output: apple
{{ 'Mitch' | first }}
# output: M
join
The join filter concatenates the items in a collection into a single string, separated by a specified delimiter.
twig
{{ ['apple', 'banana'] | join(', ') }}
# output: apple, banana
keys
The keys filter retrieves the keys from a map or the indices of an array.
twig
{{ {'foo': 'bar', 'baz': 'qux'} | keys }}
# output: ['foo', 'baz']
values
The values filter retrieves the values from a map.
twig
{{ {'foo': 'bar', 'baz': 'qux'} | values }}
# output: ['bar', 'qux']
last
The last filter retrieves the last item of a collection or the last character of a string.
twig
{{ ['apple', 'banana'] | last }}
# output: banana
{{ 'Mitch' | last }}
# output: h
length
The length filter returns the size of a collection or the length of a string.
twig
{{ 'Mitch' | length }}
# output: 5
merge
The merge filter combines two collections (lists or maps).
twig
{{ [1, 2] | merge([3, 4]) }}
# output: [1, 2, 3, 4]
reverse
The reverse filter reverses the order of items in a collection.
twig
{{ ['apple', 'banana'] | reverse }}
# output: ['banana', 'apple']
rsort
The rsort filter sorts a list in reverse order.
twig
{{ [3, 1, 2] | rsort }}
# output: [3, 2, 1]
slice
The slice filter extracts a portion of a collection or string.
twig
{{ ['apple', 'banana', 'cherry'] | slice(1, 2) }}
# output: ['banana']
{{ 'Mitch' | slice(1, 3) }}
# output: it
Arguments:
fromIndex: starting index (inclusive).
toIndex: ending index (exclusive).
sort
The sort filter sorts a collection in ascending order.
twig
{{ [3, 1, 2] | sort }}
# output: [1, 2, 3]
split
The split filter divides a string into a list based on a delimiter.
twig
{{ 'apple,banana,cherry' | split(',') }}
# output: ['apple', 'banana', 'cherry']
Arguments:
delimiter: the string to split on.
limit: limits the number of splits:
Positive: limits the array size, with the last entry containing the remaining content.
Zero or negative: no limit on splits.
twig
{{ 'apple,banana,cherry,grape' | split(',', 2) }}
# output: ['apple', 'banana,cherry,grape']
String Filters
String filters manipulate textual data, enabling operations like transformation, encoding, or formatting.
abbreviate
The abbreviate filter shortens a string using an ellipsis. The length includes the ellipsis.
twig
{{ ""this is a long sentence."" | abbreviate(7) }}
# output: this...
Arguments:
length: the maximum length of the output.
base64decode
The base64decode filter decodes a base64-encoded string into UTF-8.
twig
{{ ""dGVzdA=="" | base64decode }}
# output: test
Throws an exception for invalid base64 strings.
base64encode
The base64encode filter encodes a string to base64.
twig
{{ ""test"" | base64encode }}
# output: dGVzdA==
capitalize
The capitalize filter capitalizes the first letter of a string.
twig
{{ ""article title"" | capitalize }}
# output: Article title
title
The title filter capitalizes the first letter of each word.
twig
{{ ""article title"" | title }}
# output: Article Title
default
The default filter provides a fallback value for empty variables.
twig
{{ user.phoneNumber | default(""No phone number"") }}
# output: No phone number (if user.phoneNumber is empty)
Suppresses exceptions if the attribute is missing.
escapeChar
The escapeChar filter escapes special characters in a string.
twig
{{ ""Can't be here"" | escapeChar('single') }}
# output: Can\'t be here
Arguments:
type: escape type (single, double, or shell).
lower
The lower filter converts a string to lowercase.
twig
{{ ""LOUD TEXT"" | lower }}
# output: loud text
replace
The replace filter replaces substrings in a string with specified values.
twig
{{ ""I like %this% and %that%."" | replace({'%this%': foo, '%that%': ""bar""}) }}
# output: I like foo and bar
Arguments:
replace_pairs: a map of search-replace pairs.
regexp: enables regex-based replacements.
sha256
The sha256 filter generates a SHA-256 hash of a string.
twig
{{ ""test"" | sha256 }}
# output: 9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08
startsWith
The startsWith filter checks if a string starts with a given prefix.
twig
{{ ""hello world"" | startsWith(""hello"") }}
# output: true
slugify
The slugify filter converts a string to a URL-friendly format.
twig
{{ ""Hello World!"" | slugify }}
# output: hello-world
substringAfter
The substringAfter filter extracts the substring after the first occurrence of a separator.
twig
{{ ""a.b.c"" | substringAfter(""."") }}
# output: b.c
substringAfterLast
The substringAfterLast filter extracts the substring after the last occurrence of a separator.
twig
{{ ""a.b.c"" | substringAfterLast(""."") }}
# output: c
substringBefore
The substringBefore filter extracts the substring before the first occurrence of a separator.
twig
{{ ""a.b.c"" | substringBefore(""."") }}
# output: a
substringBeforeLast
The substringBeforeLast filter extracts the substring before the last occurrence of a separator.
twig
{{ ""a.b.c"" | substringBeforeLast(""."") }}
# output: a.b
trim
The trim filter removes whitespace from the start and end of a string.
twig
{{ ""   padded text   "" | trim }}
# output: padded text
upper
The upper filter converts a string to uppercase.
twig
{{ ""quiet sentence"" | upper }}
# output: QUIET SENTENCE
urldecode
The urldecode filter decodes a URL-encoded string.
twig
{{ ""The+string+%C3%BC%40foo-bar"" | urldecode }}
# output: The string √º@foo-bar
urlencode
The urlencode filter encodes a string for URLs.
twig
{{ ""The string √º@foo-bar"" | urlencode }}
# output: The+string+%C3%BC%40foo-bar
Temporal Filters
Temporal filters are used for formatting, manipulating, and converting dates and timestamps.
date
The date filter formats a date object or string into a specified format. It supports java.util.Date, java.time constructs like OffsetDateTime, and epoch timestamps in milliseconds.
twig
{{ user.birthday | date(""yyyy-MM-dd"") }}
# output: 2001-07-24
To format a string-based date, provide the desired output format and the existing format of the string:
twig
{{ ""July 24, 2001"" | date(""yyyy-MM-dd"", existingFormat=""MMMM dd, yyyy"") }}
# output: 2001-07-24
Time Zones
Specify a custom time zone using the timeZone argument:
twig
{{ now() | date(""yyyy-MM-dd'T'HH:mm:ssX"", timeZone=""UTC"") }}
Arguments:
format: the desired output format.
existingFormat: the input format (if parsing a string).
timeZone: the time zone for formatting.
locale: the locale for formatting.
Supported Date Formats
Standard Java formats: DateTimeFormatter
Presets: iso, sql, iso_date_time, iso_zoned_date_time, etc.
dateAdd
The dateAdd filter adds or subtracts a specified amount of time to/from a date.
twig
{{ now() | dateAdd(-1, 'DAYS') }}
# output: 2024-07-08T06:17:01.174686Z
Arguments:
amount: an integer specifying the time to add/subtract.
unit: the time unit (e.g., DAYS, HOURS, YEARS).
Additional arguments: same as the date filter.
timestamp
The timestamp filter converts a date to a Unix timestamp in seconds.
twig
{{ now() | timestamp(timeZone=""Europe/Paris"") }}
# output: 1720505821
Arguments:
existingFormat: the input format (if parsing a string).
timeZone: the time zone for conversion.
timestampMicro
The timestampMicro filter converts a date to a Unix timestamp in microseconds.
twig
{{ now() | timestampMicro(timeZone=""Asia/Kolkata"") }}
# output: 1720505821000180275
Arguments:
Same as timestamp.
timestampNano
The timestampNano filter converts a date to a Unix timestamp in nanoseconds.
twig
{{ now() | timestampNano(timeZone=""Asia/Kolkata"") }}
# output: 1720505821182413000
Arguments:
Same as timestamp.
Example with Temporal Filters
Here‚Äôs an example flow showcasing the use of temporal filters:
yaml
id: temporal-dates
namespace: company.myteam
tasks:
  - id: print_status
    type: io.kestra.plugin.core.log.Log
    message:
      - ""Present timestamp: {{ now() }}""
      - ""Formatted timestamp: {{ now() | date('yyyy-MM-dd') }}""
      - ""Previous day: {{ now() | dateAdd(-1, 'DAYS') }}""
      - ""Next day: {{ now() | dateAdd(1, 'DAYS') }}""
      - ""Timezone (seconds): {{ now() | timestamp(timeZone='Asia/Kolkata') }}""
      - ""Timezone (microseconds): {{ now() | timestampMicro(timeZone='Asia/Kolkata') }}""
      - ""Timezone (nanoseconds): {{ now() | timestampNano(timeZone='Asia/Kolkata') }}""
Running this flow will log the following:
Present timestamp: 2024-07-09T06:17:01.171193Z
Formatted timestamp: 2024-07-09
Previous day: 2024-07-08T06:17:01.174686Z
Next day: 2024-07-10T06:17:01.176138Z
Timezone (seconds): 1720505821
Timezone (microseconds): 1720505821000180275
Timezone (nanoseconds): 1720505821182413000
YAML Filters
YAML filters allow you to parse and manipulate YAML strings, converting them into objects that can be processed further.
yaml
The yaml filter, introduced in Kestra 0.16.0, parses a YAML string into an object. This is especially useful when working with templated tasks, such as the TemplatedTask.
Example:
twig
{{ ""foo: bar"" | yaml }}
Example: Using the yaml filter in a templated task
yaml
id: yaml_filter_example
namespace: company.team
tasks:
  - id: yaml_filter
    type: io.kestra.plugin.core.log.Log
    message: |
      {{ ""foo: bar"" | yaml }}
      {{ {""key"": ""value""} | yaml }}
indent
The indent filter adds indentation to strings, applying the specified number of spaces before each line (except the first).
Arguments:
amount: number of spaces to add.
prefix: the string used for indentation (default is "" "").
Example:
twig
{{ ""key: value"" | indent(2) }}
# output:
  key: value
nindent
The nindent filter adds a newline before the input and then indents all lines.
Arguments:
amount: number of spaces for indentation.
prefix: the string used for indentation (default is "" "").
Example:
twig
{{ ""key: value"" | nindent(2) }}
# output:
  key: value
Example with indent and nindent
yaml
id: templated_task_example
namespace: company.team
labels:
  example: test
variables:
  yaml_data: |
    key1: value1
    key2: value2
tasks:
  - id: yaml_with_indent
    type: io.kestra.plugin.core.templating.TemplatedTask
    spec: |
      id: example-task
      type: io.kestra.plugin.core.log.Log
      message: |
        Metadata:
        {{ labels | yaml | indent(4) }}
        Variables:
        {{ variables.yaml_data | yaml | nindent(4) }}
The above example generates a task with indented YAML content for both labels and variables.
Here is an explanation of the filters used:
Using yaml: converts the YAML string into an object.
Using indent(4): adds four spaces before each line.
Using nindent(4): adds a newline and then indents with four spaces.
Functions
Functions in Kestra allow you to dynamically generate or manipulate content. They are invoked by their name followed by parentheses () and can accept arguments.
block
The block function renders the contents of a block multiple times. It is distinct from the block tag used to declare blocks.
Example:
twig
{% block ""post"" %}content{% endblock %}
{{ block(""post"") }}
Output:
content
content
currentEachOutput
The currentEachOutput function simplifies retrieving outputs of sibling tasks within an EachSequential task.
Example:
yaml
tasks:
  - id: each
    type: io.kestra.plugin.core.flow.EachSequential
    tasks:
      - id: first
        type: io.kestra.plugin.core.debug.Return
        format: ""{{task.id}}""
      - id: second
        type: io.kestra.plugin.core.debug.Return
        format: ""{{ currentEachOutput(outputs.first).value }}""
    value: [""value 1"", ""value 2"", ""value 3""]
This eliminates the need for manual handling of taskrun.value or parents.
fromJson
The fromJson function parses a JSON string into an object, enabling property access.
Examples:
twig
{{ fromJson('[1, 2, 3]')[0] }}
# output: 1
{{ fromJson('{""foo"": [666, 1, 2]}').foo[0] }}
# output: 666
yaml
The yaml function parses a YAML string into an object.
Example:
twig
{{ yaml('foo: [666, 1, 2]').foo[0] }}
# output: 666
max
The max function returns the largest of its arguments.
Example:
twig
{{ max(20, 80, user.age) }}
# output: the largest value
min
The min function returns the smallest of its arguments.
Example:
twig
{{ min(20, 80, user.age) }}
# output: the smallest value
now
The now function generates the current datetime. Formatting options are the same as the date filter.
Example:
twig
{{ now() }}
{{ now(timeZone=""Europe/Paris"") }}
parent
The parent function renders the parent block's content within a child block.
Example:
Parent template (parent.peb):
twig
{% block ""content"" %}parent content{% endblock %}
Child template (child.peb):
twig
{% extends ""parent.peb"" %}
{% block ""content"" %}
child content
{{ parent() }}
{% endblock %}
Output:
child content
parent content
range
The range function generates a list of numbers.
Examples:
twig
{% for i in range(0, 3) %}
    {{ i }},
{% endfor %}
# output: 0, 1, 2, 3
{% for i in range(0, 6, 2) %}
    {{ i }},
{% endfor %}
# output: 0, 2, 4, 6
printContext
The printContext function is used for debugging by printing all defined variables.
Example:
twig
{{ printContext() }}
Output:
json
{""outputs"": {...}, ""execution"": {...}, ...}
read
The read function retrieves the contents of a file from internal storage or namespace files.
Examples:
twig
{{ read('subdir/file.txt') }}
{{ read(outputs.someTask.uri) }}
render
The render function enables recursive rendering of expressions. By default, Kestra only renders expressions once.
Example:
twig
{{ render(""{{ trigger.date ?? execution.startDate | date('yyyy-MM-dd') }}"") }}
Arguments:
recursive: defaults to true. Set to false for one-time rendering.
renderOnce
Equivalent to render(expression, recursive=false). It simplifies rendering without recursion.
secret
The secret function retrieves secrets stored in Kestra's secret backend.
Example:
yaml
tasks:
  - id: github_secret
    type: io.kestra.plugin.core.log.Log
    message: ""{{ secret('GITHUB_ACCESS_TOKEN') }}""
Example with Functions
yaml
id: function_example
namespace: company.team
tasks:
  - id: max_example
    type: io.kestra.plugin.core.log.Log
    message: ""Maximum value: {{ max(5, 10, 15) }}""
  - id: render_example
    type: io.kestra.plugin.core.log.Log
    message: ""{{ render('{{ trigger.date ?? execution.startDate | date(""yyyy-MM-dd"") }}') }}""
  - id: secret_example
    type: io.kestra.plugin.core.log.Log
    message: ""{{ secret('API_KEY') }}""
    allowFailure: true
Operators
Operators enable logical, arithmetic, and comparison operations within templated expressions. They are essential for dynamic content manipulation.
Comparison Operators
Supported comparison operators: ==, !=, <, >, <=, >=.
==: Uses Java.util.Objects.equals(a, b) for null-safe comparisons. Alias: equals.
Example:
twig
{% if user.name equals ""Mitchell"" %}
    ...
{% endif %}
concat
The ~ operator concatenates two or more strings.
Example:
twig
{{ ""apple"" ~ ""pear"" ~ ""banana"" }}
# results in: 'applepearbanana'
contains
The contains operator checks if an item exists within a collection, map, or array.
Examples:
twig
{% if [""apple"", ""pear"", ""banana""] contains ""apple"" %}
    ...
{% endif %}
For maps, it checks for an existing key:
twig
{% if {""apple"":""red"", ""banana"":""yellow""} contains ""banana"" %}
    ...
{% endif %}
To check multiple items:
twig
{% if [""apple"", ""pear"", ""banana"", ""peach""] contains [""apple"", ""peach""] %}
    ...
{% endif %}
is
The is operator tests variables, returning a boolean.
Examples:
twig
{% if 2 is even %}
    ...
{% endif %}
Negation with not:
twig
{% if 3 is not even %}
    ...
{% endif %}
logic
Combine boolean expressions using and and or. Use not for negation.
Examples:
twig
{% if 2 is even and 3 is odd %}
    ...
{% endif %}
{% if 3 is not even %}
    ...
{% endif %}
Group expressions with parentheses for precedence:
twig
{% if (3 is not even) and (2 is odd or 3 is even) %}
    ...
{% endif %}
math
Perform arithmetic operations with standard math operators. Follow the order of operations.
Example:
twig
{{ 2 + 2 / (10 % 3) * (8 - 1) }}
Supported operators:
+: Addition
-: Subtraction
/: Division (returns a float)
%: Modulus
*: Multiplication
not
Use not with is to negate a test.
Example:
twig
{% if 3 is not even %}
    ...
{% endif %}
null-coalescing
The null-coalescing operator (??) returns the first defined, non-null value. Use ??? to return the right-hand side only if the left-hand side is undefined.
Examples:
twig
{% set baz = ""baz"" %}
{{ foo ?? bar ?? baz }}
# results in: 'baz'
{{ foo ?? bar ?? raise }}
# raises an exception if all variables are undefined
For details, see the Handling null and undefined values guide.
ternary operator
The ternary operator (? :) evaluates conditions succinctly.
Example:
twig
{{ foo == null ? bar : baz }}
Tag
Tags in Pebble control the template's flow and logic. They are enclosed in {% %}.
block
The block tag defines reusable template blocks.
Example:
twig
{% block header %}
    Introduction
{% endblock %}
To reuse a block, use the block function:
twig
{{ block(""header"") }}
filter
The filter tag applies a filter to a block of content.
Example:
twig
{% filter upper %}
    hello
{% endfilter %}
Output:
HELLO
Filters can be chained:
twig
{% filter upper | title %}
    hello
{% endfilter %}
Output:
Hello
for
The for tag iterates over arrays, maps, or any java.lang.Iterable.
Example:
twig
{% for user in users %}
    {{ user.name }} lives in {{ user.city }}.
{% endfor %}
Special variables available within a loop:
loop.index: zero-based index
loop.length: total size of the iterable
loop.first: true if it's the first iteration
loop.last: true if it's the last iteration
loop.revindex: iterations remaining until the end
twig
{% for user in users %}
    {{ loop.index }}: {{ user.id }}
{% endfor %}
To handle empty collections, use the else tag:
twig
{% for user in users %}
    {{ user.name }}
{% else %}
    No users found.
{% endfor %}
For maps:
twig
{% for entry in map %}
    {{ entry.key }}: {{ entry.value }}
{% endfor %}
if
The if tag evaluates conditional logic.
Example:
twig
{% if users is empty %}
    No users available.
{% elseif users.length == 1 %}
    One user found.
{% else %}
    Multiple users found.
{% endif %}
if expressions can include:
boolean values
is operator (e.g., is empty, is not empty)
macro
The macro tag defines reusable blocks of content.
Example:
twig
{% macro input(type=""text"", name, value) %}
    <input type=""{{ type }}"" name=""{{ name }}"" value=""{{ value }}"">
{% endmacro %}
{{ input(name=""username"") }}
Output:
html
<input type=""text"" name=""username"" value="""">
Passing global context:
twig
{% set foo = 'bar' %}
{{ test(_context) }}
{% macro test(_context) %}
    {{ _context.foo }}
{% endmacro %}
Output:
bar
raw
The raw tag prevents Pebble from parsing its content.
Example:
twig
{% raw %}
    {{ user.name }}
{% endraw %}
Output:
{{ user.name }}
set
The set tag defines a variable in the template context.
Example:
twig
{% set header = ""Welcome Page"" %}
{{ header }}
Output:
Welcome Page
Test
Tests in Pebble are used to perform logical checks, such as determining if a variable is defined, empty, or of a specific type.
defined
Checks if a variable is defined.
twig
{% if missing is not defined %}
    ...
{% endif %}
empty
Checks if a variable is empty. A variable is considered empty if it is:
null
an empty string
an empty collection
an empty map
twig
{% if user.email is empty %}
    ...
{% endif %}
even
Checks if an integer is even.
twig
{% if 2 is even %}
    ...
{% endif %}
iterable
Checks if a variable implements java.lang.Iterable.
twig
{% if users is iterable %}
    {% for user in users %}
        ...
    {% endfor %}
{% endif %}
json
Checks if a variable is a valid JSON string.
twig
{% if '{""test"": 1}' is json %}
    ...
{% endif %}
map
Checks if a variable is an instance of a map.
twig
{% if {""apple"":""red"", ""banana"":""yellow""} is map %}
    ...
{% endif %}
null
Checks if a variable is null.
twig
{% if user.email is null %}
    ...
{% endif %}
odd
Checks if an integer is odd.
twig
{% if 3 is odd %}
    ...
{% endif %}
Was this page helpful?
Yes
No
Docs
Configuration
Docs
API Reference""""""",9904,40327,kestra
https://kestra.io/docs/api-reference,"""""""DocsAPI Reference
API Reference
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Cloud & Enterprise Edition API
Open Source API
Was this page helpful?
Yes
No
Docs
Expressions
Api Reference
Cloud & Enterprise Edition API""""""",58,245,kestra
https://kestra.io/docs/api-reference/enterprise,"""""""DocsAPI ReferenceCloud & Enterprise Edition API
Cloud & Enterprise Edition API
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Available on:
Enterprise Edition
API Reference of Kestra Cloud & Enterprise.
Was this page helpful?
Yes
No
Docs
API Reference
Api Reference
Open Source API""""""",67,294,kestra
https://kestra.io/docs/api-reference/open-source,"""""""DocsAPI ReferenceOpen Source API
Open Source API
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
API Reference of the Open-Source edition of Kestra.
Was this page helpful?
Yes
No
Api Reference
Cloud & Enterprise Edition API
Docs
Terraform Provider""""""",64,259,kestra
https://kestra.io/docs/terraform,"""""""DocsTerraform Provider
Terraform Provider
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manage resources and their underlying infrastructure with our official Terraform provider to facilitate CI/CD and infrastructure management for your Kestra resources.
Resources
kestra_binding
kestra_flow
kestra_group
kestra_kv
kestra_namespace
kestra_namespace_file
kestra_namespace_secret
kestra_role
kestra_template
kestra_tenant
kestra_user
kestra_user_password
Data Sources
kestra_binding
kestra_flow
kestra_group
kestra_kv
kestra_namespace
kestra_namespace_file
kestra_role
kestra_template
kestra_tenant
kestra_user
Was this page helpful?
Yes
No
Api Reference
Open Source API
Terraform
Data Sources""""""",179,720,kestra
https://kestra.io/docs/terraform/data-sources/binding,"""""""DocsTerraform ProviderData Sourceskestra_binding
kestra_binding
Table of Contents
Example Usage
Schema
Required
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing Kestra binding
Example Usage
hcl
data ""kestra_binding"" ""example"" {
  binding_id = ""65DsawPfiJPkTkZJIPX6jQ""
}
Schema
Required
binding_id (String) The binding id.
Read-Only
external_id (String) The binding external id.
id (String) The ID of this resource.
namespace (String) The linked namespace.
role_id (String) The role id.
tenant_id (String) The tenant id.
type (String) The binding type.
Was this page helpful?
Yes
No
Terraform
Data Sources
Data Sources
kestra_flow""""""",192,711,kestra
https://kestra.io/docs/terraform/data-sources/flow,"""""""DocsTerraform ProviderData Sourceskestra_flow
kestra_flow
Table of Contents
Example Usage
Schema
Required
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing Kestra Flow
Example Usage
hcl
data ""kestra_flow"" ""example"" {
  namespace = ""company.team""
  id        = ""my-flow""
}
Schema
Required
flow_id (String) The flow id.
namespace (String) The namespace.
Read-Only
content (String) The flow content as yaml.
id (String) The ID of this resource.
revision (Number) The flow revision.
tenant_id (String) The tenant id.
Was this page helpful?
Yes
No
Data Sources
kestra_binding
Data Sources
kestra_group""""""",176,677,kestra
https://kestra.io/docs/terraform/data-sources/group,"""""""DocsTerraform ProviderData Sourceskestra_group
kestra_group
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing Kestra Group.
Example Usage
hcl
data ""kestra_group"" ""example"" {
  group_id = ""68xAawPfiJPkTkZJIPX6jQ""
}
Schema
Required
group_id (String) The group.
Optional
namespace (String) The linked namespace.
Read-Only
description (String) The group description.
id (String) The ID of this resource.
name (String) The group name.
tenant_id (String) The tenant id.
Was this page helpful?
Yes
No
Data Sources
kestra_flow
Data Sources
kestra_kv""""""",184,679,kestra
https://kestra.io/docs/terraform/data-sources/kv,"""""""DocsTerraform ProviderData Sourceskestra_kv
kestra_kv
Table of Contents
Example Usage
Schema
Required
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing key-value Pair
Example Usage
hcl
data ""kestra_kv"" ""new"" {
  namespace = ""company.team""
  key       = ""my_key""
}
Schema
Required
namespace (String) The namespace.
key (String) The key of the KV pair.
Was this page helpful?
Yes
No
Data Sources
kestra_group
Data Sources
kestra_namespace""""""",132,507,kestra
https://kestra.io/docs/terraform/data-sources/namespace,"""""""DocsTerraform ProviderData Sourceskestra_namespace
kestra_namespace
Table of Contents
Example Usage
Schema
Required
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing Kestra Namespace.
Example Usage
hcl
data ""kestra_namespace"" ""example"" {
  namespace_id = ""company.team""
}
Schema
Required
namespace_id (String) The namespace.
Read-Only
description (String) The namespace friendly description.
id (String) The ID of this resource.
plugin_defaults (String) The namespace plugin defaults.
tenant_id (String) The tenant id.
variables (String) The namespace variables.
Was this page helpful?
Yes
No
Data Sources
kestra_kv
Data Sources
kestra_namespace_file""""""",171,731,kestra
https://kestra.io/docs/terraform/data-sources/namespace_file,"""""""DocsTerraform ProviderData Sourceskestra_namespace_file
kestra_namespace_file
Table of Contents
Example Usage
Schema
Required
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing Namespace File
Example Usage
hcl
data ""kestra_namespace_file"" ""example"" {
  namespace = ""company.team""
  filename  = ""myscript.py""
  content   = file(""myscript.py"")
}
Schema
Required
filename (String) The filename to the namespace file.
namespace (String) The namespace of the namespace file resource.
Read-Only
content (String) Content to store in the file, expected to be a UTF-8 encoded string.
id (String) The ID of this resource.
tenant_id (String) The tenant id.
Was this page helpful?
Yes
No
Data Sources
kestra_namespace
Data Sources
kestra_role""""""",198,810,kestra
https://kestra.io/docs/terraform/data-sources/role,"""""""DocsTerraform ProviderData Sourceskestra_role
kestra_role
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Nested Schema for permissions
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing Kestra Role.
Example Usage
hcl
data ""kestra_role"" ""example"" {
  role_id = ""3kcvnr27ZcdHXD2AUvIe7z""
}
Schema
Required
role_id (String) The role.
Optional
namespace (String) The linked namespace.
is_default (Boolean) The role is the default one at user creation. Only one role can be default. Latest create/update to true will be keep as default.
Read-Only
description (String) The role description.
id (String) The ID of this resource.
name (String) The role name.
permissions (Set of Object) The role permissions. (see below for nested schema)
tenant_id (String) The tenant id.
Nested Schema for permissions
Read-Only:
permissions (List of String)
type (String)
Was this page helpful?
Yes
No
Data Sources
kestra_namespace_file
Data Sources
kestra_template""""""",260,1031,kestra
https://kestra.io/docs/terraform/data-sources/template,"""""""DocsTerraform ProviderData Sourceskestra_template
kestra_template
Table of Contents
Example Usage
Schema
Required
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing Kestra Template
Example Usage
hcl
data ""kestra_template"" ""example"" {
  namespace_ = ""company.team""
  id         = ""my-template""
}
Schema
Required
namespace (String) The namespace.
template_id (String) The template id.
Read-Only
content (String) The template content as yaml.
id (String) The ID of this resource.
tenant_id (String) The tenant id.
Was this page helpful?
Yes
No
Data Sources
kestra_role
Data Sources
kestra_tenant""""""",170,672,kestra
https://kestra.io/docs/terraform/data-sources/tenant,"""""""DocsTerraform ProviderData Sourceskestra_tenant
kestra_tenant
Table of Contents
Example Usage
Schema
Required
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing Kestra Tenant.
Example Usage
hcl
data ""kestra_tenant"" ""example"" {
  tenant_id = ""my-tenant""
}
Schema
Required
tenant_id (String) The tenant id.
Read-Only
id (String) The ID of this resource.
name (String) The tenant name.
Was this page helpful?
Yes
No
Data Sources
kestra_template
Data Sources
kestra_user""""""",147,546,kestra
https://kestra.io/docs/terraform/data-sources/user,"""""""DocsTerraform ProviderData Sourceskestra_user
kestra_user
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Use this data source to access information about an existing Kestra User.
Example Usage
hcl
data ""kestra_user"" ""example"" {
  user_id = ""68xAawPfiJPkTkZJIPX6jQ""
}
Schema
Required
user_id (String) The user.
Optional
namespace (String) The linked namespace.
Read-Only
description (String) The user description.
email (String) The user email.
first_name (String) The user first name.
groups (List of String) The user global roles in yaml string.
id (String) The ID of this resource.
last_name (String) The user last name.
username (String) The user name.
Was this page helpful?
Yes
No
Data Sources
kestra_tenant
Terraform
Guides""""""",218,809,kestra
https://kestra.io/docs/terraform/guides/configurations,"""""""DocsTerraform ProviderGuidesProvider configurations
Provider configurations
Table of Contents
Example Usage
Schema
Optional
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Example Usage
hcl
provider ""kestra"" {
  # mandatory, the Kestra webserver/standalone URL
  url = ""http://localhost:8080""
  # optional basic auth username
  username = ""john""
  # optional basic auth password
  password = ""my-password""
  # optional jwt token (EE)
  jwt = ""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6Iktlc3RyYS5pbyIsImlhdCI6MTUxNjIzOTAyMn0.hm2VKztDJP7CUsI69Th6Y5NLEQrXx7OErLXay55GD5U""
  # optional tenant id (EE)
  tenant_id = ""the-tenant-id""
  # optional extra headers
  extra_headers = {
    x-pipeline = ""*****""
    authorization = ""Bearer *****""
  }
}
Schema
Optional
api_token (String, Sensitive) The API token (EE)
extra_headers (Map of String) Extra headers to add to every request
jwt (String, Sensitive) The JWT token (EE)
keep_original_source (Boolean) Keep original source code, keeping comment and indentation.
password (String, Sensitive) The BasicAuth password
tenant_id (String) The tenant id (EE)
url (String) The endpoint url without trailing slash
username (String) The BasicAuth username
Was this page helpful?
Yes
No
Terraform
Guides
Guides
Working with Yaml""""""",401,1306,kestra
https://kestra.io/docs/terraform/guides/working-with-yaml,"""""""DocsTerraform ProviderGuidesWorking with Yaml
Working with Yaml
Table of Contents
Simple multiline string example
External files
External files with template
Dealing with included yaml string
Include full yaml part
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Most of Kestra resource need to be described as Yaml like kestra_flow & kestra_template.
We have chosen to use a full yaml in terraform definition since the structure is recursive and dynamic, so it can't be described using terraform internal schema.
There is 2 ways (for flow) to handle yaml:
use keep_original_source = true method: the default one, the raw yaml will be send and save in Kestra.
use keep_original_source = false method: the yaml will be encoded in json before behind to the server, so comment and indent will be handle by the server
Those properties have to be set at the provider level.
Take care with keep_original_source = false that this terraform provider is not aware of task & plugins. It can't know default values of properties, and most of conversion logic done by Kestra Server. If you see diff that is always present (even just after apply), your flow on terraform must have a minor difference return from the server. In this case, copy the source from Kestra UI in your terraform files to avoid these difference.
There is in terraform a lot of function that allow to work properly with this yaml content :
Simple multiline string example
You can use simple terraform multiline string with Heredoc String :
hcl
resource ""kestra_flow"" ""example"" {
  namespace = ""company.team""
  flow_id = ""my-flow""
  content = <<EOT
inputs:
  - name: my-value
    type: STRING
    required: true
tasks:
  - id: t2
    type: io.kestra.core.tasks.log.Log
    message: first {{task.id}}
    level: TRACE
EOT
}
External files
Better will be to use a file function. Just create a file .yml near your terraform .tf and include the whole file in your resource:
yaml
inputs:
  - name: my-value
    type: STRING
    required: true
tasks:
  - id: t2
    type: io.kestra.core.tasks.log.Log
    message: first {{task.id}}
    level: TRACE
EOT
hcl
resource ""kestra_flow"" ""example"" {
  namespace = ""company.team""
  flow_id = ""my-flow""
  content = file(""my-flow.yml"")
}
External files with template
Even better will be to use a templatefile function that will allow more complex flows to be more readable. You can include some external external and this one can also include other file.
Take care about the indent functon that need to fit your actual flow ident. Terraform don't know anything about your yaml (it's a simple string), so you need to handle properly the indent count by yourself using the indent function
Dealing with included yaml string
Imagine a flow that will query an external database. Embedding the full query can lead to very long flow definition. In the case you can use templatefile to allow inclusion of an external files from the yaml.
Create a sql file:
sql
SELECT *
FROM ....
Create the yaml file for the flow:
yaml
tasks:
  - id: ""query""
    type: ""io.kestra.plugin.jdbc.mysql.Query""
    url: jdbc:postgresql://127.0.0.1:56982/
    username: postgres
    password: pg_passwd
    sql: |
      ${indent(6, file(""my-query.sql""))}
    fetchOne: true
And finally create the resource invoking the templatefile:
hcl
resource ""kestra_flow"" ""example"" {
  namespace = ""company.team""
  flow_id = ""my-flow""
  content = templatefile(""my-flow.yaml"", {})
}
The tf files will required the yaml files that will require the sql files and the final flow will be:
yaml
tasks:
  - id: ""query""
    type: ""io.kestra.plugin.jdbc.mysql.Query""
    url: jdbc:postgresql://127.0.0.1:56982/
    username: postgres
    password: pg_passwd
    sql: |
      SELECT *
      FROM ....
    fetchOne: true
Include full yaml part
By the same way, you can also include a full yaml specs inside another one.
Create 2 yaml files:
yaml
id: t1
type: io.kestra.core.tasks.log.Log
message: first {{task.id}}
level: TRACE
yaml
id: t2
type: io.kestra.core.tasks.log.Log
message: second {{task.id}}
level: TRACE
Create the yaml file for the flow:
yaml
tasks:
  - ${indent(4, file(""t1.yml""))}
  - ${indent(4, file(""t2.yml""))}
Was this page helpful?
Yes
No
Guides
Provider configurations
Terraform
Resources""""""",1069,4273,kestra
https://kestra.io/docs/terraform/resources/binding,"""""""DocsTerraform ProviderResourceskestra_binding
kestra_binding
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Import
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra Binding.
Example Usage
hcl
resource ""kestra_binding"" ""example"" {
  type        = ""GROUP""
  external_id = ""68xAawPfiJPkTkZJIPX6jQ""
  role_id     = ""3kcvnr27ZcdHXD2AUvIe7z""
  namespace   = ""company.team""
}
Schema
Required
external_id (String) The binding external id.
role_id (String) The role id.
type (String) The binding type.
Optional
namespace (String) The linked namespace.
Read-Only
id (String) The ID of this resource.
Import
Import is supported using the following syntax:
shell
terraform import kestra_binding.example {{binding_id}}
Was this page helpful?
Yes
No
Terraform
Resources
Resources
kestra_flow""""""",230,824,kestra
https://kestra.io/docs/terraform/resources/flow,"""""""DocsTerraform ProviderResourceskestra_flow
kestra_flow
Table of Contents
Example Usage
Schema
Required
Read-Only
Import
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra Flow.
Example Usage
hcl
resource ""kestra_flow"" ""example"" {
  namespace = ""company.team""
  flow_id   = ""my-flow""
  content   = <<EOT
inputs:
  - name: my-value
    type: STRING
variables:
  first: ""1""
tasks:
  - id: t2
    type: io.kestra.core.tasks.log.Log
    message: first {{task.id}}
    level: TRACE
pluginDefaults:
  - type: io.kestra.core.tasks.log.Log
    values:
      message: third {{flow.id}}
EOT
}
Schema
Required
content (String) The flow full content in yaml string.
flow_id (String) The flow id.
namespace (String) The flow namespace.
Read-Only
id (String) The ID of this resource.
revision (Number) The flow revision.
tenant_id (String) The tenant id.
Import
Import is supported using the following syntax:
shell
terraform import kestra_flow.example {{namespace}}/{{flow_id}}
Was this page helpful?
Yes
No
Resources
kestra_binding
Resources
kestra_group""""""",289,1067,kestra
https://kestra.io/docs/terraform/resources/group,"""""""DocsTerraform ProviderResourceskestra_group
kestra_group
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Import
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra Group.
Example Usage
hcl
resource ""kestra_group"" ""example"" {
  namespace   = ""company.team""
  name        = ""Friendly name""
  description = ""Friendly description""
}
Schema
Required
name (String) The group name.
Optional
description (String) The group description.
namespace (String) The linked namespace.
Read-Only
id (String) The ID of this resource.
tenant_id (String) The tenant id.
Import
Import is supported using the following syntax:
shell
terraform import kestra_group.example {{group_id}}
Was this page helpful?
Yes
No
Resources
kestra_flow
Resources
kestra_kv""""""",192,777,kestra
https://kestra.io/docs/terraform/resources/kv,"""""""DocsTerraform ProviderResourceskestra_kv
kestra_kv
Table of Contents
Example Usage
Schema
Required
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra KV Pair.
Example Usage
hcl
resource ""kestra_kv"" ""new"" {
  namespace = ""company.team""
  key       = ""my_key""
  value     = ""Hello World""
  type      = ""STRING""
}
Schema
Required
namespace (String) The flow namespace.
key (String) The key of the KV pair.
value (Multiple) the value of the KV pair.
type (String) the type of the value. Can be a string, number, boolean, datetime, date, duration, or JSON.
Was this page helpful?
Yes
No
Resources
kestra_group
Resources
kestra_namespace""""""",179,657,kestra
https://kestra.io/docs/terraform/resources/namespace,"""""""DocsTerraform ProviderResourceskestra_namespace
kestra_namespace
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Import
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra Namespace.
Example Usage
hcl
resource ""kestra_namespace"" ""example"" {
  namespace_id  = ""company.team""
  description   = ""Friendly description""
  variables     = <<EOT
k1: 1
k2:
    v1: 1
EOT
  plugin_defaults = <<EOT
- type: io.kestra.core.tasks.log.Log
  values:
    message: first {{flow.id}}
- type: io.kestra.core.tasks.debugs.Return
  values:
    format: first {{flow.id}}
EOT
}
Schema
Required
namespace_id (String) The namespace.
Optional
description (String) The namespace friendly description.
plugin_defaults (String) The namespace plugin defaults in yaml string.
variables (String) The namespace variables in yaml string.
Read-Only
id (String) The ID of this resource.
tenant_id (String) The tenant id.
Import
Import is supported using the following syntax:
shell
terraform import kestra_namespace.example {{namespace}}
Was this page helpful?
Yes
No
Resources
kestra_kv
Resources
kestra_namespace_file""""""",286,1128,kestra
https://kestra.io/docs/terraform/resources/namespace_file,"""""""DocsTerraform ProviderResourceskestra_namespace_file
kestra_namespace_file
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Import
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra Namespace File.
Example Usage
hcl
resource ""kestra_namespace_file"" ""example"" {
  namespace = ""company.team""
  filename  = ""/path/my-file.sh""
  content   = <<EOT
#!/bin/bash
echo ""Hello World""
EOT
}
resource ""kestra_namespace_file"" ""withsource"" {
  namespace = ""company.team""
  filename  = ""/path/my-file.sh""
  content   = file(""./kestra/file.sh"")
}
Schema
Required
filename (String) The path to the namespace file that will be created. Missing parent directories will be created. If the file already exists, it will be overridden with the given content.
namespace (String) The namespace of the namespace file resource.
Optional
content (String) Content to store in the file, expected to be a UTF-8 encoded string.
Read-Only
id (String) The ID of this resource.
tenant_id (String) The tenant id.
Import
Import is supported using the following syntax:
shell
terraform import kestra_namespace_file.example {{namespace}}/{{filename}}
Was this page helpful?
Yes
No
Resources
kestra_namespace
Resources
kestra_namespace_secret""""""",301,1246,kestra
https://kestra.io/docs/terraform/resources/namespace_secret,"""""""DocsTerraform ProviderResourceskestra_namespace_secret
kestra_namespace_secret
Table of Contents
Example Usage
Schema
Required
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra Namespace Secret.
Example Usage
hcl
resource ""kestra_namespace_secret"" ""example"" {
  namespace    = ""company.team""
  secret_key   = ""MY_KEY""
  secret_value = ""my-r34l-53cr37""
}
Schema
Required
namespace (String) The namespace.
secret_key (String) The namespace secrey key.
secret_value (String, Sensitive) The namespace secrey value.
Read-Only
id (String) The ID of this resource.
tenant_id (String) The tenant id.
Was this page helpful?
Yes
No
Resources
kestra_namespace_file
Resources
kestra_role""""""",185,712,kestra
https://kestra.io/docs/terraform/resources/role,"""""""DocsTerraform ProviderResourceskestra_role
kestra_role
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Nested Schema for permissions
Import
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra Role.
Example Usage
hcl
resource ""kestra_role"" ""example"" {
  namespace   = ""company.team""
  name        = ""Friendly name""
  description = ""Friendly description""
  permissions {
    type        = ""FLOW""
    permissions = [""READ"", ""UPDATE""]
  }
  permissions {
    type        = ""TEMPLATE""
    permissions = [""READ"", ""UPDATE""]
  }
}
Schema
Required
name (String) The role name.
Optional
description (String) The role description.
namespace (String) The linked namespace.
permissions (Block Set) The role permissions. (see below for nested schema)
Read-Only
id (String) The ID of this resource.
tenant_id (String) The tenant id.
Nested Schema for permissions
Required:
permissions (List of String) The permissions for this type.
type (String) The type of permission.
Import
Import is supported using the following syntax:
shell
terraform import kestra_role.example {{role_id}}
Was this page helpful?
Yes
No
Resources
kestra_namespace_secret
Resources
kestra_template""""""",284,1199,kestra
https://kestra.io/docs/terraform/resources/template,"""""""DocsTerraform ProviderResourceskestra_template
kestra_template
Table of Contents
Example Usage
Schema
Required
Read-Only
Import
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra Template.
Example Usage
hcl
resource ""kestra_template"" ""example"" {
  namespace   = ""company.team""
  template_id = ""my-template""
  content     = <<EOT
tasks:
  - id: t2
    type: io.kestra.core.tasks.log.Log
    message: first {{task.id}}
    level: TRACE
EOT
}
Schema
Required
content (String) The template full content in yaml string.
namespace (String) The template namespace.
template_id (String) The template id.
Read-Only
id (String) The ID of this resource.
tenant_id (String) The tenant id.
Import
Import is supported using the following syntax:
shell
terraform import kestra_template.example {{namespace}}/{{template_id}}
Was this page helpful?
Yes
No
Resources
kestra_role
Resources
kestra_tenant""""""",234,910,kestra
https://kestra.io/docs/terraform/resources/tenant,"""""""DocsTerraform ProviderResourceskestra_tenant
kestra_tenant
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Import
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra Tenant.
Example Usage
hcl
resource ""kestra_tenant"" ""example"" {
  tenant_id = ""my-tenant""
  name      = ""My Tenant""
}
Schema
Required
tenant_id (String) The tenant id.
Optional
name (String) The tenant name.
Read-Only
id (String) The ID of this resource.
Import
Import is supported using the following syntax:
shell
terraform import kestra_tenant.example {{tenant_id}}
Was this page helpful?
Yes
No
Resources
kestra_template
Resources
kestra_user""""""",174,655,kestra
https://kestra.io/docs/terraform/resources/user,"""""""DocsTerraform ProviderResourceskestra_user
kestra_user
Table of Contents
Example Usage
Schema
Required
Optional
Read-Only
Import
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra User.
Example Usage
hcl
resource ""kestra_user"" ""example"" {
  username    = ""my-username""
  namespace   = ""company.team""
  description = ""Friendly description""
  first_name  = ""John""
  last_name   = ""Doe""
  email       = ""john@doe.com""
  groups      = [""4by6NvSLcPXFhCj8nwbZOM""]
}
Schema
Required
username (String) The user name.
Optional
description (String) The user description.
email (String) The user email.
first_name (String) The user first name.
groups (List of String) The user groups id.
last_name (String) The user last name.
namespace (String) The linked namespace.
Read-Only
id (String) The ID of this resource.
Import
Import is supported using the following syntax:
shell
terraform import kestra_user.example {{user_id}}
Was this page helpful?
Yes
No
Resources
kestra_tenant
Resources
kestra_user_password""""""",276,1024,kestra
https://kestra.io/docs/terraform/resources/user_password,"""""""DocsTerraform ProviderResourceskestra_user_password
kestra_user_password
Table of Contents
Example Usage
Schema
Required
Read-Only
Contribute
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Manages a Kestra User Basic Auth Password.
Example Usage
hcl
resource ""kestra_user_password"" ""example"" {
  user_id  = ""4by6NvSLcPXFhCj8nwbZOM""
  password = ""my-random-password""
}
Schema
Required
password (String, Sensitive) The user password.
user_id (String) The user id.
Read-Only
id (String) The ID of this resource.
Was this page helpful?
Yes
No
Resources
kestra_user
Docs
Server CLI""""""",165,578,kestra
https://kestra.io/docs/server-cli,"""""""DocsServer CLI
Server CLI
Table of Contents
Separate server components
Executor
Indexer
Scheduler
Worker
Webserver
Kestra standalone, all server components in one process
Kestra local, development server with no dependencies
Kestra with server components in different services
Options for all server commands
Log Level
Internal Log
Configuration Files
Plugins directory
Server port
Contribute
Edit this page
Join us on Slack
YouTube
GitHub
Twitter
LinkedIn
Reference for server commands available in Kestra.
Kestra leverages five different server components. The kestra server command allows to start them individually, or run an all-inclusive standalone server.
Separate server components
Executor
./kestra server executor
Options:
--skip-executions: the list of execution identifiers to skip. Use it only for troubleshooting e.g. when an execution cannot be processed by Kestra.
Indexer
./kestra server indexer
Scheduler
./kestra server scheduler
Worker
./kestra server worker
Options:
-t or --thread: the number of threads that can handle tasks at the same time. By default, the worker will start 2 threads per CPU core available.
-g or --worker-group: the key of the worker group if using Worker Group (EE).
Webserver
./kestra server webserver
Kestra standalone, all server components in one process
./kestra server standalone
This server is a special server, since it will contain all the server components in one JVM. This works well for development or small-sized environments.
Options:
-f or --flow-path: the path to a directory with YAML flow files. These files will be loaded to the repository at startup.
--worker-thread: the number of worker threads. By default, the embedded worker will start 3 threads or a single thread per CPU core when more than 3 CPU cores are available.
--skip-executions: the list of execution identifiers to skip. Use it only for troubleshooting e.g. when an execution cannot be processed by Kestra.
Kestra local, development server with no dependencies
./kestra server local
This server is a local development server. It will contain all server components in one JVM, and use a local database (H2), and a local storage - perfect to start a development server. Data will be saved in the data directory within the current working directory.
Options:
-f or --flow-path: the path to a directory with YAML flow files. These files will be loaded to the repository at startup.
--worker-thread: the number of worker threads. By default, the embedded worker will start 3 threads or a single thread per CPU core when more than 3 CPU cores are available.
Kestra with server components in different services
Server components can run independently from each other. Each of them communicate through the database.
Here is a example Docker Compose configuration file running Kestra services with replicas on the Postgre database backend.
Docker Compose Example
In production you might run a similar pattern either by:
Runing Kestra services on dedicated machines. For examples, running the webserver, the scheduler and the executor on one VM and running one or more workers on other instances.
Using Kubernetes and Helm charts. Read more about how to set these up in the documentation.
Options for all server commands
Log Level
Log level can be changed with two options:
-l or --log-level: possible values: [TRACE, DEBUG, INFO, WARN, ERROR], default: INFO
-v or --verbose: for DEBUG, -vv for TRACE
These options affect global log levels for all flows only.
Internal Log
--internal-log: Kestra hides internal logs by default. Use this option to enable these logs.
This option enables logs of very high verbosity.
Configuration Files
-c or --config: You can change the location of Kestra configuration files, the default is ~/.kestra/config.yml.
Plugins directory
-p or --plugins: Path to the plugins directory. The default is the plugins directory located in the same directory as the Kestra executable.
Server port
--port: The server port, the default is 8080.
Was this page helpful?
Yes
No
Resources
kestra_user_password""""""",874,4045,kestra
